This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-31T11:06:50.382Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

================================================================
Directory Structure
================================================================
2-crawl_docs_sequential.py
3-crawl_docs_FAST.py
crawl_with_saving.py
crawled_docs/advanced_advanced-features.md
crawled_docs/advanced_crawl-dispatcher.md
crawled_docs/advanced_file-downloading.md
crawled_docs/advanced_hooks-auth.md
crawled_docs/advanced_identity-based-crawling.md
crawled_docs/advanced_lazy-loading.md
crawled_docs/advanced_multi-url-crawling.md
crawled_docs/advanced_proxy-security.md
crawled_docs/advanced_session-management.md
crawled_docs/advanced_ssl-certificate.md
crawled_docs/agents.md
crawled_docs/api_agent.md
crawled_docs/api_arun_many.md
crawled_docs/api_arun.md
crawled_docs/api_async-webcrawler.md
crawled_docs/api_crawl-result.md
crawled_docs/api_exceptions.md
crawled_docs/api_format_as_xml.md
crawled_docs/api_messages.md
crawled_docs/api_models_anthropic.md
crawled_docs/api_models_base.md
crawled_docs/api_models_cohere.md
crawled_docs/api_models_function.md
crawled_docs/api_models_gemini.md
crawled_docs/api_models_groq.md
crawled_docs/api_models_mistral.md
crawled_docs/api_models_openai.md
crawled_docs/api_models_test.md
crawled_docs/api_models_vertexai.md
crawled_docs/api_parameters.md
crawled_docs/api_pydantic_graph_exceptions.md
crawled_docs/api_pydantic_graph_graph.md
crawled_docs/api_pydantic_graph_mermaid.md
crawled_docs/api_pydantic_graph_nodes.md
crawled_docs/api_pydantic_graph_state.md
crawled_docs/api_result.md
crawled_docs/api_settings.md
crawled_docs/api_tools.md
crawled_docs/api_usage.md
crawled_docs/contributing.md
crawled_docs/dependencies.md
crawled_docs/examples_bank-support.md
crawled_docs/examples_chat-app.md
crawled_docs/examples_flight-booking.md
crawled_docs/examples_pydantic-model.md
crawled_docs/examples_question-graph.md
crawled_docs/examples_rag.md
crawled_docs/examples_sql-gen.md
crawled_docs/examples_stream-markdown.md
crawled_docs/examples_stream-whales.md
crawled_docs/examples_weather-agent.md
crawled_docs/examples.md
crawled_docs/graph.md
crawled_docs/help.md
crawled_docs/index.md
crawled_docs/install.md
crawled_docs/logfire.md
crawled_docs/message-history.md
crawled_docs/models.md
crawled_docs/multi-agent-applications.md
crawled_docs/results.md
crawled_docs/testing-evals.md
crawled_docs/tools.md
crawled_docs/troubleshooting.md
full_sites/www_bbc_com/innovation_artificial-intelligence_20250130_232010.md
full_sites/www_bbc_com/news_20250130_231942.md
full_sites/www_bbc_com/news_20250130_233402.md
full_sites/www_bbc_com/news_articles_c4g9kdgzj91o_20250130_231948.md
full_sites/www_bbc_com/news_articles_c79d7y0l03po_20250130_232001.md
full_sites/www_bbc_com/news_articles_cy8pvw3xxxeo_20250130_233406.md
full_sites/www_bbc_com/sport_football_articles_cx2pyer4d14o_20250130_231945.md
full_sites/www_bbc_com/travel_specialist_20250130_231952.md
multiple_pages.py
mutlple_page.py
requirements.txt
single_page.py

================================================================
Files
================================================================

================
File: 2-crawl_docs_sequential.py
================
import asyncio
from typing import List
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig
from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator
import requests
from xml.etree import ElementTree

async def crawl_sequential(urls: List[str]):
    print("\n=== Sequential Crawling with Session Reuse ===")

    browser_config = BrowserConfig(
        headless=True,
        # For better performance in Docker or low-memory environments:
        extra_args=["--disable-gpu", "--disable-dev-shm-usage", "--no-sandbox"],
    )

    crawl_config = CrawlerRunConfig(
        markdown_generator=DefaultMarkdownGenerator()
    )

    # Create the crawler (opens the browser)
    crawler = AsyncWebCrawler(config=browser_config)
    await crawler.start()

    try:
        session_id = "session1"  # Reuse the same session across all URLs
        for url in urls:
            result = await crawler.arun(
                url=url,
                config=crawl_config,
                session_id=session_id
            )
            if result.success:
                print(f"Successfully crawled: {url}")
                # E.g. check markdown length
                print(f"Markdown length: {len(result.markdown_v2.raw_markdown)}")
            else:
                print(f"Failed: {url} - Error: {result.error_message}")
    finally:
        # After all URLs are done, close the crawler (and the browser)
        await crawler.close()

def get_pydantic_ai_docs_urls():
    """
    Fetches all URLs from the Pydantic AI documentation.
    Uses the sitemap (https://ai.pydantic.dev/sitemap.xml) to get these URLs.
    
    Returns:
        List[str]: List of URLs
    """            
    sitemap_url = "https://docs.crawl4ai.com/sitemap.xml"
    try:
        response = requests.get(sitemap_url)
        response.raise_for_status()
        
        # Parse the XML
        root = ElementTree.fromstring(response.content)
        
        # Extract all URLs from the sitemap
        # The namespace is usually defined in the root element
        namespace = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}
        urls = [loc.text for loc in root.findall('.//ns:loc', namespace)]
        
        return urls
    except Exception as e:
        print(f"Error fetching sitemap: {e}")
        return []

async def main():
    urls = get_pydantic_ai_docs_urls()
    if urls:
        print(f"Found {len(urls)} URLs to crawl")
        await crawl_sequential(urls)
    else:
        print("No URLs found to crawl")

if __name__ == "__main__":
    asyncio.run(main())

================
File: 3-crawl_docs_FAST.py
================
import os
import sys
import psutil
import asyncio
import requests
from xml.etree import ElementTree

__location__ = os.path.dirname(os.path.abspath(__file__))
__output__ = os.path.join(__location__, "output")

# Append parent directory to system path
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(parent_dir)

from typing import List
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode

async def crawl_parallel(urls: List[str], max_concurrent: int = 3):
    print("\n=== Parallel Crawling with Browser Reuse + Memory Check ===")

    # We'll keep track of peak memory usage across all tasks
    peak_memory = 0
    process = psutil.Process(os.getpid())

    def log_memory(prefix: str = ""):
        nonlocal peak_memory
        current_mem = process.memory_info().rss  # in bytes
        if current_mem > peak_memory:
            peak_memory = current_mem
        print(f"{prefix} Current Memory: {current_mem // (1024 * 1024)} MB, Peak: {peak_memory // (1024 * 1024)} MB")

    # Minimal browser config
    browser_config = BrowserConfig(
        headless=True,
        verbose=False,   # corrected from 'verbos=False'
        extra_args=["--disable-gpu", "--disable-dev-shm-usage", "--no-sandbox"],
    )
    crawl_config = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)

    # Create the crawler instance
    crawler = AsyncWebCrawler(config=browser_config)
    await crawler.start()

    try:
        # We'll chunk the URLs in batches of 'max_concurrent'
        success_count = 0
        fail_count = 0
        for i in range(0, len(urls), max_concurrent):
            batch = urls[i : i + max_concurrent]
            tasks = []

            for j, url in enumerate(batch):
                # Unique session_id per concurrent sub-task
                session_id = f"parallel_session_{i + j}"
                task = crawler.arun(url=url, config=crawl_config, session_id=session_id)
                tasks.append(task)

            # Check memory usage prior to launching tasks
            log_memory(prefix=f"Before batch {i//max_concurrent + 1}: ")

            # Gather results
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # Check memory usage after tasks complete
            log_memory(prefix=f"After batch {i//max_concurrent + 1}: ")

            # Evaluate results
            for url, result in zip(batch, results):
                if isinstance(result, Exception):
                    print(f"Error crawling {url}: {result}")
                    fail_count += 1
                elif result.success:
                    success_count += 1
                else:
                    fail_count += 1

        print(f"\nSummary:")
        print(f"  - Successfully crawled: {success_count}")
        print(f"  - Failed: {fail_count}")

    finally:
        print("\nClosing crawler...")
        await crawler.close()
        # Final memory log
        log_memory(prefix="Final: ")
        print(f"\nPeak memory usage (MB): {peak_memory // (1024 * 1024)}")

def get_pydantic_ai_docs_urls():
    """
    Fetches all URLs from the Pydantic AI documentation.
    Uses the sitemap (https://ai.pydantic.dev/sitemap.xml) to get these URLs.
    
    Returns:
        List[str]: List of URLs
    """            
    sitemap_url = "https://ai.pydantic.dev/sitemap.xml"
    try:
        response = requests.get(sitemap_url)
        response.raise_for_status()
        
        # Parse the XML
        root = ElementTree.fromstring(response.content)
        
        # Extract all URLs from the sitemap
        # The namespace is usually defined in the root element
        namespace = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}
        urls = [loc.text for loc in root.findall('.//ns:loc', namespace)]
        
        return urls
    except Exception as e:
        print(f"Error fetching sitemap: {e}")
        return []        

async def main():
    urls = get_pydantic_ai_docs_urls()
    if urls:
        print(f"Found {len(urls)} URLs to crawl")
        await crawl_parallel(urls, max_concurrent=10)
    else:
        print("No URLs found to crawl")    

if __name__ == "__main__":
    asyncio.run(main())

================
File: crawl_with_saving.py
================
import asyncio
import os
from typing import List
from urllib.parse import urlparse
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig
from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator
import requests
from xml.etree import ElementTree

async def crawl_sequential(urls: List[str], output_dir: str = "crawled_docs"):
    """
    Crawls URLs sequentially and saves markdown content to files.
    
    Args:
        urls: List of URLs to crawl
        output_dir: Directory to save markdown files (default: "crawled_docs")
    """
    print("\n=== Sequential Crawling with Session Reuse ===")
    
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    print(f"Saving markdown files to: {os.path.abspath(output_dir)}")

    browser_config = BrowserConfig(
        headless=True,
        # For better performance in Docker or low-memory environments:
        extra_args=["--disable-gpu", "--disable-dev-shm-usage", "--no-sandbox"],
    )

    crawl_config = CrawlerRunConfig(
        markdown_generator=DefaultMarkdownGenerator()
    )

    # Create the crawler (opens the browser)
    crawler = AsyncWebCrawler(config=browser_config)
    await crawler.start()

    # Track statistics
    success_count = 0
    failed_count = 0
    total_markdown_size = 0

    try:
        session_id = "session1"  # Reuse the same session across all URLs
        for url in urls:
            result = await crawler.arun(
                url=url,
                config=crawl_config,
                session_id=session_id
            )
            
            if result.success:
                success_count += 1
                markdown_length = len(result.markdown_v2.raw_markdown)
                total_markdown_size += markdown_length
                print(f"Successfully crawled: {url}")
                print(f"Markdown length: {markdown_length}")
                
                # Create filename from URL
                parsed_url = urlparse(url)
                filename = parsed_url.path.strip('/').replace('/', '_')
                if not filename:
                    filename = 'index'
                filename = f"{filename}.md"
                
                # Save to file
                filepath = os.path.join(output_dir, filename)
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(result.markdown_v2.raw_markdown)
                print(f"Saved to: {filepath}\n")
            else:
                failed_count += 1
                print(f"Failed: {url} - Error: {result.error_message}\n")
                
    finally:
        # After all URLs are done, close the crawler (and the browser)
        await crawler.close()
        
        # Print summary statistics
        print("\n=== Crawling Summary ===")
        print(f"Successfully crawled: {success_count} URLs")
        print(f"Failed: {failed_count} URLs")
        print(f"Total markdown content: {total_markdown_size:,} characters")
        print(f"Output directory: {os.path.abspath(output_dir)}")

def get_pydantic_ai_docs_urls():
    """
    Fetches all URLs from the Pydantic AI documentation sitemap.
    
    Returns:
        List[str]: List of URLs from the sitemap
    """            
    sitemap_url = "https://docs.crawl4ai.com/sitemap.xml"
    try:
        response = requests.get(sitemap_url)
        response.raise_for_status()
        
        # Parse the XML
        root = ElementTree.fromstring(response.content)
        
        # Extract all URLs from the sitemap
        # The namespace is usually defined in the root element
        namespace = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}
        urls = [loc.text for loc in root.findall('.//ns:loc', namespace)]
        
        return urls
    except Exception as e:
        print(f"Error fetching sitemap: {e}")
        return []

async def main():
    """
    Main function to run the crawler.
    Gets URLs from sitemap and initiates crawling.
    """
    # You can customize the output directory here
    output_dir = "crawled_docs"
    
    urls = get_pydantic_ai_docs_urls()
    if urls:
        print(f"Found {len(urls)} URLs to crawl")
        await crawl_sequential(urls, output_dir)
    else:
        print("No URLs found to crawl")

if __name__ == "__main__":
    asyncio.run(main())

================
File: crawled_docs/advanced_advanced-features.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/advanced/advanced-features/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/advanced/advanced-features/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/advanced/advanced-features/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/advanced/advanced-features/<#>)


  * [Home](https://docs.crawl4ai.com/advanced/advanced-features/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/advanced/advanced-features/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/advanced/advanced-features/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/advanced/advanced-features/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/advanced/advanced-features/blog/>)
    * [Changelog](https://docs.crawl4ai.com/advanced/advanced-features/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/advanced/advanced-features/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/advanced/advanced-features/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/advanced-features/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/advanced/advanced-features/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/advanced/advanced-features/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/advanced/advanced-features/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/advanced/advanced-features/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/advanced/advanced-features/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/advanced/advanced-features/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/advanced/advanced-features/core/link-media/>)
  * Advanced
    * Overview
    * [File Downloading](https://docs.crawl4ai.com/advanced/advanced-features/<../file-downloading/>)
    * [Lazy Loading](https://docs.crawl4ai.com/advanced/advanced-features/<../lazy-loading/>)
    * [Hooks & Auth](https://docs.crawl4ai.com/advanced/advanced-features/<../hooks-auth/>)
    * [Proxy & Security](https://docs.crawl4ai.com/advanced/advanced-features/<../proxy-security/>)
    * [Session Management](https://docs.crawl4ai.com/advanced/advanced-features/<../session-management/>)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/advanced/advanced-features/<../multi-url-crawling/>)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/advanced/advanced-features/<../crawl-dispatcher/>)
    * [Identity Based Crawling](https://docs.crawl4ai.com/advanced/advanced-features/<../identity-based-crawling/>)
    * [SSL Certificate](https://docs.crawl4ai.com/advanced/advanced-features/<../ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/advanced/advanced-features/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/advanced/advanced-features/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/advanced/advanced-features/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/advanced/advanced-features/extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/advanced/advanced-features/api/async-webcrawler/>)
    * [arun()](https://docs.crawl4ai.com/advanced/advanced-features/api/arun/>)
    * [arun_many()](https://docs.crawl4ai.com/advanced/advanced-features/api/arun_many/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/advanced-features/api/parameters/>)
    * [CrawlResult](https://docs.crawl4ai.com/advanced/advanced-features/api/crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/advanced/advanced-features/api/strategies/>)


  * [Overview of Some Important Advanced Features](https://docs.crawl4ai.com/advanced/advanced-features/<#overview-of-some-important-advanced-features>)
  * [1. Proxy Usage](https://docs.crawl4ai.com/advanced/advanced-features/<#1-proxy-usage>)
  * [2. Capturing PDFs & Screenshots](https://docs.crawl4ai.com/advanced/advanced-features/<#2-capturing-pdfs-screenshots>)
  * [3. Handling SSL Certificates](https://docs.crawl4ai.com/advanced/advanced-features/<#3-handling-ssl-certificates>)
  * [4. Custom Headers](https://docs.crawl4ai.com/advanced/advanced-features/<#4-custom-headers>)
  * [5. Session Persistence & Local Storage](https://docs.crawl4ai.com/advanced/advanced-features/<#5-session-persistence-local-storage>)
  * [6. Robots.txt Compliance](https://docs.crawl4ai.com/advanced/advanced-features/<#6-robotstxt-compliance>)
  * [Putting It All Together](https://docs.crawl4ai.com/advanced/advanced-features/<#putting-it-all-together>)
  * [Conclusion & Next Steps](https://docs.crawl4ai.com/advanced/advanced-features/<#conclusion-next-steps>)


# Overview of Some Important Advanced Features
(Proxy, PDF, Screenshot, SSL, Headers, & Storage State)
Crawl4AI offers multiple power-user features that go beyond simple crawling. This tutorial covers:
1. **Proxy Usage** 2. **Capturing PDFs & Screenshots** 3. **Handling SSL Certificates** 4. **Custom Headers** 5. **Session Persistence & Local Storage** 6. **Robots.txt Compliance**
> **Prerequisites** - You have a basic grasp of [AsyncWebCrawler Basics](https://docs.crawl4ai.com/advanced/advanced-features/core/simple-crawling/>) - You know how to run or configure your Python environment with Playwright installed
## 1. Proxy Usage
If you need to route your crawl traffic through a proxy—whether for IP rotation, geo-testing, or privacy—Crawl4AI supports it via `BrowserConfig.proxy_config`.
```
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig
async def main():
  browser_cfg = BrowserConfig(
    proxy_config={
      "server": "http://proxy.example.com:8080",
      "username": "myuser",
      "password": "mypass",
    },
    headless=True
  )
  crawler_cfg = CrawlerRunConfig(
    verbose=True
  )
  async with AsyncWebCrawler(config=browser_cfg) as crawler:
    result = await crawler.arun(
      url="https://www.whatismyip.com/",
      config=crawler_cfg
    )
    if result.success:
      print("[OK] Page fetched via proxy.")
      print("Page HTML snippet:", result.html[:200])
    else:
      print("[ERROR]", result.error_message)
if __name__ == "__main__":
  asyncio.run(main())

```

**Key Points** - **`proxy_config`**expects a dict with`server` and optional auth credentials. - Many commercial proxies provide an HTTP/HTTPS “gateway” server that you specify in `server`. - If your proxy doesn’t need auth, omit `username`/`password`.
## 2. Capturing PDFs & Screenshots
Sometimes you need a visual record of a page or a PDF “printout.” Crawl4AI can do both in one pass:
```
import os, asyncio
from base64 import b64decode
from crawl4ai import AsyncWebCrawler, CacheMode
async def main():
  async with AsyncWebCrawler() as crawler:
    result = await crawler.arun(
      url="https://en.wikipedia.org/wiki/List_of_common_misconceptions",
      cache_mode=CacheMode.BYPASS,
      pdf=True,
      screenshot=True
    )
    if result.success:
      # Save screenshot
      if result.screenshot:
        with open("wikipedia_screenshot.png", "wb") as f:
          f.write(b64decode(result.screenshot))
      # Save PDF
      if result.pdf:
        with open("wikipedia_page.pdf", "wb") as f:
          f.write(result.pdf)
      print("[OK] PDF & screenshot captured.")
    else:
      print("[ERROR]", result.error_message)
if __name__ == "__main__":
  asyncio.run(main())

```

**Why PDF + Screenshot?** - Large or complex pages can be slow or error-prone with “traditional” full-page screenshots. - Exporting a PDF is more reliable for very long pages. Crawl4AI automatically converts the first PDF page into an image if you request both. 
**Relevant Parameters** - **`pdf=True`**: Exports the current page as a PDF (base64-encoded in`result.pdf`). - **`screenshot=True`**: Creates a screenshot (base64-encoded in`result.screenshot`). - **`scan_full_page`**or advanced hooking can further refine how the crawler captures content.
## 3. Handling SSL Certificates
If you need to verify or export a site’s SSL certificate—for compliance, debugging, or data analysis—Crawl4AI can fetch it during the crawl:
```
import asyncio, os
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode
async def main():
  tmp_dir = os.path.join(os.getcwd(), "tmp")
  os.makedirs(tmp_dir, exist_ok=True)
  config = CrawlerRunConfig(
    fetch_ssl_certificate=True,
    cache_mode=CacheMode.BYPASS
  )
  async with AsyncWebCrawler() as crawler:
    result = await crawler.arun(url="https://example.com", config=config)
    if result.success and result.ssl_certificate:
      cert = result.ssl_certificate
      print("\nCertificate Information:")
      print(f"Issuer (CN): {cert.issuer.get('CN', '')}")
      print(f"Valid until: {cert.valid_until}")
      print(f"Fingerprint: {cert.fingerprint}")
      # Export in multiple formats:
      cert.to_json(os.path.join(tmp_dir, "certificate.json"))
      cert.to_pem(os.path.join(tmp_dir, "certificate.pem"))
      cert.to_der(os.path.join(tmp_dir, "certificate.der"))
      print("\nCertificate exported to JSON/PEM/DER in 'tmp' folder.")
    else:
      print("[ERROR] No certificate or crawl failed.")
if __name__ == "__main__":
  asyncio.run(main())

```

**Key Points** - **`fetch_ssl_certificate=True`**triggers certificate retrieval. -`result.ssl_certificate` includes methods (`to_json`, `to_pem`, `to_der`) for saving in various formats (handy for server config, Java keystores, etc.).
## 4. Custom Headers
Sometimes you need to set custom headers (e.g., language preferences, authentication tokens, or specialized user-agent strings). You can do this in multiple ways:
```
import asyncio
from crawl4ai import AsyncWebCrawler
async def main():
  # Option 1: Set headers at the crawler strategy level
  crawler1 = AsyncWebCrawler(
    # The underlying strategy can accept headers in its constructor
    crawler_strategy=None # We'll override below for clarity
  )
  crawler1.crawler_strategy.update_user_agent("MyCustomUA/1.0")
  crawler1.crawler_strategy.set_custom_headers({
    "Accept-Language": "fr-FR,fr;q=0.9"
  })
  result1 = await crawler1.arun("https://www.example.com")
  print("Example 1 result success:", result1.success)
  # Option 2: Pass headers directly to `arun()`
  crawler2 = AsyncWebCrawler()
  result2 = await crawler2.arun(
    url="https://www.example.com",
    headers={"Accept-Language": "es-ES,es;q=0.9"}
  )
  print("Example 2 result success:", result2.success)
if __name__ == "__main__":
  asyncio.run(main())

```

**Notes** - Some sites may react differently to certain headers (e.g., `Accept-Language`). - If you need advanced user-agent randomization or client hints, see [Identity-Based Crawling (Anti-Bot)](https://docs.crawl4ai.com/advanced/advanced-features/<../identity-based-crawling/>) or use `UserAgentGenerator`.
## 5. Session Persistence & Local Storage
Crawl4AI can preserve cookies and localStorage so you can continue where you left off—ideal for logging into sites or skipping repeated auth flows.
### 5.1 `storage_state`
```
import asyncio
from crawl4ai import AsyncWebCrawler
async def main():
  storage_dict = {
    "cookies": [
      {
        "name": "session",
        "value": "abcd1234",
        "domain": "example.com",
        "path": "/",
        "expires": 1699999999.0,
        "httpOnly": False,
        "secure": False,
        "sameSite": "None"
      }
    ],
    "origins": [
      {
        "origin": "https://example.com",
        "localStorage": [
          {"name": "token", "value": "my_auth_token"}
        ]
      }
    ]
  }
  # Provide the storage state as a dictionary to start "already logged in"
  async with AsyncWebCrawler(
    headless=True,
    storage_state=storage_dict
  ) as crawler:
    result = await crawler.arun("https://example.com/protected")
    if result.success:
      print("Protected page content length:", len(result.html))
    else:
      print("Failed to crawl protected page")
if __name__ == "__main__":
  asyncio.run(main())

```

### 5.2 Exporting & Reusing State
You can sign in once, export the browser context, and reuse it later—without re-entering credentials.
  * **`await context.storage_state(path="my_storage.json")`**: Exports cookies, localStorage, etc. to a file.
  * Provide `storage_state="my_storage.json"` on subsequent runs to skip the login step.


**See** : [Detailed session management tutorial](https://docs.crawl4ai.com/advanced/advanced-features/<../session-management/>) or [Explanations → Browser Context & Managed Browser](https://docs.crawl4ai.com/advanced/advanced-features/<../identity-based-crawling/>) for more advanced scenarios (like multi-step logins, or capturing after interactive pages).
## 6. Robots.txt Compliance
Crawl4AI supports respecting robots.txt rules with efficient caching:
```
import asyncio
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig
async def main():
  # Enable robots.txt checking in config
  config = CrawlerRunConfig(
    check_robots_txt=True # Will check and respect robots.txt rules
  )
  async with AsyncWebCrawler() as crawler:
    result = await crawler.arun(
      "https://example.com",
      config=config
    )
    if not result.success and result.status_code == 403:
      print("Access denied by robots.txt")
if __name__ == "__main__":
  asyncio.run(main())

```

**Key Points** - Robots.txt files are cached locally for efficiency - Cache is stored in `~/.crawl4ai/robots/robots_cache.db` - Cache has a default TTL of 7 days - If robots.txt can't be fetched, crawling is allowed - Returns 403 status code if URL is disallowed
## Putting It All Together
Here’s a snippet that combines multiple “advanced” features (proxy, PDF, screenshot, SSL, custom headers, and session reuse) into one run. Normally, you’d tailor each setting to your project’s needs.
```
import os, asyncio
from base64 import b64decode
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode
async def main():
  # 1. Browser config with proxy + headless
  browser_cfg = BrowserConfig(
    proxy_config={
      "server": "http://proxy.example.com:8080",
      "username": "myuser",
      "password": "mypass",
    },
    headless=True,
  )
  # 2. Crawler config with PDF, screenshot, SSL, custom headers, and ignoring caches
  crawler_cfg = CrawlerRunConfig(
    pdf=True,
    screenshot=True,
    fetch_ssl_certificate=True,
    cache_mode=CacheMode.BYPASS,
    headers={"Accept-Language": "en-US,en;q=0.8"},
    storage_state="my_storage.json", # Reuse session from a previous sign-in
    verbose=True,
  )
  # 3. Crawl
  async with AsyncWebCrawler(config=browser_cfg) as crawler:
    result = await crawler.arun(
      url = "https://secure.example.com/protected", 
      config=crawler_cfg
    )
    if result.success:
      print("[OK] Crawled the secure page. Links found:", len(result.links.get("internal", [])))
      # Save PDF & screenshot
      if result.pdf:
        with open("result.pdf", "wb") as f:
          f.write(b64decode(result.pdf))
      if result.screenshot:
        with open("result.png", "wb") as f:
          f.write(b64decode(result.screenshot))
      # Check SSL cert
      if result.ssl_certificate:
        print("SSL Issuer CN:", result.ssl_certificate.issuer.get("CN", ""))
    else:
      print("[ERROR]", result.error_message)
if __name__ == "__main__":
  asyncio.run(main())

```

## Conclusion & Next Steps
You’ve now explored several **advanced** features:
  * **Proxy Usage**
  * **PDF & Screenshot** capturing for large or critical pages 
  * **SSL Certificate** retrieval & exporting 
  * **Custom Headers** for language or specialized requests 
  * **Session Persistence** via storage state
  * **Robots.txt Compliance**


With these power tools, you can build robust scraping workflows that mimic real user behavior, handle secure sites, capture detailed snapshots, and manage sessions across multiple runs—streamlining your entire data collection pipeline.
**Last Updated** : 2025-01-01
Site built with [MkDocs](https://docs.crawl4ai.com/advanced/advanced-features/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/advanced/advanced-features/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/advanced_crawl-dispatcher.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/advanced/crawl-dispatcher/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<#>)


  * [Home](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/advanced/crawl-dispatcher/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/advanced/crawl-dispatcher/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/advanced/crawl-dispatcher/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/advanced/crawl-dispatcher/blog/>)
    * [Changelog](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/advanced/crawl-dispatcher/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/advanced/crawl-dispatcher/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/crawl-dispatcher/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/advanced/crawl-dispatcher/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/advanced/crawl-dispatcher/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/advanced/crawl-dispatcher/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/advanced/crawl-dispatcher/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/advanced/crawl-dispatcher/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/advanced/crawl-dispatcher/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/advanced/crawl-dispatcher/core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<../advanced-features/>)
    * [File Downloading](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<../file-downloading/>)
    * [Lazy Loading](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<../lazy-loading/>)
    * [Hooks & Auth](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<../hooks-auth/>)
    * [Proxy & Security](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<../proxy-security/>)
    * [Session Management](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<../session-management/>)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<../multi-url-crawling/>)
    * Crawl Dispatcher
    * [Identity Based Crawling](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<../identity-based-crawling/>)
    * [SSL Certificate](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<../ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/advanced/crawl-dispatcher/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/advanced/crawl-dispatcher/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/advanced/crawl-dispatcher/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/advanced/crawl-dispatcher/extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/advanced/crawl-dispatcher/api/async-webcrawler/>)
    * [arun()](https://docs.crawl4ai.com/advanced/crawl-dispatcher/api/arun/>)
    * [arun_many()](https://docs.crawl4ai.com/advanced/crawl-dispatcher/api/arun_many/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/crawl-dispatcher/api/parameters/>)
    * [CrawlResult](https://docs.crawl4ai.com/advanced/crawl-dispatcher/api/crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/advanced/crawl-dispatcher/api/strategies/>)


  * [Crawl Dispatcher](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<#crawl-dispatcher>)


# Crawl Dispatcher
We’re excited to announce a **Crawl Dispatcher** module that can handle **thousands** of crawling tasks simultaneously. By efficiently managing system resources (memory, CPU, network), this dispatcher ensures high-performance data extraction at scale. It also provides **real-time monitoring** of each crawler’s status, memory usage, and overall progress.
Stay tuned—this feature is **coming soon** in an upcoming release of Crawl4AI! For the latest news, keep an eye on our changelogs and follow [@unclecode](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<https:/twitter.com/unclecode>) on X.
Below is a **sample** of how the dispatcher’s performance monitor might look in action:
![Crawl Dispatcher Performance Monitor](https://docs.crawl4ai.com/assets/images/dispatcher.png)
We can’t wait to bring you this streamlined, **scalable** approach to multi-URL crawling—**watch this space** for updates!
Site built with [MkDocs](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/advanced/crawl-dispatcher/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/advanced_file-downloading.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/advanced/file-downloading/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/advanced/file-downloading/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/advanced/file-downloading/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/advanced/file-downloading/<#>)


  * [Home](https://docs.crawl4ai.com/advanced/file-downloading/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/advanced/file-downloading/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/advanced/file-downloading/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/advanced/file-downloading/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/advanced/file-downloading/blog/>)
    * [Changelog](https://docs.crawl4ai.com/advanced/file-downloading/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/advanced/file-downloading/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/advanced/file-downloading/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/file-downloading/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/advanced/file-downloading/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/advanced/file-downloading/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/advanced/file-downloading/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/advanced/file-downloading/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/advanced/file-downloading/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/advanced/file-downloading/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/advanced/file-downloading/core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/advanced/file-downloading/<../advanced-features/>)
    * File Downloading
    * [Lazy Loading](https://docs.crawl4ai.com/advanced/file-downloading/<../lazy-loading/>)
    * [Hooks & Auth](https://docs.crawl4ai.com/advanced/file-downloading/<../hooks-auth/>)
    * [Proxy & Security](https://docs.crawl4ai.com/advanced/file-downloading/<../proxy-security/>)
    * [Session Management](https://docs.crawl4ai.com/advanced/file-downloading/<../session-management/>)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/advanced/file-downloading/<../multi-url-crawling/>)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/advanced/file-downloading/<../crawl-dispatcher/>)
    * [Identity Based Crawling](https://docs.crawl4ai.com/advanced/file-downloading/<../identity-based-crawling/>)
    * [SSL Certificate](https://docs.crawl4ai.com/advanced/file-downloading/<../ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/advanced/file-downloading/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/advanced/file-downloading/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/advanced/file-downloading/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/advanced/file-downloading/extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/advanced/file-downloading/api/async-webcrawler/>)
    * [arun()](https://docs.crawl4ai.com/advanced/file-downloading/api/arun/>)
    * [arun_many()](https://docs.crawl4ai.com/advanced/file-downloading/api/arun_many/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/file-downloading/api/parameters/>)
    * [CrawlResult](https://docs.crawl4ai.com/advanced/file-downloading/api/crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/advanced/file-downloading/api/strategies/>)


  * [Download Handling in Crawl4AI](https://docs.crawl4ai.com/advanced/file-downloading/<#download-handling-in-crawl4ai>)
  * [Enabling Downloads](https://docs.crawl4ai.com/advanced/file-downloading/<#enabling-downloads>)
  * [Specifying Download Location](https://docs.crawl4ai.com/advanced/file-downloading/<#specifying-download-location>)
  * [Triggering Downloads](https://docs.crawl4ai.com/advanced/file-downloading/<#triggering-downloads>)
  * [Accessing Downloaded Files](https://docs.crawl4ai.com/advanced/file-downloading/<#accessing-downloaded-files>)
  * [Example: Downloading Multiple Files](https://docs.crawl4ai.com/advanced/file-downloading/<#example-downloading-multiple-files>)
  * [Important Considerations](https://docs.crawl4ai.com/advanced/file-downloading/<#important-considerations>)


# Download Handling in Crawl4AI
This guide explains how to use Crawl4AI to handle file downloads during crawling. You'll learn how to trigger downloads, specify download locations, and access downloaded files.
## Enabling Downloads
To enable downloads, set the `accept_downloads` parameter in the `BrowserConfig` object and pass it to the crawler.
```
from crawl4ai.async_configs import BrowserConfig, AsyncWebCrawler
async def main():
  config = BrowserConfig(accept_downloads=True) # Enable downloads globally
  async with AsyncWebCrawler(config=config) as crawler:
    # ... your crawling logic ...
asyncio.run(main())

```

## Specifying Download Location
Specify the download directory using the `downloads_path` attribute in the `BrowserConfig` object. If not provided, Crawl4AI defaults to creating a "downloads" directory inside the `.crawl4ai` folder in your home directory.
```
from crawl4ai.async_configs import BrowserConfig
import os
downloads_path = os.path.join(os.getcwd(), "my_downloads") # Custom download path
os.makedirs(downloads_path, exist_ok=True)
config = BrowserConfig(accept_downloads=True, downloads_path=downloads_path)
async def main():
  async with AsyncWebCrawler(config=config) as crawler:
    result = await crawler.arun(url="https://example.com")
    # ...

```

## Triggering Downloads
Downloads are typically triggered by user interactions on a web page, such as clicking a download button. Use `js_code` in `CrawlerRunConfig` to simulate these actions and `wait_for` to allow sufficient time for downloads to start.
```
from crawl4ai.async_configs import CrawlerRunConfig
config = CrawlerRunConfig(
  js_code="""
    const downloadLink = document.querySelector('a[href$=".exe"]');
    if (downloadLink) {
      downloadLink.click();
    }
  """,
  wait_for=5 # Wait 5 seconds for the download to start
)
result = await crawler.arun(url="https://www.python.org/downloads/", config=config)

```

## Accessing Downloaded Files
The `downloaded_files` attribute of the `CrawlResult` object contains paths to downloaded files.
```
if result.downloaded_files:
  print("Downloaded files:")
  for file_path in result.downloaded_files:
    print(f"- {file_path}")
    file_size = os.path.getsize(file_path)
    print(f"- File size: {file_size} bytes")
else:
  print("No files downloaded.")

```

## Example: Downloading Multiple Files
```
from crawl4ai.async_configs import BrowserConfig, CrawlerRunConfig
import os
from pathlib import Path
async def download_multiple_files(url: str, download_path: str):
  config = BrowserConfig(accept_downloads=True, downloads_path=download_path)
  async with AsyncWebCrawler(config=config) as crawler:
    run_config = CrawlerRunConfig(
      js_code="""
        const downloadLinks = document.querySelectorAll('a[download]');
        for (const link of downloadLinks) {
          link.click();
          // Delay between clicks
          await new Promise(r => setTimeout(r, 2000)); 
        }
      """,
      wait_for=10 # Wait for all downloads to start
    )
    result = await crawler.arun(url=url, config=run_config)
    if result.downloaded_files:
      print("Downloaded files:")
      for file in result.downloaded_files:
        print(f"- {file}")
    else:
      print("No files downloaded.")
# Usage
download_path = os.path.join(Path.home(), ".crawl4ai", "downloads")
os.makedirs(download_path, exist_ok=True)
asyncio.run(download_multiple_files("https://www.python.org/downloads/windows/", download_path))

```

## Important Considerations
  * **Browser Context:** Downloads are managed within the browser context. Ensure `js_code` correctly targets the download triggers on the webpage.
  * **Timing:** Use `wait_for` in `CrawlerRunConfig` to manage download timing.
  * **Error Handling:** Handle errors to manage failed downloads or incorrect paths gracefully.
  * **Security:** Scan downloaded files for potential security threats before use.


This revised guide ensures consistency with the `Crawl4AI` codebase by using `BrowserConfig` and `CrawlerRunConfig` for all download-related configurations. Let me know if further adjustments are needed!
Site built with [MkDocs](https://docs.crawl4ai.com/advanced/file-downloading/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/advanced/file-downloading/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/advanced_hooks-auth.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/advanced/hooks-auth/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/advanced/hooks-auth/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/advanced/hooks-auth/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/advanced/hooks-auth/<#>)


  * [Home](https://docs.crawl4ai.com/advanced/hooks-auth/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/advanced/hooks-auth/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/advanced/hooks-auth/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/advanced/hooks-auth/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/advanced/hooks-auth/blog/>)
    * [Changelog](https://docs.crawl4ai.com/advanced/hooks-auth/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/advanced/hooks-auth/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/advanced/hooks-auth/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/hooks-auth/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/advanced/hooks-auth/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/advanced/hooks-auth/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/advanced/hooks-auth/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/advanced/hooks-auth/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/advanced/hooks-auth/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/advanced/hooks-auth/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/advanced/hooks-auth/core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/advanced/hooks-auth/<../advanced-features/>)
    * [File Downloading](https://docs.crawl4ai.com/advanced/hooks-auth/<../file-downloading/>)
    * [Lazy Loading](https://docs.crawl4ai.com/advanced/hooks-auth/<../lazy-loading/>)
    * Hooks & Auth
    * [Proxy & Security](https://docs.crawl4ai.com/advanced/hooks-auth/<../proxy-security/>)
    * [Session Management](https://docs.crawl4ai.com/advanced/hooks-auth/<../session-management/>)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/advanced/hooks-auth/<../multi-url-crawling/>)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/advanced/hooks-auth/<../crawl-dispatcher/>)
    * [Identity Based Crawling](https://docs.crawl4ai.com/advanced/hooks-auth/<../identity-based-crawling/>)
    * [SSL Certificate](https://docs.crawl4ai.com/advanced/hooks-auth/<../ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/advanced/hooks-auth/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/advanced/hooks-auth/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/advanced/hooks-auth/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/advanced/hooks-auth/extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/advanced/hooks-auth/api/async-webcrawler/>)
    * [arun()](https://docs.crawl4ai.com/advanced/hooks-auth/api/arun/>)
    * [arun_many()](https://docs.crawl4ai.com/advanced/hooks-auth/api/arun_many/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/hooks-auth/api/parameters/>)
    * [CrawlResult](https://docs.crawl4ai.com/advanced/hooks-auth/api/crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/advanced/hooks-auth/api/strategies/>)


  * [Hooks & Auth in AsyncWebCrawler](https://docs.crawl4ai.com/advanced/hooks-auth/<#hooks-auth-in-asyncwebcrawler>)
  * [Example: Using Hooks in AsyncWebCrawler](https://docs.crawl4ai.com/advanced/hooks-auth/<#example-using-hooks-in-asyncwebcrawler>)
  * [Hook Lifecycle Summary](https://docs.crawl4ai.com/advanced/hooks-auth/<#hook-lifecycle-summary>)
  * [When to Handle Authentication](https://docs.crawl4ai.com/advanced/hooks-auth/<#when-to-handle-authentication>)
  * [Additional Considerations](https://docs.crawl4ai.com/advanced/hooks-auth/<#additional-considerations>)
  * [Conclusion](https://docs.crawl4ai.com/advanced/hooks-auth/<#conclusion>)


# Hooks & Auth in AsyncWebCrawler
Crawl4AI’s **hooks** let you customize the crawler at specific points in the pipeline:
1. **`on_browser_created`**– After browser creation. 2.**`on_page_context_created`**– After a new context & page are created. 3. **`before_goto`**– Just before navigating to a page. 4.**`after_goto`**– Right after navigation completes. 5.**`on_user_agent_updated`**– Whenever the user agent changes. 6.**`on_execution_started`**– Once custom JavaScript execution begins. 7.**`before_retrieve_html`**– Just before the crawler retrieves final HTML. 8.**`before_return_html`**– Right before returning the HTML content.
**Important** : Avoid heavy tasks in `on_browser_created` since you don’t yet have a page context. If you need to _log in_ , do so in **`on_page_context_created`**.
> note "Important Hook Usage Warning" **Avoid Misusing Hooks** : Do not manipulate page objects in the wrong hook or at the wrong time, as it can crash the pipeline or produce incorrect results. A common mistake is attempting to handle authentication prematurely—such as creating or closing pages in `on_browser_created`. 
> **Use the Right Hook for Auth** : If you need to log in or set tokens, use `on_page_context_created`. This ensures you have a valid page/context to work with, without disrupting the main crawling flow.
> **Identity-Based Crawling** : For robust auth, consider identity-based crawling (or passing a session ID) to preserve state. Run your initial login steps in a separate, well-defined process, then feed that session to your main crawl—rather than shoehorning complex authentication into early hooks. Check out [Identity-Based Crawling](https://docs.crawl4ai.com/advanced/hooks-auth/<../identity-based-crawling/>) for more details.
> **Be Cautious** : Overwriting or removing elements in the wrong hook can compromise the final crawl. Keep hooks focused on smaller tasks (like route filters, custom headers), and let your main logic (crawling, data extraction) proceed normally.
Below is an example demonstration.
## Example: Using Hooks in AsyncWebCrawler
```
import asyncio
import json
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode
from playwright.async_api import Page, BrowserContext
async def main():
  print("🔗 Hooks Example: Demonstrating recommended usage")
  # 1) Configure the browser
  browser_config = BrowserConfig(
    headless=True,
    verbose=True
  )
  # 2) Configure the crawler run
  crawler_run_config = CrawlerRunConfig(
    js_code="window.scrollTo(0, document.body.scrollHeight);",
    wait_for="body",
    cache_mode=CacheMode.BYPASS
  )
  # 3) Create the crawler instance
  crawler = AsyncWebCrawler(config=browser_config)
  #
  # Define Hook Functions
  #
  async def on_browser_created(browser, **kwargs):
    # Called once the browser instance is created (but no pages or contexts yet)
    print("[HOOK] on_browser_created - Browser created successfully!")
    # Typically, do minimal setup here if needed
    return browser
  async def on_page_context_created(page: Page, context: BrowserContext, **kwargs):
    # Called right after a new page + context are created (ideal for auth or route config).
    print("[HOOK] on_page_context_created - Setting up page & context.")
    # Example 1: Route filtering (e.g., block images)
    async def route_filter(route):
      if route.request.resource_type == "image":
        print(f"[HOOK] Blocking image request: {route.request.url}")
        await route.abort()
      else:
        await route.continue_()
    await context.route("**", route_filter)
    # Example 2: (Optional) Simulate a login scenario
    # (We do NOT create or close pages here, just do quick steps if needed)
    # e.g., await page.goto("https://example.com/login")
    # e.g., await page.fill("input[name='username']", "testuser")
    # e.g., await page.fill("input[name='password']", "password123")
    # e.g., await page.click("button[type='submit']")
    # e.g., await page.wait_for_selector("#welcome")
    # e.g., await context.add_cookies([...])
    # Then continue
    # Example 3: Adjust the viewport
    await page.set_viewport_size({"width": 1080, "height": 600})
    return page
  async def before_goto(
    page: Page, context: BrowserContext, url: str, **kwargs
  ):
    # Called before navigating to each URL.
    print(f"[HOOK] before_goto - About to navigate: {url}")
    # e.g., inject custom headers
    await page.set_extra_http_headers({
      "Custom-Header": "my-value"
    })
    return page
  async def after_goto(
    page: Page, context: BrowserContext, 
    url: str, response, **kwargs
  ):
    # Called after navigation completes.
    print(f"[HOOK] after_goto - Successfully loaded: {url}")
    # e.g., wait for a certain element if we want to verify
    try:
      await page.wait_for_selector('.content', timeout=1000)
      print("[HOOK] Found .content element!")
    except:
      print("[HOOK] .content not found, continuing anyway.")
    return page
  async def on_user_agent_updated(
    page: Page, context: BrowserContext, 
    user_agent: str, **kwargs
  ):
    # Called whenever the user agent updates.
    print(f"[HOOK] on_user_agent_updated - New user agent: {user_agent}")
    return page
  async def on_execution_started(page: Page, context: BrowserContext, **kwargs):
    # Called after custom JavaScript execution begins.
    print("[HOOK] on_execution_started - JS code is running!")
    return page
  async def before_retrieve_html(page: Page, context: BrowserContext, **kwargs):
    # Called before final HTML retrieval.
    print("[HOOK] before_retrieve_html - We can do final actions")
    # Example: Scroll again
    await page.evaluate("window.scrollTo(0, document.body.scrollHeight);")
    return page
  async def before_return_html(
    page: Page, context: BrowserContext, html: str, **kwargs
  ):
    # Called just before returning the HTML in the result.
    print(f"[HOOK] before_return_html - HTML length: {len(html)}")
    return page
  #
  # Attach Hooks
  #
  crawler.crawler_strategy.set_hook("on_browser_created", on_browser_created)
  crawler.crawler_strategy.set_hook(
    "on_page_context_created", on_page_context_created
  )
  crawler.crawler_strategy.set_hook("before_goto", before_goto)
  crawler.crawler_strategy.set_hook("after_goto", after_goto)
  crawler.crawler_strategy.set_hook(
    "on_user_agent_updated", on_user_agent_updated
  )
  crawler.crawler_strategy.set_hook(
    "on_execution_started", on_execution_started
  )
  crawler.crawler_strategy.set_hook(
    "before_retrieve_html", before_retrieve_html
  )
  crawler.crawler_strategy.set_hook(
    "before_return_html", before_return_html
  )
  await crawler.start()
  # 4) Run the crawler on an example page
  url = "https://example.com"
  result = await crawler.arun(url, config=crawler_run_config)
  if result.success:
    print("\nCrawled URL:", result.url)
    print("HTML length:", len(result.html))
  else:
    print("Error:", result.error_message)
  await crawler.close()
if __name__ == "__main__":
  asyncio.run(main())

```

## Hook Lifecycle Summary
1. **`on_browser_created`**: - Browser is up, but**no** pages or contexts yet. - Light setup only—don’t try to open or close pages here (that belongs in `on_page_context_created`).
2. **`on_page_context_created`**: - Perfect for advanced**auth** or route blocking. - You have a **page** + **context** ready but haven’t navigated to the target URL yet.
3. **`before_goto`**: - Right before navigation. Typically used for setting**custom headers** or logging the target URL.
4. **`after_goto`**: - After page navigation is done. Good place for verifying content or waiting on essential elements.
5. **`on_user_agent_updated`**: - Whenever the user agent changes (for stealth or different UA modes).
6. **`on_execution_started`**: - If you set`js_code` or run custom scripts, this runs once your JS is about to start.
7. **`before_retrieve_html`**: - Just before the final HTML snapshot is taken. Often you do a final scroll or lazy-load triggers here.
8. **`before_return_html`**: - The last hook before returning HTML to the`CrawlResult`. Good for logging HTML length or minor modifications.
## When to Handle Authentication
**Recommended** : Use **`on_page_context_created`**if you need to:
  * Navigate to a login page or fill forms
  * Set cookies or localStorage tokens
  * Block resource routes to avoid ads


This ensures the newly created context is under your control **before** `arun()` navigates to the main URL.
## Additional Considerations
  * **Session Management** : If you want multiple `arun()` calls to reuse a single session, pass `session_id=` in your `CrawlerRunConfig`. Hooks remain the same. 
  * **Performance** : Hooks can slow down crawling if they do heavy tasks. Keep them concise. 
  * **Error Handling** : If a hook fails, the overall crawl might fail. Catch exceptions or handle them gracefully. 
  * **Concurrency** : If you run `arun_many()`, each URL triggers these hooks in parallel. Ensure your hooks are thread/async-safe.


## Conclusion
Hooks provide **fine-grained** control over:
  * **Browser** creation (light tasks only)
  * **Page** and **context** creation (auth, route blocking)
  * **Navigation** phases
  * **Final HTML** retrieval


Follow the recommended usage: - **Login** or advanced tasks in `on_page_context_created` - **Custom headers** or logs in `before_goto` / `after_goto` - **Scrolling** or final checks in `before_retrieve_html` / `before_return_html`
Site built with [MkDocs](https://docs.crawl4ai.com/advanced/hooks-auth/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/advanced/hooks-auth/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/advanced_identity-based-crawling.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/advanced/identity-based-crawling/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/advanced/identity-based-crawling/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/advanced/identity-based-crawling/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/advanced/identity-based-crawling/<#>)


  * [Home](https://docs.crawl4ai.com/advanced/identity-based-crawling/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/advanced/identity-based-crawling/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/advanced/identity-based-crawling/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/advanced/identity-based-crawling/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/advanced/identity-based-crawling/blog/>)
    * [Changelog](https://docs.crawl4ai.com/advanced/identity-based-crawling/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/advanced/identity-based-crawling/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/advanced/identity-based-crawling/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/identity-based-crawling/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/advanced/identity-based-crawling/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/advanced/identity-based-crawling/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/advanced/identity-based-crawling/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/advanced/identity-based-crawling/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/advanced/identity-based-crawling/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/advanced/identity-based-crawling/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/advanced/identity-based-crawling/core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/advanced/identity-based-crawling/<../advanced-features/>)
    * [File Downloading](https://docs.crawl4ai.com/advanced/identity-based-crawling/<../file-downloading/>)
    * [Lazy Loading](https://docs.crawl4ai.com/advanced/identity-based-crawling/<../lazy-loading/>)
    * [Hooks & Auth](https://docs.crawl4ai.com/advanced/identity-based-crawling/<../hooks-auth/>)
    * [Proxy & Security](https://docs.crawl4ai.com/advanced/identity-based-crawling/<../proxy-security/>)
    * [Session Management](https://docs.crawl4ai.com/advanced/identity-based-crawling/<../session-management/>)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/advanced/identity-based-crawling/<../multi-url-crawling/>)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/advanced/identity-based-crawling/<../crawl-dispatcher/>)
    * Identity Based Crawling
    * [SSL Certificate](https://docs.crawl4ai.com/advanced/identity-based-crawling/<../ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/advanced/identity-based-crawling/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/advanced/identity-based-crawling/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/advanced/identity-based-crawling/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/advanced/identity-based-crawling/extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/advanced/identity-based-crawling/api/async-webcrawler/>)
    * [arun()](https://docs.crawl4ai.com/advanced/identity-based-crawling/api/arun/>)
    * [arun_many()](https://docs.crawl4ai.com/advanced/identity-based-crawling/api/arun_many/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/identity-based-crawling/api/parameters/>)
    * [CrawlResult](https://docs.crawl4ai.com/advanced/identity-based-crawling/api/crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/advanced/identity-based-crawling/api/strategies/>)


  * [Preserve Your Identity with Crawl4AI](https://docs.crawl4ai.com/advanced/identity-based-crawling/<#preserve-your-identity-with-crawl4ai>)
  * [1. Managed Browsers: Your Digital Identity Solution](https://docs.crawl4ai.com/advanced/identity-based-crawling/<#1-managed-browsers-your-digital-identity-solution>)
  * [3. Using Managed Browsers in Crawl4AI](https://docs.crawl4ai.com/advanced/identity-based-crawling/<#3-using-managed-browsers-in-crawl4ai>)
  * [4. Magic Mode: Simplified Automation](https://docs.crawl4ai.com/advanced/identity-based-crawling/<#4-magic-mode-simplified-automation>)
  * [5. Comparing Managed Browsers vs. Magic Mode](https://docs.crawl4ai.com/advanced/identity-based-crawling/<#5-comparing-managed-browsers-vs-magic-mode>)
  * [6. Summary](https://docs.crawl4ai.com/advanced/identity-based-crawling/<#6-summary>)


# Preserve Your Identity with Crawl4AI
Crawl4AI empowers you to navigate and interact with the web using your **authentic digital identity** , ensuring you’re recognized as a human and not mistaken for a bot. This tutorial covers:
1. **Managed Browsers** – The recommended approach for persistent profiles and identity-based crawling. 2. **Magic Mode** – A simplified fallback solution for quick automation without persistent identity.
## 1. Managed Browsers: Your Digital Identity Solution
**Managed Browsers** let developers create and use **persistent browser profiles**. These profiles store local storage, cookies, and other session data, letting you browse as your **real self** —complete with logins, preferences, and cookies.
### Key Benefits
  * **Authentic Browsing Experience** : Retain session data and browser fingerprints as though you’re a normal user. 
  * **Effortless Configuration** : Once you log in or solve CAPTCHAs in your chosen data directory, you can re-run crawls without repeating those steps. 
  * **Empowered Data Access** : If you can see the data in your own browser, you can automate its retrieval with your genuine identity.


Below is a **partial update** to your **Managed Browsers** tutorial, specifically the section about **creating a user-data directory** using **Playwright’s Chromium** binary rather than a system-wide Chrome/Edge. We’ll show how to **locate** that binary and launch it with a `--user-data-dir` argument to set up your profile. You can then point `BrowserConfig.user_data_dir` to that folder for subsequent crawls.
### Creating a User Data Directory (Command-Line Approach via Playwright)
If you installed Crawl4AI (which installs Playwright under the hood), you already have a Playwright-managed Chromium on your system. Follow these steps to launch that **Chromium** from your command line, specifying a **custom** data directory:
1. **Find** the Playwright Chromium binary: - On most systems, installed browsers go under a `~/.cache/ms-playwright/` folder or similar path. - To see an overview of installed browsers, run: 
```
python -m playwright install --dry-run

```

or 
```
playwright install --dry-run

```

(depending on your environment). This shows where Playwright keeps Chromium. 
  * For instance, you might see a path like: 
```
~/.cache/ms-playwright/chromium-1234/chrome-linux/chrome

```

on Linux, or a corresponding folder on macOS/Windows.


2. **Launch** the Playwright Chromium binary with a **custom** user-data directory: 
```
# Linux example
~/.cache/ms-playwright/chromium-1234/chrome-linux/chrome \
  --user-data-dir=/home/<you>/my_chrome_profile

```

```
# macOS example (Playwright’s internal binary)
~/Library/Caches/ms-playwright/chromium-1234/chrome-mac/Chromium.app/Contents/MacOS/Chromium \
  --user-data-dir=/Users/<you>/my_chrome_profile

```

```
# Windows example (PowerShell/cmd)
"C:\Users\<you>\AppData\Local\ms-playwright\chromium-1234\chrome-win\chrome.exe" ^
  --user-data-dir="C:\Users\<you>\my_chrome_profile"

```

**Replace** the path with the actual subfolder indicated in your `ms-playwright` cache structure. - This **opens** a fresh Chromium with your new or existing data folder. - **Log into** any sites or configure your browser the way you want. - **Close** when done—your profile data is saved in that folder.
3. **Use** that folder in **`BrowserConfig.user_data_dir`**:
```
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig
browser_config = BrowserConfig(
  headless=True,
  use_managed_browser=True,
  user_data_dir="/home/<you>/my_chrome_profile",
  browser_type="chromium"
)

```

- Next time you run your code, it reuses that folder—**preserving** your session data, cookies, local storage, etc. 
## 3. Using Managed Browsers in Crawl4AI
Once you have a data directory with your session data, pass it to **`BrowserConfig`**:
```
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig
async def main():
  # 1) Reference your persistent data directory
  browser_config = BrowserConfig(
    headless=True,       # 'True' for automated runs
    verbose=True,
    use_managed_browser=True, # Enables persistent browser strategy
    browser_type="chromium",
    user_data_dir="/path/to/my-chrome-profile"
  )
  # 2) Standard crawl config
  crawl_config = CrawlerRunConfig(
    wait_for="css:.logged-in-content"
  )
  async with AsyncWebCrawler(config=browser_config) as crawler:
    result = await crawler.arun(url="https://example.com/private", config=crawl_config)
    if result.success:
      print("Successfully accessed private data with your identity!")
    else:
      print("Error:", result.error_message)
if __name__ == "__main__":
  asyncio.run(main())

```

### Workflow
1. **Login** externally (via CLI or your normal Chrome with `--user-data-dir=...`). 2. **Close** that browser. 3. **Use** the same folder in `user_data_dir=` in Crawl4AI. 4. **Crawl** – The site sees your identity as if you’re the same user who just logged in.
## 4. Magic Mode: Simplified Automation
If you **don’t** need a persistent profile or identity-based approach, **Magic Mode** offers a quick way to simulate human-like browsing without storing long-term data.
```
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig
async with AsyncWebCrawler() as crawler:
  result = await crawler.arun(
    url="https://example.com",
    config=CrawlerRunConfig(
      magic=True, # Simplifies a lot of interaction
      remove_overlay_elements=True,
      page_timeout=60000
    )
  )

```

**Magic Mode** :
  * Simulates a user-like experience 
  * Randomizes user agent & navigator
  * Randomizes interactions & timings 
  * Masks automation signals 
  * Attempts pop-up handling 


**But** it’s no substitute for **true** user-based sessions if you want a fully legitimate identity-based solution.
## 5. Comparing Managed Browsers vs. Magic Mode
Feature | **Managed Browsers** | **Magic Mode**  
---|---|---  
**Session Persistence** | Full localStorage/cookies retained in user_data_dir | No persistent data (fresh each run)  
**Genuine Identity** | Real user profile with full rights & preferences | Emulated user-like patterns, but no actual identity  
**Complex Sites** | Best for login-gated sites or heavy config | Simple tasks, minimal login or config needed  
**Setup** | External creation of user_data_dir, then use in Crawl4AI | Single-line approach (`magic=True`)  
**Reliability** | Extremely consistent (same data across runs) | Good for smaller tasks, can be less stable  
## 6. Summary
  * **Create** your user-data directory by launching Chrome/Chromium externally with `--user-data-dir=/some/path`. 
  * **Log in** or configure sites as needed, then close the browser. 
  * **Reference** that folder in `BrowserConfig(user_data_dir="...")` + `use_managed_browser=True`. 
  * Enjoy **persistent** sessions that reflect your real identity. 
  * If you only need quick, ephemeral automation, **Magic Mode** might suffice.


**Recommended** : Always prefer a **Managed Browser** for robust, identity-based crawling and simpler interactions with complex sites. Use **Magic Mode** for quick tasks or prototypes where persistent data is unnecessary.
With these approaches, you preserve your **authentic** browsing environment, ensuring the site sees you exactly as a normal user—no repeated logins or wasted time.
Site built with [MkDocs](https://docs.crawl4ai.com/advanced/identity-based-crawling/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/advanced/identity-based-crawling/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/advanced_lazy-loading.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/advanced/lazy-loading/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/advanced/lazy-loading/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/advanced/lazy-loading/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/advanced/lazy-loading/<#>)


  * [Home](https://docs.crawl4ai.com/advanced/lazy-loading/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/advanced/lazy-loading/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/advanced/lazy-loading/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/advanced/lazy-loading/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/advanced/lazy-loading/blog/>)
    * [Changelog](https://docs.crawl4ai.com/advanced/lazy-loading/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/advanced/lazy-loading/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/advanced/lazy-loading/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/lazy-loading/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/advanced/lazy-loading/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/advanced/lazy-loading/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/advanced/lazy-loading/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/advanced/lazy-loading/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/advanced/lazy-loading/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/advanced/lazy-loading/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/advanced/lazy-loading/core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/advanced/lazy-loading/<../advanced-features/>)
    * [File Downloading](https://docs.crawl4ai.com/advanced/lazy-loading/<../file-downloading/>)
    * Lazy Loading
    * [Hooks & Auth](https://docs.crawl4ai.com/advanced/lazy-loading/<../hooks-auth/>)
    * [Proxy & Security](https://docs.crawl4ai.com/advanced/lazy-loading/<../proxy-security/>)
    * [Session Management](https://docs.crawl4ai.com/advanced/lazy-loading/<../session-management/>)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/advanced/lazy-loading/<../multi-url-crawling/>)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/advanced/lazy-loading/<../crawl-dispatcher/>)
    * [Identity Based Crawling](https://docs.crawl4ai.com/advanced/lazy-loading/<../identity-based-crawling/>)
    * [SSL Certificate](https://docs.crawl4ai.com/advanced/lazy-loading/<../ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/advanced/lazy-loading/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/advanced/lazy-loading/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/advanced/lazy-loading/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/advanced/lazy-loading/extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/advanced/lazy-loading/api/async-webcrawler/>)
    * [arun()](https://docs.crawl4ai.com/advanced/lazy-loading/api/arun/>)
    * [arun_many()](https://docs.crawl4ai.com/advanced/lazy-loading/api/arun_many/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/lazy-loading/api/parameters/>)
    * [CrawlResult](https://docs.crawl4ai.com/advanced/lazy-loading/api/crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/advanced/lazy-loading/api/strategies/>)


  * [Handling Lazy-Loaded Images](https://docs.crawl4ai.com/advanced/lazy-loading/<#handling-lazy-loaded-images>)
  * [Example: Ensuring Lazy Images Appear](https://docs.crawl4ai.com/advanced/lazy-loading/<#example-ensuring-lazy-images-appear>)
  * [Combining with Other Link & Media Filters](https://docs.crawl4ai.com/advanced/lazy-loading/<#combining-with-other-link-media-filters>)
  * [Tips & Troubleshooting](https://docs.crawl4ai.com/advanced/lazy-loading/<#tips-troubleshooting>)


## Handling Lazy-Loaded Images
Many websites now load images **lazily** as you scroll. If you need to ensure they appear in your final crawl (and in `result.media`), consider:
1. **`wait_for_images=True`**– Wait for images to fully load. 2.**`scan_full_page`**– Force the crawler to scroll the entire page, triggering lazy loads. 3.**`scroll_delay`**– Add small delays between scroll steps.
**Note** : If the site requires multiple “Load More” triggers or complex interactions, see the [Page Interaction docs](https://docs.crawl4ai.com/advanced/lazy-loading/core/page-interaction/>).
### Example: Ensuring Lazy Images Appear
```
import asyncio
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, BrowserConfig
from crawl4ai.async_configs import CacheMode
async def main():
  config = CrawlerRunConfig(
    # Force the crawler to wait until images are fully loaded
    wait_for_images=True,
    # Option 1: If you want to automatically scroll the page to load images
    scan_full_page=True, # Tells the crawler to try scrolling the entire page
    scroll_delay=0.5,   # Delay (seconds) between scroll steps
    # Option 2: If the site uses a 'Load More' or JS triggers for images,
    # you can also specify js_code or wait_for logic here.
    cache_mode=CacheMode.BYPASS,
    verbose=True
  )
  async with AsyncWebCrawler(config=BrowserConfig(headless=True)) as crawler:
    result = await crawler.arun("https://www.example.com/gallery", config=config)
    if result.success:
      images = result.media.get("images", [])
      print("Images found:", len(images))
      for i, img in enumerate(images[:5]):
        print(f"[Image {i}] URL: {img['src']}, Score: {img.get('score','N/A')}")
    else:
      print("Error:", result.error_message)
if __name__ == "__main__":
  asyncio.run(main())

```

**Explanation** :
  * **`wait_for_images=True`**The crawler tries to ensure images have finished loading before finalizing the HTML.
  * **`scan_full_page=True`**Tells the crawler to attempt scrolling from top to bottom. Each scroll step helps trigger lazy loading.
  * **`scroll_delay=0.5`**Pause half a second between each scroll step. Helps the site load images before continuing.


**When to Use** :
  * **Lazy-Loading** : If images appear only when the user scrolls into view, `scan_full_page` + `scroll_delay` helps the crawler see them. 
  * **Heavier Pages** : If a page is extremely long, be mindful that scanning the entire page can be slow. Adjust `scroll_delay` or the max scroll steps as needed.


## Combining with Other Link & Media Filters
You can still combine **lazy-load** logic with the usual **exclude_external_images** , **exclude_domains** , or link filtration:
```
config = CrawlerRunConfig(
  wait_for_images=True,
  scan_full_page=True,
  scroll_delay=0.5,
  # Filter out external images if you only want local ones
  exclude_external_images=True,
  # Exclude certain domains for links
  exclude_domains=["spammycdn.com"],
)

```

This approach ensures you see **all** images from the main domain while ignoring external ones, and the crawler physically scrolls the entire page so that lazy-loading triggers.
## Tips & Troubleshooting
1. **Long Pages** - Setting `scan_full_page=True` on extremely long or infinite-scroll pages can be resource-intensive. - Consider using [hooks](https://docs.crawl4ai.com/advanced/lazy-loading/core/page-interaction/>) or specialized logic to load specific sections or “Load More” triggers repeatedly.
2. **Mixed Image Behavior** - Some sites load images in batches as you scroll. If you’re missing images, increase your `scroll_delay` or call multiple partial scrolls in a loop with JS code or hooks.
3. **Combining with Dynamic Wait** - If the site has a placeholder that only changes to a real image after a certain event, you might do `wait_for="css:img.loaded"` or a custom JS `wait_for`.
4. **Caching** - If `cache_mode` is enabled, repeated crawls might skip some network fetches. If you suspect caching is missing new images, set `cache_mode=CacheMode.BYPASS` for fresh fetches.
With **lazy-loading** support, **wait_for_images** , and **scan_full_page** settings, you can capture the entire gallery or feed of images you expect—even if the site only loads them as the user scrolls. Combine these with the standard media filtering and domain exclusion for a complete link & media handling strategy.
Site built with [MkDocs](https://docs.crawl4ai.com/advanced/lazy-loading/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/advanced/lazy-loading/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/advanced_multi-url-crawling.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/advanced/multi-url-crawling/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/advanced/multi-url-crawling/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/advanced/multi-url-crawling/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/advanced/multi-url-crawling/<#>)


  * [Home](https://docs.crawl4ai.com/advanced/multi-url-crawling/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/advanced/multi-url-crawling/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/advanced/multi-url-crawling/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/advanced/multi-url-crawling/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/advanced/multi-url-crawling/blog/>)
    * [Changelog](https://docs.crawl4ai.com/advanced/multi-url-crawling/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/advanced/multi-url-crawling/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/advanced/multi-url-crawling/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/multi-url-crawling/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/advanced/multi-url-crawling/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/advanced/multi-url-crawling/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/advanced/multi-url-crawling/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/advanced/multi-url-crawling/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/advanced/multi-url-crawling/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/advanced/multi-url-crawling/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/advanced/multi-url-crawling/core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/advanced/multi-url-crawling/<../advanced-features/>)
    * [File Downloading](https://docs.crawl4ai.com/advanced/multi-url-crawling/<../file-downloading/>)
    * [Lazy Loading](https://docs.crawl4ai.com/advanced/multi-url-crawling/<../lazy-loading/>)
    * [Hooks & Auth](https://docs.crawl4ai.com/advanced/multi-url-crawling/<../hooks-auth/>)
    * [Proxy & Security](https://docs.crawl4ai.com/advanced/multi-url-crawling/<../proxy-security/>)
    * [Session Management](https://docs.crawl4ai.com/advanced/multi-url-crawling/<../session-management/>)
    * Multi-URL Crawling
    * [Crawl Dispatcher](https://docs.crawl4ai.com/advanced/multi-url-crawling/<../crawl-dispatcher/>)
    * [Identity Based Crawling](https://docs.crawl4ai.com/advanced/multi-url-crawling/<../identity-based-crawling/>)
    * [SSL Certificate](https://docs.crawl4ai.com/advanced/multi-url-crawling/<../ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/advanced/multi-url-crawling/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/advanced/multi-url-crawling/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/advanced/multi-url-crawling/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/advanced/multi-url-crawling/extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/advanced/multi-url-crawling/api/async-webcrawler/>)
    * [arun()](https://docs.crawl4ai.com/advanced/multi-url-crawling/api/arun/>)
    * [arun_many()](https://docs.crawl4ai.com/advanced/multi-url-crawling/api/arun_many/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/multi-url-crawling/api/parameters/>)
    * [CrawlResult](https://docs.crawl4ai.com/advanced/multi-url-crawling/api/crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/advanced/multi-url-crawling/api/strategies/>)


  * [Advanced Multi-URL Crawling with Dispatchers](https://docs.crawl4ai.com/advanced/multi-url-crawling/<#advanced-multi-url-crawling-with-dispatchers>)
  * [1. Introduction](https://docs.crawl4ai.com/advanced/multi-url-crawling/<#1-introduction>)
  * [2. Core Components](https://docs.crawl4ai.com/advanced/multi-url-crawling/<#2-core-components>)
  * [3. Available Dispatchers](https://docs.crawl4ai.com/advanced/multi-url-crawling/<#3-available-dispatchers>)
  * [4. Usage Examples](https://docs.crawl4ai.com/advanced/multi-url-crawling/<#4-usage-examples>)
  * [5. Dispatch Results](https://docs.crawl4ai.com/advanced/multi-url-crawling/<#5-dispatch-results>)
  * [6. Summary](https://docs.crawl4ai.com/advanced/multi-url-crawling/<#6-summary>)


# Advanced Multi-URL Crawling with Dispatchers
> **Heads Up** : Crawl4AI supports advanced dispatchers for **parallel** or **throttled** crawling, providing dynamic rate limiting and memory usage checks. The built-in `arun_many()` function uses these dispatchers to handle concurrency efficiently.
## 1. Introduction
When crawling many URLs:
  * **Basic** : Use `arun()` in a loop (simple but less efficient)
  * **Better** : Use `arun_many()`, which efficiently handles multiple URLs with proper concurrency control
  * **Best** : Customize dispatcher behavior for your specific needs (memory management, rate limits, etc.)


**Why Dispatchers?**
  * **Adaptive** : Memory-based dispatchers can pause or slow down based on system resources
  * **Rate-limiting** : Built-in rate limiting with exponential backoff for 429/503 responses
  * **Real-time Monitoring** : Live dashboard of ongoing tasks, memory usage, and performance
  * **Flexibility** : Choose between memory-adaptive or semaphore-based concurrency


## 2. Core Components
### 2.1 Rate Limiter
```
class RateLimiter:
  def __init__(
    # Random delay range between requests
    base_delay: Tuple[float, float] = (1.0, 3.0), 
    # Maximum backoff delay
    max_delay: float = 60.0,            
    # Retries before giving up
    max_retries: int = 3,             
    # Status codes triggering backoff
    rate_limit_codes: List[int] = [429, 503]    
  )

```

Here’s the revised and simplified explanation of the **RateLimiter** , focusing on constructor parameters and adhering to your markdown style and mkDocs guidelines.
#### RateLimiter Constructor Parameters
The **RateLimiter** is a utility that helps manage the pace of requests to avoid overloading servers or getting blocked due to rate limits. It operates internally to delay requests and handle retries but can be configured using its constructor parameters.
**Parameters of the`RateLimiter` constructor:**
1. **`base_delay`**(`Tuple[float, float]` , default: `(1.0, 3.0)`) The range for a random delay (in seconds) between consecutive requests to the same domain.
  * A random delay is chosen between `base_delay[0]` and `base_delay[1]` for each request. 
  * This prevents sending requests at a predictable frequency, reducing the chances of triggering rate limits.


**Example:** If `base_delay = (2.0, 5.0)`, delays could be randomly chosen as `2.3s`, `4.1s`, etc.
2. **`max_delay`**(`float` , default: `60.0`) The maximum allowable delay when rate-limiting errors occur.
  * When servers return rate-limit responses (e.g., 429 or 503), the delay increases exponentially with jitter. 
  * The `max_delay` ensures the delay doesn’t grow unreasonably high, capping it at this value.


**Example:** For a `max_delay = 30.0`, even if backoff calculations suggest a delay of `45s`, it will cap at `30s`.
3. **`max_retries`**(`int` , default: `3`) The maximum number of retries for a request if rate-limiting errors occur.
  * After encountering a rate-limit response, the `RateLimiter` retries the request up to this number of times. 
  * If all retries fail, the request is marked as failed, and the process continues.


**Example:** If `max_retries = 3`, the system retries a failed request three times before giving up.
4. **`rate_limit_codes`**(`List[int]` , default: `[429, 503]`) A list of HTTP status codes that trigger the rate-limiting logic.
  * These status codes indicate the server is overwhelmed or actively limiting requests. 
  * You can customize this list to include other codes based on specific server behavior.


**Example:** If `rate_limit_codes = [429, 503, 504]`, the crawler will back off on these three error codes.
**How to Use the`RateLimiter` :**
Here’s an example of initializing and using a `RateLimiter` in your project:
```
from crawl4ai import RateLimiter
# Create a RateLimiter with custom settings
rate_limiter = RateLimiter(
  base_delay=(2.0, 4.0), # Random delay between 2-4 seconds
  max_delay=30.0,     # Cap delay at 30 seconds
  max_retries=5,     # Retry up to 5 times on rate-limiting errors
  rate_limit_codes=[429, 503] # Handle these HTTP status codes
)
# RateLimiter will handle delays and retries internally
# No additional setup is required for its operation

```

The `RateLimiter` integrates seamlessly with dispatchers like `MemoryAdaptiveDispatcher` and `SemaphoreDispatcher`, ensuring requests are paced correctly without user intervention. Its internal mechanisms manage delays and retries to avoid overwhelming servers while maximizing efficiency.
### 2.2 Crawler Monitor
The CrawlerMonitor provides real-time visibility into crawling operations:
```
from crawl4ai import CrawlerMonitor, DisplayMode
monitor = CrawlerMonitor(
  # Maximum rows in live display
  max_visible_rows=15,     
  # DETAILED or AGGREGATED view
  display_mode=DisplayMode.DETAILED 
)

```

**Display Modes** :
  1. **DETAILED** : Shows individual task status, memory usage, and timing
  2. **AGGREGATED** : Displays summary statistics and overall progress


## 3. Available Dispatchers
### 3.1 MemoryAdaptiveDispatcher (Default)
Automatically manages concurrency based on system memory usage:
```
from crawl4ai.async_dispatcher import MemoryAdaptiveDispatcher
dispatcher = MemoryAdaptiveDispatcher(
  memory_threshold_percent=90.0, # Pause if memory exceeds this
  check_interval=1.0,       # How often to check memory
  max_session_permit=10,     # Maximum concurrent tasks
  rate_limiter=RateLimiter(    # Optional rate limiting
    base_delay=(1.0, 2.0),
    max_delay=30.0,
    max_retries=2
  ),
  monitor=CrawlerMonitor(     # Optional monitoring
    max_visible_rows=15,
    display_mode=DisplayMode.DETAILED
  )
)

```

**Constructor Parameters:**
1. **`memory_threshold_percent`**(`float` , default: `90.0`) Specifies the memory usage threshold (as a percentage). If system memory usage exceeds this value, the dispatcher pauses crawling to prevent system overload.
2. **`check_interval`**(`float` , default: `1.0`) The interval (in seconds) at which the dispatcher checks system memory usage.
3. **`max_session_permit`**(`int` , default: `10`) The maximum number of concurrent crawling tasks allowed. This ensures resource limits are respected while maintaining concurrency.
4. **`memory_wait_timeout`**(`float` , default: `300.0`) Optional timeout (in seconds). If memory usage exceeds `memory_threshold_percent` for longer than this duration, a `MemoryError` is raised.
5. **`rate_limiter`**(`RateLimiter` , default: `None`) Optional rate-limiting logic to avoid server-side blocking (e.g., for handling 429 or 503 errors). See **RateLimiter** for details.
6. **`monitor`**(`CrawlerMonitor` , default: `None`) Optional monitoring for real-time task tracking and performance insights. See **CrawlerMonitor** for details.
### 3.2 SemaphoreDispatcher
Provides simple concurrency control with a fixed limit:
```
from crawl4ai.async_dispatcher import SemaphoreDispatcher
dispatcher = SemaphoreDispatcher(
  max_session_permit=20,     # Maximum concurrent tasks
  rate_limiter=RateLimiter(   # Optional rate limiting
    base_delay=(0.5, 1.0),
    max_delay=10.0
  ),
  monitor=CrawlerMonitor(    # Optional monitoring
    max_visible_rows=15,
    display_mode=DisplayMode.DETAILED
  )
)

```

**Constructor Parameters:**
1. **`max_session_permit`**(`int` , default: `20`) The maximum number of concurrent crawling tasks allowed, irrespective of semaphore slots.
2. **`rate_limiter`**(`RateLimiter` , default: `None`) Optional rate-limiting logic to avoid overwhelming servers. See **RateLimiter** for details.
3. **`monitor`**(`CrawlerMonitor` , default: `None`) Optional monitoring for tracking task progress and resource usage. See **CrawlerMonitor** for details.
## 4. Usage Examples
### 4.1 Batch Processing (Default)
```
async def crawl_batch():
  browser_config = BrowserConfig(headless=True, verbose=False)
  run_config = CrawlerRunConfig(
    cache_mode=CacheMode.BYPASS,
    stream=False # Default: get all results at once
  )
  dispatcher = MemoryAdaptiveDispatcher(
    memory_threshold_percent=70.0,
    check_interval=1.0,
    max_session_permit=10,
    monitor=CrawlerMonitor(
      display_mode=DisplayMode.DETAILED
    )
  )
  async with AsyncWebCrawler(config=browser_config) as crawler:
    # Get all results at once
    results = await crawler.arun_many(
      urls=urls,
      config=run_config,
      dispatcher=dispatcher
    )
    # Process all results after completion
    for result in results:
      if result.success:
        await process_result(result)
      else:
        print(f"Failed to crawl {result.url}: {result.error_message}")

```

**Review:** - **Purpose:** Executes a batch crawl with all URLs processed together after crawling is complete. - **Dispatcher:** Uses `MemoryAdaptiveDispatcher` to manage concurrency and system memory. - **Stream:** Disabled (`stream=False`), so all results are collected at once for post-processing. - **Best Use Case:** When you need to analyze results in bulk rather than individually during the crawl.
### 4.2 Streaming Mode
```
async def crawl_streaming():
  browser_config = BrowserConfig(headless=True, verbose=False)
  run_config = CrawlerRunConfig(
    cache_mode=CacheMode.BYPASS,
    stream=True # Enable streaming mode
  )
  dispatcher = MemoryAdaptiveDispatcher(
    memory_threshold_percent=70.0,
    check_interval=1.0,
    max_session_permit=10,
    monitor=CrawlerMonitor(
      display_mode=DisplayMode.DETAILED
    )
  )
  async with AsyncWebCrawler(config=browser_config) as crawler:
    # Process results as they become available
    async for result in await crawler.arun_many(
      urls=urls,
      config=run_config,
      dispatcher=dispatcher
    ):
      if result.success:
        # Process each result immediately
        await process_result(result)
      else:
        print(f"Failed to crawl {result.url}: {result.error_message}")

```

**Review:** - **Purpose:** Enables streaming to process results as soon as they’re available. - **Dispatcher:** Uses `MemoryAdaptiveDispatcher` for concurrency and memory management. - **Stream:** Enabled (`stream=True`), allowing real-time processing during crawling. - **Best Use Case:** When you need to act on results immediately, such as for real-time analytics or progressive data storage.
### 4.3 Semaphore-based Crawling
```
async def crawl_with_semaphore(urls):
  browser_config = BrowserConfig(headless=True, verbose=False)
  run_config = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)
  dispatcher = SemaphoreDispatcher(
    semaphore_count=5,
    rate_limiter=RateLimiter(
      base_delay=(0.5, 1.0),
      max_delay=10.0
    ),
    monitor=CrawlerMonitor(
      max_visible_rows=15,
      display_mode=DisplayMode.DETAILED
    )
  )
  async with AsyncWebCrawler(config=browser_config) as crawler:
    results = await crawler.arun_many(
      urls, 
      config=run_config,
      dispatcher=dispatcher
    )
    return results

```

**Review:** - **Purpose:** Uses `SemaphoreDispatcher` to limit concurrency with a fixed number of slots. - **Dispatcher:** Configured with a semaphore to control parallel crawling tasks. - **Rate Limiter:** Prevents servers from being overwhelmed by pacing requests. - **Best Use Case:** When you want precise control over the number of concurrent requests, independent of system memory.
### 4.4 Robots.txt Consideration
```
import asyncio
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode
async def main():
  urls = [
    "https://example1.com",
    "https://example2.com",
    "https://example3.com"
  ]
  config = CrawlerRunConfig(
    cache_mode=CacheMode.ENABLED,
    check_robots_txt=True, # Will respect robots.txt for each URL
    semaphore_count=3   # Max concurrent requests
  )
  async with AsyncWebCrawler() as crawler:
    async for result in crawler.arun_many(urls, config=config):
      if result.success:
        print(f"Successfully crawled {result.url}")
      elif result.status_code == 403 and "robots.txt" in result.error_message:
        print(f"Skipped {result.url} - blocked by robots.txt")
      else:
        print(f"Failed to crawl {result.url}: {result.error_message}")
if __name__ == "__main__":
  asyncio.run(main())

```

**Review:** - **Purpose:** Ensures compliance with `robots.txt` rules for ethical and legal web crawling. - **Configuration:** Set `check_robots_txt=True` to validate each URL against `robots.txt` before crawling. - **Dispatcher:** Handles requests with concurrency limits (`semaphore_count=3`). - **Best Use Case:** When crawling websites that strictly enforce robots.txt policies or for responsible crawling practices.
## 5. Dispatch Results
Each crawl result includes dispatch information:
```
@dataclass
class DispatchResult:
  task_id: str
  memory_usage: float
  peak_memory: float
  start_time: datetime
  end_time: datetime
  error_message: str = ""

```

Access via `result.dispatch_result`:
```
for result in results:
  if result.success:
    dr = result.dispatch_result
    print(f"URL: {result.url}")
    print(f"Memory: {dr.memory_usage:.1f}MB")
    print(f"Duration: {dr.end_time - dr.start_time}")

```

## 6. Summary
1. **Two Dispatcher Types** :
  * MemoryAdaptiveDispatcher (default): Dynamic concurrency based on memory
  * SemaphoreDispatcher: Fixed concurrency limit


2. **Optional Components** :
  * RateLimiter: Smart request pacing and backoff
  * CrawlerMonitor: Real-time progress visualization


3. **Key Benefits** :
  * Automatic memory management
  * Built-in rate limiting
  * Live progress monitoring
  * Flexible concurrency control


Choose the dispatcher that best fits your needs:
  * **MemoryAdaptiveDispatcher** : For large crawls or limited resources
  * **SemaphoreDispatcher** : For simple, fixed-concurrency scenarios


Site built with [MkDocs](https://docs.crawl4ai.com/advanced/multi-url-crawling/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/advanced/multi-url-crawling/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/advanced_proxy-security.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/advanced/proxy-security/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/advanced/proxy-security/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/advanced/proxy-security/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/advanced/proxy-security/<#>)


  * [Home](https://docs.crawl4ai.com/advanced/proxy-security/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/advanced/proxy-security/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/advanced/proxy-security/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/advanced/proxy-security/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/advanced/proxy-security/blog/>)
    * [Changelog](https://docs.crawl4ai.com/advanced/proxy-security/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/advanced/proxy-security/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/advanced/proxy-security/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/proxy-security/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/advanced/proxy-security/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/advanced/proxy-security/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/advanced/proxy-security/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/advanced/proxy-security/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/advanced/proxy-security/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/advanced/proxy-security/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/advanced/proxy-security/core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/advanced/proxy-security/<../advanced-features/>)
    * [File Downloading](https://docs.crawl4ai.com/advanced/proxy-security/<../file-downloading/>)
    * [Lazy Loading](https://docs.crawl4ai.com/advanced/proxy-security/<../lazy-loading/>)
    * [Hooks & Auth](https://docs.crawl4ai.com/advanced/proxy-security/<../hooks-auth/>)
    * Proxy & Security
    * [Session Management](https://docs.crawl4ai.com/advanced/proxy-security/<../session-management/>)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/advanced/proxy-security/<../multi-url-crawling/>)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/advanced/proxy-security/<../crawl-dispatcher/>)
    * [Identity Based Crawling](https://docs.crawl4ai.com/advanced/proxy-security/<../identity-based-crawling/>)
    * [SSL Certificate](https://docs.crawl4ai.com/advanced/proxy-security/<../ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/advanced/proxy-security/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/advanced/proxy-security/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/advanced/proxy-security/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/advanced/proxy-security/extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/advanced/proxy-security/api/async-webcrawler/>)
    * [arun()](https://docs.crawl4ai.com/advanced/proxy-security/api/arun/>)
    * [arun_many()](https://docs.crawl4ai.com/advanced/proxy-security/api/arun_many/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/proxy-security/api/parameters/>)
    * [CrawlResult](https://docs.crawl4ai.com/advanced/proxy-security/api/crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/advanced/proxy-security/api/strategies/>)


  * [Proxy](https://docs.crawl4ai.com/advanced/proxy-security/<#proxy>)
  * [Basic Proxy Setup](https://docs.crawl4ai.com/advanced/proxy-security/<#basic-proxy-setup>)
  * [Authenticated Proxy](https://docs.crawl4ai.com/advanced/proxy-security/<#authenticated-proxy>)
  * [Rotating Proxies](https://docs.crawl4ai.com/advanced/proxy-security/<#rotating-proxies>)


# Proxy
## Basic Proxy Setup
Simple proxy configuration with `BrowserConfig`:
```
from crawl4ai.async_configs import BrowserConfig
# Using proxy URL
browser_config = BrowserConfig(proxy="http://proxy.example.com:8080")
async with AsyncWebCrawler(config=browser_config) as crawler:
  result = await crawler.arun(url="https://example.com")
# Using SOCKS proxy
browser_config = BrowserConfig(proxy="socks5://proxy.example.com:1080")
async with AsyncWebCrawler(config=browser_config) as crawler:
  result = await crawler.arun(url="https://example.com")

```

## Authenticated Proxy
Use an authenticated proxy with `BrowserConfig`:
```
from crawl4ai.async_configs import BrowserConfig
proxy_config = {
  "server": "http://proxy.example.com:8080",
  "username": "user",
  "password": "pass"
}
browser_config = BrowserConfig(proxy_config=proxy_config)
async with AsyncWebCrawler(config=browser_config) as crawler:
  result = await crawler.arun(url="https://example.com")

```

Here's the corrected documentation:
## Rotating Proxies
Example using a proxy rotation service dynamically:
```
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig
async def get_next_proxy():
  # Your proxy rotation logic here
  return {"server": "http://next.proxy.com:8080"}
async def main():
  browser_config = BrowserConfig()
  run_config = CrawlerRunConfig()
  async with AsyncWebCrawler(config=browser_config) as crawler:
    # For each URL, create a new run config with different proxy
    for url in urls:
      proxy = await get_next_proxy()
      # Clone the config and update proxy - this creates a new browser context
      current_config = run_config.clone(proxy_config=proxy)
      result = await crawler.arun(url=url, config=current_config)
if __name__ == "__main__":
  import asyncio
  asyncio.run(main())

```

Site built with [MkDocs](https://docs.crawl4ai.com/advanced/proxy-security/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/advanced/proxy-security/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/advanced_session-management.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/advanced/session-management/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/advanced/session-management/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/advanced/session-management/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/advanced/session-management/<#>)


  * [Home](https://docs.crawl4ai.com/advanced/session-management/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/advanced/session-management/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/advanced/session-management/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/advanced/session-management/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/advanced/session-management/blog/>)
    * [Changelog](https://docs.crawl4ai.com/advanced/session-management/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/advanced/session-management/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/advanced/session-management/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/session-management/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/advanced/session-management/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/advanced/session-management/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/advanced/session-management/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/advanced/session-management/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/advanced/session-management/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/advanced/session-management/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/advanced/session-management/core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/advanced/session-management/<../advanced-features/>)
    * [File Downloading](https://docs.crawl4ai.com/advanced/session-management/<../file-downloading/>)
    * [Lazy Loading](https://docs.crawl4ai.com/advanced/session-management/<../lazy-loading/>)
    * [Hooks & Auth](https://docs.crawl4ai.com/advanced/session-management/<../hooks-auth/>)
    * [Proxy & Security](https://docs.crawl4ai.com/advanced/session-management/<../proxy-security/>)
    * Session Management
    * [Multi-URL Crawling](https://docs.crawl4ai.com/advanced/session-management/<../multi-url-crawling/>)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/advanced/session-management/<../crawl-dispatcher/>)
    * [Identity Based Crawling](https://docs.crawl4ai.com/advanced/session-management/<../identity-based-crawling/>)
    * [SSL Certificate](https://docs.crawl4ai.com/advanced/session-management/<../ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/advanced/session-management/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/advanced/session-management/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/advanced/session-management/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/advanced/session-management/extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/advanced/session-management/api/async-webcrawler/>)
    * [arun()](https://docs.crawl4ai.com/advanced/session-management/api/arun/>)
    * [arun_many()](https://docs.crawl4ai.com/advanced/session-management/api/arun_many/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/session-management/api/parameters/>)
    * [CrawlResult](https://docs.crawl4ai.com/advanced/session-management/api/crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/advanced/session-management/api/strategies/>)


  * [Session Management](https://docs.crawl4ai.com/advanced/session-management/<#session-management>)
  * [Basic Session Usage](https://docs.crawl4ai.com/advanced/session-management/<#basic-session-usage>)
  * [Dynamic Content with Sessions](https://docs.crawl4ai.com/advanced/session-management/<#dynamic-content-with-sessions>)
  * [Example 1: Basic Session-Based Crawling](https://docs.crawl4ai.com/advanced/session-management/<#example-1-basic-session-based-crawling>)
  * [Advanced Technique 1: Custom Execution Hooks](https://docs.crawl4ai.com/advanced/session-management/<#advanced-technique-1-custom-execution-hooks>)
  * [Advanced Technique 2: Integrated JavaScript Execution and Waiting](https://docs.crawl4ai.com/advanced/session-management/<#advanced-technique-2-integrated-javascript-execution-and-waiting>)


# Session Management
Session management in Crawl4AI is a powerful feature that allows you to maintain state across multiple requests, making it particularly suitable for handling complex multi-step crawling tasks. It enables you to reuse the same browser tab (or page object) across sequential actions and crawls, which is beneficial for:
  * **Performing JavaScript actions before and after crawling.**
  * **Executing multiple sequential crawls faster** without needing to reopen tabs or allocate memory repeatedly.


**Note:** This feature is designed for sequential workflows and is not suitable for parallel operations.
#### Basic Session Usage
Use `BrowserConfig` and `CrawlerRunConfig` to maintain state with a `session_id`:
```
from crawl4ai.async_configs import BrowserConfig, CrawlerRunConfig
async with AsyncWebCrawler() as crawler:
  session_id = "my_session"
  # Define configurations
  config1 = CrawlerRunConfig(
    url="https://example.com/page1", session_id=session_id
  )
  config2 = CrawlerRunConfig(
    url="https://example.com/page2", session_id=session_id
  )
  # First request
  result1 = await crawler.arun(config=config1)
  # Subsequent request using the same session
  result2 = await crawler.arun(config=config2)
  # Clean up when done
  await crawler.crawler_strategy.kill_session(session_id)

```

#### Dynamic Content with Sessions
Here's an example of crawling GitHub commits across multiple pages while preserving session state:
```
from crawl4ai.async_configs import CrawlerRunConfig
from crawl4ai.extraction_strategy import JsonCssExtractionStrategy
from crawl4ai.cache_context import CacheMode
async def crawl_dynamic_content():
  async with AsyncWebCrawler() as crawler:
    session_id = "github_commits_session"
    url = "https://github.com/microsoft/TypeScript/commits/main"
    all_commits = []
    # Define extraction schema
    schema = {
      "name": "Commit Extractor",
      "baseSelector": "li.Box-sc-g0xbh4-0",
      "fields": [{
        "name": "title", "selector": "h4.markdown-title", "type": "text"
      }],
    }
    extraction_strategy = JsonCssExtractionStrategy(schema)
    # JavaScript and wait configurations
    js_next_page = """document.querySelector('a[data-testid="pagination-next-button"]').click();"""
    wait_for = """() => document.querySelectorAll('li.Box-sc-g0xbh4-0').length > 0"""
    # Crawl multiple pages
    for page in range(3):
      config = CrawlerRunConfig(
        url=url,
        session_id=session_id,
        extraction_strategy=extraction_strategy,
        js_code=js_next_page if page > 0 else None,
        wait_for=wait_for if page > 0 else None,
        js_only=page > 0,
        cache_mode=CacheMode.BYPASS
      )
      result = await crawler.arun(config=config)
      if result.success:
        commits = json.loads(result.extracted_content)
        all_commits.extend(commits)
        print(f"Page {page + 1}: Found {len(commits)} commits")
    # Clean up session
    await crawler.crawler_strategy.kill_session(session_id)
    return all_commits

```

## Example 1: Basic Session-Based Crawling
A simple example using session-based crawling:
```
import asyncio
from crawl4ai.async_configs import BrowserConfig, CrawlerRunConfig
from crawl4ai.cache_context import CacheMode
async def basic_session_crawl():
  async with AsyncWebCrawler() as crawler:
    session_id = "dynamic_content_session"
    url = "https://example.com/dynamic-content"
    for page in range(3):
      config = CrawlerRunConfig(
        url=url,
        session_id=session_id,
        js_code="document.querySelector('.load-more-button').click();" if page > 0 else None,
        css_selector=".content-item",
        cache_mode=CacheMode.BYPASS
      )
      result = await crawler.arun(config=config)
      print(f"Page {page + 1}: Found {result.extracted_content.count('.content-item')} items")
    await crawler.crawler_strategy.kill_session(session_id)
asyncio.run(basic_session_crawl())

```

This example shows: 1. Reusing the same `session_id` across multiple requests. 2. Executing JavaScript to load more content dynamically. 3. Properly closing the session to free resources.
## Advanced Technique 1: Custom Execution Hooks
> Warning: You might feel confused by the end of the next few examples 😅, so make sure you are comfortable with the order of the parts before you start this.
Use custom hooks to handle complex scenarios, such as waiting for content to load dynamically:
```
async def advanced_session_crawl_with_hooks():
  first_commit = ""
  async def on_execution_started(page):
    nonlocal first_commit
    try:
      while True:
        await page.wait_for_selector("li.commit-item h4")
        commit = await page.query_selector("li.commit-item h4")
        commit = await commit.evaluate("(element) => element.textContent").strip()
        if commit and commit != first_commit:
          first_commit = commit
          break
        await asyncio.sleep(0.5)
    except Exception as e:
      print(f"Warning: New content didn't appear: {e}")
  async with AsyncWebCrawler() as crawler:
    session_id = "commit_session"
    url = "https://github.com/example/repo/commits/main"
    crawler.crawler_strategy.set_hook("on_execution_started", on_execution_started)
    js_next_page = """document.querySelector('a.pagination-next').click();"""
    for page in range(3):
      config = CrawlerRunConfig(
        url=url,
        session_id=session_id,
        js_code=js_next_page if page > 0 else None,
        css_selector="li.commit-item",
        js_only=page > 0,
        cache_mode=CacheMode.BYPASS
      )
      result = await crawler.arun(config=config)
      print(f"Page {page + 1}: Found {len(result.extracted_content)} commits")
    await crawler.crawler_strategy.kill_session(session_id)
asyncio.run(advanced_session_crawl_with_hooks())

```

This technique ensures new content loads before the next action.
## Advanced Technique 2: Integrated JavaScript Execution and Waiting
Combine JavaScript execution and waiting logic for concise handling of dynamic content:
```
async def integrated_js_and_wait_crawl():
  async with AsyncWebCrawler() as crawler:
    session_id = "integrated_session"
    url = "https://github.com/example/repo/commits/main"
    js_next_page_and_wait = """
    (async () => {
      const getCurrentCommit = () => document.querySelector('li.commit-item h4').textContent.trim();
      const initialCommit = getCurrentCommit();
      document.querySelector('a.pagination-next').click();
      while (getCurrentCommit() === initialCommit) {
        await new Promise(resolve => setTimeout(resolve, 100));
      }
    })();
    """
    for page in range(3):
      config = CrawlerRunConfig(
        url=url,
        session_id=session_id,
        js_code=js_next_page_and_wait if page > 0 else None,
        css_selector="li.commit-item",
        js_only=page > 0,
        cache_mode=CacheMode.BYPASS
      )
      result = await crawler.arun(config=config)
      print(f"Page {page + 1}: Found {len(result.extracted_content)} commits")
    await crawler.crawler_strategy.kill_session(session_id)
asyncio.run(integrated_js_and_wait_crawl())

```

#### Common Use Cases for Sessions
1. **Authentication Flows** : Login and interact with secured pages.
2. **Pagination Handling** : Navigate through multiple pages.
3. **Form Submissions** : Fill forms, submit, and process results.
4. **Multi-step Processes** : Complete workflows that span multiple actions.
5. **Dynamic Content Navigation** : Handle JavaScript-rendered or event-triggered content.
Site built with [MkDocs](https://docs.crawl4ai.com/advanced/session-management/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/advanced/session-management/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/advanced_ssl-certificate.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/advanced/ssl-certificate/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/advanced/ssl-certificate/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/advanced/ssl-certificate/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/advanced/ssl-certificate/<#>)


  * [Home](https://docs.crawl4ai.com/advanced/ssl-certificate/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/advanced/ssl-certificate/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/advanced/ssl-certificate/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/advanced/ssl-certificate/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/advanced/ssl-certificate/blog/>)
    * [Changelog](https://docs.crawl4ai.com/advanced/ssl-certificate/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/advanced/ssl-certificate/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/advanced/ssl-certificate/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/ssl-certificate/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/advanced/ssl-certificate/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/advanced/ssl-certificate/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/advanced/ssl-certificate/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/advanced/ssl-certificate/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/advanced/ssl-certificate/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/advanced/ssl-certificate/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/advanced/ssl-certificate/core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/advanced/ssl-certificate/<../advanced-features/>)
    * [File Downloading](https://docs.crawl4ai.com/advanced/ssl-certificate/<../file-downloading/>)
    * [Lazy Loading](https://docs.crawl4ai.com/advanced/ssl-certificate/<../lazy-loading/>)
    * [Hooks & Auth](https://docs.crawl4ai.com/advanced/ssl-certificate/<../hooks-auth/>)
    * [Proxy & Security](https://docs.crawl4ai.com/advanced/ssl-certificate/<../proxy-security/>)
    * [Session Management](https://docs.crawl4ai.com/advanced/ssl-certificate/<../session-management/>)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/advanced/ssl-certificate/<../multi-url-crawling/>)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/advanced/ssl-certificate/<../crawl-dispatcher/>)
    * [Identity Based Crawling](https://docs.crawl4ai.com/advanced/ssl-certificate/<../identity-based-crawling/>)
    * SSL Certificate
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/advanced/ssl-certificate/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/advanced/ssl-certificate/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/advanced/ssl-certificate/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/advanced/ssl-certificate/extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/advanced/ssl-certificate/api/async-webcrawler/>)
    * [arun()](https://docs.crawl4ai.com/advanced/ssl-certificate/api/arun/>)
    * [arun_many()](https://docs.crawl4ai.com/advanced/ssl-certificate/api/arun_many/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/advanced/ssl-certificate/api/parameters/>)
    * [CrawlResult](https://docs.crawl4ai.com/advanced/ssl-certificate/api/crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/advanced/ssl-certificate/api/strategies/>)


  * [SSLCertificate Reference](https://docs.crawl4ai.com/advanced/ssl-certificate/<#sslcertificate-reference>)
  * [1. Overview](https://docs.crawl4ai.com/advanced/ssl-certificate/<#1-overview>)
  * [2. Construction & Fetching](https://docs.crawl4ai.com/advanced/ssl-certificate/<#2-construction-fetching>)
  * [3. Common Properties](https://docs.crawl4ai.com/advanced/ssl-certificate/<#3-common-properties>)
  * [4. Export Methods](https://docs.crawl4ai.com/advanced/ssl-certificate/<#4-export-methods>)
  * [5. Example Usage in Crawl4AI](https://docs.crawl4ai.com/advanced/ssl-certificate/<#5-example-usage-in-crawl4ai>)
  * [6. Notes & Best Practices](https://docs.crawl4ai.com/advanced/ssl-certificate/<#6-notes-best-practices>)


# `SSLCertificate` Reference
The **`SSLCertificate`**class encapsulates an SSL certificate’s data and allows exporting it in various formats (PEM, DER, JSON, or text). It’s used within**Crawl4AI** whenever you set **`fetch_ssl_certificate=True`**in your**`CrawlerRunConfig`**.
## 1. Overview
**Location** : `crawl4ai/ssl_certificate.py`
```
class SSLCertificate:
  """
  Represents an SSL certificate with methods to export in various formats.
  Main Methods:
  - from_url(url, timeout=10)
  - from_file(file_path)
  - from_binary(binary_data)
  - to_json(filepath=None)
  - to_pem(filepath=None)
  - to_der(filepath=None)
  ...
  Common Properties:
  - issuer
  - subject
  - valid_from
  - valid_until
  - fingerprint
  """

```

### Typical Use Case
  1. You **enable** certificate fetching in your crawl by: 
```
CrawlerRunConfig(fetch_ssl_certificate=True, ...)

```

  2. After `arun()`, if `result.ssl_certificate` is present, it’s an instance of **`SSLCertificate`**.
  3. You can **read** basic properties (issuer, subject, validity) or **export** them in multiple formats.


## 2. Construction & Fetching
### 2.1 **`from_url(url, timeout=10)`**
Manually load an SSL certificate from a given URL (port 443). Typically used internally, but you can call it directly if you want:
```
cert = SSLCertificate.from_url("https://example.com")
if cert:
  print("Fingerprint:", cert.fingerprint)

```

### 2.2 **`from_file(file_path)`**
Load from a file containing certificate data in ASN.1 or DER. Rarely needed unless you have local cert files:
```
cert = SSLCertificate.from_file("/path/to/cert.der")

```

### 2.3 **`from_binary(binary_data)`**
Initialize from raw binary. E.g., if you captured it from a socket or another source:
```
cert = SSLCertificate.from_binary(raw_bytes)

```

## 3. Common Properties
After obtaining a **`SSLCertificate`**instance (e.g.`result.ssl_certificate` from a crawl), you can read:
1. **`issuer`**_(dict)_ - E.g. `{"CN": "My Root CA", "O": "..."}` 2. **`subject`**_(dict)_ - E.g. `{"CN": "example.com", "O": "ExampleOrg"}` 3. **`valid_from`**_(str)_ - NotBefore date/time. Often in ASN.1/UTC format. 4. **`valid_until`**_(str)_ - NotAfter date/time. 5. **`fingerprint`**_(str)_ - The SHA-256 digest (lowercase hex). - E.g. `"d14d2e..."`
## 4. Export Methods
Once you have a **`SSLCertificate`**object, you can**export** or **inspect** it:
### 4.1 **`to_json(filepath=None)`→`Optional[str]`**
  * Returns a JSON string containing the parsed certificate fields. 
  * If `filepath` is provided, saves it to disk instead, returning `None`.


**Usage** : 
```
json_data = cert.to_json() # returns JSON string
cert.to_json("certificate.json") # writes file, returns None

```

### 4.2 **`to_pem(filepath=None)`→`Optional[str]`**
  * Returns a PEM-encoded string (common for web servers). 
  * If `filepath` is provided, saves it to disk instead.


```
pem_str = cert.to_pem()       # in-memory PEM string
cert.to_pem("/path/to/cert.pem")   # saved to file

```

### 4.3 **`to_der(filepath=None)`→`Optional[bytes]`**
  * Returns the original DER (binary ASN.1) bytes. 
  * If `filepath` is specified, writes the bytes there instead.


```
der_bytes = cert.to_der()
cert.to_der("certificate.der")

```

### 4.4 (Optional) **`export_as_text()`**
  * If you see a method like `export_as_text()`, it typically returns an OpenSSL-style textual representation. 
  * Not always needed, but can help for debugging or manual inspection.


## 5. Example Usage in Crawl4AI
Below is a minimal sample showing how the crawler obtains an SSL cert from a site, then reads or exports it. The code snippet:
```
import asyncio
import os
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode
async def main():
  tmp_dir = "tmp"
  os.makedirs(tmp_dir, exist_ok=True)
  config = CrawlerRunConfig(
    fetch_ssl_certificate=True,
    cache_mode=CacheMode.BYPASS
  )
  async with AsyncWebCrawler() as crawler:
    result = await crawler.arun("https://example.com", config=config)
    if result.success and result.ssl_certificate:
      cert = result.ssl_certificate
      # 1. Basic Info
      print("Issuer CN:", cert.issuer.get("CN", ""))
      print("Valid until:", cert.valid_until)
      print("Fingerprint:", cert.fingerprint)
      # 2. Export
      cert.to_json(os.path.join(tmp_dir, "certificate.json"))
      cert.to_pem(os.path.join(tmp_dir, "certificate.pem"))
      cert.to_der(os.path.join(tmp_dir, "certificate.der"))
if __name__ == "__main__":
  asyncio.run(main())

```

## 6. Notes & Best Practices
1. **Timeout** : `SSLCertificate.from_url` internally uses a default **10s** socket connect and wraps SSL. 2. **Binary Form** : The certificate is loaded in ASN.1 (DER) form, then re-parsed by `OpenSSL.crypto`. 3. **Validation** : This does **not** validate the certificate chain or trust store. It only fetches and parses. 4. **Integration** : Within Crawl4AI, you typically just set `fetch_ssl_certificate=True` in `CrawlerRunConfig`; the final result’s `ssl_certificate` is automatically built. 5. **Export** : If you need to store or analyze a cert, the `to_json` and `to_pem` are quite universal.
### Summary
  * **`SSLCertificate`**is a convenience class for capturing and exporting the**TLS certificate** from your crawled site(s). 
  * Common usage is in the **`CrawlResult.ssl_certificate`**field, accessible after setting`fetch_ssl_certificate=True`. 
  * Offers quick access to essential certificate details (`issuer`, `subject`, `fingerprint`) and is easy to export (PEM, DER, JSON) for further analysis or server usage.


Use it whenever you need **insight** into a site’s certificate or require some form of cryptographic or compliance check.
Site built with [MkDocs](https://docs.crawl4ai.com/advanced/ssl-certificate/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/advanced/ssl-certificate/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/agents.md
================
[ Skip to content ](https://ai.pydantic.dev/agents/<#introduction>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/agents/<..> "PydanticAI")
PydanticAI 
Agents 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/agents/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/agents/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/agents/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/agents/<..>)
  * [ Installation  ](https://ai.pydantic.dev/agents/<../install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/agents/<../help/>)
  * [ Contributing  ](https://ai.pydantic.dev/agents/<../contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/agents/<../troubleshooting/>)
  * Documentation  Documentation 
    * Agents  [ Agents  ](https://ai.pydantic.dev/agents/<./>) Table of contents 
      * [ Introduction  ](https://ai.pydantic.dev/agents/<#introduction>)
      * [ Running Agents  ](https://ai.pydantic.dev/agents/<#running-agents>)
        * [ Additional Configuration  ](https://ai.pydantic.dev/agents/<#additional-configuration>)
          * [ Usage Limits  ](https://ai.pydantic.dev/agents/<#usage-limits>)
          * [ Model (Run) Settings  ](https://ai.pydantic.dev/agents/<#model-run-settings>)
        * [ Model specific settings  ](https://ai.pydantic.dev/agents/<#model-specific-settings>)
      * [ Runs vs. Conversations  ](https://ai.pydantic.dev/agents/<#runs-vs-conversations>)
      * [ Type safe by design  ](https://ai.pydantic.dev/agents/<#static-type-checking>)
      * [ System Prompts  ](https://ai.pydantic.dev/agents/<#system-prompts>)
      * [ Reflection and self-correction  ](https://ai.pydantic.dev/agents/<#reflection-and-self-correction>)
      * [ Model errors  ](https://ai.pydantic.dev/agents/<#model-errors>)
    * [ Models  ](https://ai.pydantic.dev/agents/<../models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/agents/<../dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/agents/<../tools/>)
    * [ Results  ](https://ai.pydantic.dev/agents/<../results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/agents/<../message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/agents/<../testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/agents/<../logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/agents/<../multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/agents/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/agents/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/agents/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/agents/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/agents/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/agents/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/agents/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/agents/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/agents/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/agents/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/agents/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/agents/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/agents/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/agents/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/agents/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/agents/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/agents/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/agents/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/agents/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/agents/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/agents/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/agents/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/agents/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/agents/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/agents/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/agents/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/agents/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/agents/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/agents/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/agents/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/agents/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/agents/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/agents/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/agents/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/agents/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Introduction  ](https://ai.pydantic.dev/agents/<#introduction>)
  * [ Running Agents  ](https://ai.pydantic.dev/agents/<#running-agents>)
    * [ Additional Configuration  ](https://ai.pydantic.dev/agents/<#additional-configuration>)
      * [ Usage Limits  ](https://ai.pydantic.dev/agents/<#usage-limits>)
      * [ Model (Run) Settings  ](https://ai.pydantic.dev/agents/<#model-run-settings>)
    * [ Model specific settings  ](https://ai.pydantic.dev/agents/<#model-specific-settings>)
  * [ Runs vs. Conversations  ](https://ai.pydantic.dev/agents/<#runs-vs-conversations>)
  * [ Type safe by design  ](https://ai.pydantic.dev/agents/<#static-type-checking>)
  * [ System Prompts  ](https://ai.pydantic.dev/agents/<#system-prompts>)
  * [ Reflection and self-correction  ](https://ai.pydantic.dev/agents/<#reflection-and-self-correction>)
  * [ Model errors  ](https://ai.pydantic.dev/agents/<#model-errors>)


  1. [ Introduction  ](https://ai.pydantic.dev/agents/<..>)
  2. [ Documentation  ](https://ai.pydantic.dev/agents/<./>)


# Agents
## Introduction
Agents are PydanticAI's primary interface for interacting with LLMs.
In some use cases a single Agent will control an entire application or component, but multiple agents can also interact to embody more complex workflows.
The `Agent`[](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.Agent>) class has full API documentation, but conceptually you can think of an agent as a container for:
**Component** | **Description**  
---|---  
[System prompt(s)](https://ai.pydantic.dev/agents/<#system-prompts>) | A set of instructions for the LLM written by the developer.  
[Function tool(s)](https://ai.pydantic.dev/agents/<../tools/>) | Functions that the LLM may call to get information while generating a response.  
[Structured result type](https://ai.pydantic.dev/agents/<../results/>) | The structured datatype the LLM must return at the end of a run, if specified.  
[Dependency type constraint](https://ai.pydantic.dev/agents/<../dependencies/>) | System prompt functions, tools, and result validators may all use dependencies when they're run.  
[LLM model](https://ai.pydantic.dev/agents/<../api/models/base/>) | Optional default LLM model associated with the agent. Can also be specified when running the agent.  
[Model Settings](https://ai.pydantic.dev/agents/<#additional-configuration>) | Optional default model settings to help fine tune requests. Can also be specified when running the agent.  
In typing terms, agents are generic in their dependency and result types, e.g., an agent which required dependencies of type `Foobar` and returned results of type `list[str]` would have type `Agent[Foobar, list[str]]`. In practice, you shouldn't need to care about this, it should just mean your IDE can tell you when you have the right type, and if you choose to use [static type checking](https://ai.pydantic.dev/agents/<#static-type-checking>) it should work well with PydanticAI.
Here's a toy example of an agent that simulates a roulette wheel:
roulette_wheel.py```
from pydantic_ai import Agent, RunContext
roulette_agent = Agent( 
Create an agent, which expects an integer dependency and returns a boolean result. This agent will have type Agent[int, bool].
[](https://ai.pydantic.dev/agents/<#__code_0_annotation_1>)
  'openai:gpt-4o',
  deps_type=int,
  result_type=bool,
  system_prompt=(
    'Use the `roulette_wheel` function to see if the '
    'customer has won based on the number they provide.'
  ),
)

@roulette_agent.tool
async def roulette_wheel(ctx: RunContext[int], square: int) -> str: 
Define a tool that checks if the square is a winner. Here RunContext[](https://ai.pydantic.dev/agents/<../api/tools/#pydantic_ai.tools.RunContext>) is parameterized with the dependency type int; if you got the dependency type wrong you'd get a typing error.
[](https://ai.pydantic.dev/agents/<#__code_0_annotation_2>)
"""check if the square is a winner"""
  return 'winner' if square == ctx.deps else 'loser'

# Run the agent
success_number = 18 
In reality, you might want to use a random number here e.g. random.randint(0, 36).
[](https://ai.pydantic.dev/agents/<#__code_0_annotation_3>)
result = roulette_agent.run_sync('Put my money on square eighteen', deps=success_number)
print(result.data) 
result.data will be a boolean indicating if the square is a winner. Pydantic performs the result validation, it'll be typed as a bool since its type is derived from the result_type generic parameter of the agent.
[](https://ai.pydantic.dev/agents/<#__code_0_annotation_4>)
#> True
result = roulette_agent.run_sync('I bet five is the winner', deps=success_number)
print(result.data)
#> False

```

Agents are designed for reuse, like FastAPI Apps
Agents are intended to be instantiated once (frequently as module globals) and reused throughout your application, similar to a small [FastAPI](https://ai.pydantic.dev/agents/<https:/fastapi.tiangolo.com/reference/fastapi/#fastapi.FastAPI>) app or an [APIRouter](https://ai.pydantic.dev/agents/<https:/fastapi.tiangolo.com/reference/apirouter/#fastapi.APIRouter>).
## Running Agents
There are three ways to run an agent:
  1. `agent.run()`[](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.Agent.run>) — a coroutine which returns a `RunResult`[](https://ai.pydantic.dev/agents/<../api/result/#pydantic_ai.result.RunResult>) containing a completed response
  2. `agent.run_sync()`[](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.Agent.run_sync>) — a plain, synchronous function which returns a `RunResult`[](https://ai.pydantic.dev/agents/<../api/result/#pydantic_ai.result.RunResult>) containing a completed response (internally, this just calls `loop.run_until_complete(self.run())`)
  3. `agent.run_stream()`[](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.Agent.run_stream>) — a coroutine which returns a `StreamedRunResult`[](https://ai.pydantic.dev/agents/<../api/result/#pydantic_ai.result.StreamedRunResult>), which contains methods to stream a response as an async iterable


Here's a simple example demonstrating all three:
run_agent.py```
from pydantic_ai import Agent
agent = Agent('openai:gpt-4o')
result_sync = agent.run_sync('What is the capital of Italy?')
print(result_sync.data)
#> Rome

async def main():
  result = await agent.run('What is the capital of France?')
  print(result.data)
  #> Paris
  async with agent.run_stream('What is the capital of the UK?') as response:
    print(await response.get_data())
    #> London

```

_(This example is complete, it can be run "as is" — you'll need to add`asyncio.run(main())` to run `main`)_
You can also pass messages from previous runs to continue a conversation or provide context, as described in [Messages and Chat History](https://ai.pydantic.dev/agents/<../message-history/>).
### Additional Configuration
#### Usage Limits
PydanticAI offers a `UsageLimits`[](https://ai.pydantic.dev/agents/<../api/usage/#pydantic_ai.usage.UsageLimits>) structure to help you limit your usage (tokens and/or requests) on model runs.
You can apply these settings by passing the `usage_limits` argument to the `run{_sync,_stream}` functions.
Consider the following example, where we limit the number of response tokens:
```
from pydantic_ai import Agent
from pydantic_ai.exceptions import UsageLimitExceeded
from pydantic_ai.usage import UsageLimits
agent = Agent('anthropic:claude-3-5-sonnet-latest')
result_sync = agent.run_sync(
  'What is the capital of Italy? Answer with just the city.',
  usage_limits=UsageLimits(response_tokens_limit=10),
)
print(result_sync.data)
#> Rome
print(result_sync.usage())
"""
Usage(requests=1, request_tokens=62, response_tokens=1, total_tokens=63, details=None)
"""
try:
  result_sync = agent.run_sync(
    'What is the capital of Italy? Answer with a paragraph.',
    usage_limits=UsageLimits(response_tokens_limit=10),
  )
except UsageLimitExceeded as e:
  print(e)
  #> Exceeded the response_tokens_limit of 10 (response_tokens=32)

```

Restricting the number of requests can be useful in preventing infinite loops or excessive tool calling:
```
from typing_extensions import TypedDict
from pydantic_ai import Agent, ModelRetry
from pydantic_ai.exceptions import UsageLimitExceeded
from pydantic_ai.usage import UsageLimits

class NeverResultType(TypedDict):
"""
  Never ever coerce data to this type.
  """
  never_use_this: str

agent = Agent(
  'anthropic:claude-3-5-sonnet-latest',
  retries=3,
  result_type=NeverResultType,
  system_prompt='Any time you get a response, call the `infinite_retry_tool` to produce another response.',
)

@agent.tool_plain(retries=5) 
This tool has the ability to retry 5 times before erroring, simulating a tool that might get stuck in a loop.
[](https://ai.pydantic.dev/agents/<#__code_3_annotation_1>)
def infinite_retry_tool() -> int:
  raise ModelRetry('Please try again.')

try:
  result_sync = agent.run_sync(
    'Begin infinite retry loop!', usage_limits=UsageLimits(request_limit=3) 
This run will error after 3 requests, preventing the infinite tool calling.
[](https://ai.pydantic.dev/agents/<#__code_3_annotation_2>)
  )
except UsageLimitExceeded as e:
  print(e)
  #> The next request would exceed the request_limit of 3

```

Note
This is especially relevant if you're registered a lot of tools, `request_limit` can be used to prevent the model from choosing to make too many of these calls.
#### Model (Run) Settings
PydanticAI offers a `settings.ModelSettings`[](https://ai.pydantic.dev/agents/<../api/settings/#pydantic_ai.settings.ModelSettings>) structure to help you fine tune your requests. This structure allows you to configure common parameters that influence the model's behavior, such as `temperature`, `max_tokens`, `timeout`, and more.
There are two ways to apply these settings: 1. Passing to `run{_sync,_stream}` functions via the `model_settings` argument. This allows for fine-tuning on a per-request basis. 2. Setting during `Agent`[](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.Agent>) initialization via the `model_settings` argument. These settings will be applied by default to all subsequent run calls using said agent. However, `model_settings` provided during a specific run call will override the agent's default settings.
For example, if you'd like to set the `temperature` setting to `0.0` to ensure less random behavior, you can do the following:
```
from pydantic_ai import Agent
agent = Agent('openai:gpt-4o')
result_sync = agent.run_sync(
  'What is the capital of Italy?', model_settings={'temperature': 0.0}
)
print(result_sync.data)
#> Rome

```

### Model specific settings
If you wish to further customize model behavior, you can use a subclass of `ModelSettings`[](https://ai.pydantic.dev/agents/<../api/settings/#pydantic_ai.settings.ModelSettings>), like `AnthropicModelSettings`[](https://ai.pydantic.dev/agents/<../api/models/anthropic/#pydantic_ai.models.anthropic.AnthropicModelSettings>), associated with your model of choice.
For example:
```
from pydantic_ai import Agent
from pydantic_ai.models.anthropic import AnthropicModelSettings
agent = Agent('anthropic:claude-3-5-sonnet-latest')
result_sync = agent.run_sync(
  'What is the capital of Italy?',
  model_settings=AnthropicModelSettings(anthropic_metadata={'user_id': 'my_user_id'}),
)
print(result_sync.data)
#> Rome

```

## Runs vs. Conversations
An agent **run** might represent an entire conversation — there's no limit to how many messages can be exchanged in a single run. However, a **conversation** might also be composed of multiple runs, especially if you need to maintain state between separate interactions or API calls.
Here's an example of a conversation comprised of multiple runs:
conversation_example.py```
from pydantic_ai import Agent
agent = Agent('openai:gpt-4o')
# First run
result1 = agent.run_sync('Who was Albert Einstein?')
print(result1.data)
#> Albert Einstein was a German-born theoretical physicist.
# Second run, passing previous messages
result2 = agent.run_sync(
  'What was his most famous equation?',
  message_history=result1.new_messages(), 
Continue the conversation; without message_history the model would not know who "his" was referring to.
[](https://ai.pydantic.dev/agents/<#__code_6_annotation_1>)
)
print(result2.data)
#> Albert Einstein's most famous equation is (E = mc^2).

```

_(This example is complete, it can be run "as is")_
## Type safe by design
PydanticAI is designed to work well with static type checkers, like mypy and pyright.
Typing is (somewhat) optional
PydanticAI is designed to make type checking as useful as possible for you if you choose to use it, but you don't have to use types everywhere all the time.
That said, because PydanticAI uses Pydantic, and Pydantic uses type hints as the definition for schema and validation, some types (specifically type hints on parameters to tools, and the `result_type` arguments to `Agent`[](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.Agent>)) are used at runtime.
We (the library developers) have messed up if type hints are confusing you more than helping you, if you find this, please create an [issue](https://ai.pydantic.dev/agents/<https:/github.com/pydantic/pydantic-ai/issues>) explaining what's annoying you!
In particular, agents are generic in both the type of their dependencies and the type of results they return, so you can use the type hints to ensure you're using the right types.
Consider the following script with type mistakes:
type_mistakes.py```
from dataclasses import dataclass
from pydantic_ai import Agent, RunContext

@dataclass
class User:
  name: str

agent = Agent(
  'test',
  deps_type=User, 
The agent is defined as expecting an instance of User as deps.
[](https://ai.pydantic.dev/agents/<#__code_7_annotation_1>)
  result_type=bool,
)

@agent.system_prompt
def add_user_name(ctx: RunContext[str]) -> str: 
But here add_user_name is defined as taking a str as the dependency, not a User.
[](https://ai.pydantic.dev/agents/<#__code_7_annotation_2>)
  return f"The user's name is {ctx.deps}."

def foobar(x: bytes) -> None:
  pass

result = agent.run_sync('Does their name start with "A"?', deps=User('Anne'))
foobar(result.data) 
Since the agent is defined as returning a bool, this will raise a type error since foobar expects bytes.
[](https://ai.pydantic.dev/agents/<#__code_7_annotation_3>)

```

Running `mypy` on this will give the following output:
```
➤uvrunmypytype_mistakes.py
type_mistakes.py:18:error:Argument1to"system_prompt"of"Agent"hasincompatibletype"Callable[[RunContext[str]], str]";expected"Callable[[RunContext[User]], str]"[arg-type]
type_mistakes.py:28:error:Argument1to"foobar"hasincompatibletype"bool";expected"bytes"[arg-type]
Found2errorsin1file(checked1sourcefile)

```

Running `pyright` would identify the same issues.
## System Prompts
System prompts might seem simple at first glance since they're just strings (or sequences of strings that are concatenated), but crafting the right system prompt is key to getting the model to behave as you want.
Generally, system prompts fall into two categories:
  1. **Static system prompts** : These are known when writing the code and can be defined via the `system_prompt` parameter of the `Agent`[ constructor](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.Agent.__init__>).
  2. **Dynamic system prompts** : These depend in some way on context that isn't known until runtime, and should be defined via functions decorated with `@agent.system_prompt`[](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.Agent.system_prompt>).


You can add both to a single agent; they're appended in the order they're defined at runtime.
Here's an example using both types of system prompts:
system_prompts.py```
from datetime import date
from pydantic_ai import Agent, RunContext
agent = Agent(
  'openai:gpt-4o',
  deps_type=str, 
The agent expects a string dependency.
[](https://ai.pydantic.dev/agents/<#__code_9_annotation_1>)
  system_prompt="Use the customer's name while replying to them.", 
Static system prompt defined at agent creation time.
[](https://ai.pydantic.dev/agents/<#__code_9_annotation_2>)
)

@agent.system_prompt 
Dynamic system prompt defined via a decorator with RunContext[](https://ai.pydantic.dev/agents/<../api/tools/#pydantic_ai.tools.RunContext>), this is called just after run_sync, not when the agent is created, so can benefit from runtime information like the dependencies used on that run.
[](https://ai.pydantic.dev/agents/<#__code_9_annotation_3>)
def add_the_users_name(ctx: RunContext[str]) -> str:
  return f"The user's name is {ctx.deps}."

@agent.system_prompt
def add_the_date() -> str: 
Another dynamic system prompt, system prompts don't have to have the RunContext parameter.
[](https://ai.pydantic.dev/agents/<#__code_9_annotation_4>)
  return f'The date is {date.today()}.'

result = agent.run_sync('What is the date?', deps='Frank')
print(result.data)
#> Hello Frank, the date today is 2032-01-02.

```

_(This example is complete, it can be run "as is")_
## Reflection and self-correction
Validation errors from both function tool parameter validation and [structured result validation](https://ai.pydantic.dev/agents/<../results/#structured-result-validation>) can be passed back to the model with a request to retry.
You can also raise `ModelRetry`[](https://ai.pydantic.dev/agents/<../api/exceptions/#pydantic_ai.exceptions.ModelRetry>) from within a [tool](https://ai.pydantic.dev/agents/<../tools/>) or [result validator function](https://ai.pydantic.dev/agents/<../results/#result-validators-functions>) to tell the model it should retry generating a response.
  * The default retry count is **1** but can be altered for the [entire agent](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.Agent.__init__>), a [specific tool](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.Agent.tool>), or a [result validator](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.Agent.__init__>).
  * You can access the current retry count from within a tool or result validator via `ctx.retry`[](https://ai.pydantic.dev/agents/<../api/tools/#pydantic_ai.tools.RunContext>).


Here's an example:
tool_retry.py```
from pydantic import BaseModel
from pydantic_ai import Agent, RunContext, ModelRetry
from fake_database import DatabaseConn

class ChatResult(BaseModel):
  user_id: int
  message: str

agent = Agent(
  'openai:gpt-4o',
  deps_type=DatabaseConn,
  result_type=ChatResult,
)

@agent.tool(retries=2)
def get_user_by_name(ctx: RunContext[DatabaseConn], name: str) -> int:
"""Get a user's ID from their full name."""
  print(name)
  #> John
  #> John Doe
  user_id = ctx.deps.users.get(name=name)
  if user_id is None:
    raise ModelRetry(
      f'No user found with name {name!r}, remember to provide their full name'
    )
  return user_id

result = agent.run_sync(
  'Send a message to John Doe asking for coffee next week', deps=DatabaseConn()
)
print(result.data)
"""
user_id=123 message='Hello John, would you be free for coffee sometime next week? Let me know what works for you!'
"""

```

## Model errors
If models behave unexpectedly (e.g., the retry limit is exceeded, or their API returns `503`), agent runs will raise `UnexpectedModelBehavior`[](https://ai.pydantic.dev/agents/<../api/exceptions/#pydantic_ai.exceptions.UnexpectedModelBehavior>).
In these cases, `capture_run_messages`[](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.capture_run_messages>) can be used to access the messages exchanged during the run to help diagnose the issue.
```
from pydantic_ai import Agent, ModelRetry, UnexpectedModelBehavior, capture_run_messages
agent = Agent('openai:gpt-4o')

@agent.tool_plain
def calc_volume(size: int) -> int: 
Define a tool that will raise ModelRetry repeatedly in this case.
[](https://ai.pydantic.dev/agents/<#__code_11_annotation_1>)
  if size == 42:
    return size**3
  else:
    raise ModelRetry('Please try again.')

with capture_run_messages() as messages: 
capture_run_messages[](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.capture_run_messages>) is used to capture the messages exchanged during the run.
[](https://ai.pydantic.dev/agents/<#__code_11_annotation_2>)
  try:
    result = agent.run_sync('Please get me the volume of a box with size 6.')
  except UnexpectedModelBehavior as e:
    print('An error occurred:', e)
    #> An error occurred: Tool exceeded max retries count of 1
    print('cause:', repr(e.__cause__))
    #> cause: ModelRetry('Please try again.')
    print('messages:', messages)
"""
    messages:
    [
      ModelRequest(
        parts=[
          UserPromptPart(
            content='Please get me the volume of a box with size 6.',
            timestamp=datetime.datetime(...),
            part_kind='user-prompt',
          )
        ],
        kind='request',
      ),
      ModelResponse(
        parts=[
          ToolCallPart(
            tool_name='calc_volume',
            args={'size': 6},
            tool_call_id=None,
            part_kind='tool-call',
          )
        ],
        model_name='function:model_logic',
        timestamp=datetime.datetime(...),
        kind='response',
      ),
      ModelRequest(
        parts=[
          RetryPromptPart(
            content='Please try again.',
            tool_name='calc_volume',
            tool_call_id=None,
            timestamp=datetime.datetime(...),
            part_kind='retry-prompt',
          )
        ],
        kind='request',
      ),
      ModelResponse(
        parts=[
          ToolCallPart(
            tool_name='calc_volume',
            args={'size': 6},
            tool_call_id=None,
            part_kind='tool-call',
          )
        ],
        model_name='function:model_logic',
        timestamp=datetime.datetime(...),
        kind='response',
      ),
    ]
    """
  else:
    print(result.data)

```

_(This example is complete, it can be run "as is")_
Note
If you call `run`[](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.Agent.run>), `run_sync`[](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.Agent.run_sync>), or `run_stream`[](https://ai.pydantic.dev/agents/<../api/agent/#pydantic_ai.agent.Agent.run_stream>) more than once within a single `capture_run_messages` context, `messages` will represent the messages exchanged during the first call only.
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_agent.md
================
[ Skip to content ](https://ai.pydantic.dev/api/agent/<#pydantic_aiagent>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/agent/<../..> "PydanticAI")
PydanticAI 
pydantic_ai.agent 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/agent/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/agent/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/agent/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/agent/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/api/agent/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/agent/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/agent/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/agent/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/agent/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/agent/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/agent/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/agent/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/agent/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/agent/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/agent/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/agent/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/agent/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/agent/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/agent/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/agent/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/agent/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/agent/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/agent/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/agent/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/agent/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/agent/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/agent/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/agent/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/agent/examples/question-graph/>)
  * API Reference  API Reference 
    * pydantic_ai.agent  [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/agent/<./>) Table of contents 
      * [ agent  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent>)
      * [ Agent  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent>)
        * [ model  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.model>)
        * [ __init__  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.__init__>)
        * [ end_strategy  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.end_strategy>)
        * [ name  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.name>)
        * [ model_settings  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.model_settings>)
        * [ result_type  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.result_type>)
        * [ run  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.run>)
        * [ run_sync  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.run_sync>)
        * [ run_stream  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.run_stream>)
        * [ override  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.override>)
        * [ system_prompt  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.system_prompt>)
        * [ result_validator  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.result_validator>)
        * [ tool  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.tool>)
        * [ tool_plain  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.tool_plain>)
      * [ EndStrategy  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.EndStrategy>)
      * [ capture_run_messages  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.capture_run_messages>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/agent/<../tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/agent/<../result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/agent/<../messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/agent/<../exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/agent/<../settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/agent/<../usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/agent/<../format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/agent/<../models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/agent/<../models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/agent/<../models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/agent/<../models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/agent/<../models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/agent/<../models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/agent/<../models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/agent/<../models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/agent/<../models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/agent/<../models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/agent/<../pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/agent/<../pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/agent/<../pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/agent/<../pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/agent/<../pydantic_graph/exceptions/>)


Table of contents 
  * [ agent  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent>)
  * [ Agent  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent>)
    * [ model  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.model>)
    * [ __init__  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.__init__>)
    * [ end_strategy  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.end_strategy>)
    * [ name  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.name>)
    * [ model_settings  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.model_settings>)
    * [ result_type  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.result_type>)
    * [ run  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.run>)
    * [ run_sync  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.run_sync>)
    * [ run_stream  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.run_stream>)
    * [ override  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.override>)
    * [ system_prompt  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.system_prompt>)
    * [ result_validator  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.result_validator>)
    * [ tool  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.tool>)
    * [ tool_plain  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.tool_plain>)
  * [ EndStrategy  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.EndStrategy>)
  * [ capture_run_messages  ](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.capture_run_messages>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/agent/<../..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/agent/<./>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/agent/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/agent/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_ai.agent`
###  Agent `dataclass`
Bases: `Generic[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Generic> "typing.Generic")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]`
Class for defining "agents" - a way to have a specific type of "conversation" with an LLM.
Agents are generic in the dependency type they take `AgentDepsT`[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT>) and the result data type they return, `ResultDataT`[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT>).
By default, if neither generic parameter is customised, agents have type `Agent[None, str]`.
Minimal usage example:
```
from pydantic_ai import Agent
agent = Agent('openai:gpt-4o')
result = agent.run_sync('What is the capital of France?')
print(result.data)
#> Paris

```

Source code in `pydantic_ai_slim/pydantic_ai/agent.py`
```
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
 100
 101
 102
 103
 104
 105
 106
 107
 108
 109
 110
 111
 112
 113
 114
 115
 116
 117
 118
 119
 120
 121
 122
 123
 124
 125
 126
 127
 128
 129
 130
 131
 132
 133
 134
 135
 136
 137
 138
 139
 140
 141
 142
 143
 144
 145
 146
 147
 148
 149
 150
 151
 152
 153
 154
 155
 156
 157
 158
 159
 160
 161
 162
 163
 164
 165
 166
 167
 168
 169
 170
 171
 172
 173
 174
 175
 176
 177
 178
 179
 180
 181
 182
 183
 184
 185
 186
 187
 188
 189
 190
 191
 192
 193
 194
 195
 196
 197
 198
 199
 200
 201
 202
 203
 204
 205
 206
 207
 208
 209
 210
 211
 212
 213
 214
 215
 216
 217
 218
 219
 220
 221
 222
 223
 224
 225
 226
 227
 228
 229
 230
 231
 232
 233
 234
 235
 236
 237
 238
 239
 240
 241
 242
 243
 244
 245
 246
 247
 248
 249
 250
 251
 252
 253
 254
 255
 256
 257
 258
 259
 260
 261
 262
 263
 264
 265
 266
 267
 268
 269
 270
 271
 272
 273
 274
 275
 276
 277
 278
 279
 280
 281
 282
 283
 284
 285
 286
 287
 288
 289
 290
 291
 292
 293
 294
 295
 296
 297
 298
 299
 300
 301
 302
 303
 304
 305
 306
 307
 308
 309
 310
 311
 312
 313
 314
 315
 316
 317
 318
 319
 320
 321
 322
 323
 324
 325
 326
 327
 328
 329
 330
 331
 332
 333
 334
 335
 336
 337
 338
 339
 340
 341
 342
 343
 344
 345
 346
 347
 348
 349
 350
 351
 352
 353
 354
 355
 356
 357
 358
 359
 360
 361
 362
 363
 364
 365
 366
 367
 368
 369
 370
 371
 372
 373
 374
 375
 376
 377
 378
 379
 380
 381
 382
 383
 384
 385
 386
 387
 388
 389
 390
 391
 392
 393
 394
 395
 396
 397
 398
 399
 400
 401
 402
 403
 404
 405
 406
 407
 408
 409
 410
 411
 412
 413
 414
 415
 416
 417
 418
 419
 420
 421
 422
 423
 424
 425
 426
 427
 428
 429
 430
 431
 432
 433
 434
 435
 436
 437
 438
 439
 440
 441
 442
 443
 444
 445
 446
 447
 448
 449
 450
 451
 452
 453
 454
 455
 456
 457
 458
 459
 460
 461
 462
 463
 464
 465
 466
 467
 468
 469
 470
 471
 472
 473
 474
 475
 476
 477
 478
 479
 480
 481
 482
 483
 484
 485
 486
 487
 488
 489
 490
 491
 492
 493
 494
 495
 496
 497
 498
 499
 500
 501
 502
 503
 504
 505
 506
 507
 508
 509
 510
 511
 512
 513
 514
 515
 516
 517
 518
 519
 520
 521
 522
 523
 524
 525
 526
 527
 528
 529
 530
 531
 532
 533
 534
 535
 536
 537
 538
 539
 540
 541
 542
 543
 544
 545
 546
 547
 548
 549
 550
 551
 552
 553
 554
 555
 556
 557
 558
 559
 560
 561
 562
 563
 564
 565
 566
 567
 568
 569
 570
 571
 572
 573
 574
 575
 576
 577
 578
 579
 580
 581
 582
 583
 584
 585
 586
 587
 588
 589
 590
 591
 592
 593
 594
 595
 596
 597
 598
 599
 600
 601
 602
 603
 604
 605
 606
 607
 608
 609
 610
 611
 612
 613
 614
 615
 616
 617
 618
 619
 620
 621
 622
 623
 624
 625
 626
 627
 628
 629
 630
 631
 632
 633
 634
 635
 636
 637
 638
 639
 640
 641
 642
 643
 644
 645
 646
 647
 648
 649
 650
 651
 652
 653
 654
 655
 656
 657
 658
 659
 660
 661
 662
 663
 664
 665
 666
 667
 668
 669
 670
 671
 672
 673
 674
 675
 676
 677
 678
 679
 680
 681
 682
 683
 684
 685
 686
 687
 688
 689
 690
 691
 692
 693
 694
 695
 696
 697
 698
 699
 700
 701
 702
 703
 704
 705
 706
 707
 708
 709
 710
 711
 712
 713
 714
 715
 716
 717
 718
 719
 720
 721
 722
 723
 724
 725
 726
 727
 728
 729
 730
 731
 732
 733
 734
 735
 736
 737
 738
 739
 740
 741
 742
 743
 744
 745
 746
 747
 748
 749
 750
 751
 752
 753
 754
 755
 756
 757
 758
 759
 760
 761
 762
 763
 764
 765
 766
 767
 768
 769
 770
 771
 772
 773
 774
 775
 776
 777
 778
 779
 780
 781
 782
 783
 784
 785
 786
 787
 788
 789
 790
 791
 792
 793
 794
 795
 796
 797
 798
 799
 800
 801
 802
 803
 804
 805
 806
 807
 808
 809
 810
 811
 812
 813
 814
 815
 816
 817
 818
 819
 820
 821
 822
 823
 824
 825
 826
 827
 828
 829
 830
 831
 832
 833
 834
 835
 836
 837
 838
 839
 840
 841
 842
 843
 844
 845
 846
 847
 848
 849
 850
 851
 852
 853
 854
 855
 856
 857
 858
 859
 860
 861
 862
 863
 864
 865
 866
 867
 868
 869
 870
 871
 872
 873
 874
 875
 876
 877
 878
 879
 880
 881
 882
 883
 884
 885
 886
 887
 888
 889
 890
 891
 892
 893
 894
 895
 896
 897
 898
 899
 900
 901
 902
 903
 904
 905
 906
 907
 908
 909
 910
 911
 912
 913
 914
 915
 916
 917
 918
 919
 920
 921
 922
 923
 924
 925
 926
 927
 928
 929
 930
 931
 932
 933
 934
 935
 936
 937
 938
 939
 940
 941
 942
 943
 944
 945
 946
 947
 948
 949
 950
 951
 952
 953
 954
 955
 956
 957
 958
 959
 960
 961
 962
 963
 964
 965
 966
 967
 968
 969
 970
 971
 972
 973
 974
 975
 976
 977
 978
 979
 980
 981
 982
 983
 984
 985
 986
 987
 988
 989
 990
 991
 992
 993
 994
 995
 996
 997
 998
 999
1000
1001
1002
1003
1004
1005
1006
1007
1008
1009
1010
1011
1012
1013
1014
1015
1016
1017
1018
1019
1020
1021
1022
1023
1024
1025
1026
1027
1028
1029
1030
1031
1032
1033
1034
1035
1036
1037
1038
1039
1040
1041
1042
1043
1044
1045
1046
1047
1048
1049
1050
1051
1052
1053
1054
1055
1056
1057
1058
1059
1060
```
| ```
@final
@dataclasses.dataclass(init=False)
class Agent(Generic[AgentDepsT, ResultDataT]):
"""Class for defining "agents" - a way to have a specific type of "conversation" with an LLM.
  Agents are generic in the dependency type they take [`AgentDepsT`][pydantic_ai.tools.AgentDepsT]
  and the result data type they return, [`ResultDataT`][pydantic_ai.result.ResultDataT].
  By default, if neither generic parameter is customised, agents have type `Agent[None, str]`.
  Minimal usage example:
  ```python
  from pydantic_ai import Agent
  agent = Agent('openai:gpt-4o')
  result = agent.run_sync('What is the capital of France?')
  print(result.data)
  #> Paris
  ```
  """
  # we use dataclass fields in order to conveniently know what attributes are available
  model: models.Model | models.KnownModelName | None
"""The default model configured for this agent."""
  name: str | None
"""The name of the agent, used for logging.
  If `None`, we try to infer the agent name from the call frame when the agent is first run.
  """
  end_strategy: EndStrategy
"""Strategy for handling tool calls when a final result is found."""
  model_settings: ModelSettings | None
"""Optional model request settings to use for this agents's runs, by default.
  Note, if `model_settings` is provided by `run`, `run_sync`, or `run_stream`, those settings will
  be merged with this value, with the runtime argument taking priority.
  """
  result_type: type[ResultDataT] = dataclasses.field(repr=False)
"""
  The type of the result data, used to validate the result data, defaults to `str`.
  """
  _deps_type: type[AgentDepsT] = dataclasses.field(repr=False)
  _result_tool_name: str = dataclasses.field(repr=False)
  _result_tool_description: str | None = dataclasses.field(repr=False)
  _result_schema: _result.ResultSchema[ResultDataT] | None = dataclasses.field(repr=False)
  _result_validators: list[_result.ResultValidator[AgentDepsT, ResultDataT]] = dataclasses.field(repr=False)
  _system_prompts: tuple[str, ...] = dataclasses.field(repr=False)
  _system_prompt_functions: list[_system_prompt.SystemPromptRunner[AgentDepsT]] = dataclasses.field(repr=False)
  _system_prompt_dynamic_functions: dict[str, _system_prompt.SystemPromptRunner[AgentDepsT]] = dataclasses.field(
    repr=False
  )
  _function_tools: dict[str, Tool[AgentDepsT]] = dataclasses.field(repr=False)
  _default_retries: int = dataclasses.field(repr=False)
  _max_result_retries: int = dataclasses.field(repr=False)
  _override_deps: _utils.Option[AgentDepsT] = dataclasses.field(default=None, repr=False)
  _override_model: _utils.Option[models.Model] = dataclasses.field(default=None, repr=False)
  def __init__(
    self,
    model: models.Model | models.KnownModelName | None = None,
    *,
    result_type: type[ResultDataT] = str,
    system_prompt: str | Sequence[str] = (),
    deps_type: type[AgentDepsT] = NoneType,
    name: str | None = None,
    model_settings: ModelSettings | None = None,
    retries: int = 1,
    result_tool_name: str = 'final_result',
    result_tool_description: str | None = None,
    result_retries: int | None = None,
    tools: Sequence[Tool[AgentDepsT] | ToolFuncEither[AgentDepsT, ...]] = (),
    defer_model_check: bool = False,
    end_strategy: EndStrategy = 'early',
  ):
"""Create an agent.
    Args:
      model: The default model to use for this agent, if not provide,
        you must provide the model when calling it.
      result_type: The type of the result data, used to validate the result data, defaults to `str`.
      system_prompt: Static system prompts to use for this agent, you can also register system
        prompts via a function with [`system_prompt`][pydantic_ai.Agent.system_prompt].
      deps_type: The type used for dependency injection, this parameter exists solely to allow you to fully
        parameterize the agent, and therefore get the best out of static type checking.
        If you're not using deps, but want type checking to pass, you can set `deps=None` to satisfy Pyright
        or add a type hint `: Agent[None, <return type>]`.
      name: The name of the agent, used for logging. If `None`, we try to infer the agent name from the call frame
        when the agent is first run.
      model_settings: Optional model request settings to use for this agent's runs, by default.
      retries: The default number of retries to allow before raising an error.
      result_tool_name: The name of the tool to use for the final result.
      result_tool_description: The description of the final result tool.
      result_retries: The maximum number of retries to allow for result validation, defaults to `retries`.
      tools: Tools to register with the agent, you can also register tools via the decorators
        [`@agent.tool`][pydantic_ai.Agent.tool] and [`@agent.tool_plain`][pydantic_ai.Agent.tool_plain].
      defer_model_check: by default, if you provide a [named][pydantic_ai.models.KnownModelName] model,
        it's evaluated to create a [`Model`][pydantic_ai.models.Model] instance immediately,
        which checks for the necessary environment variables. Set this to `false`
        to defer the evaluation until the first run. Useful if you want to
        [override the model][pydantic_ai.Agent.override] for testing.
      end_strategy: Strategy for handling tool calls that are requested alongside a final result.
        See [`EndStrategy`][pydantic_ai.agent.EndStrategy] for more information.
    """
    if model is None or defer_model_check:
      self.model = model
    else:
      self.model = models.infer_model(model)
    self.end_strategy = end_strategy
    self.name = name
    self.model_settings = model_settings
    self.result_type = result_type
    self._deps_type = deps_type
    self._result_tool_name = result_tool_name
    self._result_tool_description = result_tool_description
    self._result_schema: _result.ResultSchema[ResultDataT] | None = _result.ResultSchema[result_type].build(
      result_type, result_tool_name, result_tool_description
    )
    self._result_validators: list[_result.ResultValidator[AgentDepsT, ResultDataT]] = []
    self._system_prompts = (system_prompt,) if isinstance(system_prompt, str) else tuple(system_prompt)
    self._system_prompt_functions: list[_system_prompt.SystemPromptRunner[AgentDepsT]] = []
    self._system_prompt_dynamic_functions: dict[str, _system_prompt.SystemPromptRunner[AgentDepsT]] = {}
    self._function_tools: dict[str, Tool[AgentDepsT]] = {}
    self._default_retries = retries
    self._max_result_retries = result_retries if result_retries is not None else retries
    for tool in tools:
      if isinstance(tool, Tool):
        self._register_tool(tool)
      else:
        self._register_tool(Tool(tool))
  @overload
  async def run(
    self,
    user_prompt: str,
    *,
    result_type: None = None,
    message_history: list[_messages.ModelMessage] | None = None,
    model: models.Model | models.KnownModelName | None = None,
    deps: AgentDepsT = None,
    model_settings: ModelSettings | None = None,
    usage_limits: _usage.UsageLimits | None = None,
    usage: _usage.Usage | None = None,
    infer_name: bool = True,
  ) -> result.RunResult[ResultDataT]: ...
  @overload
  async def run(
    self,
    user_prompt: str,
    *,
    result_type: type[RunResultDataT],
    message_history: list[_messages.ModelMessage] | None = None,
    model: models.Model | models.KnownModelName | None = None,
    deps: AgentDepsT = None,
    model_settings: ModelSettings | None = None,
    usage_limits: _usage.UsageLimits | None = None,
    usage: _usage.Usage | None = None,
    infer_name: bool = True,
  ) -> result.RunResult[RunResultDataT]: ...
  async def run(
    self,
    user_prompt: str,
    *,
    message_history: list[_messages.ModelMessage] | None = None,
    model: models.Model | models.KnownModelName | None = None,
    deps: AgentDepsT = None,
    model_settings: ModelSettings | None = None,
    usage_limits: _usage.UsageLimits | None = None,
    usage: _usage.Usage | None = None,
    result_type: type[RunResultDataT] | None = None,
    infer_name: bool = True,
  ) -> result.RunResult[Any]:
"""Run the agent with a user prompt in async mode.
    Example:
```python
    from pydantic_ai import Agent
    agent = Agent('openai:gpt-4o')
    async def main():
      result = await agent.run('What is the capital of France?')
      print(result.data)
      #> Paris
```
    Args:
      result_type: Custom result type to use for this run, `result_type` may only be used if the agent has no
        result validators since result validators would expect an argument that matches the agent's result type.
      user_prompt: User input to start/continue the conversation.
      message_history: History of the conversation so far.
      model: Optional model to use for this run, required if `model` was not set when creating the agent.
      deps: Optional dependencies to use for this run.
      model_settings: Optional settings to use for this model's request.
      usage_limits: Optional limits on model request count or token usage.
      usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.
      infer_name: Whether to try to infer the agent name from the call frame if it's not set.
    Returns:
      The result of the run.
    """
    if infer_name and self.name is None:
      self._infer_name(inspect.currentframe())
    model_used = await self._get_model(model)
    deps = self._get_deps(deps)
    new_message_index = len(message_history) if message_history else 0
    result_schema: _result.ResultSchema[RunResultDataT] | None = self._prepare_result_schema(result_type)
    # Build the graph
    graph = _agent_graph.build_agent_graph(self.name, self._deps_type, result_type or self.result_type)
    # Build the initial state
    state = _agent_graph.GraphAgentState(
      message_history=message_history[:] if message_history else [],
      usage=usage or _usage.Usage(),
      retries=0,
      run_step=0,
    )
    # We consider it a user error if a user tries to restrict the result type while having a result validator that
    # may change the result type from the restricted type to something else. Therefore, we consider the following
    # typecast reasonable, even though it is possible to violate it with otherwise-type-checked code.
    result_validators = cast(list[_result.ResultValidator[AgentDepsT, RunResultDataT]], self._result_validators)
    # TODO: Instead of this, copy the function tools to ensure they don't share current_retry state between agent
    # runs. Requires some changes to `Tool` to make them copyable though.
    for v in self._function_tools.values():
      v.current_retry = 0
    model_settings = merge_model_settings(self.model_settings, model_settings)
    usage_limits = usage_limits or _usage.UsageLimits()
    with _logfire.span(
      '{agent_name} run {prompt=}',
      prompt=user_prompt,
      agent=self,
      model_name=model_used.name() if model_used else 'no-model',
      agent_name=self.name or 'agent',
    ) as run_span:
      # Build the deps object for the graph
      graph_deps = _agent_graph.GraphAgentDeps[AgentDepsT, RunResultDataT](
        user_deps=deps,
        prompt=user_prompt,
        new_message_index=new_message_index,
        model=model_used,
        model_settings=model_settings,
        usage_limits=usage_limits,
        max_result_retries=self._max_result_retries,
        end_strategy=self.end_strategy,
        result_schema=result_schema,
        result_tools=self._result_schema.tool_defs() if self._result_schema else [],
        result_validators=result_validators,
        function_tools=self._function_tools,
        run_span=run_span,
      )
      start_node = _agent_graph.UserPromptNode[AgentDepsT](
        user_prompt=user_prompt,
        system_prompts=self._system_prompts,
        system_prompt_functions=self._system_prompt_functions,
        system_prompt_dynamic_functions=self._system_prompt_dynamic_functions,
      )
      # Actually run
      end_result, _ = await graph.run(
        start_node,
        state=state,
        deps=graph_deps,
        infer_name=False,
      )
    # Build final run result
    # We don't do any advanced checking if the data is actually from a final result or not
    return result.RunResult(
      state.message_history,
      new_message_index,
      end_result.data,
      end_result.tool_name,
      state.usage,
    )
  @overload
  def run_sync(
    self,
    user_prompt: str,
    *,
    message_history: list[_messages.ModelMessage] | None = None,
    model: models.Model | models.KnownModelName | None = None,
    deps: AgentDepsT = None,
    model_settings: ModelSettings | None = None,
    usage_limits: _usage.UsageLimits | None = None,
    usage: _usage.Usage | None = None,
    infer_name: bool = True,
  ) -> result.RunResult[ResultDataT]: ...
  @overload
  def run_sync(
    self,
    user_prompt: str,
    *,
    result_type: type[RunResultDataT] | None,
    message_history: list[_messages.ModelMessage] | None = None,
    model: models.Model | models.KnownModelName | None = None,
    deps: AgentDepsT = None,
    model_settings: ModelSettings | None = None,
    usage_limits: _usage.UsageLimits | None = None,
    usage: _usage.Usage | None = None,
    infer_name: bool = True,
  ) -> result.RunResult[RunResultDataT]: ...
  def run_sync(
    self,
    user_prompt: str,
    *,
    result_type: type[RunResultDataT] | None = None,
    message_history: list[_messages.ModelMessage] | None = None,
    model: models.Model | models.KnownModelName | None = None,
    deps: AgentDepsT = None,
    model_settings: ModelSettings | None = None,
    usage_limits: _usage.UsageLimits | None = None,
    usage: _usage.Usage | None = None,
    infer_name: bool = True,
  ) -> result.RunResult[Any]:
"""Run the agent with a user prompt synchronously.
    This is a convenience method that wraps [`self.run`][pydantic_ai.Agent.run] with `loop.run_until_complete(...)`.
    You therefore can't use this method inside async code or if there's an active event loop.
    Example:
```python
    from pydantic_ai import Agent
    agent = Agent('openai:gpt-4o')
    result_sync = agent.run_sync('What is the capital of Italy?')
    print(result_sync.data)
    #> Rome
```
    Args:
      result_type: Custom result type to use for this run, `result_type` may only be used if the agent has no
        result validators since result validators would expect an argument that matches the agent's result type.
      user_prompt: User input to start/continue the conversation.
      message_history: History of the conversation so far.
      model: Optional model to use for this run, required if `model` was not set when creating the agent.
      deps: Optional dependencies to use for this run.
      model_settings: Optional settings to use for this model's request.
      usage_limits: Optional limits on model request count or token usage.
      usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.
      infer_name: Whether to try to infer the agent name from the call frame if it's not set.
    Returns:
      The result of the run.
    """
    if infer_name and self.name is None:
      self._infer_name(inspect.currentframe())
    return asyncio.get_event_loop().run_until_complete(
      self.run(
        user_prompt,
        result_type=result_type,
        message_history=message_history,
        model=model,
        deps=deps,
        model_settings=model_settings,
        usage_limits=usage_limits,
        usage=usage,
        infer_name=False,
      )
    )
  @overload
  def run_stream(
    self,
    user_prompt: str,
    *,
    result_type: None = None,
    message_history: list[_messages.ModelMessage] | None = None,
    model: models.Model | models.KnownModelName | None = None,
    deps: AgentDepsT = None,
    model_settings: ModelSettings | None = None,
    usage_limits: _usage.UsageLimits | None = None,
    usage: _usage.Usage | None = None,
    infer_name: bool = True,
  ) -> AbstractAsyncContextManager[result.StreamedRunResult[AgentDepsT, ResultDataT]]: ...
  @overload
  def run_stream(
    self,
    user_prompt: str,
    *,
    result_type: type[RunResultDataT],
    message_history: list[_messages.ModelMessage] | None = None,
    model: models.Model | models.KnownModelName | None = None,
    deps: AgentDepsT = None,
    model_settings: ModelSettings | None = None,
    usage_limits: _usage.UsageLimits | None = None,
    usage: _usage.Usage | None = None,
    infer_name: bool = True,
  ) -> AbstractAsyncContextManager[result.StreamedRunResult[AgentDepsT, RunResultDataT]]: ...
  @asynccontextmanager
  async def run_stream(
    self,
    user_prompt: str,
    *,
    result_type: type[RunResultDataT] | None = None,
    message_history: list[_messages.ModelMessage] | None = None,
    model: models.Model | models.KnownModelName | None = None,
    deps: AgentDepsT = None,
    model_settings: ModelSettings | None = None,
    usage_limits: _usage.UsageLimits | None = None,
    usage: _usage.Usage | None = None,
    infer_name: bool = True,
  ) -> AsyncIterator[result.StreamedRunResult[AgentDepsT, Any]]:
"""Run the agent with a user prompt in async mode, returning a streamed response.
    Example:
```python
    from pydantic_ai import Agent
    agent = Agent('openai:gpt-4o')
    async def main():
      async with agent.run_stream('What is the capital of the UK?') as response:
        print(await response.get_data())
        #> London
```
    Args:
      result_type: Custom result type to use for this run, `result_type` may only be used if the agent has no
        result validators since result validators would expect an argument that matches the agent's result type.
      user_prompt: User input to start/continue the conversation.
      message_history: History of the conversation so far.
      model: Optional model to use for this run, required if `model` was not set when creating the agent.
      deps: Optional dependencies to use for this run.
      model_settings: Optional settings to use for this model's request.
      usage_limits: Optional limits on model request count or token usage.
      usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.
      infer_name: Whether to try to infer the agent name from the call frame if it's not set.
    Returns:
      The result of the run.
    """
    if infer_name and self.name is None:
      # f_back because `asynccontextmanager` adds one frame
      if frame := inspect.currentframe(): # pragma: no branch
        self._infer_name(frame.f_back)
    model_used = await self._get_model(model)
    deps = self._get_deps(deps)
    new_message_index = len(message_history) if message_history else 0
    result_schema: _result.ResultSchema[RunResultDataT] | None = self._prepare_result_schema(result_type)
    # Build the graph
    graph = self._build_stream_graph(result_type)
    # Build the initial state
    graph_state = _agent_graph.GraphAgentState(
      message_history=message_history[:] if message_history else [],
      usage=usage or _usage.Usage(),
      retries=0,
      run_step=0,
    )
    # We consider it a user error if a user tries to restrict the result type while having a result validator that
    # may change the result type from the restricted type to something else. Therefore, we consider the following
    # typecast reasonable, even though it is possible to violate it with otherwise-type-checked code.
    result_validators = cast(list[_result.ResultValidator[AgentDepsT, RunResultDataT]], self._result_validators)
    # TODO: Instead of this, copy the function tools to ensure they don't share current_retry state between agent
    # runs. Requires some changes to `Tool` to make them copyable though.
    for v in self._function_tools.values():
      v.current_retry = 0
    model_settings = merge_model_settings(self.model_settings, model_settings)
    usage_limits = usage_limits or _usage.UsageLimits()
    with _logfire.span(
      '{agent_name} run stream {prompt=}',
      prompt=user_prompt,
      agent=self,
      model_name=model_used.name(),
      agent_name=self.name or 'agent',
    ) as run_span:
      # Build the deps object for the graph
      graph_deps = _agent_graph.GraphAgentDeps[AgentDepsT, RunResultDataT](
        user_deps=deps,
        prompt=user_prompt,
        new_message_index=new_message_index,
        model=model_used,
        model_settings=model_settings,
        usage_limits=usage_limits,
        max_result_retries=self._max_result_retries,
        end_strategy=self.end_strategy,
        result_schema=result_schema,
        result_tools=self._result_schema.tool_defs() if self._result_schema else [],
        result_validators=result_validators,
        function_tools=self._function_tools,
        run_span=run_span,
      )
      start_node = _agent_graph.StreamUserPromptNode[AgentDepsT](
        user_prompt=user_prompt,
        system_prompts=self._system_prompts,
        system_prompt_functions=self._system_prompt_functions,
        system_prompt_dynamic_functions=self._system_prompt_dynamic_functions,
      )
      # Actually run
      node = start_node
      history: list[HistoryStep[_agent_graph.GraphAgentState, RunResultDataT]] = []
      while True:
        if isinstance(node, _agent_graph.StreamModelRequestNode):
          node = cast(
            _agent_graph.StreamModelRequestNode[
              AgentDepsT, result.StreamedRunResult[AgentDepsT, RunResultDataT]
            ],
            node,
          )
          async with node.run_to_result(GraphRunContext(graph_state, graph_deps)) as r:
            if isinstance(r, End):
              yield r.data
              break
        assert not isinstance(node, End) # the previous line should be hit first
        node = await graph.next(
          node,
          history,
          state=graph_state,
          deps=graph_deps,
          infer_name=False,
        )
  @contextmanager
  def override(
    self,
    *,
    deps: AgentDepsT | _utils.Unset = _utils.UNSET,
    model: models.Model | models.KnownModelName | _utils.Unset = _utils.UNSET,
  ) -> Iterator[None]:
"""Context manager to temporarily override agent dependencies and model.
    This is particularly useful when testing.
    You can find an example of this [here](../testing-evals.md#overriding-model-via-pytest-fixtures).
    Args:
      deps: The dependencies to use instead of the dependencies passed to the agent run.
      model: The model to use instead of the model passed to the agent run.
    """
    if _utils.is_set(deps):
      override_deps_before = self._override_deps
      self._override_deps = _utils.Some(deps)
    else:
      override_deps_before = _utils.UNSET
    # noinspection PyTypeChecker
    if _utils.is_set(model):
      override_model_before = self._override_model
      # noinspection PyTypeChecker
      self._override_model = _utils.Some(models.infer_model(model)) # pyright: ignore[reportArgumentType]
    else:
      override_model_before = _utils.UNSET
    try:
      yield
    finally:
      if _utils.is_set(override_deps_before):
        self._override_deps = override_deps_before
      if _utils.is_set(override_model_before):
        self._override_model = override_model_before
  @overload
  def system_prompt(
    self, func: Callable[[RunContext[AgentDepsT]], str], /
  ) -> Callable[[RunContext[AgentDepsT]], str]: ...
  @overload
  def system_prompt(
    self, func: Callable[[RunContext[AgentDepsT]], Awaitable[str]], /
  ) -> Callable[[RunContext[AgentDepsT]], Awaitable[str]]: ...
  @overload
  def system_prompt(self, func: Callable[[], str], /) -> Callable[[], str]: ...
  @overload
  def system_prompt(self, func: Callable[[], Awaitable[str]], /) -> Callable[[], Awaitable[str]]: ...
  @overload
  def system_prompt(
    self, /, *, dynamic: bool = False
  ) -> Callable[[_system_prompt.SystemPromptFunc[AgentDepsT]], _system_prompt.SystemPromptFunc[AgentDepsT]]: ...
  def system_prompt(
    self,
    func: _system_prompt.SystemPromptFunc[AgentDepsT] | None = None,
    /,
    *,
    dynamic: bool = False,
  ) -> (
    Callable[[_system_prompt.SystemPromptFunc[AgentDepsT]], _system_prompt.SystemPromptFunc[AgentDepsT]]
    | _system_prompt.SystemPromptFunc[AgentDepsT]
  ):
"""Decorator to register a system prompt function.
    Optionally takes [`RunContext`][pydantic_ai.tools.RunContext] as its only argument.
    Can decorate a sync or async functions.
    The decorator can be used either bare (`agent.system_prompt`) or as a function call
    (`agent.system_prompt(...)`), see the examples below.
    Overloads for every possible signature of `system_prompt` are included so the decorator doesn't obscure
    the type of the function, see `tests/typed_agent.py` for tests.
    Args:
      func: The function to decorate
      dynamic: If True, the system prompt will be reevaluated even when `messages_history` is provided,
        see [`SystemPromptPart.dynamic_ref`][pydantic_ai.messages.SystemPromptPart.dynamic_ref]
    Example:
```python
    from pydantic_ai import Agent, RunContext
    agent = Agent('test', deps_type=str)
    @agent.system_prompt
    def simple_system_prompt() -> str:
      return 'foobar'
    @agent.system_prompt(dynamic=True)
    async def async_system_prompt(ctx: RunContext[str]) -> str:
      return f'{ctx.deps} is the best'
```
    """
    if func is None:
      def decorator(
        func_: _system_prompt.SystemPromptFunc[AgentDepsT],
      ) -> _system_prompt.SystemPromptFunc[AgentDepsT]:
        runner = _system_prompt.SystemPromptRunner[AgentDepsT](func_, dynamic=dynamic)
        self._system_prompt_functions.append(runner)
        if dynamic:
          self._system_prompt_dynamic_functions[func_.__qualname__] = runner
        return func_
      return decorator
    else:
      assert not dynamic, "dynamic can't be True in this case"
      self._system_prompt_functions.append(_system_prompt.SystemPromptRunner[AgentDepsT](func, dynamic=dynamic))
      return func
  @overload
  def result_validator(
    self, func: Callable[[RunContext[AgentDepsT], ResultDataT], ResultDataT], /
  ) -> Callable[[RunContext[AgentDepsT], ResultDataT], ResultDataT]: ...
  @overload
  def result_validator(
    self, func: Callable[[RunContext[AgentDepsT], ResultDataT], Awaitable[ResultDataT]], /
  ) -> Callable[[RunContext[AgentDepsT], ResultDataT], Awaitable[ResultDataT]]: ...
  @overload
  def result_validator(
    self, func: Callable[[ResultDataT], ResultDataT], /
  ) -> Callable[[ResultDataT], ResultDataT]: ...
  @overload
  def result_validator(
    self, func: Callable[[ResultDataT], Awaitable[ResultDataT]], /
  ) -> Callable[[ResultDataT], Awaitable[ResultDataT]]: ...
  def result_validator(
    self, func: _result.ResultValidatorFunc[AgentDepsT, ResultDataT], /
  ) -> _result.ResultValidatorFunc[AgentDepsT, ResultDataT]:
"""Decorator to register a result validator function.
    Optionally takes [`RunContext`][pydantic_ai.tools.RunContext] as its first argument.
    Can decorate a sync or async functions.
    Overloads for every possible signature of `result_validator` are included so the decorator doesn't obscure
    the type of the function, see `tests/typed_agent.py` for tests.
    Example:
```python
    from pydantic_ai import Agent, ModelRetry, RunContext
    agent = Agent('test', deps_type=str)
    @agent.result_validator
    def result_validator_simple(data: str) -> str:
      if 'wrong' in data:
        raise ModelRetry('wrong response')
      return data
    @agent.result_validator
    async def result_validator_deps(ctx: RunContext[str], data: str) -> str:
      if ctx.deps in data:
        raise ModelRetry('wrong response')
      return data
    result = agent.run_sync('foobar', deps='spam')
    print(result.data)
    #> success (no tool calls)
```
    """
    self._result_validators.append(_result.ResultValidator[AgentDepsT, Any](func))
    return func
  @overload
  def tool(self, func: ToolFuncContext[AgentDepsT, ToolParams], /) -> ToolFuncContext[AgentDepsT, ToolParams]: ...
  @overload
  def tool(
    self,
    /,
    *,
    retries: int | None = None,
    prepare: ToolPrepareFunc[AgentDepsT] | None = None,
    docstring_format: DocstringFormat = 'auto',
    require_parameter_descriptions: bool = False,
  ) -> Callable[[ToolFuncContext[AgentDepsT, ToolParams]], ToolFuncContext[AgentDepsT, ToolParams]]: ...
  def tool(
    self,
    func: ToolFuncContext[AgentDepsT, ToolParams] | None = None,
    /,
    *,
    retries: int | None = None,
    prepare: ToolPrepareFunc[AgentDepsT] | None = None,
    docstring_format: DocstringFormat = 'auto',
    require_parameter_descriptions: bool = False,
  ) -> Any:
"""Decorator to register a tool function which takes [`RunContext`][pydantic_ai.tools.RunContext] as its first argument.
    Can decorate a sync or async functions.
    The docstring is inspected to extract both the tool description and description of each parameter,
    [learn more](../tools.md#function-tools-and-schema).
    We can't add overloads for every possible signature of tool, since the return type is a recursive union
    so the signature of functions decorated with `@agent.tool` is obscured.
    Example:
```python
    from pydantic_ai import Agent, RunContext
    agent = Agent('test', deps_type=int)
    @agent.tool
    def foobar(ctx: RunContext[int], x: int) -> int:
      return ctx.deps + x
    @agent.tool(retries=2)
    async def spam(ctx: RunContext[str], y: float) -> float:
      return ctx.deps + y
    result = agent.run_sync('foobar', deps=1)
    print(result.data)
    #> {"foobar":1,"spam":1.0}
```
    Args:
      func: The tool function to register.
      retries: The number of retries to allow for this tool, defaults to the agent's default retries,
        which defaults to 1.
      prepare: custom method to prepare the tool definition for each step, return `None` to omit this
        tool from a given step. This is useful if you want to customise a tool at call time,
        or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].
      docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].
        Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.
      require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.
    """
    if func is None:
      def tool_decorator(
        func_: ToolFuncContext[AgentDepsT, ToolParams],
      ) -> ToolFuncContext[AgentDepsT, ToolParams]:
        # noinspection PyTypeChecker
        self._register_function(func_, True, retries, prepare, docstring_format, require_parameter_descriptions)
        return func_
      return tool_decorator
    else:
      # noinspection PyTypeChecker
      self._register_function(func, True, retries, prepare, docstring_format, require_parameter_descriptions)
      return func
  @overload
  def tool_plain(self, func: ToolFuncPlain[ToolParams], /) -> ToolFuncPlain[ToolParams]: ...
  @overload
  def tool_plain(
    self,
    /,
    *,
    retries: int | None = None,
    prepare: ToolPrepareFunc[AgentDepsT] | None = None,
    docstring_format: DocstringFormat = 'auto',
    require_parameter_descriptions: bool = False,
  ) -> Callable[[ToolFuncPlain[ToolParams]], ToolFuncPlain[ToolParams]]: ...
  def tool_plain(
    self,
    func: ToolFuncPlain[ToolParams] | None = None,
    /,
    *,
    retries: int | None = None,
    prepare: ToolPrepareFunc[AgentDepsT] | None = None,
    docstring_format: DocstringFormat = 'auto',
    require_parameter_descriptions: bool = False,
  ) -> Any:
"""Decorator to register a tool function which DOES NOT take `RunContext` as an argument.
    Can decorate a sync or async functions.
    The docstring is inspected to extract both the tool description and description of each parameter,
    [learn more](../tools.md#function-tools-and-schema).
    We can't add overloads for every possible signature of tool, since the return type is a recursive union
    so the signature of functions decorated with `@agent.tool` is obscured.
    Example:
```python
    from pydantic_ai import Agent, RunContext
    agent = Agent('test')
    @agent.tool
    def foobar(ctx: RunContext[int]) -> int:
      return 123
    @agent.tool(retries=2)
    async def spam(ctx: RunContext[str]) -> float:
      return 3.14
    result = agent.run_sync('foobar', deps=1)
    print(result.data)
    #> {"foobar":123,"spam":3.14}
```
    Args:
      func: The tool function to register.
      retries: The number of retries to allow for this tool, defaults to the agent's default retries,
        which defaults to 1.
      prepare: custom method to prepare the tool definition for each step, return `None` to omit this
        tool from a given step. This is useful if you want to customise a tool at call time,
        or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].
      docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].
        Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.
      require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.
    """
    if func is None:
      def tool_decorator(func_: ToolFuncPlain[ToolParams]) -> ToolFuncPlain[ToolParams]:
        # noinspection PyTypeChecker
        self._register_function(
          func_, False, retries, prepare, docstring_format, require_parameter_descriptions
        )
        return func_
      return tool_decorator
    else:
      self._register_function(func, False, retries, prepare, docstring_format, require_parameter_descriptions)
      return func
  def _register_function(
    self,
    func: ToolFuncEither[AgentDepsT, ToolParams],
    takes_ctx: bool,
    retries: int | None,
    prepare: ToolPrepareFunc[AgentDepsT] | None,
    docstring_format: DocstringFormat,
    require_parameter_descriptions: bool,
  ) -> None:
"""Private utility to register a function as a tool."""
    retries_ = retries if retries is not None else self._default_retries
    tool = Tool[AgentDepsT](
      func,
      takes_ctx=takes_ctx,
      max_retries=retries_,
      prepare=prepare,
      docstring_format=docstring_format,
      require_parameter_descriptions=require_parameter_descriptions,
    )
    self._register_tool(tool)
  def _register_tool(self, tool: Tool[AgentDepsT]) -> None:
"""Private utility to register a tool instance."""
    if tool.max_retries is None:
      # noinspection PyTypeChecker
      tool = dataclasses.replace(tool, max_retries=self._default_retries)
    if tool.name in self._function_tools:
      raise exceptions.UserError(f'Tool name conflicts with existing tool: {tool.name!r}')
    if self._result_schema and tool.name in self._result_schema.tools:
      raise exceptions.UserError(f'Tool name conflicts with result schema name: {tool.name!r}')
    self._function_tools[tool.name] = tool
  async def _get_model(self, model: models.Model | models.KnownModelName | None) -> models.Model:
"""Create a model configured for this agent.
    Args:
      model: model to use for this run, required if `model` was not set when creating the agent.
    Returns:
      The model used
    """
    model_: models.Model
    if some_model := self._override_model:
      # we don't want `override()` to cover up errors from the model not being defined, hence this check
      if model is None and self.model is None:
        raise exceptions.UserError(
          '`model` must be set either when creating the agent or when calling it. '
          '(Even when `override(model=...)` is customizing the model that will actually be called)'
        )
      model_ = some_model.value
    elif model is not None:
      model_ = models.infer_model(model)
    elif self.model is not None:
      # noinspection PyTypeChecker
      model_ = self.model = models.infer_model(self.model)
    else:
      raise exceptions.UserError('`model` must be set either when creating the agent or when calling it.')
    return model_
  def _get_deps(self: Agent[T, ResultDataT], deps: T) -> T:
"""Get deps for a run.
    If we've overridden deps via `_override_deps`, use that, otherwise use the deps passed to the call.
    We could do runtime type checking of deps against `self._deps_type`, but that's a slippery slope.
    """
    if some_deps := self._override_deps:
      return some_deps.value
    else:
      return deps
  def _infer_name(self, function_frame: FrameType | None) -> None:
"""Infer the agent name from the call frame.
    Usage should be `self._infer_name(inspect.currentframe())`.
    """
    assert self.name is None, 'Name already set'
    if function_frame is not None: # pragma: no branch
      if parent_frame := function_frame.f_back: # pragma: no branch
        for name, item in parent_frame.f_locals.items():
          if item is self:
            self.name = name
            return
        if parent_frame.f_locals != parent_frame.f_globals:
          # if we couldn't find the agent in locals and globals are a different dict, try globals
          for name, item in parent_frame.f_globals.items():
            if item is self:
              self.name = name
              return
  @property
  @deprecated(
    'The `last_run_messages` attribute has been removed, use `capture_run_messages` instead.', category=None
  )
  def last_run_messages(self) -> list[_messages.ModelMessage]:
    raise AttributeError('The `last_run_messages` attribute has been removed, use `capture_run_messages` instead.')
  def _build_graph(
    self, result_type: type[RunResultDataT] | None
  ) -> Graph[_agent_graph.GraphAgentState, _agent_graph.GraphAgentDeps[AgentDepsT, Any], Any]:
    return _agent_graph.build_agent_graph(self.name, self._deps_type, result_type or self.result_type)
  def _build_stream_graph(
    self, result_type: type[RunResultDataT] | None
  ) -> Graph[_agent_graph.GraphAgentState, _agent_graph.GraphAgentDeps[AgentDepsT, Any], Any]:
    return _agent_graph.build_agent_stream_graph(self.name, self._deps_type, result_type or self.result_type)
  def _prepare_result_schema(
    self, result_type: type[RunResultDataT] | None
  ) -> _result.ResultSchema[RunResultDataT] | None:
    if result_type is not None:
      if self._result_validators:
        raise exceptions.UserError('Cannot set a custom run `result_type` when the agent has result validators')
      return _result.ResultSchema[result_type].build(
        result_type, self._result_tool_name, self._result_tool_description
      )
    else:
      return self._result_schema # pyright: ignore[reportReturnType]

```
  
---|---  
####  model `instance-attribute`
```
model: Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None

```

The default model configured for this agent.
####  __init__
```
__init__(
  model: Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None = None,
  *,
  result_type: type[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#type>)[ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")] = str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>),
  system_prompt: str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>) | Sequence[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)] = (),
  deps_type: type[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#type>)[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")] = NoneType,
  name: str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None,
  model_settings: ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None = None,
  retries: int[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#int>) = 1,
  result_tool_name: str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>) = "final_result",
  result_tool_description: str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None,
  result_retries: int[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#int>) | None = None,
  tools: Sequence[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[
    Tool[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.Tool> "pydantic_ai.tools.Tool")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")] | ToolFuncEither[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolFuncEither> "pydantic_ai.tools.ToolFuncEither")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), ...]
  ] = (),
  defer_model_check: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = False,
  end_strategy: EndStrategy[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.EndStrategy> "pydantic_ai._agent_graph.EndStrategy") = "early"
)

```

Create an agent.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`model` |  `Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None` |  The default model to use for this agent, if not provide, you must provide the model when calling it. |  `None`  
`result_type` |  `type[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#type>)[ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]` |  The type of the result data, used to validate the result data, defaults to `str`. |  `str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)`  
`system_prompt` |  `str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>) | Sequence[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)]` |  Static system prompts to use for this agent, you can also register system prompts via a function with `system_prompt`[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.system_prompt>). |  `()`  
`deps_type` |  `type[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#type>)[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")]` |  The type used for dependency injection, this parameter exists solely to allow you to fully parameterize the agent, and therefore get the best out of static type checking. If you're not using deps, but want type checking to pass, you can set `deps=None` to satisfy Pyright or add a type hint `: Agent[None, <return type>]`. |  `NoneType`  
`name` |  `str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The name of the agent, used for logging. If `None`, we try to infer the agent name from the call frame when the agent is first run. |  `None`  
`model_settings` |  `ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None` |  Optional model request settings to use for this agent's runs, by default. |  `None`  
`retries` |  `int[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#int>)` |  The default number of retries to allow before raising an error. |  `1`  
`result_tool_name` |  `str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  The name of the tool to use for the final result. |  `'final_result'`  
`result_tool_description` |  `str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The description of the final result tool. |  `None`  
`result_retries` |  `int[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#int>) | None` |  The maximum number of retries to allow for result validation, defaults to `retries`. |  `None`  
`tools` |  `Sequence[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[Tool[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.Tool> "pydantic_ai.tools.Tool")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")] | ToolFuncEither[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolFuncEither> "pydantic_ai.tools.ToolFuncEither")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), ...]]` |  Tools to register with the agent, you can also register tools via the decorators `@agent.tool`[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.tool>) and `@agent.tool_plain`[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.tool_plain>). |  `()`  
`defer_model_check` |  `bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>)` |  by default, if you provide a [named](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName>) model, it's evaluated to create a `Model`[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model>) instance immediately, which checks for the necessary environment variables. Set this to `false` to defer the evaluation until the first run. Useful if you want to [override the model](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.override>) for testing. |  `False`  
`end_strategy` |  `EndStrategy[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.EndStrategy> "pydantic_ai._agent_graph.EndStrategy")` |  Strategy for handling tool calls that are requested alongside a final result. See `EndStrategy`[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.EndStrategy>) for more information. |  `'early'`  
Source code in `pydantic_ai_slim/pydantic_ai/agent.py`
```
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
```
| ```
def __init__(
  self,
  model: models.Model | models.KnownModelName | None = None,
  *,
  result_type: type[ResultDataT] = str,
  system_prompt: str | Sequence[str] = (),
  deps_type: type[AgentDepsT] = NoneType,
  name: str | None = None,
  model_settings: ModelSettings | None = None,
  retries: int = 1,
  result_tool_name: str = 'final_result',
  result_tool_description: str | None = None,
  result_retries: int | None = None,
  tools: Sequence[Tool[AgentDepsT] | ToolFuncEither[AgentDepsT, ...]] = (),
  defer_model_check: bool = False,
  end_strategy: EndStrategy = 'early',
):
"""Create an agent.
  Args:
    model: The default model to use for this agent, if not provide,
      you must provide the model when calling it.
    result_type: The type of the result data, used to validate the result data, defaults to `str`.
    system_prompt: Static system prompts to use for this agent, you can also register system
      prompts via a function with [`system_prompt`][pydantic_ai.Agent.system_prompt].
    deps_type: The type used for dependency injection, this parameter exists solely to allow you to fully
      parameterize the agent, and therefore get the best out of static type checking.
      If you're not using deps, but want type checking to pass, you can set `deps=None` to satisfy Pyright
      or add a type hint `: Agent[None, <return type>]`.
    name: The name of the agent, used for logging. If `None`, we try to infer the agent name from the call frame
      when the agent is first run.
    model_settings: Optional model request settings to use for this agent's runs, by default.
    retries: The default number of retries to allow before raising an error.
    result_tool_name: The name of the tool to use for the final result.
    result_tool_description: The description of the final result tool.
    result_retries: The maximum number of retries to allow for result validation, defaults to `retries`.
    tools: Tools to register with the agent, you can also register tools via the decorators
      [`@agent.tool`][pydantic_ai.Agent.tool] and [`@agent.tool_plain`][pydantic_ai.Agent.tool_plain].
    defer_model_check: by default, if you provide a [named][pydantic_ai.models.KnownModelName] model,
      it's evaluated to create a [`Model`][pydantic_ai.models.Model] instance immediately,
      which checks for the necessary environment variables. Set this to `false`
      to defer the evaluation until the first run. Useful if you want to
      [override the model][pydantic_ai.Agent.override] for testing.
    end_strategy: Strategy for handling tool calls that are requested alongside a final result.
      See [`EndStrategy`][pydantic_ai.agent.EndStrategy] for more information.
  """
  if model is None or defer_model_check:
    self.model = model
  else:
    self.model = models.infer_model(model)
  self.end_strategy = end_strategy
  self.name = name
  self.model_settings = model_settings
  self.result_type = result_type
  self._deps_type = deps_type
  self._result_tool_name = result_tool_name
  self._result_tool_description = result_tool_description
  self._result_schema: _result.ResultSchema[ResultDataT] | None = _result.ResultSchema[result_type].build(
    result_type, result_tool_name, result_tool_description
  )
  self._result_validators: list[_result.ResultValidator[AgentDepsT, ResultDataT]] = []
  self._system_prompts = (system_prompt,) if isinstance(system_prompt, str) else tuple(system_prompt)
  self._system_prompt_functions: list[_system_prompt.SystemPromptRunner[AgentDepsT]] = []
  self._system_prompt_dynamic_functions: dict[str, _system_prompt.SystemPromptRunner[AgentDepsT]] = {}
  self._function_tools: dict[str, Tool[AgentDepsT]] = {}
  self._default_retries = retries
  self._max_result_retries = result_retries if result_retries is not None else retries
  for tool in tools:
    if isinstance(tool, Tool):
      self._register_tool(tool)
    else:
      self._register_tool(Tool(tool))

```
  
---|---  
####  end_strategy `instance-attribute`
```
end_strategy: EndStrategy[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.EndStrategy> "pydantic_ai._agent_graph.EndStrategy") = end_strategy[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.end_strategy> "pydantic_ai.agent.Agent.end_strategy")

```

Strategy for handling tool calls when a final result is found.
####  name `instance-attribute`
```
name: str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = name[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.name> "pydantic_ai.agent.Agent.name")

```

The name of the agent, used for logging.
If `None`, we try to infer the agent name from the call frame when the agent is first run.
####  model_settings `instance-attribute`
```
model_settings: ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None = model_settings[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.model_settings> "pydantic_ai.agent.Agent.model_settings")

```

Optional model request settings to use for this agents's runs, by default.
Note, if `model_settings` is provided by `run`, `run_sync`, or `run_stream`, those settings will be merged with this value, with the runtime argument taking priority.
####  result_type `class-attribute` `instance-attribute`
```
result_type: type[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#type>)[ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")] = result_type[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.result_type> "pydantic_ai.agent.Agent.result_type")

```

The type of the result data, used to validate the result data, defaults to `str`.
####  run `async`
```
run(
  user_prompt: str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>),
  *,
  result_type: None = None,
  message_history: list[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/agent/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")] | None = None,
  model: Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None = None,
  deps: AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT") = None,
  model_settings: ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None = None,
  usage_limits: UsageLimits[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.UsageLimits> "pydantic_ai.usage.UsageLimits") | None = None,
  usage: Usage[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage") | None = None,
  infer_name: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = True
) -> RunResult[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.RunResult> "pydantic_ai.result.RunResult")[ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]

```

```
run(
  user_prompt: str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>),
  *,
  result_type: type[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#type>)[RunResultDataT],
  message_history: list[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/agent/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")] | None = None,
  model: Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None = None,
  deps: AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT") = None,
  model_settings: ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None = None,
  usage_limits: UsageLimits[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.UsageLimits> "pydantic_ai.usage.UsageLimits") | None = None,
  usage: Usage[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage") | None = None,
  infer_name: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = True
) -> RunResult[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.RunResult> "pydantic_ai.result.RunResult")[RunResultDataT]

```

```
run(
  user_prompt: str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>),
  *,
  message_history: list[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/agent/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")] | None = None,
  model: Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None = None,
  deps: AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT") = None,
  model_settings: ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None = None,
  usage_limits: UsageLimits[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.UsageLimits> "pydantic_ai.usage.UsageLimits") | None = None,
  usage: Usage[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage") | None = None,
  result_type: type[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#type>)[RunResultDataT] | None = None,
  infer_name: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = True
) -> RunResult[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.RunResult> "pydantic_ai.result.RunResult")[Any[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")]

```

Run the agent with a user prompt in async mode.
Example: 
```
from pydantic_ai import Agent
agent = Agent('openai:gpt-4o')
async def main():
  result = await agent.run('What is the capital of France?')
  print(result.data)
  #> Paris

```

Parameters:
Name | Type | Description | Default  
---|---|---|---  
`result_type` |  `type[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#type>)[RunResultDataT] | None` |  Custom result type to use for this run, `result_type` may only be used if the agent has no result validators since result validators would expect an argument that matches the agent's result type. |  `None`  
`user_prompt` |  `str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  User input to start/continue the conversation. |  _required_  
`message_history` |  `list[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/agent/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")] | None` |  History of the conversation so far. |  `None`  
`model` |  `Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None` |  Optional model to use for this run, required if `model` was not set when creating the agent. |  `None`  
`deps` |  `AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")` |  Optional dependencies to use for this run. |  `None`  
`model_settings` |  `ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None` |  Optional settings to use for this model's request. |  `None`  
`usage_limits` |  `UsageLimits[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.UsageLimits> "pydantic_ai.usage.UsageLimits") | None` |  Optional limits on model request count or token usage. |  `None`  
`usage` |  `Usage[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage") | None` |  Optional usage to start with, useful for resuming a conversation or agents used in tools. |  `None`  
`infer_name` |  `bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to try to infer the agent name from the call frame if it's not set. |  `True`  
Returns:
Type | Description  
---|---  
`RunResult[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.RunResult> "pydantic_ai.result.RunResult")[Any[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")]` |  The result of the run.  
Source code in `pydantic_ai_slim/pydantic_ai/agent.py`
```
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
```
| ```
async def run(
  self,
  user_prompt: str,
  *,
  message_history: list[_messages.ModelMessage] | None = None,
  model: models.Model | models.KnownModelName | None = None,
  deps: AgentDepsT = None,
  model_settings: ModelSettings | None = None,
  usage_limits: _usage.UsageLimits | None = None,
  usage: _usage.Usage | None = None,
  result_type: type[RunResultDataT] | None = None,
  infer_name: bool = True,
) -> result.RunResult[Any]:
"""Run the agent with a user prompt in async mode.
  Example:
  ```python
  from pydantic_ai import Agent
  agent = Agent('openai:gpt-4o')
  async def main():
    result = await agent.run('What is the capital of France?')
    print(result.data)
    #> Paris
  ```
  Args:
    result_type: Custom result type to use for this run, `result_type` may only be used if the agent has no
      result validators since result validators would expect an argument that matches the agent's result type.
    user_prompt: User input to start/continue the conversation.
    message_history: History of the conversation so far.
    model: Optional model to use for this run, required if `model` was not set when creating the agent.
    deps: Optional dependencies to use for this run.
    model_settings: Optional settings to use for this model's request.
    usage_limits: Optional limits on model request count or token usage.
    usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.
    infer_name: Whether to try to infer the agent name from the call frame if it's not set.
  Returns:
    The result of the run.
  """
  if infer_name and self.name is None:
    self._infer_name(inspect.currentframe())
  model_used = await self._get_model(model)
  deps = self._get_deps(deps)
  new_message_index = len(message_history) if message_history else 0
  result_schema: _result.ResultSchema[RunResultDataT] | None = self._prepare_result_schema(result_type)
  # Build the graph
  graph = _agent_graph.build_agent_graph(self.name, self._deps_type, result_type or self.result_type)
  # Build the initial state
  state = _agent_graph.GraphAgentState(
    message_history=message_history[:] if message_history else [],
    usage=usage or _usage.Usage(),
    retries=0,
    run_step=0,
  )
  # We consider it a user error if a user tries to restrict the result type while having a result validator that
  # may change the result type from the restricted type to something else. Therefore, we consider the following
  # typecast reasonable, even though it is possible to violate it with otherwise-type-checked code.
  result_validators = cast(list[_result.ResultValidator[AgentDepsT, RunResultDataT]], self._result_validators)
  # TODO: Instead of this, copy the function tools to ensure they don't share current_retry state between agent
  # runs. Requires some changes to `Tool` to make them copyable though.
  for v in self._function_tools.values():
    v.current_retry = 0
  model_settings = merge_model_settings(self.model_settings, model_settings)
  usage_limits = usage_limits or _usage.UsageLimits()
  with _logfire.span(
    '{agent_name} run {prompt=}',
    prompt=user_prompt,
    agent=self,
    model_name=model_used.name() if model_used else 'no-model',
    agent_name=self.name or 'agent',
  ) as run_span:
    # Build the deps object for the graph
    graph_deps = _agent_graph.GraphAgentDeps[AgentDepsT, RunResultDataT](
      user_deps=deps,
      prompt=user_prompt,
      new_message_index=new_message_index,
      model=model_used,
      model_settings=model_settings,
      usage_limits=usage_limits,
      max_result_retries=self._max_result_retries,
      end_strategy=self.end_strategy,
      result_schema=result_schema,
      result_tools=self._result_schema.tool_defs() if self._result_schema else [],
      result_validators=result_validators,
      function_tools=self._function_tools,
      run_span=run_span,
    )
    start_node = _agent_graph.UserPromptNode[AgentDepsT](
      user_prompt=user_prompt,
      system_prompts=self._system_prompts,
      system_prompt_functions=self._system_prompt_functions,
      system_prompt_dynamic_functions=self._system_prompt_dynamic_functions,
    )
    # Actually run
    end_result, _ = await graph.run(
      start_node,
      state=state,
      deps=graph_deps,
      infer_name=False,
    )
  # Build final run result
  # We don't do any advanced checking if the data is actually from a final result or not
  return result.RunResult(
    state.message_history,
    new_message_index,
    end_result.data,
    end_result.tool_name,
    state.usage,
  )

```
  
---|---  
####  run_sync
```
run_sync(
  user_prompt: str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>),
  *,
  message_history: list[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/agent/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")] | None = None,
  model: Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None = None,
  deps: AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT") = None,
  model_settings: ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None = None,
  usage_limits: UsageLimits[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.UsageLimits> "pydantic_ai.usage.UsageLimits") | None = None,
  usage: Usage[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage") | None = None,
  infer_name: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = True
) -> RunResult[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.RunResult> "pydantic_ai.result.RunResult")[ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]

```

```
run_sync(
  user_prompt: str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>),
  *,
  result_type: type[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#type>)[RunResultDataT] | None,
  message_history: list[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/agent/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")] | None = None,
  model: Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None = None,
  deps: AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT") = None,
  model_settings: ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None = None,
  usage_limits: UsageLimits[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.UsageLimits> "pydantic_ai.usage.UsageLimits") | None = None,
  usage: Usage[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage") | None = None,
  infer_name: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = True
) -> RunResult[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.RunResult> "pydantic_ai.result.RunResult")[RunResultDataT]

```

```
run_sync(
  user_prompt: str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>),
  *,
  result_type: type[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#type>)[RunResultDataT] | None = None,
  message_history: list[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/agent/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")] | None = None,
  model: Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None = None,
  deps: AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT") = None,
  model_settings: ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None = None,
  usage_limits: UsageLimits[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.UsageLimits> "pydantic_ai.usage.UsageLimits") | None = None,
  usage: Usage[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage") | None = None,
  infer_name: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = True
) -> RunResult[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.RunResult> "pydantic_ai.result.RunResult")[Any[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")]

```

Run the agent with a user prompt synchronously.
This is a convenience method that wraps `self.run`[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.run>) with `loop.run_until_complete(...)`. You therefore can't use this method inside async code or if there's an active event loop.
Example: 
```
from pydantic_ai import Agent
agent = Agent('openai:gpt-4o')
result_sync = agent.run_sync('What is the capital of Italy?')
print(result_sync.data)
#> Rome

```

Parameters:
Name | Type | Description | Default  
---|---|---|---  
`result_type` |  `type[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#type>)[RunResultDataT] | None` |  Custom result type to use for this run, `result_type` may only be used if the agent has no result validators since result validators would expect an argument that matches the agent's result type. |  `None`  
`user_prompt` |  `str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  User input to start/continue the conversation. |  _required_  
`message_history` |  `list[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/agent/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")] | None` |  History of the conversation so far. |  `None`  
`model` |  `Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None` |  Optional model to use for this run, required if `model` was not set when creating the agent. |  `None`  
`deps` |  `AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")` |  Optional dependencies to use for this run. |  `None`  
`model_settings` |  `ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None` |  Optional settings to use for this model's request. |  `None`  
`usage_limits` |  `UsageLimits[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.UsageLimits> "pydantic_ai.usage.UsageLimits") | None` |  Optional limits on model request count or token usage. |  `None`  
`usage` |  `Usage[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage") | None` |  Optional usage to start with, useful for resuming a conversation or agents used in tools. |  `None`  
`infer_name` |  `bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to try to infer the agent name from the call frame if it's not set. |  `True`  
Returns:
Type | Description  
---|---  
`RunResult[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.RunResult> "pydantic_ai.result.RunResult")[Any[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")]` |  The result of the run.  
Source code in `pydantic_ai_slim/pydantic_ai/agent.py`
```
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439
440
441
442
443
444
```
| ```
def run_sync(
  self,
  user_prompt: str,
  *,
  result_type: type[RunResultDataT] | None = None,
  message_history: list[_messages.ModelMessage] | None = None,
  model: models.Model | models.KnownModelName | None = None,
  deps: AgentDepsT = None,
  model_settings: ModelSettings | None = None,
  usage_limits: _usage.UsageLimits | None = None,
  usage: _usage.Usage | None = None,
  infer_name: bool = True,
) -> result.RunResult[Any]:
"""Run the agent with a user prompt synchronously.
  This is a convenience method that wraps [`self.run`][pydantic_ai.Agent.run] with `loop.run_until_complete(...)`.
  You therefore can't use this method inside async code or if there's an active event loop.
  Example:
  ```python
  from pydantic_ai import Agent
  agent = Agent('openai:gpt-4o')
  result_sync = agent.run_sync('What is the capital of Italy?')
  print(result_sync.data)
  #> Rome
  ```
  Args:
    result_type: Custom result type to use for this run, `result_type` may only be used if the agent has no
      result validators since result validators would expect an argument that matches the agent's result type.
    user_prompt: User input to start/continue the conversation.
    message_history: History of the conversation so far.
    model: Optional model to use for this run, required if `model` was not set when creating the agent.
    deps: Optional dependencies to use for this run.
    model_settings: Optional settings to use for this model's request.
    usage_limits: Optional limits on model request count or token usage.
    usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.
    infer_name: Whether to try to infer the agent name from the call frame if it's not set.
  Returns:
    The result of the run.
  """
  if infer_name and self.name is None:
    self._infer_name(inspect.currentframe())
  return asyncio.get_event_loop().run_until_complete(
    self.run(
      user_prompt,
      result_type=result_type,
      message_history=message_history,
      model=model,
      deps=deps,
      model_settings=model_settings,
      usage_limits=usage_limits,
      usage=usage,
      infer_name=False,
    )
  )

```
  
---|---  
####  run_stream `async`
```
run_stream(
  user_prompt: str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>),
  *,
  result_type: None = None,
  message_history: list[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/agent/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")] | None = None,
  model: Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None = None,
  deps: AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT") = None,
  model_settings: ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None = None,
  usage_limits: UsageLimits[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.UsageLimits> "pydantic_ai.usage.UsageLimits") | None = None,
  usage: Usage[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage") | None = None,
  infer_name: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = True
) -> AbstractAsyncContextManager[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/contextlib.html#contextlib.AbstractAsyncContextManager> "contextlib.AbstractAsyncContextManager")[
  StreamedRunResult[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.StreamedRunResult> "pydantic_ai.result.StreamedRunResult")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]
]

```

```
run_stream(
  user_prompt: str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>),
  *,
  result_type: type[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#type>)[RunResultDataT],
  message_history: list[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/agent/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")] | None = None,
  model: Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None = None,
  deps: AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT") = None,
  model_settings: ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None = None,
  usage_limits: UsageLimits[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.UsageLimits> "pydantic_ai.usage.UsageLimits") | None = None,
  usage: Usage[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage") | None = None,
  infer_name: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = True
) -> AbstractAsyncContextManager[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/contextlib.html#contextlib.AbstractAsyncContextManager> "contextlib.AbstractAsyncContextManager")[
  StreamedRunResult[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.StreamedRunResult> "pydantic_ai.result.StreamedRunResult")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), RunResultDataT]
]

```

```
run_stream(
  user_prompt: str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>),
  *,
  result_type: type[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#type>)[RunResultDataT] | None = None,
  message_history: list[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/agent/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")] | None = None,
  model: Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None = None,
  deps: AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT") = None,
  model_settings: ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None = None,
  usage_limits: UsageLimits[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.UsageLimits> "pydantic_ai.usage.UsageLimits") | None = None,
  usage: Usage[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage") | None = None,
  infer_name: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = True
) -> AsyncIterator[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.AsyncIterator> "collections.abc.AsyncIterator")[StreamedRunResult[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.StreamedRunResult> "pydantic_ai.result.StreamedRunResult")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), Any[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")]]

```

Run the agent with a user prompt in async mode, returning a streamed response.
Example: 
```
from pydantic_ai import Agent
agent = Agent('openai:gpt-4o')
async def main():
  async with agent.run_stream('What is the capital of the UK?') as response:
    print(await response.get_data())
    #> London

```

Parameters:
Name | Type | Description | Default  
---|---|---|---  
`result_type` |  `type[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#type>)[RunResultDataT] | None` |  Custom result type to use for this run, `result_type` may only be used if the agent has no result validators since result validators would expect an argument that matches the agent's result type. |  `None`  
`user_prompt` |  `str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  User input to start/continue the conversation. |  _required_  
`message_history` |  `list[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/agent/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")] | None` |  History of the conversation so far. |  `None`  
`model` |  `Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | None` |  Optional model to use for this run, required if `model` was not set when creating the agent. |  `None`  
`deps` |  `AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")` |  Optional dependencies to use for this run. |  `None`  
`model_settings` |  `ModelSettings[](https://ai.pydantic.dev/api/agent/<../settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None` |  Optional settings to use for this model's request. |  `None`  
`usage_limits` |  `UsageLimits[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.UsageLimits> "pydantic_ai.usage.UsageLimits") | None` |  Optional limits on model request count or token usage. |  `None`  
`usage` |  `Usage[](https://ai.pydantic.dev/api/agent/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage") | None` |  Optional usage to start with, useful for resuming a conversation or agents used in tools. |  `None`  
`infer_name` |  `bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to try to infer the agent name from the call frame if it's not set. |  `True`  
Returns:
Type | Description  
---|---  
`AsyncIterator[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.AsyncIterator> "collections.abc.AsyncIterator")[StreamedRunResult[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.StreamedRunResult> "pydantic_ai.result.StreamedRunResult")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), Any[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")]]` |  The result of the run.  
Source code in `pydantic_ai_slim/pydantic_ai/agent.py`
```
476
477
478
479
480
481
482
483
484
485
486
487
488
489
490
491
492
493
494
495
496
497
498
499
500
501
502
503
504
505
506
507
508
509
510
511
512
513
514
515
516
517
518
519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544
545
546
547
548
549
550
551
552
553
554
555
556
557
558
559
560
561
562
563
564
565
566
567
568
569
570
571
572
573
574
575
576
577
578
579
580
581
582
583
584
585
586
587
588
589
590
591
592
593
594
595
596
597
598
599
600
601
602
603
604
605
606
```
| ```
@asynccontextmanager
async def run_stream(
  self,
  user_prompt: str,
  *,
  result_type: type[RunResultDataT] | None = None,
  message_history: list[_messages.ModelMessage] | None = None,
  model: models.Model | models.KnownModelName | None = None,
  deps: AgentDepsT = None,
  model_settings: ModelSettings | None = None,
  usage_limits: _usage.UsageLimits | None = None,
  usage: _usage.Usage | None = None,
  infer_name: bool = True,
) -> AsyncIterator[result.StreamedRunResult[AgentDepsT, Any]]:
"""Run the agent with a user prompt in async mode, returning a streamed response.
  Example:
  ```python
  from pydantic_ai import Agent
  agent = Agent('openai:gpt-4o')
  async def main():
    async with agent.run_stream('What is the capital of the UK?') as response:
      print(await response.get_data())
      #> London
  ```
  Args:
    result_type: Custom result type to use for this run, `result_type` may only be used if the agent has no
      result validators since result validators would expect an argument that matches the agent's result type.
    user_prompt: User input to start/continue the conversation.
    message_history: History of the conversation so far.
    model: Optional model to use for this run, required if `model` was not set when creating the agent.
    deps: Optional dependencies to use for this run.
    model_settings: Optional settings to use for this model's request.
    usage_limits: Optional limits on model request count or token usage.
    usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.
    infer_name: Whether to try to infer the agent name from the call frame if it's not set.
  Returns:
    The result of the run.
  """
  if infer_name and self.name is None:
    # f_back because `asynccontextmanager` adds one frame
    if frame := inspect.currentframe(): # pragma: no branch
      self._infer_name(frame.f_back)
  model_used = await self._get_model(model)
  deps = self._get_deps(deps)
  new_message_index = len(message_history) if message_history else 0
  result_schema: _result.ResultSchema[RunResultDataT] | None = self._prepare_result_schema(result_type)
  # Build the graph
  graph = self._build_stream_graph(result_type)
  # Build the initial state
  graph_state = _agent_graph.GraphAgentState(
    message_history=message_history[:] if message_history else [],
    usage=usage or _usage.Usage(),
    retries=0,
    run_step=0,
  )
  # We consider it a user error if a user tries to restrict the result type while having a result validator that
  # may change the result type from the restricted type to something else. Therefore, we consider the following
  # typecast reasonable, even though it is possible to violate it with otherwise-type-checked code.
  result_validators = cast(list[_result.ResultValidator[AgentDepsT, RunResultDataT]], self._result_validators)
  # TODO: Instead of this, copy the function tools to ensure they don't share current_retry state between agent
  # runs. Requires some changes to `Tool` to make them copyable though.
  for v in self._function_tools.values():
    v.current_retry = 0
  model_settings = merge_model_settings(self.model_settings, model_settings)
  usage_limits = usage_limits or _usage.UsageLimits()
  with _logfire.span(
    '{agent_name} run stream {prompt=}',
    prompt=user_prompt,
    agent=self,
    model_name=model_used.name(),
    agent_name=self.name or 'agent',
  ) as run_span:
    # Build the deps object for the graph
    graph_deps = _agent_graph.GraphAgentDeps[AgentDepsT, RunResultDataT](
      user_deps=deps,
      prompt=user_prompt,
      new_message_index=new_message_index,
      model=model_used,
      model_settings=model_settings,
      usage_limits=usage_limits,
      max_result_retries=self._max_result_retries,
      end_strategy=self.end_strategy,
      result_schema=result_schema,
      result_tools=self._result_schema.tool_defs() if self._result_schema else [],
      result_validators=result_validators,
      function_tools=self._function_tools,
      run_span=run_span,
    )
    start_node = _agent_graph.StreamUserPromptNode[AgentDepsT](
      user_prompt=user_prompt,
      system_prompts=self._system_prompts,
      system_prompt_functions=self._system_prompt_functions,
      system_prompt_dynamic_functions=self._system_prompt_dynamic_functions,
    )
    # Actually run
    node = start_node
    history: list[HistoryStep[_agent_graph.GraphAgentState, RunResultDataT]] = []
    while True:
      if isinstance(node, _agent_graph.StreamModelRequestNode):
        node = cast(
          _agent_graph.StreamModelRequestNode[
            AgentDepsT, result.StreamedRunResult[AgentDepsT, RunResultDataT]
          ],
          node,
        )
        async with node.run_to_result(GraphRunContext(graph_state, graph_deps)) as r:
          if isinstance(r, End):
            yield r.data
            break
      assert not isinstance(node, End) # the previous line should be hit first
      node = await graph.next(
        node,
        history,
        state=graph_state,
        deps=graph_deps,
        infer_name=False,
      )

```
  
---|---  
####  override
```
override(
  *,
  deps: AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT") | Unset = UNSET,
  model: Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | Unset = UNSET
) -> Iterator[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Iterator> "collections.abc.Iterator")[None]

```

Context manager to temporarily override agent dependencies and model.
This is particularly useful when testing. You can find an example of this [here](https://ai.pydantic.dev/api/agent/testing-evals/#overriding-model-via-pytest-fixtures>).
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`deps` |  `AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT") | Unset` |  The dependencies to use instead of the dependencies passed to the agent run. |  `UNSET`  
`model` |  `Model[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model") | KnownModelName[](https://ai.pydantic.dev/api/agent/<../models/base/#pydantic_ai.models.KnownModelName> "pydantic_ai.models.KnownModelName") | Unset` |  The model to use instead of the model passed to the agent run. |  `UNSET`  
Source code in `pydantic_ai_slim/pydantic_ai/agent.py`
```
608
609
610
611
612
613
614
615
616
617
618
619
620
621
622
623
624
625
626
627
628
629
630
631
632
633
634
635
636
637
638
639
640
641
642
643
644
```
| ```
@contextmanager
def override(
  self,
  *,
  deps: AgentDepsT | _utils.Unset = _utils.UNSET,
  model: models.Model | models.KnownModelName | _utils.Unset = _utils.UNSET,
) -> Iterator[None]:
"""Context manager to temporarily override agent dependencies and model.
  This is particularly useful when testing.
  You can find an example of this [here](../testing-evals.md#overriding-model-via-pytest-fixtures).
  Args:
    deps: The dependencies to use instead of the dependencies passed to the agent run.
    model: The model to use instead of the model passed to the agent run.
  """
  if _utils.is_set(deps):
    override_deps_before = self._override_deps
    self._override_deps = _utils.Some(deps)
  else:
    override_deps_before = _utils.UNSET
  # noinspection PyTypeChecker
  if _utils.is_set(model):
    override_model_before = self._override_model
    # noinspection PyTypeChecker
    self._override_model = _utils.Some(models.infer_model(model)) # pyright: ignore[reportArgumentType]
  else:
    override_model_before = _utils.UNSET
  try:
    yield
  finally:
    if _utils.is_set(override_deps_before):
      self._override_deps = override_deps_before
    if _utils.is_set(override_model_before):
      self._override_model = override_model_before

```
  
---|---  
####  system_prompt
```
system_prompt(
  func: Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[RunContext[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")]], str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)]
) -> Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[RunContext[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")]], str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)]

```

```
system_prompt(
  func: Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[RunContext[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")]], Awaitable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Awaitable> "collections.abc.Awaitable")[str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)]]
) -> Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[RunContext[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")]], Awaitable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Awaitable> "collections.abc.Awaitable")[str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)]]

```

```
system_prompt(func: Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[], str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)]) -> Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[], str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)]

```

```
system_prompt(
  func: Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[], Awaitable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Awaitable> "collections.abc.Awaitable")[str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)]]
) -> Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[], Awaitable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Awaitable> "collections.abc.Awaitable")[str[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#str>)]]

```

```
system_prompt(*, dynamic: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = False) -> Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[
  [SystemPromptFunc[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.SystemPromptFunc> "pydantic_ai._system_prompt.SystemPromptFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")]],
  SystemPromptFunc[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.SystemPromptFunc> "pydantic_ai._system_prompt.SystemPromptFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")],
]

```

```
system_prompt(
  func: SystemPromptFunc[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.SystemPromptFunc> "pydantic_ai._system_prompt.SystemPromptFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")] | None = None,
  /,
  *,
  dynamic: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = False,
) -> (
  Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[
    [SystemPromptFunc[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.SystemPromptFunc> "pydantic_ai._system_prompt.SystemPromptFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")]],
    SystemPromptFunc[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.SystemPromptFunc> "pydantic_ai._system_prompt.SystemPromptFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")],
  ]
  | SystemPromptFunc[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.SystemPromptFunc> "pydantic_ai._system_prompt.SystemPromptFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")]
)

```

Decorator to register a system prompt function.
Optionally takes `RunContext`[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.RunContext>) as its only argument. Can decorate a sync or async functions.
The decorator can be used either bare (`agent.system_prompt`) or as a function call (`agent.system_prompt(...)`), see the examples below.
Overloads for every possible signature of `system_prompt` are included so the decorator doesn't obscure the type of the function, see `tests/typed_agent.py` for tests.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`func` |  `SystemPromptFunc[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.SystemPromptFunc> "pydantic_ai._system_prompt.SystemPromptFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")] | None` |  The function to decorate |  `None`  
`dynamic` |  `bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>)` |  If True, the system prompt will be reevaluated even when `messages_history` is provided, see `SystemPromptPart.dynamic_ref`[](https://ai.pydantic.dev/api/agent/<../messages/#pydantic_ai.messages.SystemPromptPart.dynamic_ref>) |  `False`  
Example: 
```
from pydantic_ai import Agent, RunContext
agent = Agent('test', deps_type=str)
@agent.system_prompt
def simple_system_prompt() -> str:
  return 'foobar'
@agent.system_prompt(dynamic=True)
async def async_system_prompt(ctx: RunContext[str]) -> str:
  return f'{ctx.deps} is the best'

```

Source code in `pydantic_ai_slim/pydantic_ai/agent.py`
```
667
668
669
670
671
672
673
674
675
676
677
678
679
680
681
682
683
684
685
686
687
688
689
690
691
692
693
694
695
696
697
698
699
700
701
702
703
704
705
706
707
708
709
710
711
712
713
714
715
716
717
718
719
720
721
722
723
```
| ```
def system_prompt(
  self,
  func: _system_prompt.SystemPromptFunc[AgentDepsT] | None = None,
  /,
  *,
  dynamic: bool = False,
) -> (
  Callable[[_system_prompt.SystemPromptFunc[AgentDepsT]], _system_prompt.SystemPromptFunc[AgentDepsT]]
  | _system_prompt.SystemPromptFunc[AgentDepsT]
):
"""Decorator to register a system prompt function.
  Optionally takes [`RunContext`][pydantic_ai.tools.RunContext] as its only argument.
  Can decorate a sync or async functions.
  The decorator can be used either bare (`agent.system_prompt`) or as a function call
  (`agent.system_prompt(...)`), see the examples below.
  Overloads for every possible signature of `system_prompt` are included so the decorator doesn't obscure
  the type of the function, see `tests/typed_agent.py` for tests.
  Args:
    func: The function to decorate
    dynamic: If True, the system prompt will be reevaluated even when `messages_history` is provided,
      see [`SystemPromptPart.dynamic_ref`][pydantic_ai.messages.SystemPromptPart.dynamic_ref]
  Example:
  ```python
  from pydantic_ai import Agent, RunContext
  agent = Agent('test', deps_type=str)
  @agent.system_prompt
  def simple_system_prompt() -> str:
    return 'foobar'
  @agent.system_prompt(dynamic=True)
  async def async_system_prompt(ctx: RunContext[str]) -> str:
    return f'{ctx.deps} is the best'
  ```
  """
  if func is None:
    def decorator(
      func_: _system_prompt.SystemPromptFunc[AgentDepsT],
    ) -> _system_prompt.SystemPromptFunc[AgentDepsT]:
      runner = _system_prompt.SystemPromptRunner[AgentDepsT](func_, dynamic=dynamic)
      self._system_prompt_functions.append(runner)
      if dynamic:
        self._system_prompt_dynamic_functions[func_.__qualname__] = runner
      return func_
    return decorator
  else:
    assert not dynamic, "dynamic can't be True in this case"
    self._system_prompt_functions.append(_system_prompt.SystemPromptRunner[AgentDepsT](func, dynamic=dynamic))
    return func

```
  
---|---  
####  result_validator
```
result_validator(
  func: Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[
    [RunContext[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")], ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")], ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")
  ]
) -> Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[
  [RunContext[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")], ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")], ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")
]

```

```
result_validator(
  func: Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[
    [RunContext[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")], ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")],
    Awaitable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Awaitable> "collections.abc.Awaitable")[ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")],
  ]
) -> Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[
  [RunContext[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")], ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")],
  Awaitable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Awaitable> "collections.abc.Awaitable")[ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")],
]

```

```
result_validator(
  func: Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")], ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]
) -> Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")], ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]

```

```
result_validator(
  func: Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")], Awaitable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Awaitable> "collections.abc.Awaitable")[ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]]
) -> Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")], Awaitable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Awaitable> "collections.abc.Awaitable")[ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]]

```

```
result_validator(
  func: ResultValidatorFunc[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultValidatorFunc> "pydantic_ai._result.ResultValidatorFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]
) -> ResultValidatorFunc[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultValidatorFunc> "pydantic_ai._result.ResultValidatorFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), ResultDataT[](https://ai.pydantic.dev/api/agent/<../result/#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]

```

Decorator to register a result validator function.
Optionally takes `RunContext`[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.RunContext>) as its first argument. Can decorate a sync or async functions.
Overloads for every possible signature of `result_validator` are included so the decorator doesn't obscure the type of the function, see `tests/typed_agent.py` for tests.
Example: 
```
from pydantic_ai import Agent, ModelRetry, RunContext
agent = Agent('test', deps_type=str)
@agent.result_validator
def result_validator_simple(data: str) -> str:
  if 'wrong' in data:
    raise ModelRetry('wrong response')
  return data
@agent.result_validator
async def result_validator_deps(ctx: RunContext[str], data: str) -> str:
  if ctx.deps in data:
    raise ModelRetry('wrong response')
  return data
result = agent.run_sync('foobar', deps='spam')
print(result.data)
#> success (no tool calls)

```

Source code in `pydantic_ai_slim/pydantic_ai/agent.py`
```
745
746
747
748
749
750
751
752
753
754
755
756
757
758
759
760
761
762
763
764
765
766
767
768
769
770
771
772
773
774
775
776
777
778
779
780
```
| ```
def result_validator(
  self, func: _result.ResultValidatorFunc[AgentDepsT, ResultDataT], /
) -> _result.ResultValidatorFunc[AgentDepsT, ResultDataT]:
"""Decorator to register a result validator function.
  Optionally takes [`RunContext`][pydantic_ai.tools.RunContext] as its first argument.
  Can decorate a sync or async functions.
  Overloads for every possible signature of `result_validator` are included so the decorator doesn't obscure
  the type of the function, see `tests/typed_agent.py` for tests.
  Example:
  ```python
  from pydantic_ai import Agent, ModelRetry, RunContext
  agent = Agent('test', deps_type=str)
  @agent.result_validator
  def result_validator_simple(data: str) -> str:
    if 'wrong' in data:
      raise ModelRetry('wrong response')
    return data
  @agent.result_validator
  async def result_validator_deps(ctx: RunContext[str], data: str) -> str:
    if ctx.deps in data:
      raise ModelRetry('wrong response')
    return data
  result = agent.run_sync('foobar', deps='spam')
  print(result.data)
  #> success (no tool calls)
  ```
  """
  self._result_validators.append(_result.ResultValidator[AgentDepsT, Any](func))
  return func

```
  
---|---  
####  tool
```
tool(
  func: ToolFuncContext[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolFuncContext> "pydantic_ai.tools.ToolFuncContext")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), ToolParams[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")]
) -> ToolFuncContext[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolFuncContext> "pydantic_ai.tools.ToolFuncContext")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), ToolParams[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")]

```

```
tool(
  *,
  retries: int[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#int>) | None = None,
  prepare: ToolPrepareFunc[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolPrepareFunc> "pydantic_ai.tools.ToolPrepareFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")] | None = None,
  docstring_format: DocstringFormat[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.DocstringFormat> "pydantic_ai.tools.DocstringFormat") = "auto",
  require_parameter_descriptions: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = False
) -> Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[
  [ToolFuncContext[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolFuncContext> "pydantic_ai.tools.ToolFuncContext")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), ToolParams[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")]],
  ToolFuncContext[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolFuncContext> "pydantic_ai.tools.ToolFuncContext")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), ToolParams[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")],
]

```

```
tool(
  func: (
    ToolFuncContext[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolFuncContext> "pydantic_ai.tools.ToolFuncContext")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), ToolParams[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")] | None
  ) = None,
  /,
  *,
  retries: int[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#int>) | None = None,
  prepare: ToolPrepareFunc[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolPrepareFunc> "pydantic_ai.tools.ToolPrepareFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")] | None = None,
  docstring_format: DocstringFormat[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.DocstringFormat> "pydantic_ai.tools.DocstringFormat") = "auto",
  require_parameter_descriptions: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = False,
) -> Any[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")

```

Decorator to register a tool function which takes `RunContext`[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.RunContext>) as its first argument.
Can decorate a sync or async functions.
The docstring is inspected to extract both the tool description and description of each parameter, [learn more](https://ai.pydantic.dev/api/agent/tools/#function-tools-and-schema>).
We can't add overloads for every possible signature of tool, since the return type is a recursive union so the signature of functions decorated with `@agent.tool` is obscured.
Example: 
```
from pydantic_ai import Agent, RunContext
agent = Agent('test', deps_type=int)
@agent.tool
def foobar(ctx: RunContext[int], x: int) -> int:
  return ctx.deps + x
@agent.tool(retries=2)
async def spam(ctx: RunContext[str], y: float) -> float:
  return ctx.deps + y
result = agent.run_sync('foobar', deps=1)
print(result.data)
#> {"foobar":1,"spam":1.0}

```

Parameters:
Name | Type | Description | Default  
---|---|---|---  
`func` |  `ToolFuncContext[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolFuncContext> "pydantic_ai.tools.ToolFuncContext")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), ToolParams[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")] | None` |  The tool function to register. |  `None`  
`retries` |  `int[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#int>) | None` |  The number of retries to allow for this tool, defaults to the agent's default retries, which defaults to 1. |  `None`  
`prepare` |  `ToolPrepareFunc[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolPrepareFunc> "pydantic_ai.tools.ToolPrepareFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")] | None` |  custom method to prepare the tool definition for each step, return `None` to omit this tool from a given step. This is useful if you want to customise a tool at call time, or omit it completely from a step. See `ToolPrepareFunc`[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolPrepareFunc>). |  `None`  
`docstring_format` |  `DocstringFormat[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.DocstringFormat> "pydantic_ai.tools.DocstringFormat")` |  The format of the docstring, see `DocstringFormat`[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.DocstringFormat>). Defaults to `'auto'`, such that the format is inferred from the structure of the docstring. |  `'auto'`  
`require_parameter_descriptions` |  `bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>)` |  If True, raise an error if a parameter description is missing. Defaults to False. |  `False`  
Source code in `pydantic_ai_slim/pydantic_ai/agent.py`
```
796
797
798
799
800
801
802
803
804
805
806
807
808
809
810
811
812
813
814
815
816
817
818
819
820
821
822
823
824
825
826
827
828
829
830
831
832
833
834
835
836
837
838
839
840
841
842
843
844
845
846
847
848
849
850
851
852
853
854
855
856
857
858
859
```
| ```
def tool(
  self,
  func: ToolFuncContext[AgentDepsT, ToolParams] | None = None,
  /,
  *,
  retries: int | None = None,
  prepare: ToolPrepareFunc[AgentDepsT] | None = None,
  docstring_format: DocstringFormat = 'auto',
  require_parameter_descriptions: bool = False,
) -> Any:
"""Decorator to register a tool function which takes [`RunContext`][pydantic_ai.tools.RunContext] as its first argument.
  Can decorate a sync or async functions.
  The docstring is inspected to extract both the tool description and description of each parameter,
  [learn more](../tools.md#function-tools-and-schema).
  We can't add overloads for every possible signature of tool, since the return type is a recursive union
  so the signature of functions decorated with `@agent.tool` is obscured.
  Example:
  ```python
  from pydantic_ai import Agent, RunContext
  agent = Agent('test', deps_type=int)
  @agent.tool
  def foobar(ctx: RunContext[int], x: int) -> int:
    return ctx.deps + x
  @agent.tool(retries=2)
  async def spam(ctx: RunContext[str], y: float) -> float:
    return ctx.deps + y
  result = agent.run_sync('foobar', deps=1)
  print(result.data)
  #> {"foobar":1,"spam":1.0}
  ```
  Args:
    func: The tool function to register.
    retries: The number of retries to allow for this tool, defaults to the agent's default retries,
      which defaults to 1.
    prepare: custom method to prepare the tool definition for each step, return `None` to omit this
      tool from a given step. This is useful if you want to customise a tool at call time,
      or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].
    docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].
      Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.
    require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.
  """
  if func is None:
    def tool_decorator(
      func_: ToolFuncContext[AgentDepsT, ToolParams],
    ) -> ToolFuncContext[AgentDepsT, ToolParams]:
      # noinspection PyTypeChecker
      self._register_function(func_, True, retries, prepare, docstring_format, require_parameter_descriptions)
      return func_
    return tool_decorator
  else:
    # noinspection PyTypeChecker
    self._register_function(func, True, retries, prepare, docstring_format, require_parameter_descriptions)
    return func

```
  
---|---  
####  tool_plain
```
tool_plain(
  func: ToolFuncPlain[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolFuncPlain> "pydantic_ai.tools.ToolFuncPlain")[ToolParams[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")],
) -> ToolFuncPlain[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolFuncPlain> "pydantic_ai.tools.ToolFuncPlain")[ToolParams[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")]

```

```
tool_plain(
  *,
  retries: int[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#int>) | None = None,
  prepare: ToolPrepareFunc[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolPrepareFunc> "pydantic_ai.tools.ToolPrepareFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")] | None = None,
  docstring_format: DocstringFormat[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.DocstringFormat> "pydantic_ai.tools.DocstringFormat") = "auto",
  require_parameter_descriptions: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = False
) -> Callable[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[
  [ToolFuncPlain[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolFuncPlain> "pydantic_ai.tools.ToolFuncPlain")[ToolParams[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")]], ToolFuncPlain[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolFuncPlain> "pydantic_ai.tools.ToolFuncPlain")[ToolParams[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")]
]

```

```
tool_plain(
  func: ToolFuncPlain[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolFuncPlain> "pydantic_ai.tools.ToolFuncPlain")[ToolParams[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")] | None = None,
  /,
  *,
  retries: int[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#int>) | None = None,
  prepare: ToolPrepareFunc[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolPrepareFunc> "pydantic_ai.tools.ToolPrepareFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")] | None = None,
  docstring_format: DocstringFormat[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.DocstringFormat> "pydantic_ai.tools.DocstringFormat") = "auto",
  require_parameter_descriptions: bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>) = False,
) -> Any[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")

```

Decorator to register a tool function which DOES NOT take `RunContext` as an argument.
Can decorate a sync or async functions.
The docstring is inspected to extract both the tool description and description of each parameter, [learn more](https://ai.pydantic.dev/api/agent/tools/#function-tools-and-schema>).
We can't add overloads for every possible signature of tool, since the return type is a recursive union so the signature of functions decorated with `@agent.tool` is obscured.
Example: 
```
from pydantic_ai import Agent, RunContext
agent = Agent('test')
@agent.tool
def foobar(ctx: RunContext[int]) -> int:
  return 123
@agent.tool(retries=2)
async def spam(ctx: RunContext[str]) -> float:
  return 3.14
result = agent.run_sync('foobar', deps=1)
print(result.data)
#> {"foobar":123,"spam":3.14}

```

Parameters:
Name | Type | Description | Default  
---|---|---|---  
`func` |  `ToolFuncPlain[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolFuncPlain> "pydantic_ai.tools.ToolFuncPlain")[ToolParams[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")] | None` |  The tool function to register. |  `None`  
`retries` |  `int[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#int>) | None` |  The number of retries to allow for this tool, defaults to the agent's default retries, which defaults to 1. |  `None`  
`prepare` |  `ToolPrepareFunc[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolPrepareFunc> "pydantic_ai.tools.ToolPrepareFunc")[AgentDepsT[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")] | None` |  custom method to prepare the tool definition for each step, return `None` to omit this tool from a given step. This is useful if you want to customise a tool at call time, or omit it completely from a step. See `ToolPrepareFunc`[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.ToolPrepareFunc>). |  `None`  
`docstring_format` |  `DocstringFormat[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.DocstringFormat> "pydantic_ai.tools.DocstringFormat")` |  The format of the docstring, see `DocstringFormat`[](https://ai.pydantic.dev/api/agent/<../tools/#pydantic_ai.tools.DocstringFormat>). Defaults to `'auto'`, such that the format is inferred from the structure of the docstring. |  `'auto'`  
`require_parameter_descriptions` |  `bool[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/functions.html#bool>)` |  If True, raise an error if a parameter description is missing. Defaults to False. |  `False`  
Source code in `pydantic_ai_slim/pydantic_ai/agent.py`
```
875
876
877
878
879
880
881
882
883
884
885
886
887
888
889
890
891
892
893
894
895
896
897
898
899
900
901
902
903
904
905
906
907
908
909
910
911
912
913
914
915
916
917
918
919
920
921
922
923
924
925
926
927
928
929
930
931
932
933
934
935
936
937
```
| ```
def tool_plain(
  self,
  func: ToolFuncPlain[ToolParams] | None = None,
  /,
  *,
  retries: int | None = None,
  prepare: ToolPrepareFunc[AgentDepsT] | None = None,
  docstring_format: DocstringFormat = 'auto',
  require_parameter_descriptions: bool = False,
) -> Any:
"""Decorator to register a tool function which DOES NOT take `RunContext` as an argument.
  Can decorate a sync or async functions.
  The docstring is inspected to extract both the tool description and description of each parameter,
  [learn more](../tools.md#function-tools-and-schema).
  We can't add overloads for every possible signature of tool, since the return type is a recursive union
  so the signature of functions decorated with `@agent.tool` is obscured.
  Example:
  ```python
  from pydantic_ai import Agent, RunContext
  agent = Agent('test')
  @agent.tool
  def foobar(ctx: RunContext[int]) -> int:
    return 123
  @agent.tool(retries=2)
  async def spam(ctx: RunContext[str]) -> float:
    return 3.14
  result = agent.run_sync('foobar', deps=1)
  print(result.data)
  #> {"foobar":123,"spam":3.14}
  ```
  Args:
    func: The tool function to register.
    retries: The number of retries to allow for this tool, defaults to the agent's default retries,
      which defaults to 1.
    prepare: custom method to prepare the tool definition for each step, return `None` to omit this
      tool from a given step. This is useful if you want to customise a tool at call time,
      or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].
    docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].
      Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.
    require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.
  """
  if func is None:
    def tool_decorator(func_: ToolFuncPlain[ToolParams]) -> ToolFuncPlain[ToolParams]:
      # noinspection PyTypeChecker
      self._register_function(
        func_, False, retries, prepare, docstring_format, require_parameter_descriptions
      )
      return func_
    return tool_decorator
  else:
    self._register_function(func, False, retries, prepare, docstring_format, require_parameter_descriptions)
    return func

```
  
---|---  
###  EndStrategy `module-attribute`
```
EndStrategy = Literal[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['early', 'exhaustive']

```

The strategy for handling multiple tool calls when a final result is found.
  * `'early'`: Stop processing other tool calls once a final result is found
  * `'exhaustive'`: Process all tool calls even after finding a final result


###  capture_run_messages
```
capture_run_messages() -> Iterator[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Iterator> "collections.abc.Iterator")[list[](https://ai.pydantic.dev/api/agent/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/agent/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")]]

```

Context manager to access the messages used in a `run`[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.run>), `run_sync`[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.run_sync>), or `run_stream`[](https://ai.pydantic.dev/api/agent/<#pydantic_ai.agent.Agent.run_stream>) call.
Useful when a run may raise an exception, see [model errors](https://ai.pydantic.dev/api/agent/agents/#model-errors>) for more information.
Examples: 
```
from pydantic_ai import Agent, capture_run_messages
agent = Agent('test')
with capture_run_messages() as messages:
  try:
    result = agent.run_sync('foobar')
  except Exception:
    print(messages)
    raise

```

Note
If you call `run`, `run_sync`, or `run_stream` more than once within a single `capture_run_messages` context, `messages` will represent the messages exchanged during the first call only.
Source code in `pydantic_ai_slim/pydantic_ai/_agent_graph.py`
```
698
699
700
701
702
703
704
705
706
707
708
709
710
711
712
713
714
715
716
717
718
719
720
721
722
723
724
725
726
727
728
729
730
```
| ```
@contextmanager
def capture_run_messages() -> Iterator[list[_messages.ModelMessage]]:
"""Context manager to access the messages used in a [`run`][pydantic_ai.Agent.run], [`run_sync`][pydantic_ai.Agent.run_sync], or [`run_stream`][pydantic_ai.Agent.run_stream] call.
  Useful when a run may raise an exception, see [model errors](../agents.md#model-errors) for more information.
  Examples:
  ```python
  from pydantic_ai import Agent, capture_run_messages
  agent = Agent('test')
  with capture_run_messages() as messages:
    try:
      result = agent.run_sync('foobar')
    except Exception:
      print(messages)
      raise
  ```
  !!! note
    If you call `run`, `run_sync`, or `run_stream` more than once within a single `capture_run_messages` context,
    `messages` will represent the messages exchanged during the first call only.
  """
  try:
    yield _messages_ctx_var.get().messages
  except LookupError:
    messages: list[_messages.ModelMessage] = []
    token = _messages_ctx_var.set(_RunMessages(messages))
    try:
      yield messages
    finally:
      _messages_ctx_var.reset(token)

```
  
---|---  
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_arun_many.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/api/arun_many/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/api/arun_many/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/api/arun_many/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/api/arun_many/<#>)


  * [Home](https://docs.crawl4ai.com/api/arun_many/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/api/arun_many/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/api/arun_many/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/api/arun_many/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/api/arun_many/blog/>)
    * [Changelog](https://docs.crawl4ai.com/api/arun_many/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/api/arun_many/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/api/arun_many/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/api/arun_many/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/api/arun_many/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/api/arun_many/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/api/arun_many/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/api/arun_many/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/api/arun_many/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/api/arun_many/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/api/arun_many/core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/api/arun_many/advanced/advanced-features/>)
    * [File Downloading](https://docs.crawl4ai.com/api/arun_many/advanced/file-downloading/>)
    * [Lazy Loading](https://docs.crawl4ai.com/api/arun_many/advanced/lazy-loading/>)
    * [Hooks & Auth](https://docs.crawl4ai.com/api/arun_many/advanced/hooks-auth/>)
    * [Proxy & Security](https://docs.crawl4ai.com/api/arun_many/advanced/proxy-security/>)
    * [Session Management](https://docs.crawl4ai.com/api/arun_many/advanced/session-management/>)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/api/arun_many/advanced/multi-url-crawling/>)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/api/arun_many/advanced/crawl-dispatcher/>)
    * [Identity Based Crawling](https://docs.crawl4ai.com/api/arun_many/advanced/identity-based-crawling/>)
    * [SSL Certificate](https://docs.crawl4ai.com/api/arun_many/advanced/ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/api/arun_many/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/api/arun_many/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/api/arun_many/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/api/arun_many/extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/api/arun_many/<../async-webcrawler/>)
    * [arun()](https://docs.crawl4ai.com/api/arun_many/<../arun/>)
    * arun_many()
    * [Browser & Crawler Config](https://docs.crawl4ai.com/api/arun_many/<../parameters/>)
    * [CrawlResult](https://docs.crawl4ai.com/api/arun_many/<../crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/api/arun_many/<../strategies/>)


  * [arun_many(...) Reference](https://docs.crawl4ai.com/api/arun_many/<#arun_many-reference>)
  * [Function Signature](https://docs.crawl4ai.com/api/arun_many/<#function-signature>)
  * [Differences from arun()](https://docs.crawl4ai.com/api/arun_many/<#differences-from-arun>)
  * [Dispatcher Reference](https://docs.crawl4ai.com/api/arun_many/<#dispatcher-reference>)
  * [Common Pitfalls](https://docs.crawl4ai.com/api/arun_many/<#common-pitfalls>)
  * [Conclusion](https://docs.crawl4ai.com/api/arun_many/<#conclusion>)


# `arun_many(...)` Reference
> **Note** : This function is very similar to `arun()`[](https://docs.crawl4ai.com/api/arun_many/<../arun/>) but focused on **concurrent** or **batch** crawling. If you’re unfamiliar with `arun()` usage, please read that doc first, then review this for differences.
## Function Signature
```
async def arun_many(
  urls: Union[List[str], List[Any]],
  config: Optional[CrawlerRunConfig] = None,
  dispatcher: Optional[BaseDispatcher] = None,
  ...
) -> Union[List[CrawlResult], AsyncGenerator[CrawlResult, None]]:
  """
  Crawl multiple URLs concurrently or in batches.
  :param urls: A list of URLs (or tasks) to crawl.
  :param config: (Optional) A default `CrawlerRunConfig` applying to each crawl.
  :param dispatcher: (Optional) A concurrency controller (e.g. MemoryAdaptiveDispatcher).
  ...
  :return: Either a list of `CrawlResult` objects, or an async generator if streaming is enabled.
  """

```

## Differences from `arun()`
1. **Multiple URLs** : 
  * Instead of crawling a single URL, you pass a list of them (strings or tasks). 
  * The function returns either a **list** of `CrawlResult` or an **async generator** if streaming is enabled.


2. **Concurrency & Dispatchers**: 
  * **`dispatcher`**param allows advanced concurrency control.
  * If omitted, a default dispatcher (like `MemoryAdaptiveDispatcher`) is used internally. 
  * Dispatchers handle concurrency, rate limiting, and memory-based adaptive throttling (see [Multi-URL Crawling](https://docs.crawl4ai.com/api/arun_many/advanced/multi-url-crawling/>)).


3. **Streaming Support** : 
  * Enable streaming by setting `stream=True` in your `CrawlerRunConfig`.
  * When streaming, use `async for` to process results as they become available.
  * Ideal for processing large numbers of URLs without waiting for all to complete.


4. **Parallel** Execution**: 
  * `arun_many()` can run multiple requests concurrently under the hood. 
  * Each `CrawlResult` might also include a **`dispatch_result`**with concurrency details (like memory usage, start/end times).


### Basic Example (Batch Mode)
```
# Minimal usage: The default dispatcher will be used
results = await crawler.arun_many(
  urls=["https://site1.com", "https://site2.com"],
  config=CrawlerRunConfig(stream=False) # Default behavior
)
for res in results:
  if res.success:
    print(res.url, "crawled OK!")
  else:
    print("Failed:", res.url, "-", res.error_message)

```

### Streaming Example
```
config = CrawlerRunConfig(
  stream=True, # Enable streaming mode
  cache_mode=CacheMode.BYPASS
)
# Process results as they complete
async for result in await crawler.arun_many(
  urls=["https://site1.com", "https://site2.com", "https://site3.com"],
  config=config
):
  if result.success:
    print(f"Just completed: {result.url}")
    # Process each result immediately
    process_result(result)

```

### With a Custom Dispatcher
```
dispatcher = MemoryAdaptiveDispatcher(
  memory_threshold_percent=70.0,
  max_session_permit=10
)
results = await crawler.arun_many(
  urls=["https://site1.com", "https://site2.com", "https://site3.com"],
  config=my_run_config,
  dispatcher=dispatcher
)

```

**Key Points** : - Each URL is processed by the same or separate sessions, depending on the dispatcher’s strategy. - `dispatch_result` in each `CrawlResult` (if using concurrency) can hold memory and timing info. - If you need to handle authentication or session IDs, pass them in each individual task or within your run config.
### Return Value
Either a **list** of `CrawlResult`[](https://docs.crawl4ai.com/api/arun_many/<../crawl-result/>) objects, or an **async generator** if streaming is enabled. You can iterate to check `result.success` or read each item’s `extracted_content`, `markdown`, or `dispatch_result`.
## Dispatcher Reference
  * **`MemoryAdaptiveDispatcher`**: Dynamically manages concurrency based on system memory usage.
  * **`SemaphoreDispatcher`**: Fixed concurrency limit, simpler but less adaptive.


For advanced usage or custom settings, see [Multi-URL Crawling with Dispatchers](https://docs.crawl4ai.com/api/arun_many/advanced/multi-url-crawling/>).
## Common Pitfalls
1. **Large Lists** : If you pass thousands of URLs, be mindful of memory or rate-limits. A dispatcher can help. 
2. **Session Reuse** : If you need specialized logins or persistent contexts, ensure your dispatcher or tasks handle sessions accordingly. 
3. **Error Handling** : Each `CrawlResult` might fail for different reasons—always check `result.success` or the `error_message` before proceeding.
## Conclusion
Use `arun_many()` when you want to **crawl multiple URLs** simultaneously or in controlled parallel tasks. If you need advanced concurrency features (like memory-based adaptive throttling or complex rate-limiting), provide a **dispatcher**. Each result is a standard `CrawlResult`, possibly augmented with concurrency stats (`dispatch_result`) for deeper inspection. For more details on concurrency logic and dispatchers, see the [Advanced Multi-URL Crawling](https://docs.crawl4ai.com/api/arun_many/advanced/multi-url-crawling/>) docs.
Site built with [MkDocs](https://docs.crawl4ai.com/api/arun_many/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/api/arun_many/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/api_arun.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/api/arun/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/api/arun/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/api/arun/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/api/arun/<#>)


  * [Home](https://docs.crawl4ai.com/api/arun/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/api/arun/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/api/arun/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/api/arun/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/api/arun/blog/>)
    * [Changelog](https://docs.crawl4ai.com/api/arun/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/api/arun/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/api/arun/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/api/arun/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/api/arun/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/api/arun/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/api/arun/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/api/arun/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/api/arun/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/api/arun/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/api/arun/core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/api/arun/advanced/advanced-features/>)
    * [File Downloading](https://docs.crawl4ai.com/api/arun/advanced/file-downloading/>)
    * [Lazy Loading](https://docs.crawl4ai.com/api/arun/advanced/lazy-loading/>)
    * [Hooks & Auth](https://docs.crawl4ai.com/api/arun/advanced/hooks-auth/>)
    * [Proxy & Security](https://docs.crawl4ai.com/api/arun/advanced/proxy-security/>)
    * [Session Management](https://docs.crawl4ai.com/api/arun/advanced/session-management/>)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/api/arun/advanced/multi-url-crawling/>)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/api/arun/advanced/crawl-dispatcher/>)
    * [Identity Based Crawling](https://docs.crawl4ai.com/api/arun/advanced/identity-based-crawling/>)
    * [SSL Certificate](https://docs.crawl4ai.com/api/arun/advanced/ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/api/arun/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/api/arun/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/api/arun/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/api/arun/extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/api/arun/<../async-webcrawler/>)
    * arun()
    * [arun_many()](https://docs.crawl4ai.com/api/arun/<../arun_many/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/api/arun/<../parameters/>)
    * [CrawlResult](https://docs.crawl4ai.com/api/arun/<../crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/api/arun/<../strategies/>)


  * [arun() Parameter Guide (New Approach)](https://docs.crawl4ai.com/api/arun/<#arun-parameter-guide-new-approach>)
  * [1. Core Usage](https://docs.crawl4ai.com/api/arun/<#1-core-usage>)
  * [2. Cache Control](https://docs.crawl4ai.com/api/arun/<#2-cache-control>)
  * [3. Content Processing & Selection](https://docs.crawl4ai.com/api/arun/<#3-content-processing-selection>)
  * [4. Page Navigation & Timing](https://docs.crawl4ai.com/api/arun/<#4-page-navigation-timing>)
  * [5. Session Management](https://docs.crawl4ai.com/api/arun/<#5-session-management>)
  * [6. Screenshot, PDF & Media Options](https://docs.crawl4ai.com/api/arun/<#6-screenshot-pdf-media-options>)
  * [7. Extraction Strategy](https://docs.crawl4ai.com/api/arun/<#7-extraction-strategy>)
  * [8. Comprehensive Example](https://docs.crawl4ai.com/api/arun/<#8-comprehensive-example>)
  * [9. Best Practices](https://docs.crawl4ai.com/api/arun/<#9-best-practices>)
  * [10. Conclusion](https://docs.crawl4ai.com/api/arun/<#10-conclusion>)


# `arun()` Parameter Guide (New Approach)
In Crawl4AI’s **latest** configuration model, nearly all parameters that once went directly to `arun()` are now part of **`CrawlerRunConfig`**. When calling`arun()` , you provide:
```
await crawler.arun(
  url="https://example.com", 
  config=my_run_config
)

```

Below is an organized look at the parameters that can go inside `CrawlerRunConfig`, divided by their functional areas. For **Browser** settings (e.g., `headless`, `browser_type`), see [BrowserConfig](https://docs.crawl4ai.com/api/arun/<../parameters/>).
## 1. Core Usage
```
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode
async def main():
  run_config = CrawlerRunConfig(
    verbose=True,      # Detailed logging
    cache_mode=CacheMode.ENABLED, # Use normal read/write cache
    check_robots_txt=True,  # Respect robots.txt rules
    # ... other parameters
  )
  async with AsyncWebCrawler() as crawler:
    result = await crawler.arun(
      url="https://example.com",
      config=run_config
    )
    # Check if blocked by robots.txt
    if not result.success and result.status_code == 403:
      print(f"Error: {result.error_message}")

```

**Key Fields** : - `verbose=True` logs each crawl step. - `cache_mode` decides how to read/write the local crawl cache.
## 2. Cache Control
**`cache_mode`**(default:`CacheMode.ENABLED`) Use a built-in enum from `CacheMode`:
  * `ENABLED`: Normal caching—reads if available, writes if missing.
  * `DISABLED`: No caching—always refetch pages.
  * `READ_ONLY`: Reads from cache only; no new writes.
  * `WRITE_ONLY`: Writes to cache but doesn’t read existing data.
  * `BYPASS`: Skips reading cache for this crawl (though it might still write if set up that way).


```
run_config = CrawlerRunConfig(
  cache_mode=CacheMode.BYPASS
)

```

**Additional flags** :
  * `bypass_cache=True` acts like `CacheMode.BYPASS`.
  * `disable_cache=True` acts like `CacheMode.DISABLED`.
  * `no_cache_read=True` acts like `CacheMode.WRITE_ONLY`.
  * `no_cache_write=True` acts like `CacheMode.READ_ONLY`.


## 3. Content Processing & Selection
### 3.1 Text Processing
```
run_config = CrawlerRunConfig(
  word_count_threshold=10,  # Ignore text blocks <10 words
  only_text=False,      # If True, tries to remove non-text elements
  keep_data_attributes=False # Keep or discard data-* attributes
)

```

### 3.2 Content Selection
```
run_config = CrawlerRunConfig(
  css_selector=".main-content", # Focus on .main-content region only
  excluded_tags=["form", "nav"], # Remove entire tag blocks
  remove_forms=True,       # Specifically strip <form> elements
  remove_overlay_elements=True, # Attempt to remove modals/popups
)

```

### 3.3 Link Handling
```
run_config = CrawlerRunConfig(
  exclude_external_links=True,     # Remove external links from final content
  exclude_social_media_links=True,   # Remove links to known social sites
  exclude_domains=["ads.example.com"], # Exclude links to these domains
  exclude_social_media_domains=["facebook.com","twitter.com"], # Extend the default list
)

```

### 3.4 Media Filtering
```
run_config = CrawlerRunConfig(
  exclude_external_images=True # Strip images from other domains
)

```

## 4. Page Navigation & Timing
### 4.1 Basic Browser Flow
```
run_config = CrawlerRunConfig(
  wait_for="css:.dynamic-content", # Wait for .dynamic-content
  delay_before_return_html=2.0,  # Wait 2s before capturing final HTML
  page_timeout=60000,       # Navigation & script timeout (ms)
)

```

**Key Fields** :
  * `wait_for`: 
  * `"css:selector"` or 
  * `"js:() => boolean"` e.g. `js:() => document.querySelectorAll('.item').length > 10`.
  * `mean_delay` & `max_range`: define random delays for `arun_many()` calls. 
  * `semaphore_count`: concurrency limit when crawling multiple URLs.


### 4.2 JavaScript Execution
```
run_config = CrawlerRunConfig(
  js_code=[
    "window.scrollTo(0, document.body.scrollHeight);",
    "document.querySelector('.load-more')?.click();"
  ],
  js_only=False
)

```

  * `js_code` can be a single string or a list of strings. 
  * `js_only=True` means “I’m continuing in the same session with new JS steps, no new full navigation.”


### 4.3 Anti-Bot
```
run_config = CrawlerRunConfig(
  magic=True,
  simulate_user=True,
  override_navigator=True
)

```

- `magic=True` tries multiple stealth features. - `simulate_user=True` mimics mouse movements or random delays. - `override_navigator=True` fakes some navigator properties (like user agent checks). 
## 5. Session Management
**`session_id`**:
```
run_config = CrawlerRunConfig(
  session_id="my_session123"
)

```

If re-used in subsequent `arun()` calls, the same tab/page context is continued (helpful for multi-step tasks or stateful browsing). 
## 6. Screenshot, PDF & Media Options
```
run_config = CrawlerRunConfig(
  screenshot=True,       # Grab a screenshot as base64
  screenshot_wait_for=1.0,   # Wait 1s before capturing
  pdf=True,          # Also produce a PDF
  image_description_min_word_threshold=5, # If analyzing alt text
  image_score_threshold=3,        # Filter out low-score images
)

```

**Where they appear** : - `result.screenshot` → Base64 screenshot string. - `result.pdf` → Byte array with PDF data. 
## 7. Extraction Strategy
**For advanced data extraction** (CSS/LLM-based), set `extraction_strategy`:
```
run_config = CrawlerRunConfig(
  extraction_strategy=my_css_or_llm_strategy
)

```

The extracted data will appear in `result.extracted_content`.
## 8. Comprehensive Example
Below is a snippet combining many parameters:
```
import asyncio
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode
from crawl4ai.extraction_strategy import JsonCssExtractionStrategy
async def main():
  # Example schema
  schema = {
    "name": "Articles",
    "baseSelector": "article.post",
    "fields": [
      {"name": "title", "selector": "h2", "type": "text"},
      {"name": "link", "selector": "a", "type": "attribute", "attribute": "href"}
    ]
  }
  run_config = CrawlerRunConfig(
    # Core
    verbose=True,
    cache_mode=CacheMode.ENABLED,
    check_robots_txt=True,  # Respect robots.txt rules
    # Content
    word_count_threshold=10,
    css_selector="main.content",
    excluded_tags=["nav", "footer"],
    exclude_external_links=True,
    # Page & JS
    js_code="document.querySelector('.show-more')?.click();",
    wait_for="css:.loaded-block",
    page_timeout=30000,
    # Extraction
    extraction_strategy=JsonCssExtractionStrategy(schema),
    # Session
    session_id="persistent_session",
    # Media
    screenshot=True,
    pdf=True,
    # Anti-bot
    simulate_user=True,
    magic=True,
  )
  async with AsyncWebCrawler() as crawler:
    result = await crawler.arun("https://example.com/posts", config=run_config)
    if result.success:
      print("HTML length:", len(result.cleaned_html))
      print("Extraction JSON:", result.extracted_content)
      if result.screenshot:
        print("Screenshot length:", len(result.screenshot))
      if result.pdf:
        print("PDF bytes length:", len(result.pdf))
    else:
      print("Error:", result.error_message)
if __name__ == "__main__":
  asyncio.run(main())

```

**What we covered** :
1. **Crawling** the main content region, ignoring external links. 2. Running **JavaScript** to click “.show-more”. 3. **Waiting** for “.loaded-block” to appear. 4. Generating a **screenshot** & **PDF** of the final page. 5. Extracting repeated “article.post” elements with a **CSS-based** extraction strategy.
## 9. Best Practices
1. **Use`BrowserConfig` for global browser** settings (headless, user agent). 2. **Use`CrawlerRunConfig`** to handle the **specific** crawl needs: content filtering, caching, JS, screenshot, extraction, etc. 3. Keep your **parameters consistent** in run configs—especially if you’re part of a large codebase with multiple crawls. 4. **Limit** large concurrency (`semaphore_count`) if the site or your system can’t handle it. 5. For dynamic pages, set `js_code` or `scan_full_page` so you load all content.
## 10. Conclusion
All parameters that used to be direct arguments to `arun()` now belong in **`CrawlerRunConfig`**. This approach:
  * Makes code **clearer** and **more maintainable**. 
  * Minimizes confusion about which arguments affect global vs. per-crawl behavior. 
  * Allows you to create **reusable** config objects for different pages or tasks.


For a **full** reference, check out the [CrawlerRunConfig Docs](https://docs.crawl4ai.com/api/arun/<../parameters/>). 
Happy crawling with your **structured, flexible** config approach!
Site built with [MkDocs](https://docs.crawl4ai.com/api/arun/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/api/arun/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/api_async-webcrawler.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/api/async-webcrawler/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/api/async-webcrawler/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/api/async-webcrawler/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/api/async-webcrawler/<#>)


  * [Home](https://docs.crawl4ai.com/api/async-webcrawler/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/api/async-webcrawler/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/api/async-webcrawler/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/api/async-webcrawler/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/api/async-webcrawler/blog/>)
    * [Changelog](https://docs.crawl4ai.com/api/async-webcrawler/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/api/async-webcrawler/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/api/async-webcrawler/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/api/async-webcrawler/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/api/async-webcrawler/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/api/async-webcrawler/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/api/async-webcrawler/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/api/async-webcrawler/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/api/async-webcrawler/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/api/async-webcrawler/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/api/async-webcrawler/core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/api/async-webcrawler/advanced/advanced-features/>)
    * [File Downloading](https://docs.crawl4ai.com/api/async-webcrawler/advanced/file-downloading/>)
    * [Lazy Loading](https://docs.crawl4ai.com/api/async-webcrawler/advanced/lazy-loading/>)
    * [Hooks & Auth](https://docs.crawl4ai.com/api/async-webcrawler/advanced/hooks-auth/>)
    * [Proxy & Security](https://docs.crawl4ai.com/api/async-webcrawler/advanced/proxy-security/>)
    * [Session Management](https://docs.crawl4ai.com/api/async-webcrawler/advanced/session-management/>)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/api/async-webcrawler/advanced/multi-url-crawling/>)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/api/async-webcrawler/advanced/crawl-dispatcher/>)
    * [Identity Based Crawling](https://docs.crawl4ai.com/api/async-webcrawler/advanced/identity-based-crawling/>)
    * [SSL Certificate](https://docs.crawl4ai.com/api/async-webcrawler/advanced/ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/api/async-webcrawler/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/api/async-webcrawler/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/api/async-webcrawler/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/api/async-webcrawler/extraction/chunking/>)
  * API Reference
    * AsyncWebCrawler
    * [arun()](https://docs.crawl4ai.com/api/async-webcrawler/<../arun/>)
    * [arun_many()](https://docs.crawl4ai.com/api/async-webcrawler/<../arun_many/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/api/async-webcrawler/<../parameters/>)
    * [CrawlResult](https://docs.crawl4ai.com/api/async-webcrawler/<../crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/api/async-webcrawler/<../strategies/>)


  * [AsyncWebCrawler](https://docs.crawl4ai.com/api/async-webcrawler/<#asyncwebcrawler>)
  * [1. Constructor Overview](https://docs.crawl4ai.com/api/async-webcrawler/<#1-constructor-overview>)
  * [2. Lifecycle: Start/Close or Context Manager](https://docs.crawl4ai.com/api/async-webcrawler/<#2-lifecycle-startclose-or-context-manager>)
  * [3. Primary Method: arun()](https://docs.crawl4ai.com/api/async-webcrawler/<#3-primary-method-arun>)
  * [4. Batch Processing: arun_many()](https://docs.crawl4ai.com/api/async-webcrawler/<#4-batch-processing-arun_many>)
  * [5. CrawlResult Output](https://docs.crawl4ai.com/api/async-webcrawler/<#5-crawlresult-output>)
  * [6. Quick Example](https://docs.crawl4ai.com/api/async-webcrawler/<#6-quick-example>)
  * [7. Best Practices & Migration Notes](https://docs.crawl4ai.com/api/async-webcrawler/<#7-best-practices-migration-notes>)
  * [8. Summary](https://docs.crawl4ai.com/api/async-webcrawler/<#8-summary>)


# AsyncWebCrawler
The **`AsyncWebCrawler`**is the core class for asynchronous web crawling in Crawl4AI. You typically create it**once** , optionally customize it with a **`BrowserConfig`**(e.g., headless, user agent), then**run** multiple **`arun()`**calls with different**`CrawlerRunConfig`**objects.
**Recommended usage** :
1. **Create** a `BrowserConfig` for global browser settings. 
2. **Instantiate** `AsyncWebCrawler(config=browser_config)`. 
3. **Use** the crawler in an async context manager (`async with`) or manage start/close manually. 
4. **Call** `arun(url, config=crawler_run_config)` for each page you want.
## 1. Constructor Overview
```
class AsyncWebCrawler:
  def __init__(
    self,
    crawler_strategy: Optional[AsyncCrawlerStrategy] = None,
    config: Optional[BrowserConfig] = None,
    always_bypass_cache: bool = False,      # deprecated
    always_by_pass_cache: Optional[bool] = None, # also deprecated
    base_directory: str = ...,
    thread_safe: bool = False,
    **kwargs,
  ):
    """
    Create an AsyncWebCrawler instance.
    Args:
      crawler_strategy: 
        (Advanced) Provide a custom crawler strategy if needed.
      config: 
        A BrowserConfig object specifying how the browser is set up.
      always_bypass_cache: 
        (Deprecated) Use CrawlerRunConfig.cache_mode instead.
      base_directory:   
        Folder for storing caches/logs (if relevant).
      thread_safe: 
        If True, attempts some concurrency safeguards. Usually False.
      **kwargs: 
        Additional legacy or debugging parameters.
    """
  )
### Typical Initialization
```python
from crawl4ai import AsyncWebCrawler, BrowserConfig
browser_cfg = BrowserConfig(
  browser_type="chromium",
  headless=True,
  verbose=True
)
crawler = AsyncWebCrawler(config=browser_cfg)

```

**Notes** :
  * **Legacy** parameters like `always_bypass_cache` remain for backward compatibility, but prefer to set **caching** in `CrawlerRunConfig`.


## 2. Lifecycle: Start/Close or Context Manager
### 2.1 Context Manager (Recommended)
```
async with AsyncWebCrawler(config=browser_cfg) as crawler:
  result = await crawler.arun("https://example.com")
  # The crawler automatically starts/closes resources

```

When the `async with` block ends, the crawler cleans up (closes the browser, etc.).
### 2.2 Manual Start & Close
```
crawler = AsyncWebCrawler(config=browser_cfg)
await crawler.start()
result1 = await crawler.arun("https://example.com")
result2 = await crawler.arun("https://another.com")
await crawler.close()

```

Use this style if you have a **long-running** application or need full control of the crawler’s lifecycle.
## 3. Primary Method: `arun()`
```
async def arun(
  self,
  url: str,
  config: Optional[CrawlerRunConfig] = None,
  # Legacy parameters for backward compatibility...
) -> CrawlResult:
  ...

```

### 3.1 New Approach
You pass a `CrawlerRunConfig` object that sets up everything about a crawl—content filtering, caching, session reuse, JS code, screenshots, etc.
```
import asyncio
from crawl4ai import CrawlerRunConfig, CacheMode
run_cfg = CrawlerRunConfig(
  cache_mode=CacheMode.BYPASS,
  css_selector="main.article",
  word_count_threshold=10,
  screenshot=True
)
async with AsyncWebCrawler(config=browser_cfg) as crawler:
  result = await crawler.arun("https://example.com/news", config=run_cfg)
  print("Crawled HTML length:", len(result.cleaned_html))
  if result.screenshot:
    print("Screenshot base64 length:", len(result.screenshot))

```

### 3.2 Legacy Parameters Still Accepted
For **backward** compatibility, `arun()` can still accept direct arguments like `css_selector=...`, `word_count_threshold=...`, etc., but we strongly advise migrating them into a **`CrawlerRunConfig`**.
## 4. Batch Processing: `arun_many()`
```
async def arun_many(
  self,
  urls: List[str],
  config: Optional[CrawlerRunConfig] = None,
  # Legacy parameters maintained for backwards compatibility...
) -> List[CrawlResult]:
  """
  Process multiple URLs with intelligent rate limiting and resource monitoring.
  """

```

### 4.1 Resource-Aware Crawling
The `arun_many()` method now uses an intelligent dispatcher that:
  * Monitors system memory usage
  * Implements adaptive rate limiting
  * Provides detailed progress monitoring
  * Manages concurrent crawls efficiently


### 4.2 Example Usage
```
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, RateLimitConfig
from crawl4ai.dispatcher import DisplayMode
# Configure browser
browser_cfg = BrowserConfig(headless=True)
# Configure crawler with rate limiting
run_cfg = CrawlerRunConfig(
  # Enable rate limiting
  enable_rate_limiting=True,
  rate_limit_config=RateLimitConfig(
    base_delay=(1.0, 2.0), # Random delay between 1-2 seconds
    max_delay=30.0,     # Maximum delay after rate limit hits
    max_retries=2,     # Number of retries before giving up
    rate_limit_codes=[429, 503] # Status codes that trigger rate limiting
  ),
  # Resource monitoring
  memory_threshold_percent=70.0, # Pause if memory exceeds this
  check_interval=0.5,      # How often to check resources
  max_session_permit=3,     # Maximum concurrent crawls
  display_mode=DisplayMode.DETAILED.value # Show detailed progress
)
urls = [
  "https://example.com/page1",
  "https://example.com/page2",
  "https://example.com/page3"
]
async with AsyncWebCrawler(config=browser_cfg) as crawler:
  results = await crawler.arun_many(urls, config=run_cfg)
  for result in results:
    print(f"URL: {result.url}, Success: {result.success}")

```

### 4.3 Key Features
1. **Rate Limiting**
  * Automatic delay between requests
  * Exponential backoff on rate limit detection
  * Domain-specific rate limiting
  * Configurable retry strategy


2. **Resource Monitoring**
  * Memory usage tracking
  * Adaptive concurrency based on system load
  * Automatic pausing when resources are constrained


3. **Progress Monitoring**
  * Detailed or aggregated progress display
  * Real-time status updates
  * Memory usage statistics


4. **Error Handling**
  * Graceful handling of rate limits
  * Automatic retries with backoff
  * Detailed error reporting


## 5. `CrawlResult` Output
Each `arun()` returns a **`CrawlResult`**containing:
  * `url`: Final URL (if redirected).
  * `html`: Original HTML.
  * `cleaned_html`: Sanitized HTML.
  * `markdown_v2` (or future `markdown`): Markdown outputs (raw, fit, etc.).
  * `extracted_content`: If an extraction strategy was used (JSON for CSS/LLM strategies).
  * `screenshot`, `pdf`: If screenshots/PDF requested.
  * `media`, `links`: Information about discovered images/links.
  * `success`, `error_message`: Status info.


For details, see [CrawlResult doc](https://docs.crawl4ai.com/api/async-webcrawler/<../crawl-result/>).
## 6. Quick Example
Below is an example hooking it all together:
```
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode
from crawl4ai.extraction_strategy import JsonCssExtractionStrategy
import json
async def main():
  # 1. Browser config
  browser_cfg = BrowserConfig(
    browser_type="firefox",
    headless=False,
    verbose=True
  )
  # 2. Run config
  schema = {
    "name": "Articles",
    "baseSelector": "article.post",
    "fields": [
      {
        "name": "title", 
        "selector": "h2", 
        "type": "text"
      },
      {
        "name": "url", 
        "selector": "a", 
        "type": "attribute", 
        "attribute": "href"
      }
    ]
  }
  run_cfg = CrawlerRunConfig(
    cache_mode=CacheMode.BYPASS,
    extraction_strategy=JsonCssExtractionStrategy(schema),
    word_count_threshold=15,
    remove_overlay_elements=True,
    wait_for="css:.post" # Wait for posts to appear
  )
  async with AsyncWebCrawler(config=browser_cfg) as crawler:
    result = await crawler.arun(
      url="https://example.com/blog",
      config=run_cfg
    )
    if result.success:
      print("Cleaned HTML length:", len(result.cleaned_html))
      if result.extracted_content:
        articles = json.loads(result.extracted_content)
        print("Extracted articles:", articles[:2])
    else:
      print("Error:", result.error_message)
asyncio.run(main())

```

**Explanation** :
  * We define a **`BrowserConfig`**with Firefox, no headless, and`verbose=True`. 
  * We define a **`CrawlerRunConfig`**that**bypasses cache** , uses a **CSS** extraction schema, has a `word_count_threshold=15`, etc. 
  * We pass them to `AsyncWebCrawler(config=...)` and `arun(url=..., config=...)`.


## 7. Best Practices & Migration Notes
1. **Use** `BrowserConfig` for **global** settings about the browser’s environment. 2. **Use** `CrawlerRunConfig` for **per-crawl** logic (caching, content filtering, extraction strategies, wait conditions). 3. **Avoid** legacy parameters like `css_selector` or `word_count_threshold` directly in `arun()`. Instead:
```
run_cfg = CrawlerRunConfig(css_selector=".main-content", word_count_threshold=20)
result = await crawler.arun(url="...", config=run_cfg)

```

4. **Context Manager** usage is simplest unless you want a persistent crawler across many calls.
## 8. Summary
**AsyncWebCrawler** is your entry point to asynchronous crawling:
  * **Constructor** accepts **`BrowserConfig`**(or defaults).
  * **`arun(url, config=CrawlerRunConfig)`**is the main method for single-page crawls.
  * **`arun_many(urls, config=CrawlerRunConfig)`**handles concurrency across multiple URLs.
  * For advanced lifecycle control, use `start()` and `close()` explicitly. 


**Migration** : 
  * If you used `AsyncWebCrawler(browser_type="chromium", css_selector="...")`, move browser settings to `BrowserConfig(...)` and content/crawl logic to `CrawlerRunConfig(...)`.


This modular approach ensures your code is **clean** , **scalable** , and **easy to maintain**. For any advanced or rarely used parameters, see the [BrowserConfig docs](https://docs.crawl4ai.com/api/async-webcrawler/<../parameters/>).
Site built with [MkDocs](https://docs.crawl4ai.com/api/async-webcrawler/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/api/async-webcrawler/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/api_crawl-result.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/api/crawl-result/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/api/crawl-result/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/api/crawl-result/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/api/crawl-result/<#>)


  * [Home](https://docs.crawl4ai.com/api/crawl-result/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/api/crawl-result/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/api/crawl-result/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/api/crawl-result/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/api/crawl-result/blog/>)
    * [Changelog](https://docs.crawl4ai.com/api/crawl-result/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/api/crawl-result/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/api/crawl-result/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/api/crawl-result/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/api/crawl-result/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/api/crawl-result/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/api/crawl-result/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/api/crawl-result/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/api/crawl-result/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/api/crawl-result/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/api/crawl-result/core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/api/crawl-result/advanced/advanced-features/>)
    * [File Downloading](https://docs.crawl4ai.com/api/crawl-result/advanced/file-downloading/>)
    * [Lazy Loading](https://docs.crawl4ai.com/api/crawl-result/advanced/lazy-loading/>)
    * [Hooks & Auth](https://docs.crawl4ai.com/api/crawl-result/advanced/hooks-auth/>)
    * [Proxy & Security](https://docs.crawl4ai.com/api/crawl-result/advanced/proxy-security/>)
    * [Session Management](https://docs.crawl4ai.com/api/crawl-result/advanced/session-management/>)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/api/crawl-result/advanced/multi-url-crawling/>)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/api/crawl-result/advanced/crawl-dispatcher/>)
    * [Identity Based Crawling](https://docs.crawl4ai.com/api/crawl-result/advanced/identity-based-crawling/>)
    * [SSL Certificate](https://docs.crawl4ai.com/api/crawl-result/advanced/ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/api/crawl-result/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/api/crawl-result/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/api/crawl-result/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/api/crawl-result/extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/api/crawl-result/<../async-webcrawler/>)
    * [arun()](https://docs.crawl4ai.com/api/crawl-result/<../arun/>)
    * [arun_many()](https://docs.crawl4ai.com/api/crawl-result/<../arun_many/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/api/crawl-result/<../parameters/>)
    * CrawlResult
    * [Strategies](https://docs.crawl4ai.com/api/crawl-result/<../strategies/>)


  * [CrawlResult Reference](https://docs.crawl4ai.com/api/crawl-result/<#crawlresult-reference>)
  * [1. Basic Crawl Info](https://docs.crawl4ai.com/api/crawl-result/<#1-basic-crawl-info>)
  * [2. Raw / Cleaned Content](https://docs.crawl4ai.com/api/crawl-result/<#2-raw-cleaned-content>)
  * [3. Markdown Fields](https://docs.crawl4ai.com/api/crawl-result/<#3-markdown-fields>)
  * [4. Media & Links](https://docs.crawl4ai.com/api/crawl-result/<#4-media-links>)
  * [5. Additional Fields](https://docs.crawl4ai.com/api/crawl-result/<#5-additional-fields>)
  * [6. dispatch_result (optional)](https://docs.crawl4ai.com/api/crawl-result/<#6-dispatch_result-optional>)
  * [7. Example: Accessing Everything](https://docs.crawl4ai.com/api/crawl-result/<#7-example-accessing-everything>)
  * [8. Key Points & Future](https://docs.crawl4ai.com/api/crawl-result/<#8-key-points-future>)


# `CrawlResult` Reference
The **`CrawlResult`**class encapsulates everything returned after a single crawl operation. It provides the**raw or processed content** , details on links and media, plus optional metadata (like screenshots, PDFs, or extracted JSON).
**Location** : `crawl4ai/crawler/models.py` (for reference)
```
class CrawlResult(BaseModel):
  url: str
  html: str
  success: bool
  cleaned_html: Optional[str] = None
  media: Dict[str, List[Dict]] = {}
  links: Dict[str, List[Dict]] = {}
  downloaded_files: Optional[List[str]] = None
  screenshot: Optional[str] = None
  pdf : Optional[bytes] = None
  markdown: Optional[Union[str, MarkdownGenerationResult]] = None
  markdown_v2: Optional[MarkdownGenerationResult] = None
  fit_markdown: Optional[str] = None
  fit_html: Optional[str] = None
  extracted_content: Optional[str] = None
  metadata: Optional[dict] = None
  error_message: Optional[str] = None
  session_id: Optional[str] = None
  response_headers: Optional[dict] = None
  status_code: Optional[int] = None
  ssl_certificate: Optional[SSLCertificate] = None
  dispatch_result: Optional[DispatchResult] = None
  ...

```

Below is a **field-by-field** explanation and possible usage patterns.
## 1. Basic Crawl Info
### 1.1 **`url`**_(str)_
**What** : The final crawled URL (after any redirects). **Usage** : 
```
print(result.url) # e.g., "https://example.com/"

```

### 1.2 **`success`**_(bool)_
**What** : `True` if the crawl pipeline ended without major errors; `False` otherwise. **Usage** : 
```
if not result.success:
  print(f"Crawl failed: {result.error_message}")

```

### 1.3 **`status_code`**_(Optional[int])_
**What** : The page’s HTTP status code (e.g., 200, 404). **Usage** : 
```
if result.status_code == 404:
  print("Page not found!")

```

### 1.4 **`error_message`**_(Optional[str])_
**What** : If `success=False`, a textual description of the failure. **Usage** : 
```
if not result.success:
  print("Error:", result.error_message)

```

### 1.5 **`session_id`**_(Optional[str])_
**What** : The ID used for reusing a browser context across multiple calls. **Usage** : 
```
# If you used session_id="login_session" in CrawlerRunConfig, see it here:
print("Session:", result.session_id)

```

### 1.6 **`response_headers`**_(Optional[dict])_
**What** : Final HTTP response headers. **Usage** : 
```
if result.response_headers:
  print("Server:", result.response_headers.get("Server", "Unknown"))

```

### 1.7 **`ssl_certificate`**_(Optional[SSLCertificate])_
**What** : If `fetch_ssl_certificate=True` in your CrawlerRunConfig, **`result.ssl_certificate`**contains a[**`SSLCertificate`**](https://docs.crawl4ai.com/api/crawl-result/advanced/ssl-certificate/>)object describing the site’s certificate. You can export the cert in multiple formats (PEM/DER/JSON) or access its properties like`issuer`, `subject`, `valid_from`, `valid_until`, etc. **Usage** : 
```
if result.ssl_certificate:
  print("Issuer:", result.ssl_certificate.issuer)

```

## 2. Raw / Cleaned Content
### 2.1 **`html`**_(str)_
**What** : The **original** unmodified HTML from the final page load. **Usage** : 
```
# Possibly large
print(len(result.html))

```

### 2.2 **`cleaned_html`**_(Optional[str])_
**What** : A sanitized HTML version—scripts, styles, or excluded tags are removed based on your `CrawlerRunConfig`. **Usage** : 
```
print(result.cleaned_html[:500]) # Show a snippet

```

### 2.3 **`fit_html`**_(Optional[str])_
**What** : If a **content filter** or heuristic (e.g., Pruning/BM25) modifies the HTML, the “fit” or post-filter version. **When** : This is **only** present if your `markdown_generator` or `content_filter` produces it. **Usage** : 
```
if result.fit_html:
  print("High-value HTML content:", result.fit_html[:300])

```

## 3. Markdown Fields
### 3.1 The Markdown Generation Approach
Crawl4AI can convert HTML→Markdown, optionally including:
  * **Raw** markdown 
  * **Links as citations** (with a references section) 
  * **Fit** markdown if a **content filter** is used (like Pruning or BM25)


### 3.2 **`markdown_v2`**_(Optional[MarkdownGenerationResult])_
**What** : The **structured** object holding multiple markdown variants. Soon to be consolidated into `markdown`. 
**`MarkdownGenerationResult`**includes: -**`raw_markdown`**_(str)_ : The full HTML→Markdown conversion. - **`markdown_with_citations`**_(str)_ : Same markdown, but with link references as academic-style citations. - **`references_markdown`**_(str)_ : The reference list or footnotes at the end. - **`fit_markdown`**_(Optional[str])_ : If content filtering (Pruning/BM25) was applied, the filtered “fit” text. - **`fit_html`**_(Optional[str])_ : The HTML that led to `fit_markdown`.
**Usage** : 
```
if result.markdown_v2:
  md_res = result.markdown_v2
  print("Raw MD:", md_res.raw_markdown[:300])
  print("Citations MD:", md_res.markdown_with_citations[:300])
  print("References:", md_res.references_markdown)
  if md_res.fit_markdown:
    print("Pruned text:", md_res.fit_markdown[:300])

```

### 3.3 **`markdown`**_(Optional[Union[str, MarkdownGenerationResult]])_
**What** : In future versions, `markdown` will fully replace `markdown_v2`. Right now, it might be a `str` or a `MarkdownGenerationResult`. **Usage** : 
```
# Soon, you might see:
if isinstance(result.markdown, MarkdownGenerationResult):
  print(result.markdown.raw_markdown[:200])
else:
  print(result.markdown)

```

### 3.4 **`fit_markdown`**_(Optional[str])_
**What** : A direct reference to the final filtered markdown (legacy approach). **When** : This is set if a filter or content strategy explicitly writes there. Usually overshadowed by `markdown_v2.fit_markdown`. **Usage** : 
```
print(result.fit_markdown) # Legacy field, prefer result.markdown_v2.fit_markdown

```

**Important** : “Fit” content (in `fit_markdown`/`fit_html`) only exists if you used a **filter** (like **PruningContentFilter** or **BM25ContentFilter**) within a `MarkdownGenerationStrategy`.
## 4. Media & Links
### 4.1 **`media`**_(Dict[str, List[Dict]])_
**What** : Contains info about discovered images, videos, or audio. Typically keys: `"images"`, `"videos"`, `"audios"`. **Common Fields** in each item:
  * `src` _(str)_ : Media URL 
  * `alt` or `title` _(str)_ : Descriptive text 
  * `score` _(float)_ : Relevance score if the crawler’s heuristic found it “important” 
  * `desc` or `description` _(Optional[str])_ : Additional context extracted from surrounding text 


**Usage** : 
```
images = result.media.get("images", [])
for img in images:
  if img.get("score", 0) > 5:
    print("High-value image:", img["src"])

```

### 4.2 **`links`**_(Dict[str, List[Dict]])_
**What** : Holds internal and external link data. Usually two keys: `"internal"` and `"external"`. **Common Fields** :
  * `href` _(str)_ : The link target 
  * `text` _(str)_ : Link text 
  * `title` _(str)_ : Title attribute 
  * `context` _(str)_ : Surrounding text snippet 
  * `domain` _(str)_ : If external, the domain


**Usage** : 
```
for link in result.links["internal"]:
  print(f"Internal link to {link['href']} with text {link['text']}")

```

## 5. Additional Fields
### 5.1 **`extracted_content`**_(Optional[str])_
**What** : If you used **`extraction_strategy`**(CSS, LLM, etc.), the structured output (JSON).**Usage** : 
```
if result.extracted_content:
  data = json.loads(result.extracted_content)
  print(data)

```

### 5.2 **`downloaded_files`**_(Optional[List[str]])_
**What** : If `accept_downloads=True` in your `BrowserConfig` + `downloads_path`, lists local file paths for downloaded items. **Usage** : 
```
if result.downloaded_files:
  for file_path in result.downloaded_files:
    print("Downloaded:", file_path)

```

### 5.3 **`screenshot`**_(Optional[str])_
**What** : Base64-encoded screenshot if `screenshot=True` in `CrawlerRunConfig`. **Usage** : 
```
import base64
if result.screenshot:
  with open("page.png", "wb") as f:
    f.write(base64.b64decode(result.screenshot))

```

### 5.4 **`pdf`**_(Optional[bytes])_
**What** : Raw PDF bytes if `pdf=True` in `CrawlerRunConfig`. **Usage** : 
```
if result.pdf:
  with open("page.pdf", "wb") as f:
    f.write(result.pdf)

```

### 5.5 **`metadata`**_(Optional[dict])_
**What** : Page-level metadata if discovered (title, description, OG data, etc.). **Usage** : 
```
if result.metadata:
  print("Title:", result.metadata.get("title"))
  print("Author:", result.metadata.get("author"))

```

## 6. `dispatch_result` (optional)
A `DispatchResult` object providing additional concurrency and resource usage information when crawling URLs in parallel (e.g., via `arun_many()` with custom dispatchers). It contains:
  * **`task_id`**: A unique identifier for the parallel task.
  * **`memory_usage`**(float): The memory (in MB) used at the time of completion.
  * **`peak_memory`**(float): The peak memory usage (in MB) recorded during the task’s execution.
  * **`start_time`**/**`end_time`**(datetime): Time range for this crawling task.
  * **`error_message`**(str): Any dispatcher- or concurrency-related error encountered.


```
# Example usage:
for result in results:
  if result.success and result.dispatch_result:
    dr = result.dispatch_result
    print(f"URL: {result.url}, Task ID: {dr.task_id}")
    print(f"Memory: {dr.memory_usage:.1f} MB (Peak: {dr.peak_memory:.1f} MB)")
    print(f"Duration: {dr.end_time - dr.start_time}")

```

> **Note** : This field is typically populated when using `arun_many(...)` alongside a **dispatcher** (e.g., `MemoryAdaptiveDispatcher` or `SemaphoreDispatcher`). If no concurrency or dispatcher is used, `dispatch_result` may remain `None`. 
## 7. Example: Accessing Everything
```
async def handle_result(result: CrawlResult):
  if not result.success:
    print("Crawl error:", result.error_message)
    return
  # Basic info
  print("Crawled URL:", result.url)
  print("Status code:", result.status_code)
  # HTML
  print("Original HTML size:", len(result.html))
  print("Cleaned HTML size:", len(result.cleaned_html or ""))
  # Markdown output
  if result.markdown_v2:
    print("Raw Markdown:", result.markdown_v2.raw_markdown[:300])
    print("Citations Markdown:", result.markdown_v2.markdown_with_citations[:300])
    if result.markdown_v2.fit_markdown:
      print("Fit Markdown:", result.markdown_v2.fit_markdown[:200])
  else:
    print("Raw Markdown (legacy):", result.markdown[:200] if result.markdown else "N/A")
  # Media & Links
  if "images" in result.media:
    print("Image count:", len(result.media["images"]))
  if "internal" in result.links:
    print("Internal link count:", len(result.links["internal"]))
  # Extraction strategy result
  if result.extracted_content:
    print("Structured data:", result.extracted_content)
  # Screenshot/PDF
  if result.screenshot:
    print("Screenshot length:", len(result.screenshot))
  if result.pdf:
    print("PDF bytes length:", len(result.pdf))

```

## 8. Key Points & Future
1. **`markdown_v2`vs`markdown`** - Right now, `markdown_v2` is the more robust container (`MarkdownGenerationResult`), providing **raw_markdown** , **markdown_with_citations** , references, plus possible **fit_markdown**. - In future versions, everything will unify under **`markdown`**. If you rely on advanced features (citations, fit content), check`markdown_v2`.
2. **Fit Content** - **`fit_markdown`**and**`fit_html`**appear only if you used a content filter (like**PruningContentFilter** or **BM25ContentFilter**) inside your **MarkdownGenerationStrategy** or set them directly. - If no filter is used, they remain `None`.
3. **References & Citations** - If you enable link citations in your `DefaultMarkdownGenerator` (`options={"citations": True}`), you’ll see `markdown_with_citations` plus a **`references_markdown`**block. This helps large language models or academic-like referencing.
4. **Links & Media** - `links["internal"]` and `links["external"]` group discovered anchors by domain. - `media["images"]` / `["videos"]` / `["audios"]` store extracted media elements with optional scoring or context.
5. **Error Cases** - If `success=False`, check `error_message` (e.g., timeouts, invalid URLs). - `status_code` might be `None` if we failed before an HTTP response.
Use **`CrawlResult`**to glean all final outputs and feed them into your data pipelines, AI models, or archives. With the synergy of a properly configured**BrowserConfig** and **CrawlerRunConfig** , the crawler can produce robust, structured results here in **`CrawlResult`**.
Site built with [MkDocs](https://docs.crawl4ai.com/api/crawl-result/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/api/crawl-result/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/api_exceptions.md
================
[ Skip to content ](https://ai.pydantic.dev/api/exceptions/<#pydantic_aiexceptions>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/exceptions/<../..> "PydanticAI")
PydanticAI 
pydantic_ai.exceptions 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/exceptions/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/exceptions/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/exceptions/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/exceptions/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/api/exceptions/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/exceptions/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/exceptions/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/exceptions/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/exceptions/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/exceptions/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/exceptions/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/exceptions/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/exceptions/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/exceptions/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/exceptions/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/exceptions/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/exceptions/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/exceptions/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/exceptions/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/exceptions/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/exceptions/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/exceptions/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/exceptions/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/exceptions/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/exceptions/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/exceptions/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/exceptions/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/exceptions/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/exceptions/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/exceptions/<../agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/exceptions/<../tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/exceptions/<../result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/exceptions/<../messages/>)
    * pydantic_ai.exceptions  [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/exceptions/<./>) Table of contents 
      * [ exceptions  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions>)
      * [ ModelRetry  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.ModelRetry>)
        * [ message  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.ModelRetry.message>)
      * [ UserError  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UserError>)
        * [ message  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UserError.message>)
      * [ AgentRunError  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.AgentRunError>)
        * [ message  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.AgentRunError.message>)
      * [ UsageLimitExceeded  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UsageLimitExceeded>)
      * [ UnexpectedModelBehavior  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UnexpectedModelBehavior>)
        * [ message  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UnexpectedModelBehavior.message>)
        * [ body  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UnexpectedModelBehavior.body>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/exceptions/<../settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/exceptions/<../usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/exceptions/<../format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/exceptions/<../models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/exceptions/<../models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/exceptions/<../models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/exceptions/<../models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/exceptions/<../models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/exceptions/<../models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/exceptions/<../models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/exceptions/<../models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/exceptions/<../models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/exceptions/<../models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/exceptions/<../pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/exceptions/<../pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/exceptions/<../pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/exceptions/<../pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/exceptions/<../pydantic_graph/exceptions/>)


Table of contents 
  * [ exceptions  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions>)
  * [ ModelRetry  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.ModelRetry>)
    * [ message  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.ModelRetry.message>)
  * [ UserError  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UserError>)
    * [ message  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UserError.message>)
  * [ AgentRunError  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.AgentRunError>)
    * [ message  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.AgentRunError.message>)
  * [ UsageLimitExceeded  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UsageLimitExceeded>)
  * [ UnexpectedModelBehavior  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UnexpectedModelBehavior>)
    * [ message  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UnexpectedModelBehavior.message>)
    * [ body  ](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UnexpectedModelBehavior.body>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/exceptions/<../..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/exceptions/<../agent/>)


# `pydantic_ai.exceptions`
###  ModelRetry
Bases: `Exception[](https://ai.pydantic.dev/api/exceptions/<https:/docs.python.org/3/library/exceptions.html#Exception>)`
Exception raised when a tool function should be retried.
The agent will return the message to the model and ask it to try calling the function/tool again.
Source code in `pydantic_ai_slim/pydantic_ai/exceptions.py`
```
 8
 9
10
11
12
13
14
15
16
17
18
19
```
| ```
class ModelRetry(Exception):
"""Exception raised when a tool function should be retried.
  The agent will return the message to the model and ask it to try calling the function/tool again.
  """
  message: str
"""The message to return to the model."""
  def __init__(self, message: str):
    self.message = message
    super().__init__(message)

```
  
---|---  
####  message `instance-attribute`
```
message: str[](https://ai.pydantic.dev/api/exceptions/<https:/docs.python.org/3/library/stdtypes.html#str>) = message[](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.ModelRetry.message> "pydantic_ai.exceptions.ModelRetry.message")

```

The message to return to the model.
###  UserError
Bases: `RuntimeError[](https://ai.pydantic.dev/api/exceptions/<https:/docs.python.org/3/library/exceptions.html#RuntimeError>)`
Error caused by a usage mistake by the application developer — You!
Source code in `pydantic_ai_slim/pydantic_ai/exceptions.py`
```
22
23
24
25
26
27
28
29
30
```
| ```
class UserError(RuntimeError):
"""Error caused by a usage mistake by the application developer — You!"""
  message: str
"""Description of the mistake."""
  def __init__(self, message: str):
    self.message = message
    super().__init__(message)

```
  
---|---  
####  message `instance-attribute`
```
message: str[](https://ai.pydantic.dev/api/exceptions/<https:/docs.python.org/3/library/stdtypes.html#str>) = message[](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UserError.message> "pydantic_ai.exceptions.UserError.message")

```

Description of the mistake.
###  AgentRunError
Bases: `RuntimeError[](https://ai.pydantic.dev/api/exceptions/<https:/docs.python.org/3/library/exceptions.html#RuntimeError>)`
Base class for errors occurring during an agent run.
Source code in `pydantic_ai_slim/pydantic_ai/exceptions.py`
```
33
34
35
36
37
38
39
40
41
42
43
44
```
| ```
class AgentRunError(RuntimeError):
"""Base class for errors occurring during an agent run."""
  message: str
"""The error message."""
  def __init__(self, message: str):
    self.message = message
    super().__init__(message)
  def __str__(self) -> str:
    return self.message

```
  
---|---  
####  message `instance-attribute`
```
message: str[](https://ai.pydantic.dev/api/exceptions/<https:/docs.python.org/3/library/stdtypes.html#str>) = message[](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.AgentRunError.message> "pydantic_ai.exceptions.AgentRunError.message")

```

The error message.
###  UsageLimitExceeded
Bases: `AgentRunError[](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.AgentRunError> "pydantic_ai.exceptions.AgentRunError")`
Error raised when a Model's usage exceeds the specified limits.
Source code in `pydantic_ai_slim/pydantic_ai/exceptions.py`
```
47
48
```
| ```
class UsageLimitExceeded(AgentRunError):
"""Error raised when a Model's usage exceeds the specified limits."""

```
  
---|---  
###  UnexpectedModelBehavior
Bases: `AgentRunError[](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.AgentRunError> "pydantic_ai.exceptions.AgentRunError")`
Error caused by unexpected Model behavior, e.g. an unexpected response code.
Source code in `pydantic_ai_slim/pydantic_ai/exceptions.py`
```
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
```
| ```
class UnexpectedModelBehavior(AgentRunError):
"""Error caused by unexpected Model behavior, e.g. an unexpected response code."""
  message: str
"""Description of the unexpected behavior."""
  body: str | None
"""The body of the response, if available."""
  def __init__(self, message: str, body: str | None = None):
    self.message = message
    if body is None:
      self.body: str | None = None
    else:
      try:
        self.body = json.dumps(json.loads(body), indent=2)
      except ValueError:
        self.body = body
    super().__init__(message)
  def __str__(self) -> str:
    if self.body:
      return f'{self.message}, body:\n{self.body}'
    else:
      return self.message

```
  
---|---  
####  message `instance-attribute`
```
message: str[](https://ai.pydantic.dev/api/exceptions/<https:/docs.python.org/3/library/stdtypes.html#str>) = message[](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UnexpectedModelBehavior.message> "pydantic_ai.exceptions.UnexpectedModelBehavior.message")

```

Description of the unexpected behavior.
####  body `instance-attribute`
```
body: str[](https://ai.pydantic.dev/api/exceptions/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = dumps[](https://ai.pydantic.dev/api/exceptions/<https:/docs.python.org/3/library/json.html#json.dumps> "json.dumps")(loads[](https://ai.pydantic.dev/api/exceptions/<https:/docs.python.org/3/library/json.html#json.loads> "json.loads")(body[](https://ai.pydantic.dev/api/exceptions/<#pydantic_ai.exceptions.UnexpectedModelBehavior.body> "pydantic_ai.exceptions.UnexpectedModelBehavior.body")), indent=2)

```

The body of the response, if available.
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_format_as_xml.md
================
[ Skip to content ](https://ai.pydantic.dev/api/format_as_xml/<#pydantic_aiformat_as_xml>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/format_as_xml/<../..> "PydanticAI")
PydanticAI 
pydantic_ai.format_as_xml 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/format_as_xml/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/format_as_xml/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/format_as_xml/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/format_as_xml/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/api/format_as_xml/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/format_as_xml/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/format_as_xml/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/format_as_xml/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/format_as_xml/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/format_as_xml/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/format_as_xml/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/format_as_xml/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/format_as_xml/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/format_as_xml/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/format_as_xml/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/format_as_xml/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/format_as_xml/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/format_as_xml/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/format_as_xml/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/format_as_xml/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/format_as_xml/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/format_as_xml/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/format_as_xml/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/format_as_xml/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/format_as_xml/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/format_as_xml/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/format_as_xml/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/format_as_xml/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/format_as_xml/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/format_as_xml/<../agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/format_as_xml/<../tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/format_as_xml/<../result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/format_as_xml/<../messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/format_as_xml/<../exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/format_as_xml/<../settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/format_as_xml/<../usage/>)
    * pydantic_ai.format_as_xml  [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/format_as_xml/<./>) Table of contents 
      * [ format_as_xml  ](https://ai.pydantic.dev/api/format_as_xml/<#pydantic_ai.format_as_xml>)
      * [ format_as_xml  ](https://ai.pydantic.dev/api/format_as_xml/<#pydantic_ai.format_as_xml.format_as_xml>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/format_as_xml/<../models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/format_as_xml/<../models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/format_as_xml/<../models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/format_as_xml/<../models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/format_as_xml/<../models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/format_as_xml/<../models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/format_as_xml/<../models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/format_as_xml/<../models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/format_as_xml/<../models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/format_as_xml/<../models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/format_as_xml/<../pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/format_as_xml/<../pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/format_as_xml/<../pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/format_as_xml/<../pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/format_as_xml/<../pydantic_graph/exceptions/>)


Table of contents 
  * [ format_as_xml  ](https://ai.pydantic.dev/api/format_as_xml/<#pydantic_ai.format_as_xml>)
  * [ format_as_xml  ](https://ai.pydantic.dev/api/format_as_xml/<#pydantic_ai.format_as_xml.format_as_xml>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/format_as_xml/<../..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/format_as_xml/<../agent/>)


# `pydantic_ai.format_as_xml`
###  format_as_xml
```
format_as_xml(
  obj: Any[](https://ai.pydantic.dev/api/format_as_xml/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"),
  root_tag: str[](https://ai.pydantic.dev/api/format_as_xml/<https:/docs.python.org/3/library/stdtypes.html#str>) = "examples",
  item_tag: str[](https://ai.pydantic.dev/api/format_as_xml/<https:/docs.python.org/3/library/stdtypes.html#str>) = "example",
  include_root_tag: bool[](https://ai.pydantic.dev/api/format_as_xml/<https:/docs.python.org/3/library/functions.html#bool>) = True,
  none_str: str[](https://ai.pydantic.dev/api/format_as_xml/<https:/docs.python.org/3/library/stdtypes.html#str>) = "null",
  indent: str[](https://ai.pydantic.dev/api/format_as_xml/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = " ",
) -> str[](https://ai.pydantic.dev/api/format_as_xml/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

Format a Python object as XML.
This is useful since LLMs often find it easier to read semi-structured data (e.g. examples) as XML, rather than JSON etc.
Supports: `str`, `bytes`, `bytearray`, `bool`, `int`, `float`, `date`, `datetime`, `Mapping`, `Iterable`, `dataclass`, and `BaseModel`.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`obj` |  `Any[](https://ai.pydantic.dev/api/format_as_xml/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")` |  Python Object to serialize to XML. |  _required_  
`root_tag` |  `str[](https://ai.pydantic.dev/api/format_as_xml/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  Outer tag to wrap the XML in, use `None` to omit the outer tag. |  `'examples'`  
`item_tag` |  `str[](https://ai.pydantic.dev/api/format_as_xml/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  Tag to use for each item in an iterable (e.g. list), this is overridden by the class name for dataclasses and Pydantic models. |  `'example'`  
`include_root_tag` |  `bool[](https://ai.pydantic.dev/api/format_as_xml/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to include the root tag in the output (The root tag is always included if it includes a body - e.g. when the input is a simple value). |  `True`  
`none_str` |  `str[](https://ai.pydantic.dev/api/format_as_xml/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  String to use for `None` values. |  `'null'`  
`indent` |  `str[](https://ai.pydantic.dev/api/format_as_xml/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  Indentation string to use for pretty printing. |  `' '`  
Returns:
Type | Description  
---|---  
`str[](https://ai.pydantic.dev/api/format_as_xml/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  XML representation of the object.  
Example: 
format_as_xml_example.py```
from pydantic_ai.format_as_xml import format_as_xml
print(format_as_xml({'name': 'John', 'height': 6, 'weight': 200}, root_tag='user'))
'''
<user>
 <name>John</name>
 <height>6</height>
 <weight>200</weight>
</user>
'''

```

Source code in `pydantic_ai_slim/pydantic_ai/format_as_xml.py`
```
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
```
| ```
def format_as_xml(
  obj: Any,
  root_tag: str = 'examples',
  item_tag: str = 'example',
  include_root_tag: bool = True,
  none_str: str = 'null',
  indent: str | None = ' ',
) -> str:
"""Format a Python object as XML.
  This is useful since LLMs often find it easier to read semi-structured data (e.g. examples) as XML,
  rather than JSON etc.
  Supports: `str`, `bytes`, `bytearray`, `bool`, `int`, `float`, `date`, `datetime`, `Mapping`,
  `Iterable`, `dataclass`, and `BaseModel`.
  Args:
    obj: Python Object to serialize to XML.
    root_tag: Outer tag to wrap the XML in, use `None` to omit the outer tag.
    item_tag: Tag to use for each item in an iterable (e.g. list), this is overridden by the class name
      for dataclasses and Pydantic models.
    include_root_tag: Whether to include the root tag in the output
      (The root tag is always included if it includes a body - e.g. when the input is a simple value).
    none_str: String to use for `None` values.
    indent: Indentation string to use for pretty printing.
  Returns:
    XML representation of the object.
  Example:
  ```python {title="format_as_xml_example.py" lint="skip"}
  from pydantic_ai.format_as_xml import format_as_xml
  print(format_as_xml({'name': 'John', 'height': 6, 'weight': 200}, root_tag='user'))
  '''
  <user>
   <name>John</name>
   <height>6</height>
   <weight>200</weight>
  </user>
  '''
  ```
  """
  el = _ToXml(item_tag=item_tag, none_str=none_str).to_xml(obj, root_tag)
  if not include_root_tag and el.text is None:
    join = '' if indent is None else '\n'
    return join.join(_rootless_xml_elements(el, indent))
  else:
    if indent is not None:
      ElementTree.indent(el, space=indent)
    return ElementTree.tostring(el, encoding='unicode')

```
  
---|---  
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_messages.md
================
[ Skip to content ](https://ai.pydantic.dev/api/messages/<#pydantic_aimessages>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/messages/<../..> "PydanticAI")
PydanticAI 
pydantic_ai.messages 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/messages/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/messages/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/messages/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/messages/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/api/messages/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/messages/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/messages/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/messages/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/messages/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/messages/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/messages/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/messages/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/messages/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/messages/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/messages/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/messages/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/messages/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/messages/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/messages/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/messages/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/messages/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/messages/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/messages/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/messages/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/messages/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/messages/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/messages/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/messages/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/messages/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/messages/<../agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/messages/<../tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/messages/<../result/>)
    * pydantic_ai.messages  [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/messages/<./>) Table of contents 
      * [ messages  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages>)
      * [ SystemPromptPart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.SystemPromptPart>)
        * [ content  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.SystemPromptPart.content>)
        * [ dynamic_ref  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.SystemPromptPart.dynamic_ref>)
        * [ part_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.SystemPromptPart.part_kind>)
      * [ UserPromptPart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.UserPromptPart>)
        * [ content  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.UserPromptPart.content>)
        * [ timestamp  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.UserPromptPart.timestamp>)
        * [ part_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.UserPromptPart.part_kind>)
      * [ ToolReturnPart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart>)
        * [ tool_name  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart.tool_name>)
        * [ content  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart.content>)
        * [ tool_call_id  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart.tool_call_id>)
        * [ timestamp  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart.timestamp>)
        * [ part_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart.part_kind>)
        * [ model_response_str  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart.model_response_str>)
        * [ model_response_object  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart.model_response_object>)
      * [ RetryPromptPart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart>)
        * [ content  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart.content>)
        * [ tool_name  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart.tool_name>)
        * [ tool_call_id  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart.tool_call_id>)
        * [ timestamp  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart.timestamp>)
        * [ part_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart.part_kind>)
        * [ model_response  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart.model_response>)
      * [ ModelRequestPart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelRequestPart>)
      * [ ModelRequest  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelRequest>)
        * [ parts  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelRequest.parts>)
        * [ kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelRequest.kind>)
      * [ TextPart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPart>)
        * [ content  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPart.content>)
        * [ part_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPart.part_kind>)
        * [ has_content  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPart.has_content>)
      * [ ToolCallPart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart>)
        * [ tool_name  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart.tool_name>)
        * [ args  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart.args>)
        * [ tool_call_id  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart.tool_call_id>)
        * [ part_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart.part_kind>)
        * [ args_as_dict  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart.args_as_dict>)
        * [ args_as_json_str  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart.args_as_json_str>)
        * [ has_content  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart.has_content>)
      * [ ModelResponsePart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponsePart>)
      * [ ModelResponse  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponse>)
        * [ parts  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponse.parts>)
        * [ model_name  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponse.model_name>)
        * [ timestamp  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponse.timestamp>)
        * [ kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponse.kind>)
      * [ ModelMessage  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelMessage>)
      * [ ModelMessagesTypeAdapter  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelMessagesTypeAdapter>)
      * [ TextPartDelta  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPartDelta>)
        * [ content_delta  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPartDelta.content_delta>)
        * [ part_delta_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPartDelta.part_delta_kind>)
        * [ apply  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPartDelta.apply>)
      * [ ToolCallPartDelta  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta>)
        * [ tool_name_delta  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta.tool_name_delta>)
        * [ args_delta  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta.args_delta>)
        * [ tool_call_id  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta.tool_call_id>)
        * [ part_delta_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta.part_delta_kind>)
        * [ as_part  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta.as_part>)
        * [ apply  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta.apply>)
      * [ ModelResponsePartDelta  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponsePartDelta>)
      * [ PartStartEvent  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartStartEvent>)
        * [ index  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartStartEvent.index>)
        * [ part  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartStartEvent.part>)
        * [ event_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartStartEvent.event_kind>)
      * [ PartDeltaEvent  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartDeltaEvent>)
        * [ index  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartDeltaEvent.index>)
        * [ delta  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartDeltaEvent.delta>)
        * [ event_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartDeltaEvent.event_kind>)
      * [ ModelResponseStreamEvent  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponseStreamEvent>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/messages/<../exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/messages/<../settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/messages/<../usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/messages/<../format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/messages/<../models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/messages/<../models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/messages/<../models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/messages/<../models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/messages/<../models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/messages/<../models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/messages/<../models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/messages/<../models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/messages/<../models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/messages/<../models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/messages/<../pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/messages/<../pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/messages/<../pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/messages/<../pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/messages/<../pydantic_graph/exceptions/>)


Table of contents 
  * [ messages  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages>)
  * [ SystemPromptPart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.SystemPromptPart>)
    * [ content  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.SystemPromptPart.content>)
    * [ dynamic_ref  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.SystemPromptPart.dynamic_ref>)
    * [ part_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.SystemPromptPart.part_kind>)
  * [ UserPromptPart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.UserPromptPart>)
    * [ content  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.UserPromptPart.content>)
    * [ timestamp  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.UserPromptPart.timestamp>)
    * [ part_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.UserPromptPart.part_kind>)
  * [ ToolReturnPart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart>)
    * [ tool_name  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart.tool_name>)
    * [ content  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart.content>)
    * [ tool_call_id  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart.tool_call_id>)
    * [ timestamp  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart.timestamp>)
    * [ part_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart.part_kind>)
    * [ model_response_str  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart.model_response_str>)
    * [ model_response_object  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart.model_response_object>)
  * [ RetryPromptPart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart>)
    * [ content  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart.content>)
    * [ tool_name  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart.tool_name>)
    * [ tool_call_id  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart.tool_call_id>)
    * [ timestamp  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart.timestamp>)
    * [ part_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart.part_kind>)
    * [ model_response  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart.model_response>)
  * [ ModelRequestPart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelRequestPart>)
  * [ ModelRequest  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelRequest>)
    * [ parts  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelRequest.parts>)
    * [ kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelRequest.kind>)
  * [ TextPart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPart>)
    * [ content  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPart.content>)
    * [ part_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPart.part_kind>)
    * [ has_content  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPart.has_content>)
  * [ ToolCallPart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart>)
    * [ tool_name  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart.tool_name>)
    * [ args  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart.args>)
    * [ tool_call_id  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart.tool_call_id>)
    * [ part_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart.part_kind>)
    * [ args_as_dict  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart.args_as_dict>)
    * [ args_as_json_str  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart.args_as_json_str>)
    * [ has_content  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart.has_content>)
  * [ ModelResponsePart  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponsePart>)
  * [ ModelResponse  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponse>)
    * [ parts  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponse.parts>)
    * [ model_name  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponse.model_name>)
    * [ timestamp  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponse.timestamp>)
    * [ kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponse.kind>)
  * [ ModelMessage  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelMessage>)
  * [ ModelMessagesTypeAdapter  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelMessagesTypeAdapter>)
  * [ TextPartDelta  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPartDelta>)
    * [ content_delta  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPartDelta.content_delta>)
    * [ part_delta_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPartDelta.part_delta_kind>)
    * [ apply  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPartDelta.apply>)
  * [ ToolCallPartDelta  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta>)
    * [ tool_name_delta  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta.tool_name_delta>)
    * [ args_delta  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta.args_delta>)
    * [ tool_call_id  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta.tool_call_id>)
    * [ part_delta_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta.part_delta_kind>)
    * [ as_part  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta.as_part>)
    * [ apply  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta.apply>)
  * [ ModelResponsePartDelta  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponsePartDelta>)
  * [ PartStartEvent  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartStartEvent>)
    * [ index  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartStartEvent.index>)
    * [ part  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartStartEvent.part>)
    * [ event_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartStartEvent.event_kind>)
  * [ PartDeltaEvent  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartDeltaEvent>)
    * [ index  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartDeltaEvent.index>)
    * [ delta  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartDeltaEvent.delta>)
    * [ event_kind  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartDeltaEvent.event_kind>)
  * [ ModelResponseStreamEvent  ](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponseStreamEvent>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/messages/<../..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/messages/<../agent/>)


# `pydantic_ai.messages`
The structure of `ModelMessage`[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelMessage>) can be shown as a graph:
```
graph RL
  SystemPromptPart(SystemPromptPart) --- ModelRequestPart
  UserPromptPart(UserPromptPart) --- ModelRequestPart
  ToolReturnPart(ToolReturnPart) --- ModelRequestPart
  RetryPromptPart(RetryPromptPart) --- ModelRequestPart
  TextPart(TextPart) --- ModelResponsePart
  ToolCallPart(ToolCallPart) --- ModelResponsePart
  ModelRequestPart("ModelRequestPart<br>(Union)") --- ModelRequest
  ModelRequest("ModelRequest(parts=list[...])") --- ModelMessage
  ModelResponsePart("ModelResponsePart<br>(Union)") --- ModelResponse
  ModelResponse("ModelResponse(parts=list[...])") --- ModelMessage("ModelMessage<br>(Union)")
```

###  SystemPromptPart `dataclass`
A system prompt, generally written by the application developer.
This gives the model context and guidance on how to respond.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
```
| ```
@dataclass
class SystemPromptPart:
"""A system prompt, generally written by the application developer.
  This gives the model context and guidance on how to respond.
  """
  content: str
"""The content of the prompt."""
  dynamic_ref: str | None = None
"""The ref of the dynamic system prompt function that generated this part.
  Only set if system prompt is dynamic, see [`system_prompt`][pydantic_ai.Agent.system_prompt] for more information.
  """
  part_kind: Literal['system-prompt'] = 'system-prompt'
"""Part type identifier, this is available on all parts as a discriminator."""

```
  
---|---  
####  content `instance-attribute`
```
content: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

The content of the prompt.
####  dynamic_ref `class-attribute` `instance-attribute`
```
dynamic_ref: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None

```

The ref of the dynamic system prompt function that generated this part.
Only set if system prompt is dynamic, see `system_prompt`[](https://ai.pydantic.dev/api/messages/<../agent/#pydantic_ai.agent.Agent.system_prompt>) for more information.
####  part_kind `class-attribute` `instance-attribute`
```
part_kind: Literal[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['system-prompt'] = 'system-prompt'

```

Part type identifier, this is available on all parts as a discriminator.
###  UserPromptPart `dataclass`
A user prompt, generally written by the end user.
Content comes from the `user_prompt` parameter of `Agent.run`[](https://ai.pydantic.dev/api/messages/<../agent/#pydantic_ai.agent.Agent.run>), `Agent.run_sync`[](https://ai.pydantic.dev/api/messages/<../agent/#pydantic_ai.agent.Agent.run_sync>), and `Agent.run_stream`[](https://ai.pydantic.dev/api/messages/<../agent/#pydantic_ai.agent.Agent.run_stream>).
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
```
| ```
@dataclass
class UserPromptPart:
"""A user prompt, generally written by the end user.
  Content comes from the `user_prompt` parameter of [`Agent.run`][pydantic_ai.Agent.run],
  [`Agent.run_sync`][pydantic_ai.Agent.run_sync], and [`Agent.run_stream`][pydantic_ai.Agent.run_stream].
  """
  content: str
"""The content of the prompt."""
  timestamp: datetime = field(default_factory=_now_utc)
"""The timestamp of the prompt."""
  part_kind: Literal['user-prompt'] = 'user-prompt'
"""Part type identifier, this is available on all parts as a discriminator."""

```
  
---|---  
####  content `instance-attribute`
```
content: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

The content of the prompt.
####  timestamp `class-attribute` `instance-attribute`
```
timestamp: datetime[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/datetime.html#datetime.datetime> "datetime.datetime") = field[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/dataclasses.html#dataclasses.field> "dataclasses.field")(default_factory=now_utc)

```

The timestamp of the prompt.
####  part_kind `class-attribute` `instance-attribute`
```
part_kind: Literal[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['user-prompt'] = 'user-prompt'

```

Part type identifier, this is available on all parts as a discriminator.
###  ToolReturnPart `dataclass`
A tool return message, this encodes the result of running a tool.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
```
| ```
@dataclass
class ToolReturnPart:
"""A tool return message, this encodes the result of running a tool."""
  tool_name: str
"""The name of the "tool" was called."""
  content: Any
"""The return value."""
  tool_call_id: str | None = None
"""Optional tool call identifier, this is used by some models including OpenAI."""
  timestamp: datetime = field(default_factory=_now_utc)
"""The timestamp, when the tool returned."""
  part_kind: Literal['tool-return'] = 'tool-return'
"""Part type identifier, this is available on all parts as a discriminator."""
  def model_response_str(self) -> str:
"""Return a string representation of the content for the model."""
    if isinstance(self.content, str):
      return self.content
    else:
      return tool_return_ta.dump_json(self.content).decode()
  def model_response_object(self) -> dict[str, Any]:
"""Return a dictionary representation of the content, wrapping non-dict types appropriately."""
    # gemini supports JSON dict return values, but no other JSON types, hence we wrap anything else in a dict
    if isinstance(self.content, dict):
      return tool_return_ta.dump_python(self.content, mode='json') # pyright: ignore[reportUnknownMemberType]
    else:
      return {'return_value': tool_return_ta.dump_python(self.content, mode='json')}

```
  
---|---  
####  tool_name `instance-attribute`
```
tool_name: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

The name of the "tool" was called.
####  content `instance-attribute`
```
content: Any[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")

```

The return value.
####  tool_call_id `class-attribute` `instance-attribute`
```
tool_call_id: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None

```

Optional tool call identifier, this is used by some models including OpenAI.
####  timestamp `class-attribute` `instance-attribute`
```
timestamp: datetime[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/datetime.html#datetime.datetime> "datetime.datetime") = field[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/dataclasses.html#dataclasses.field> "dataclasses.field")(default_factory=now_utc)

```

The timestamp, when the tool returned.
####  part_kind `class-attribute` `instance-attribute`
```
part_kind: Literal[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['tool-return'] = 'tool-return'

```

Part type identifier, this is available on all parts as a discriminator.
####  model_response_str
```
model_response_str() -> str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

Return a string representation of the content for the model.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
74
75
76
77
78
79
```
| ```
def model_response_str(self) -> str:
"""Return a string representation of the content for the model."""
  if isinstance(self.content, str):
    return self.content
  else:
    return tool_return_ta.dump_json(self.content).decode()

```
  
---|---  
####  model_response_object
```
model_response_object() -> dict[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#dict>)[str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>), Any[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")]

```

Return a dictionary representation of the content, wrapping non-dict types appropriately.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
81
82
83
84
85
86
87
```
| ```
def model_response_object(self) -> dict[str, Any]:
"""Return a dictionary representation of the content, wrapping non-dict types appropriately."""
  # gemini supports JSON dict return values, but no other JSON types, hence we wrap anything else in a dict
  if isinstance(self.content, dict):
    return tool_return_ta.dump_python(self.content, mode='json') # pyright: ignore[reportUnknownMemberType]
  else:
    return {'return_value': tool_return_ta.dump_python(self.content, mode='json')}

```
  
---|---  
###  RetryPromptPart `dataclass`
A message back to a model asking it to try again.
This can be sent for a number of reasons:
  * Pydantic validation of tool arguments failed, here content is derived from a Pydantic `ValidationError`[](https://ai.pydantic.dev/api/messages/<https:/docs.pydantic.dev/latest/api/pydantic_core/#pydantic_core.ValidationError>)
  * a tool raised a `ModelRetry`[](https://ai.pydantic.dev/api/messages/<../exceptions/#pydantic_ai.exceptions.ModelRetry>) exception
  * no tool was found for the tool name
  * the model returned plain text when a structured response was expected
  * Pydantic validation of a structured response failed, here content is derived from a Pydantic `ValidationError`[](https://ai.pydantic.dev/api/messages/<https:/docs.pydantic.dev/latest/api/pydantic_core/#pydantic_core.ValidationError>)
  * a result validator raised a `ModelRetry`[](https://ai.pydantic.dev/api/messages/<../exceptions/#pydantic_ai.exceptions.ModelRetry>) exception

Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
```
| ```
@dataclass
class RetryPromptPart:
"""A message back to a model asking it to try again.
  This can be sent for a number of reasons:
  * Pydantic validation of tool arguments failed, here content is derived from a Pydantic
   [`ValidationError`][pydantic_core.ValidationError]
  * a tool raised a [`ModelRetry`][pydantic_ai.exceptions.ModelRetry] exception
  * no tool was found for the tool name
  * the model returned plain text when a structured response was expected
  * Pydantic validation of a structured response failed, here content is derived from a Pydantic
   [`ValidationError`][pydantic_core.ValidationError]
  * a result validator raised a [`ModelRetry`][pydantic_ai.exceptions.ModelRetry] exception
  """
  content: list[pydantic_core.ErrorDetails] | str
"""Details of why and how the model should retry.
  If the retry was triggered by a [`ValidationError`][pydantic_core.ValidationError], this will be a list of
  error details.
  """
  tool_name: str | None = None
"""The name of the tool that was called, if any."""
  tool_call_id: str | None = None
"""Optional tool call identifier, this is used by some models including OpenAI."""
  timestamp: datetime = field(default_factory=_now_utc)
"""The timestamp, when the retry was triggered."""
  part_kind: Literal['retry-prompt'] = 'retry-prompt'
"""Part type identifier, this is available on all parts as a discriminator."""
  def model_response(self) -> str:
"""Return a string message describing why the retry is requested."""
    if isinstance(self.content, str):
      description = self.content
    else:
      json_errors = error_details_ta.dump_json(self.content, exclude={'__all__': {'ctx'}}, indent=2)
      description = f'{len(self.content)} validation errors: {json_errors.decode()}'
    return f'{description}\n\nFix the errors and try again.'

```
  
---|---  
####  content `instance-attribute`
```
content: list[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#list>)[ErrorDetails[](https://ai.pydantic.dev/api/messages/<https:/docs.pydantic.dev/latest/api/pydantic_core/#pydantic_core.ErrorDetails> "pydantic_core.ErrorDetails")] | str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

Details of why and how the model should retry.
If the retry was triggered by a `ValidationError`[](https://ai.pydantic.dev/api/messages/<https:/docs.pydantic.dev/latest/api/pydantic_core/#pydantic_core.ValidationError>), this will be a list of error details.
####  tool_name `class-attribute` `instance-attribute`
```
tool_name: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None

```

The name of the tool that was called, if any.
####  tool_call_id `class-attribute` `instance-attribute`
```
tool_call_id: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None

```

Optional tool call identifier, this is used by some models including OpenAI.
####  timestamp `class-attribute` `instance-attribute`
```
timestamp: datetime[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/datetime.html#datetime.datetime> "datetime.datetime") = field[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/dataclasses.html#dataclasses.field> "dataclasses.field")(default_factory=now_utc)

```

The timestamp, when the retry was triggered.
####  part_kind `class-attribute` `instance-attribute`
```
part_kind: Literal[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['retry-prompt'] = 'retry-prompt'

```

Part type identifier, this is available on all parts as a discriminator.
####  model_response
```
model_response() -> str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

Return a string message describing why the retry is requested.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
128
129
130
131
132
133
134
135
```
| ```
def model_response(self) -> str:
"""Return a string message describing why the retry is requested."""
  if isinstance(self.content, str):
    description = self.content
  else:
    json_errors = error_details_ta.dump_json(self.content, exclude={'__all__': {'ctx'}}, indent=2)
    description = f'{len(self.content)} validation errors: {json_errors.decode()}'
  return f'{description}\n\nFix the errors and try again.'

```
  
---|---  
###  ModelRequestPart `module-attribute`
```
ModelRequestPart = Annotated[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Annotated> "typing.Annotated")[
  Union[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Union> "typing.Union")[
    SystemPromptPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.SystemPromptPart> "pydantic_ai.messages.SystemPromptPart"),
    UserPromptPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.UserPromptPart> "pydantic_ai.messages.UserPromptPart"),
    ToolReturnPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolReturnPart> "pydantic_ai.messages.ToolReturnPart"),
    RetryPromptPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.RetryPromptPart> "pydantic_ai.messages.RetryPromptPart"),
  ],
  Discriminator[](https://ai.pydantic.dev/api/messages/<https:/docs.pydantic.dev/latest/api/types/#pydantic.types.Discriminator> "pydantic.Discriminator")("part_kind"),
]

```

A message part sent by PydanticAI to a model.
###  ModelRequest `dataclass`
A request generated by PydanticAI and sent to a model, e.g. a message from the PydanticAI app to the model.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
144
145
146
147
148
149
150
151
152
```
| ```
@dataclass
class ModelRequest:
"""A request generated by PydanticAI and sent to a model, e.g. a message from the PydanticAI app to the model."""
  parts: list[ModelRequestPart]
"""The parts of the user message."""
  kind: Literal['request'] = 'request'
"""Message type identifier, this is available on all parts as a discriminator."""

```
  
---|---  
####  parts `instance-attribute`
```
parts: list[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelRequestPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelRequestPart> "pydantic_ai.messages.ModelRequestPart")]

```

The parts of the user message.
####  kind `class-attribute` `instance-attribute`
```
kind: Literal[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['request'] = 'request'

```

Message type identifier, this is available on all parts as a discriminator.
###  TextPart `dataclass`
A plain text response from a model.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
155
156
157
158
159
160
161
162
163
164
165
166
167
```
| ```
@dataclass
class TextPart:
"""A plain text response from a model."""
  content: str
"""The text content of the response."""
  part_kind: Literal['text'] = 'text'
"""Part type identifier, this is available on all parts as a discriminator."""
  def has_content(self) -> bool:
"""Return `True` if the text content is non-empty."""
    return bool(self.content)

```
  
---|---  
####  content `instance-attribute`
```
content: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

The text content of the response.
####  part_kind `class-attribute` `instance-attribute`
```
part_kind: Literal[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['text'] = 'text'

```

Part type identifier, this is available on all parts as a discriminator.
####  has_content
```
has_content() -> bool[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/functions.html#bool>)

```

Return `True` if the text content is non-empty.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
165
166
167
```
| ```
def has_content(self) -> bool:
"""Return `True` if the text content is non-empty."""
  return bool(self.content)

```
  
---|---  
###  ToolCallPart `dataclass`
A tool call from a model.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
```
| ```
@dataclass
class ToolCallPart:
"""A tool call from a model."""
  tool_name: str
"""The name of the tool to call."""
  args: str | dict[str, Any]
"""The arguments to pass to the tool.
  This is stored either as a JSON string or a Python dictionary depending on how data was received.
  """
  tool_call_id: str | None = None
"""Optional tool call identifier, this is used by some models including OpenAI."""
  part_kind: Literal['tool-call'] = 'tool-call'
"""Part type identifier, this is available on all parts as a discriminator."""
  def args_as_dict(self) -> dict[str, Any]:
"""Return the arguments as a Python dictionary.
    This is just for convenience with models that require dicts as input.
    """
    if isinstance(self.args, dict):
      return self.args
    args = pydantic_core.from_json(self.args)
    assert isinstance(args, dict), 'args should be a dict'
    return cast(dict[str, Any], args)
  def args_as_json_str(self) -> str:
"""Return the arguments as a JSON string.
    This is just for convenience with models that require JSON strings as input.
    """
    if isinstance(self.args, str):
      return self.args
    return pydantic_core.to_json(self.args).decode()
  def has_content(self) -> bool:
"""Return `True` if the arguments contain any data."""
    if isinstance(self.args, dict):
      # TODO: This should probably return True if you have the value False, or 0, etc.
      #  It makes sense to me to ignore empty strings, but not sure about empty lists or dicts
      return any(self.args.values())
    else:
      return bool(self.args)

```
  
---|---  
####  tool_name `instance-attribute`
```
tool_name: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

The name of the tool to call.
####  args `instance-attribute`
```
args: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>) | dict[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#dict>)[str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>), Any[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")]

```

The arguments to pass to the tool.
This is stored either as a JSON string or a Python dictionary depending on how data was received.
####  tool_call_id `class-attribute` `instance-attribute`
```
tool_call_id: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None

```

Optional tool call identifier, this is used by some models including OpenAI.
####  part_kind `class-attribute` `instance-attribute`
```
part_kind: Literal[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['tool-call'] = 'tool-call'

```

Part type identifier, this is available on all parts as a discriminator.
####  args_as_dict
```
args_as_dict() -> dict[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#dict>)[str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>), Any[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")]

```

Return the arguments as a Python dictionary.
This is just for convenience with models that require dicts as input.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
189
190
191
192
193
194
195
196
197
198
```
| ```
def args_as_dict(self) -> dict[str, Any]:
"""Return the arguments as a Python dictionary.
  This is just for convenience with models that require dicts as input.
  """
  if isinstance(self.args, dict):
    return self.args
  args = pydantic_core.from_json(self.args)
  assert isinstance(args, dict), 'args should be a dict'
  return cast(dict[str, Any], args)

```
  
---|---  
####  args_as_json_str
```
args_as_json_str() -> str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

Return the arguments as a JSON string.
This is just for convenience with models that require JSON strings as input.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
200
201
202
203
204
205
206
207
```
| ```
def args_as_json_str(self) -> str:
"""Return the arguments as a JSON string.
  This is just for convenience with models that require JSON strings as input.
  """
  if isinstance(self.args, str):
    return self.args
  return pydantic_core.to_json(self.args).decode()

```
  
---|---  
####  has_content
```
has_content() -> bool[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/functions.html#bool>)

```

Return `True` if the arguments contain any data.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
209
210
211
212
213
214
215
216
```
| ```
def has_content(self) -> bool:
"""Return `True` if the arguments contain any data."""
  if isinstance(self.args, dict):
    # TODO: This should probably return True if you have the value False, or 0, etc.
    #  It makes sense to me to ignore empty strings, but not sure about empty lists or dicts
    return any(self.args.values())
  else:
    return bool(self.args)

```
  
---|---  
###  ModelResponsePart `module-attribute`
```
ModelResponsePart = Annotated[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Annotated> "typing.Annotated")[
  Union[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Union> "typing.Union")[TextPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPart> "pydantic_ai.messages.TextPart"), ToolCallPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart> "pydantic_ai.messages.ToolCallPart")],
  Discriminator[](https://ai.pydantic.dev/api/messages/<https:/docs.pydantic.dev/latest/api/types/#pydantic.types.Discriminator> "pydantic.Discriminator")("part_kind"),
]

```

A message part returned by a model.
###  ModelResponse `dataclass`
A response from a model, e.g. a message from the model to the PydanticAI app.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
```
| ```
@dataclass
class ModelResponse:
"""A response from a model, e.g. a message from the model to the PydanticAI app."""
  parts: list[ModelResponsePart]
"""The parts of the model message."""
  model_name: str | None = None
"""The name of the model that generated the response."""
  timestamp: datetime = field(default_factory=_now_utc)
"""The timestamp of the response.
  If the model provides a timestamp in the response (as OpenAI does) that will be used.
  """
  kind: Literal['response'] = 'response'
"""Message type identifier, this is available on all parts as a discriminator."""

```
  
---|---  
####  parts `instance-attribute`
```
parts: list[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelResponsePart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponsePart> "pydantic_ai.messages.ModelResponsePart")]

```

The parts of the model message.
####  model_name `class-attribute` `instance-attribute`
```
model_name: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None

```

The name of the model that generated the response.
####  timestamp `class-attribute` `instance-attribute`
```
timestamp: datetime[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/datetime.html#datetime.datetime> "datetime.datetime") = field[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/dataclasses.html#dataclasses.field> "dataclasses.field")(default_factory=now_utc)

```

The timestamp of the response.
If the model provides a timestamp in the response (as OpenAI does) that will be used.
####  kind `class-attribute` `instance-attribute`
```
kind: Literal[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['response'] = 'response'

```

Message type identifier, this is available on all parts as a discriminator.
###  ModelMessage `module-attribute`
```
ModelMessage = Annotated[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Annotated> "typing.Annotated")[
  Union[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Union> "typing.Union")[ModelRequest[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelRequest> "pydantic_ai.messages.ModelRequest"), ModelResponse[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponse> "pydantic_ai.messages.ModelResponse")],
  Discriminator[](https://ai.pydantic.dev/api/messages/<https:/docs.pydantic.dev/latest/api/types/#pydantic.types.Discriminator> "pydantic.Discriminator")("kind"),
]

```

Any message sent to or returned by a model.
###  ModelMessagesTypeAdapter `module-attribute`
```
ModelMessagesTypeAdapter = TypeAdapter[](https://ai.pydantic.dev/api/messages/<https:/docs.pydantic.dev/latest/api/type_adapter/#pydantic.type_adapter.TypeAdapter> "pydantic.TypeAdapter")(
  list[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")], config=ConfigDict[](https://ai.pydantic.dev/api/messages/<https:/docs.pydantic.dev/latest/api/config/#pydantic.config.ConfigDict> "pydantic.ConfigDict")(defer_build=True)
)

```

Pydantic `TypeAdapter`[](https://ai.pydantic.dev/api/messages/<https:/docs.pydantic.dev/latest/api/type_adapter/#pydantic.type_adapter.TypeAdapter>) for (de)serializing messages.
###  TextPartDelta `dataclass`
A partial update (delta) for a `TextPart` to append new text content.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
```
| ```
@dataclass
class TextPartDelta:
"""A partial update (delta) for a `TextPart` to append new text content."""
  content_delta: str
"""The incremental text content to add to the existing `TextPart` content."""
  part_delta_kind: Literal['text'] = 'text'
"""Part delta type identifier, used as a discriminator."""
  def apply(self, part: ModelResponsePart) -> TextPart:
"""Apply this text delta to an existing `TextPart`.
    Args:
      part: The existing model response part, which must be a `TextPart`.
    Returns:
      A new `TextPart` with updated text content.
    Raises:
      ValueError: If `part` is not a `TextPart`.
    """
    if not isinstance(part, TextPart):
      raise ValueError('Cannot apply TextPartDeltas to non-TextParts')
    return replace(part, content=part.content + self.content_delta)

```
  
---|---  
####  content_delta `instance-attribute`
```
content_delta: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

The incremental text content to add to the existing `TextPart` content.
####  part_delta_kind `class-attribute` `instance-attribute`
```
part_delta_kind: Literal[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['text'] = 'text'

```

Part delta type identifier, used as a discriminator.
####  apply
```
apply(part: ModelResponsePart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponsePart> "pydantic_ai.messages.ModelResponsePart")) -> TextPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPart> "pydantic_ai.messages.TextPart")

```

Apply this text delta to an existing `TextPart`.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`part` |  `ModelResponsePart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponsePart> "pydantic_ai.messages.ModelResponsePart")` |  The existing model response part, which must be a `TextPart`. |  _required_  
Returns:
Type | Description  
---|---  
`TextPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPart> "pydantic_ai.messages.TextPart")` |  A new `TextPart` with updated text content.  
Raises:
Type | Description  
---|---  
`ValueError[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/exceptions.html#ValueError>)` |  If `part` is not a `TextPart`.  
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
```
| ```
def apply(self, part: ModelResponsePart) -> TextPart:
"""Apply this text delta to an existing `TextPart`.
  Args:
    part: The existing model response part, which must be a `TextPart`.
  Returns:
    A new `TextPart` with updated text content.
  Raises:
    ValueError: If `part` is not a `TextPart`.
  """
  if not isinstance(part, TextPart):
    raise ValueError('Cannot apply TextPartDeltas to non-TextParts')
  return replace(part, content=part.content + self.content_delta)

```
  
---|---  
###  ToolCallPartDelta `dataclass`
A partial update (delta) for a `ToolCallPart` to modify tool name, arguments, or tool call ID.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
```
| ```
@dataclass
class ToolCallPartDelta:
"""A partial update (delta) for a `ToolCallPart` to modify tool name, arguments, or tool call ID."""
  tool_name_delta: str | None = None
"""Incremental text to add to the existing tool name, if any."""
  args_delta: str | dict[str, Any] | None = None
"""Incremental data to add to the tool arguments.
  If this is a string, it will be appended to existing JSON arguments.
  If this is a dict, it will be merged with existing dict arguments.
  """
  tool_call_id: str | None = None
"""Optional tool call identifier, this is used by some models including OpenAI.
  Note this is never treated as a delta — it can replace None, but otherwise if a
  non-matching value is provided an error will be raised."""
  part_delta_kind: Literal['tool_call'] = 'tool_call'
"""Part delta type identifier, used as a discriminator."""
  def as_part(self) -> ToolCallPart | None:
"""Convert this delta to a fully formed `ToolCallPart` if possible, otherwise return `None`.
    Returns:
      A `ToolCallPart` if both `tool_name_delta` and `args_delta` are set, otherwise `None`.
    """
    if self.tool_name_delta is None or self.args_delta is None:
      return None
    return ToolCallPart(
      self.tool_name_delta,
      self.args_delta,
      self.tool_call_id,
    )
  @overload
  def apply(self, part: ModelResponsePart) -> ToolCallPart: ...
  @overload
  def apply(self, part: ModelResponsePart | ToolCallPartDelta) -> ToolCallPart | ToolCallPartDelta: ...
  def apply(self, part: ModelResponsePart | ToolCallPartDelta) -> ToolCallPart | ToolCallPartDelta:
"""Apply this delta to a part or delta, returning a new part or delta with the changes applied.
    Args:
      part: The existing model response part or delta to update.
    Returns:
      Either a new `ToolCallPart` or an updated `ToolCallPartDelta`.
    Raises:
      ValueError: If `part` is neither a `ToolCallPart` nor a `ToolCallPartDelta`.
      UnexpectedModelBehavior: If applying JSON deltas to dict arguments or vice versa.
    """
    if isinstance(part, ToolCallPart):
      return self._apply_to_part(part)
    if isinstance(part, ToolCallPartDelta):
      return self._apply_to_delta(part)
    raise ValueError(f'Can only apply ToolCallPartDeltas to ToolCallParts or ToolCallPartDeltas, not {part}')
  def _apply_to_delta(self, delta: ToolCallPartDelta) -> ToolCallPart | ToolCallPartDelta:
"""Internal helper to apply this delta to another delta."""
    if self.tool_name_delta:
      # Append incremental text to the existing tool_name_delta
      updated_tool_name_delta = (delta.tool_name_delta or '') + self.tool_name_delta
      delta = replace(delta, tool_name_delta=updated_tool_name_delta)
    if isinstance(self.args_delta, str):
      if isinstance(delta.args_delta, dict):
        raise UnexpectedModelBehavior(
          f'Cannot apply JSON deltas to non-JSON tool arguments ({delta=}, {self=})'
        )
      updated_args_delta = (delta.args_delta or '') + self.args_delta
      delta = replace(delta, args_delta=updated_args_delta)
    elif isinstance(self.args_delta, dict):
      if isinstance(delta.args_delta, str):
        raise UnexpectedModelBehavior(
          f'Cannot apply dict deltas to non-dict tool arguments ({delta=}, {self=})'
        )
      updated_args_delta = {**(delta.args_delta or {}), **self.args_delta}
      delta = replace(delta, args_delta=updated_args_delta)
    if self.tool_call_id:
      # Set the tool_call_id if it wasn't present, otherwise error if it has changed
      if delta.tool_call_id is not None and delta.tool_call_id != self.tool_call_id:
        raise UnexpectedModelBehavior(
          f'Cannot apply a new tool_call_id to a ToolCallPartDelta that already has one ({delta=}, {self=})'
        )
      delta = replace(delta, tool_call_id=self.tool_call_id)
    # If we now have enough data to create a full ToolCallPart, do so
    if delta.tool_name_delta is not None and delta.args_delta is not None:
      return ToolCallPart(
        delta.tool_name_delta,
        delta.args_delta,
        delta.tool_call_id,
      )
    return delta
  def _apply_to_part(self, part: ToolCallPart) -> ToolCallPart:
"""Internal helper to apply this delta directly to a `ToolCallPart`."""
    if self.tool_name_delta:
      # Append incremental text to the existing tool_name
      tool_name = part.tool_name + self.tool_name_delta
      part = replace(part, tool_name=tool_name)
    if isinstance(self.args_delta, str):
      if not isinstance(part.args, str):
        raise UnexpectedModelBehavior(f'Cannot apply JSON deltas to non-JSON tool arguments ({part=}, {self=})')
      updated_json = part.args + self.args_delta
      part = replace(part, args=updated_json)
    elif isinstance(self.args_delta, dict):
      if not isinstance(part.args, dict):
        raise UnexpectedModelBehavior(f'Cannot apply dict deltas to non-dict tool arguments ({part=}, {self=})')
      updated_dict = {**(part.args or {}), **self.args_delta}
      part = replace(part, args=updated_dict)
    if self.tool_call_id:
      # Replace the tool_call_id entirely if given
      if part.tool_call_id is not None and part.tool_call_id != self.tool_call_id:
        raise UnexpectedModelBehavior(
          f'Cannot apply a new tool_call_id to a ToolCallPartDelta that already has one ({part=}, {self=})'
        )
      part = replace(part, tool_call_id=self.tool_call_id)
    return part

```
  
---|---  
####  tool_name_delta `class-attribute` `instance-attribute`
```
tool_name_delta: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None

```

Incremental text to add to the existing tool name, if any.
####  args_delta `class-attribute` `instance-attribute`
```
args_delta: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>) | dict[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#dict>)[str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>), Any[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")] | None = None

```

Incremental data to add to the tool arguments.
If this is a string, it will be appended to existing JSON arguments. If this is a dict, it will be merged with existing dict arguments.
####  tool_call_id `class-attribute` `instance-attribute`
```
tool_call_id: str[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None

```

Optional tool call identifier, this is used by some models including OpenAI.
Note this is never treated as a delta — it can replace None, but otherwise if a non-matching value is provided an error will be raised.
####  part_delta_kind `class-attribute` `instance-attribute`
```
part_delta_kind: Literal[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['tool_call'] = 'tool_call'

```

Part delta type identifier, used as a discriminator.
####  as_part
```
as_part() -> ToolCallPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart> "pydantic_ai.messages.ToolCallPart") | None

```

Convert this delta to a fully formed `ToolCallPart` if possible, otherwise return `None`.
Returns:
Type | Description  
---|---  
`ToolCallPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart> "pydantic_ai.messages.ToolCallPart") | None` |  A `ToolCallPart` if both `tool_name_delta` and `args_delta` are set, otherwise `None`.  
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
300
301
302
303
304
305
306
307
308
309
310
311
312
313
```
| ```
def as_part(self) -> ToolCallPart | None:
"""Convert this delta to a fully formed `ToolCallPart` if possible, otherwise return `None`.
  Returns:
    A `ToolCallPart` if both `tool_name_delta` and `args_delta` are set, otherwise `None`.
  """
  if self.tool_name_delta is None or self.args_delta is None:
    return None
  return ToolCallPart(
    self.tool_name_delta,
    self.args_delta,
    self.tool_call_id,
  )

```
  
---|---  
####  apply
```
apply(part: ModelResponsePart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponsePart> "pydantic_ai.messages.ModelResponsePart")) -> ToolCallPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart> "pydantic_ai.messages.ToolCallPart")

```

```
apply(
  part: ModelResponsePart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponsePart> "pydantic_ai.messages.ModelResponsePart") | ToolCallPartDelta[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta> "pydantic_ai.messages.ToolCallPartDelta"),
) -> ToolCallPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart> "pydantic_ai.messages.ToolCallPart") | ToolCallPartDelta[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta> "pydantic_ai.messages.ToolCallPartDelta")

```

```
apply(
  part: ModelResponsePart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponsePart> "pydantic_ai.messages.ModelResponsePart") | ToolCallPartDelta[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta> "pydantic_ai.messages.ToolCallPartDelta"),
) -> ToolCallPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart> "pydantic_ai.messages.ToolCallPart") | ToolCallPartDelta[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta> "pydantic_ai.messages.ToolCallPartDelta")

```

Apply this delta to a part or delta, returning a new part or delta with the changes applied.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`part` |  `ModelResponsePart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponsePart> "pydantic_ai.messages.ModelResponsePart") | ToolCallPartDelta[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta> "pydantic_ai.messages.ToolCallPartDelta")` |  The existing model response part or delta to update. |  _required_  
Returns:
Type | Description  
---|---  
`ToolCallPart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPart> "pydantic_ai.messages.ToolCallPart") | ToolCallPartDelta[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta> "pydantic_ai.messages.ToolCallPartDelta")` |  Either a new `ToolCallPart` or an updated `ToolCallPartDelta`.  
Raises:
Type | Description  
---|---  
`ValueError[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/exceptions.html#ValueError>)` |  If `part` is neither a `ToolCallPart` nor a `ToolCallPartDelta`.  
`UnexpectedModelBehavior[](https://ai.pydantic.dev/api/messages/<../exceptions/#pydantic_ai.exceptions.UnexpectedModelBehavior> "pydantic_ai.exceptions.UnexpectedModelBehavior")` |  If applying JSON deltas to dict arguments or vice versa.  
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
```
| ```
def apply(self, part: ModelResponsePart | ToolCallPartDelta) -> ToolCallPart | ToolCallPartDelta:
"""Apply this delta to a part or delta, returning a new part or delta with the changes applied.
  Args:
    part: The existing model response part or delta to update.
  Returns:
    Either a new `ToolCallPart` or an updated `ToolCallPartDelta`.
  Raises:
    ValueError: If `part` is neither a `ToolCallPart` nor a `ToolCallPartDelta`.
    UnexpectedModelBehavior: If applying JSON deltas to dict arguments or vice versa.
  """
  if isinstance(part, ToolCallPart):
    return self._apply_to_part(part)
  if isinstance(part, ToolCallPartDelta):
    return self._apply_to_delta(part)
  raise ValueError(f'Can only apply ToolCallPartDeltas to ToolCallParts or ToolCallPartDeltas, not {part}')

```
  
---|---  
###  ModelResponsePartDelta `module-attribute`
```
ModelResponsePartDelta = Annotated[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Annotated> "typing.Annotated")[
  Union[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Union> "typing.Union")[TextPartDelta[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.TextPartDelta> "pydantic_ai.messages.TextPartDelta"), ToolCallPartDelta[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ToolCallPartDelta> "pydantic_ai.messages.ToolCallPartDelta")],
  Discriminator[](https://ai.pydantic.dev/api/messages/<https:/docs.pydantic.dev/latest/api/types/#pydantic.types.Discriminator> "pydantic.Discriminator")("part_delta_kind"),
]

```

A partial update (delta) for any model response part.
###  PartStartEvent `dataclass`
An event indicating that a new part has started.
If multiple `PartStartEvent`s are received with the same index, the new one should fully replace the old one.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
```
| ```
@dataclass
class PartStartEvent:
"""An event indicating that a new part has started.
  If multiple `PartStartEvent`s are received with the same index,
  the new one should fully replace the old one.
  """
  index: int
"""The index of the part within the overall response parts list."""
  part: ModelResponsePart
"""The newly started `ModelResponsePart`."""
  event_kind: Literal['part_start'] = 'part_start'
"""Event type identifier, used as a discriminator."""

```
  
---|---  
####  index `instance-attribute`
```
index: int[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/functions.html#int>)

```

The index of the part within the overall response parts list.
####  part `instance-attribute`
```
part: ModelResponsePart[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponsePart> "pydantic_ai.messages.ModelResponsePart")

```

The newly started `ModelResponsePart`.
####  event_kind `class-attribute` `instance-attribute`
```
event_kind: Literal[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['part_start'] = 'part_start'

```

Event type identifier, used as a discriminator.
###  PartDeltaEvent `dataclass`
An event indicating a delta update for an existing part.
Source code in `pydantic_ai_slim/pydantic_ai/messages.py`
```
432
433
434
435
436
437
438
439
440
441
442
443
```
| ```
@dataclass
class PartDeltaEvent:
"""An event indicating a delta update for an existing part."""
  index: int
"""The index of the part within the overall response parts list."""
  delta: ModelResponsePartDelta
"""The delta to apply to the specified part."""
  event_kind: Literal['part_delta'] = 'part_delta'
"""Event type identifier, used as a discriminator."""

```
  
---|---  
####  index `instance-attribute`
```
index: int[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/functions.html#int>)

```

The index of the part within the overall response parts list.
####  delta `instance-attribute`
```
delta: ModelResponsePartDelta[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.ModelResponsePartDelta> "pydantic_ai.messages.ModelResponsePartDelta")

```

The delta to apply to the specified part.
####  event_kind `class-attribute` `instance-attribute`
```
event_kind: Literal[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['part_delta'] = 'part_delta'

```

Event type identifier, used as a discriminator.
###  ModelResponseStreamEvent `module-attribute`
```
ModelResponseStreamEvent = Annotated[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Annotated> "typing.Annotated")[
  Union[](https://ai.pydantic.dev/api/messages/<https:/docs.python.org/3/library/typing.html#typing.Union> "typing.Union")[PartStartEvent[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartStartEvent> "pydantic_ai.messages.PartStartEvent"), PartDeltaEvent[](https://ai.pydantic.dev/api/messages/<#pydantic_ai.messages.PartDeltaEvent> "pydantic_ai.messages.PartDeltaEvent")],
  Discriminator[](https://ai.pydantic.dev/api/messages/<https:/docs.pydantic.dev/latest/api/types/#pydantic.types.Discriminator> "pydantic.Discriminator")("event_kind"),
]

```

An event in the model response stream, either starting a new part or applying a delta to an existing one.
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_models_anthropic.md
================
[ Skip to content ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_aimodelsanthropic>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/anthropic/..> "PydanticAI")
PydanticAI 
pydantic_ai.models.anthropic 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/anthropic/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/anthropic/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/anthropic/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/models/anthropic/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/models/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/models/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/models/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/models/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/models/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/models/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/models/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/models/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/models/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/models/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/models/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/models/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/models/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/models/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/models/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/models/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/models/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/models/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/models/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/models/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/models/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/models/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/models/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/models/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/models/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/models/anthropic/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/models/anthropic/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/models/anthropic/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/models/anthropic/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/models/anthropic/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/models/anthropic/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/models/anthropic/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/models/anthropic/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/models/anthropic/<../base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/models/anthropic/<../openai/>)
    * pydantic_ai.models.anthropic  [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/models/anthropic/<./>) Table of contents 
      * [ Setup  ](https://ai.pydantic.dev/api/models/anthropic/<#setup>)
        * [ anthropic  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic>)
        * [ LatestAnthropicModelNames  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.LatestAnthropicModelNames>)
        * [ AnthropicModelName  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicModelName>)
        * [ AnthropicModelSettings  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicModelSettings>)
          * [ anthropic_metadata  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicModelSettings.anthropic_metadata>)
        * [ AnthropicModel  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicModel>)
          * [ __init__  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicModel.__init__>)
        * [ AnthropicAgentModel  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicAgentModel>)
        * [ AnthropicStreamedResponse  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicStreamedResponse>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/models/anthropic/<../cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/models/anthropic/<../gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/models/anthropic/<../vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/models/anthropic/<../groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/models/anthropic/<../mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/models/anthropic/<../test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/models/anthropic/<../function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/models/anthropic/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/models/anthropic/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/models/anthropic/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/models/anthropic/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/models/anthropic/pydantic_graph/exceptions/>)


Table of contents 
  * [ Setup  ](https://ai.pydantic.dev/api/models/anthropic/<#setup>)
    * [ anthropic  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic>)
    * [ LatestAnthropicModelNames  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.LatestAnthropicModelNames>)
    * [ AnthropicModelName  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicModelName>)
    * [ AnthropicModelSettings  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicModelSettings>)
      * [ anthropic_metadata  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicModelSettings.anthropic_metadata>)
    * [ AnthropicModel  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicModel>)
      * [ __init__  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicModel.__init__>)
    * [ AnthropicAgentModel  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicAgentModel>)
    * [ AnthropicStreamedResponse  ](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicStreamedResponse>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/models/anthropic/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/models/anthropic/agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/models/anthropic/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/models/anthropic/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_ai.models.anthropic`
## Setup
For details on how to set up authentication with this model, see [model configuration for Anthropic](https://ai.pydantic.dev/api/models/models/#anthropic>).
###  LatestAnthropicModelNames `module-attribute`
```
LatestAnthropicModelNames = Literal[](https://ai.pydantic.dev/api/models/anthropic/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")[
  "claude-3-5-haiku-latest",
  "claude-3-5-sonnet-latest",
  "claude-3-opus-latest",
]

```

Latest named Anthropic models.
###  AnthropicModelName `module-attribute`
```
AnthropicModelName = Union[](https://ai.pydantic.dev/api/models/anthropic/<https:/docs.python.org/3/library/typing.html#typing.Union> "typing.Union")[str[](https://ai.pydantic.dev/api/models/anthropic/<https:/docs.python.org/3/library/stdtypes.html#str>), LatestAnthropicModelNames[](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.LatestAnthropicModelNames> "pydantic_ai.models.anthropic.LatestAnthropicModelNames")]

```

Possible Anthropic model names.
Since Anthropic supports a variety of date-stamped models, we explicitly list the latest models but allow any name in the type hints. Since [the Anthropic docs](https://ai.pydantic.dev/api/models/anthropic/<https:/docs.anthropic.com/en/docs/about-claude/models>) for a full list.
###  AnthropicModelSettings
Bases: `ModelSettings[](https://ai.pydantic.dev/api/models/anthropic/settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings")`
Settings used for an Anthropic model request.
Source code in `pydantic_ai_slim/pydantic_ai/models/anthropic.py`
```
82
83
84
85
86
87
88
```
| ```
class AnthropicModelSettings(ModelSettings):
"""Settings used for an Anthropic model request."""
  anthropic_metadata: MetadataParam
"""An object describing metadata about the request.
  Contains `user_id`, an external identifier for the user who is associated with the request."""

```
  
---|---  
####  anthropic_metadata `instance-attribute`
```
anthropic_metadata: MetadataParam

```

An object describing metadata about the request.
Contains `user_id`, an external identifier for the user who is associated with the request.
###  AnthropicModel `dataclass`
Bases: `Model[](https://ai.pydantic.dev/api/models/anthropic/<../base/#pydantic_ai.models.Model> "pydantic_ai.models.Model")`
A model that uses the Anthropic API.
Internally, this uses the [Anthropic Python client](https://ai.pydantic.dev/api/models/anthropic/<https:/github.com/anthropics/anthropic-sdk-python>) to interact with the API.
Apart from `__init__`, all methods are private or match those of the base class.
Note
The `AnthropicModel` class does not yet support streaming responses. We anticipate adding support for streaming responses in a near-term future release.
Source code in `pydantic_ai_slim/pydantic_ai/models/anthropic.py`
```
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
```
| ```
@dataclass(init=False)
class AnthropicModel(Model):
"""A model that uses the Anthropic API.
  Internally, this uses the [Anthropic Python client](https://github.com/anthropics/anthropic-sdk-python) to interact with the API.
  Apart from `__init__`, all methods are private or match those of the base class.
  !!! note
    The `AnthropicModel` class does not yet support streaming responses.
    We anticipate adding support for streaming responses in a near-term future release.
  """
  model_name: AnthropicModelName
  client: AsyncAnthropic = field(repr=False)
  def __init__(
    self,
    model_name: AnthropicModelName,
    *,
    api_key: str | None = None,
    anthropic_client: AsyncAnthropic | None = None,
    http_client: AsyncHTTPClient | None = None,
  ):
"""Initialize an Anthropic model.
    Args:
      model_name: The name of the Anthropic model to use. List of model names available
        [here](https://docs.anthropic.com/en/docs/about-claude/models).
      api_key: The API key to use for authentication, if not provided, the `ANTHROPIC_API_KEY` environment variable
        will be used if available.
      anthropic_client: An existing
        [`AsyncAnthropic`](https://github.com/anthropics/anthropic-sdk-python?tab=readme-ov-file#async-usage)
        client to use, if provided, `api_key` and `http_client` must be `None`.
      http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
    """
    self.model_name = model_name
    if anthropic_client is not None:
      assert http_client is None, 'Cannot provide both `anthropic_client` and `http_client`'
      assert api_key is None, 'Cannot provide both `anthropic_client` and `api_key`'
      self.client = anthropic_client
    elif http_client is not None:
      self.client = AsyncAnthropic(api_key=api_key, http_client=http_client)
    else:
      self.client = AsyncAnthropic(api_key=api_key, http_client=cached_async_http_client())
  async def agent_model(
    self,
    *,
    function_tools: list[ToolDefinition],
    allow_text_result: bool,
    result_tools: list[ToolDefinition],
  ) -> AgentModel:
    check_allow_model_requests()
    tools = [self._map_tool_definition(r) for r in function_tools]
    if result_tools:
      tools += [self._map_tool_definition(r) for r in result_tools]
    return AnthropicAgentModel(
      self.client,
      self.model_name,
      allow_text_result,
      tools,
    )
  def name(self) -> str:
    return f'anthropic:{self.model_name}'
  @staticmethod
  def _map_tool_definition(f: ToolDefinition) -> ToolParam:
    return {
      'name': f.name,
      'description': f.description,
      'input_schema': f.parameters_json_schema,
    }

```
  
---|---  
####  __init__
```
__init__(
  model_name: AnthropicModelName[](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicModelName> "pydantic_ai.models.anthropic.AnthropicModelName"),
  *,
  api_key: str[](https://ai.pydantic.dev/api/models/anthropic/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None,
  anthropic_client: AsyncAnthropic | None = None,
  http_client: AsyncClient | None = None
)

```

Initialize an Anthropic model.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`model_name` |  `AnthropicModelName[](https://ai.pydantic.dev/api/models/anthropic/<#pydantic_ai.models.anthropic.AnthropicModelName> "pydantic_ai.models.anthropic.AnthropicModelName")` |  The name of the Anthropic model to use. List of model names available [here](https://ai.pydantic.dev/api/models/anthropic/<https:/docs.anthropic.com/en/docs/about-claude/models>). |  _required_  
`api_key` |  `str[](https://ai.pydantic.dev/api/models/anthropic/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The API key to use for authentication, if not provided, the `ANTHROPIC_API_KEY` environment variable will be used if available. |  `None`  
`anthropic_client` |  `AsyncAnthropic | None` |  An existing `AsyncAnthropic`[](https://ai.pydantic.dev/api/models/anthropic/<https:/github.com/anthropics/anthropic-sdk-python?tab=readme-ov-file#async-usage>) client to use, if provided, `api_key` and `http_client` must be `None`. |  `None`  
`http_client` |  `AsyncClient | None` |  An existing `httpx.AsyncClient` to use for making HTTP requests. |  `None`  
Source code in `pydantic_ai_slim/pydantic_ai/models/anthropic.py`
```
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
```
| ```
def __init__(
  self,
  model_name: AnthropicModelName,
  *,
  api_key: str | None = None,
  anthropic_client: AsyncAnthropic | None = None,
  http_client: AsyncHTTPClient | None = None,
):
"""Initialize an Anthropic model.
  Args:
    model_name: The name of the Anthropic model to use. List of model names available
      [here](https://docs.anthropic.com/en/docs/about-claude/models).
    api_key: The API key to use for authentication, if not provided, the `ANTHROPIC_API_KEY` environment variable
      will be used if available.
    anthropic_client: An existing
      [`AsyncAnthropic`](https://github.com/anthropics/anthropic-sdk-python?tab=readme-ov-file#async-usage)
      client to use, if provided, `api_key` and `http_client` must be `None`.
    http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
  """
  self.model_name = model_name
  if anthropic_client is not None:
    assert http_client is None, 'Cannot provide both `anthropic_client` and `http_client`'
    assert api_key is None, 'Cannot provide both `anthropic_client` and `api_key`'
    self.client = anthropic_client
  elif http_client is not None:
    self.client = AsyncAnthropic(api_key=api_key, http_client=http_client)
  else:
    self.client = AsyncAnthropic(api_key=api_key, http_client=cached_async_http_client())

```
  
---|---  
###  AnthropicAgentModel `dataclass`
Bases: `AgentModel[](https://ai.pydantic.dev/api/models/anthropic/<../base/#pydantic_ai.models.AgentModel> "pydantic_ai.models.AgentModel")`
Implementation of `AgentModel` for Anthropic models.
Source code in `pydantic_ai_slim/pydantic_ai/models/anthropic.py`
```
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
```
| ```
@dataclass
class AnthropicAgentModel(AgentModel):
"""Implementation of `AgentModel` for Anthropic models."""
  client: AsyncAnthropic
  model_name: AnthropicModelName
  allow_text_result: bool
  tools: list[ToolParam]
  async def request(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> tuple[ModelResponse, usage.Usage]:
    response = await self._messages_create(messages, False, cast(AnthropicModelSettings, model_settings or {}))
    return self._process_response(response), _map_usage(response)
  @asynccontextmanager
  async def request_stream(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> AsyncIterator[StreamedResponse]:
    response = await self._messages_create(messages, True, cast(AnthropicModelSettings, model_settings or {}))
    async with response:
      yield await self._process_streamed_response(response)
  @overload
  async def _messages_create(
    self, messages: list[ModelMessage], stream: Literal[True], model_settings: AnthropicModelSettings
  ) -> AsyncStream[RawMessageStreamEvent]:
    pass
  @overload
  async def _messages_create(
    self, messages: list[ModelMessage], stream: Literal[False], model_settings: AnthropicModelSettings
  ) -> AnthropicMessage:
    pass
  async def _messages_create(
    self, messages: list[ModelMessage], stream: bool, model_settings: AnthropicModelSettings
  ) -> AnthropicMessage | AsyncStream[RawMessageStreamEvent]:
    # standalone function to make it easier to override
    tool_choice: ToolChoiceParam | None
    if not self.tools:
      tool_choice = None
    else:
      if not self.allow_text_result:
        tool_choice = {'type': 'any'}
      else:
        tool_choice = {'type': 'auto'}
      if (allow_parallel_tool_calls := model_settings.get('parallel_tool_calls')) is not None:
        tool_choice['disable_parallel_tool_use'] = not allow_parallel_tool_calls
    system_prompt, anthropic_messages = self._map_message(messages)
    return await self.client.messages.create(
      max_tokens=model_settings.get('max_tokens', 1024),
      system=system_prompt or NOT_GIVEN,
      messages=anthropic_messages,
      model=self.model_name,
      tools=self.tools or NOT_GIVEN,
      tool_choice=tool_choice or NOT_GIVEN,
      stream=stream,
      temperature=model_settings.get('temperature', NOT_GIVEN),
      top_p=model_settings.get('top_p', NOT_GIVEN),
      timeout=model_settings.get('timeout', NOT_GIVEN),
      metadata=model_settings.get('anthropic_metadata', NOT_GIVEN),
    )
  def _process_response(self, response: AnthropicMessage) -> ModelResponse:
"""Process a non-streamed response, and prepare a message to return."""
    items: list[ModelResponsePart] = []
    for item in response.content:
      if isinstance(item, TextBlock):
        items.append(TextPart(content=item.text))
      else:
        assert isinstance(item, ToolUseBlock), 'unexpected item type'
        items.append(
          ToolCallPart(
            tool_name=item.name,
            args=cast(dict[str, Any], item.input),
            tool_call_id=item.id,
          )
        )
    return ModelResponse(items, model_name=self.model_name)
  async def _process_streamed_response(self, response: AsyncStream[RawMessageStreamEvent]) -> StreamedResponse:
    peekable_response = _utils.PeekableAsyncStream(response)
    first_chunk = await peekable_response.peek()
    if isinstance(first_chunk, _utils.Unset):
      raise UnexpectedModelBehavior('Streamed response ended without content or tool calls')
    # Since Anthropic doesn't provide a timestamp in the message, we'll use the current time
    timestamp = datetime.now(tz=timezone.utc)
    return AnthropicStreamedResponse(_model_name=self.model_name, _response=peekable_response, _timestamp=timestamp)
  @staticmethod
  def _map_message(messages: list[ModelMessage]) -> tuple[str, list[MessageParam]]:
"""Just maps a `pydantic_ai.Message` to a `anthropic.types.MessageParam`."""
    system_prompt: str = ''
    anthropic_messages: list[MessageParam] = []
    for m in messages:
      if isinstance(m, ModelRequest):
        for part in m.parts:
          if isinstance(part, SystemPromptPart):
            system_prompt += part.content
          elif isinstance(part, UserPromptPart):
            anthropic_messages.append(MessageParam(role='user', content=part.content))
          elif isinstance(part, ToolReturnPart):
            anthropic_messages.append(
              MessageParam(
                role='user',
                content=[
                  ToolResultBlockParam(
                    tool_use_id=_guard_tool_call_id(t=part, model_source='Anthropic'),
                    type='tool_result',
                    content=part.model_response_str(),
                    is_error=False,
                  )
                ],
              )
            )
          elif isinstance(part, RetryPromptPart):
            if part.tool_name is None:
              anthropic_messages.append(MessageParam(role='user', content=part.model_response()))
            else:
              anthropic_messages.append(
                MessageParam(
                  role='user',
                  content=[
                    ToolResultBlockParam(
                      tool_use_id=_guard_tool_call_id(t=part, model_source='Anthropic'),
                      type='tool_result',
                      content=part.model_response(),
                      is_error=True,
                    ),
                  ],
                )
              )
      elif isinstance(m, ModelResponse):
        content: list[TextBlockParam | ToolUseBlockParam] = []
        for item in m.parts:
          if isinstance(item, TextPart):
            content.append(TextBlockParam(text=item.content, type='text'))
          else:
            assert isinstance(item, ToolCallPart)
            content.append(_map_tool_call(item))
        anthropic_messages.append(MessageParam(role='assistant', content=content))
      else:
        assert_never(m)
    return system_prompt, anthropic_messages

```
  
---|---  
###  AnthropicStreamedResponse `dataclass`
Bases: `StreamedResponse[](https://ai.pydantic.dev/api/models/anthropic/<../base/#pydantic_ai.models.StreamedResponse> "pydantic_ai.models.StreamedResponse")`
Implementation of `StreamedResponse` for Anthropic models.
Source code in `pydantic_ai_slim/pydantic_ai/models/anthropic.py`
```
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
```
| ```
@dataclass
class AnthropicStreamedResponse(StreamedResponse):
"""Implementation of `StreamedResponse` for Anthropic models."""
  _response: AsyncIterable[RawMessageStreamEvent]
  _timestamp: datetime
  async def _get_event_iterator(self) -> AsyncIterator[ModelResponseStreamEvent]:
    current_block: TextBlock | ToolUseBlock | None = None
    current_json: str = ''
    async for event in self._response:
      self._usage += _map_usage(event)
      if isinstance(event, RawContentBlockStartEvent):
        current_block = event.content_block
        if isinstance(current_block, TextBlock) and current_block.text:
          yield self._parts_manager.handle_text_delta(vendor_part_id='content', content=current_block.text)
        elif isinstance(current_block, ToolUseBlock):
          maybe_event = self._parts_manager.handle_tool_call_delta(
            vendor_part_id=current_block.id,
            tool_name=current_block.name,
            args=cast(dict[str, Any], current_block.input),
            tool_call_id=current_block.id,
          )
          if maybe_event is not None:
            yield maybe_event
      elif isinstance(event, RawContentBlockDeltaEvent):
        if isinstance(event.delta, TextDelta):
          yield self._parts_manager.handle_text_delta(vendor_part_id='content', content=event.delta.text)
        elif (
          current_block and event.delta.type == 'input_json_delta' and isinstance(current_block, ToolUseBlock)
        ):
          # Try to parse the JSON immediately, otherwise cache the value for later. This handles
          # cases where the JSON is not currently valid but will be valid once we stream more tokens.
          try:
            parsed_args = json_loads(current_json + event.delta.partial_json)
            current_json = ''
          except JSONDecodeError:
            current_json += event.delta.partial_json
            continue
          # For tool calls, we need to handle partial JSON updates
          maybe_event = self._parts_manager.handle_tool_call_delta(
            vendor_part_id=current_block.id,
            tool_name='',
            args=parsed_args,
            tool_call_id=current_block.id,
          )
          if maybe_event is not None:
            yield maybe_event
      elif isinstance(event, (RawContentBlockStopEvent, RawMessageStopEvent)):
        current_block = None
  def timestamp(self) -> datetime:
    return self._timestamp

```
  
---|---  
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_models_base.md
================
[ Skip to content ](https://ai.pydantic.dev/api/models/base/<#pydantic_aimodels>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/base/..> "PydanticAI")
PydanticAI 
pydantic_ai.models 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/base/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/base/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/base/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/models/base/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/models/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/models/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/models/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/models/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/models/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/models/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/models/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/models/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/models/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/models/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/models/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/models/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/models/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/models/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/models/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/models/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/models/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/models/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/models/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/models/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/models/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/models/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/models/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/models/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/models/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/models/base/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/models/base/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/models/base/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/models/base/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/models/base/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/models/base/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/models/base/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/models/base/format_as_xml/>)
    * pydantic_ai.models  [ pydantic_ai.models  ](https://ai.pydantic.dev/api/models/base/<./>) Table of contents 
      * [ models  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models>)
      * [ KnownModelName  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.KnownModelName>)
      * [ Model  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.Model>)
        * [ agent_model  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.Model.agent_model>)
      * [ AgentModel  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.AgentModel>)
        * [ request  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.AgentModel.request>)
        * [ request_stream  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.AgentModel.request_stream>)
      * [ StreamedResponse  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.StreamedResponse>)
        * [ __aiter__  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.StreamedResponse.__aiter__>)
        * [ get  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.StreamedResponse.get>)
        * [ model_name  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.StreamedResponse.model_name>)
        * [ usage  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.StreamedResponse.usage>)
        * [ timestamp  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.StreamedResponse.timestamp>)
      * [ ALLOW_MODEL_REQUESTS  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.ALLOW_MODEL_REQUESTS>)
      * [ check_allow_model_requests  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.check_allow_model_requests>)
      * [ override_allow_model_requests  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.override_allow_model_requests>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/models/base/<../openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/models/base/<../anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/models/base/<../cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/models/base/<../gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/models/base/<../vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/models/base/<../groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/models/base/<../mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/models/base/<../test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/models/base/<../function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/models/base/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/models/base/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/models/base/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/models/base/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/models/base/pydantic_graph/exceptions/>)


Table of contents 
  * [ models  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models>)
  * [ KnownModelName  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.KnownModelName>)
  * [ Model  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.Model>)
    * [ agent_model  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.Model.agent_model>)
  * [ AgentModel  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.AgentModel>)
    * [ request  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.AgentModel.request>)
    * [ request_stream  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.AgentModel.request_stream>)
  * [ StreamedResponse  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.StreamedResponse>)
    * [ __aiter__  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.StreamedResponse.__aiter__>)
    * [ get  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.StreamedResponse.get>)
    * [ model_name  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.StreamedResponse.model_name>)
    * [ usage  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.StreamedResponse.usage>)
    * [ timestamp  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.StreamedResponse.timestamp>)
  * [ ALLOW_MODEL_REQUESTS  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.ALLOW_MODEL_REQUESTS>)
  * [ check_allow_model_requests  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.check_allow_model_requests>)
  * [ override_allow_model_requests  ](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.override_allow_model_requests>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/models/base/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/models/base/agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/models/base/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/models/base/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_ai.models`
Logic related to making requests to an LLM.
The aim here is to make a common interface for different LLMs, so that the rest of the code can be agnostic to the specific LLM being used.
###  KnownModelName `module-attribute`
```
KnownModelName = Literal[](https://ai.pydantic.dev/api/models/base/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.Literal> "typing_extensions.Literal")[
  "anthropic:claude-3-5-haiku-latest",
  "anthropic:claude-3-5-sonnet-latest",
  "anthropic:claude-3-opus-latest",
  "claude-3-5-haiku-latest",
  "claude-3-5-sonnet-latest",
  "claude-3-opus-latest",
  "cohere:c4ai-aya-expanse-32b",
  "cohere:c4ai-aya-expanse-8b",
  "cohere:command",
  "cohere:command-light",
  "cohere:command-light-nightly",
  "cohere:command-nightly",
  "cohere:command-r",
  "cohere:command-r-03-2024",
  "cohere:command-r-08-2024",
  "cohere:command-r-plus",
  "cohere:command-r-plus-04-2024",
  "cohere:command-r-plus-08-2024",
  "cohere:command-r7b-12-2024",
  "google-gla:gemini-1.0-pro",
  "google-gla:gemini-1.5-flash",
  "google-gla:gemini-1.5-flash-8b",
  "google-gla:gemini-1.5-pro",
  "google-gla:gemini-2.0-flash-exp",
  "google-vertex:gemini-1.0-pro",
  "google-vertex:gemini-1.5-flash",
  "google-vertex:gemini-1.5-flash-8b",
  "google-vertex:gemini-1.5-pro",
  "google-vertex:gemini-2.0-flash-exp",
  "gpt-3.5-turbo",
  "gpt-3.5-turbo-0125",
  "gpt-3.5-turbo-0301",
  "gpt-3.5-turbo-0613",
  "gpt-3.5-turbo-1106",
  "gpt-3.5-turbo-16k",
  "gpt-3.5-turbo-16k-0613",
  "gpt-4",
  "gpt-4-0125-preview",
  "gpt-4-0314",
  "gpt-4-0613",
  "gpt-4-1106-preview",
  "gpt-4-32k",
  "gpt-4-32k-0314",
  "gpt-4-32k-0613",
  "gpt-4-turbo",
  "gpt-4-turbo-2024-04-09",
  "gpt-4-turbo-preview",
  "gpt-4-vision-preview",
  "gpt-4o",
  "gpt-4o-2024-05-13",
  "gpt-4o-2024-08-06",
  "gpt-4o-2024-11-20",
  "gpt-4o-audio-preview",
  "gpt-4o-audio-preview-2024-10-01",
  "gpt-4o-audio-preview-2024-12-17",
  "gpt-4o-mini",
  "gpt-4o-mini-2024-07-18",
  "gpt-4o-mini-audio-preview",
  "gpt-4o-mini-audio-preview-2024-12-17",
  "groq:gemma2-9b-it",
  "groq:llama-3.1-8b-instant",
  "groq:llama-3.2-11b-vision-preview",
  "groq:llama-3.2-1b-preview",
  "groq:llama-3.2-3b-preview",
  "groq:llama-3.2-90b-vision-preview",
  "groq:llama-3.3-70b-specdec",
  "groq:llama-3.3-70b-versatile",
  "groq:llama3-70b-8192",
  "groq:llama3-8b-8192",
  "groq:mixtral-8x7b-32768",
  "mistral:codestral-latest",
  "mistral:mistral-large-latest",
  "mistral:mistral-moderation-latest",
  "mistral:mistral-small-latest",
  "o1",
  "o1-2024-12-17",
  "o1-mini",
  "o1-mini-2024-09-12",
  "o1-preview",
  "o1-preview-2024-09-12",
  "openai:chatgpt-4o-latest",
  "openai:gpt-3.5-turbo",
  "openai:gpt-3.5-turbo-0125",
  "openai:gpt-3.5-turbo-0301",
  "openai:gpt-3.5-turbo-0613",
  "openai:gpt-3.5-turbo-1106",
  "openai:gpt-3.5-turbo-16k",
  "openai:gpt-3.5-turbo-16k-0613",
  "openai:gpt-4",
  "openai:gpt-4-0125-preview",
  "openai:gpt-4-0314",
  "openai:gpt-4-0613",
  "openai:gpt-4-1106-preview",
  "openai:gpt-4-32k",
  "openai:gpt-4-32k-0314",
  "openai:gpt-4-32k-0613",
  "openai:gpt-4-turbo",
  "openai:gpt-4-turbo-2024-04-09",
  "openai:gpt-4-turbo-preview",
  "openai:gpt-4-vision-preview",
  "openai:gpt-4o",
  "openai:gpt-4o-2024-05-13",
  "openai:gpt-4o-2024-08-06",
  "openai:gpt-4o-2024-11-20",
  "openai:gpt-4o-audio-preview",
  "openai:gpt-4o-audio-preview-2024-10-01",
  "openai:gpt-4o-audio-preview-2024-12-17",
  "openai:gpt-4o-mini",
  "openai:gpt-4o-mini-2024-07-18",
  "openai:gpt-4o-mini-audio-preview",
  "openai:gpt-4o-mini-audio-preview-2024-12-17",
  "openai:o1",
  "openai:o1-2024-12-17",
  "openai:o1-mini",
  "openai:o1-mini-2024-09-12",
  "openai:o1-preview",
  "openai:o1-preview-2024-09-12",
  "test",
]

```

Known model names that can be used with the `model` parameter of `Agent`[](https://ai.pydantic.dev/api/models/base/agent/#pydantic_ai.agent.Agent>).
`KnownModelName` is provided as a concise way to specify a model.
###  Model
Bases: `ABC[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/abc.html#abc.ABC> "abc.ABC")`
Abstract class for a model.
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`
```
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
```
| ```
class Model(ABC):
"""Abstract class for a model."""
  @abstractmethod
  async def agent_model(
    self,
    *,
    function_tools: list[ToolDefinition],
    allow_text_result: bool,
    result_tools: list[ToolDefinition],
  ) -> AgentModel:
"""Create an agent model, this is called for each step of an agent run.
    This is async in case slow/async config checks need to be performed that can't be done in `__init__`.
    Args:
      function_tools: The tools available to the agent.
      allow_text_result: Whether a plain text final response/result is permitted.
      result_tools: Tool definitions for the final result tool(s), if any.
    Returns:
      An agent model.
    """
    raise NotImplementedError()
  @abstractmethod
  def name(self) -> str:
    raise NotImplementedError()

```
  
---|---  
####  agent_model `abstractmethod` `async`
```
agent_model(
  *,
  function_tools: list[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/stdtypes.html#list>)[ToolDefinition[](https://ai.pydantic.dev/api/models/base/tools/#pydantic_ai.tools.ToolDefinition> "pydantic_ai.tools.ToolDefinition")],
  allow_text_result: bool[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/functions.html#bool>),
  result_tools: list[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/stdtypes.html#list>)[ToolDefinition[](https://ai.pydantic.dev/api/models/base/tools/#pydantic_ai.tools.ToolDefinition> "pydantic_ai.tools.ToolDefinition")]
) -> AgentModel[](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.AgentModel> "pydantic_ai.models.AgentModel")

```

Create an agent model, this is called for each step of an agent run.
This is async in case slow/async config checks need to be performed that can't be done in `__init__`.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`function_tools` |  `list[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/stdtypes.html#list>)[ToolDefinition[](https://ai.pydantic.dev/api/models/base/tools/#pydantic_ai.tools.ToolDefinition> "pydantic_ai.tools.ToolDefinition")]` |  The tools available to the agent. |  _required_  
`allow_text_result` |  `bool[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether a plain text final response/result is permitted. |  _required_  
`result_tools` |  `list[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/stdtypes.html#list>)[ToolDefinition[](https://ai.pydantic.dev/api/models/base/tools/#pydantic_ai.tools.ToolDefinition> "pydantic_ai.tools.ToolDefinition")]` |  Tool definitions for the final result tool(s), if any. |  _required_  
Returns:
Type | Description  
---|---  
`AgentModel[](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.AgentModel> "pydantic_ai.models.AgentModel")` |  An agent model.  
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`
```
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
```
| ```
@abstractmethod
async def agent_model(
  self,
  *,
  function_tools: list[ToolDefinition],
  allow_text_result: bool,
  result_tools: list[ToolDefinition],
) -> AgentModel:
"""Create an agent model, this is called for each step of an agent run.
  This is async in case slow/async config checks need to be performed that can't be done in `__init__`.
  Args:
    function_tools: The tools available to the agent.
    allow_text_result: Whether a plain text final response/result is permitted.
    result_tools: Tool definitions for the final result tool(s), if any.
  Returns:
    An agent model.
  """
  raise NotImplementedError()

```
  
---|---  
###  AgentModel
Bases: `ABC[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/abc.html#abc.ABC> "abc.ABC")`
Model configured for each step of an Agent run.
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`
```
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
```
| ```
class AgentModel(ABC):
"""Model configured for each step of an Agent run."""
  @abstractmethod
  async def request(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> tuple[ModelResponse, Usage]:
"""Make a request to the model."""
    raise NotImplementedError()
  @asynccontextmanager
  async def request_stream(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> AsyncIterator[StreamedResponse]:
"""Make a request to the model and return a streaming response."""
    # This method is not required, but you need to implement it if you want to support streamed responses
    raise NotImplementedError(f'Streamed requests not supported by this {self.__class__.__name__}')
    # yield is required to make this a generator for type checking
    # noinspection PyUnreachableCode
    yield # pragma: no cover

```
  
---|---  
####  request `abstractmethod` `async`
```
request(
  messages: list[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/models/base/messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")],
  model_settings: ModelSettings[](https://ai.pydantic.dev/api/models/base/settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None,
) -> tuple[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/stdtypes.html#tuple>)[ModelResponse[](https://ai.pydantic.dev/api/models/base/messages/#pydantic_ai.messages.ModelResponse> "pydantic_ai.messages.ModelResponse"), Usage[](https://ai.pydantic.dev/api/models/base/usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage")]

```

Make a request to the model.
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`
```
189
190
191
192
193
194
```
| ```
@abstractmethod
async def request(
  self, messages: list[ModelMessage], model_settings: ModelSettings | None
) -> tuple[ModelResponse, Usage]:
"""Make a request to the model."""
  raise NotImplementedError()

```
  
---|---  
####  request_stream `async`
```
request_stream(
  messages: list[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/models/base/messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")],
  model_settings: ModelSettings[](https://ai.pydantic.dev/api/models/base/settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None,
) -> AsyncIterator[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.AsyncIterator> "collections.abc.AsyncIterator")[StreamedResponse[](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.StreamedResponse> "pydantic_ai.models.StreamedResponse")]

```

Make a request to the model and return a streaming response.
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`
```
196
197
198
199
200
201
202
203
204
205
```
| ```
@asynccontextmanager
async def request_stream(
  self, messages: list[ModelMessage], model_settings: ModelSettings | None
) -> AsyncIterator[StreamedResponse]:
"""Make a request to the model and return a streaming response."""
  # This method is not required, but you need to implement it if you want to support streamed responses
  raise NotImplementedError(f'Streamed requests not supported by this {self.__class__.__name__}')
  # yield is required to make this a generator for type checking
  # noinspection PyUnreachableCode
  yield # pragma: no cover

```
  
---|---  
###  StreamedResponse `dataclass`
Bases: `ABC[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/abc.html#abc.ABC> "abc.ABC")`
Streamed response from an LLM when calling a tool.
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`
```
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
```
| ```
@dataclass
class StreamedResponse(ABC):
"""Streamed response from an LLM when calling a tool."""
  _model_name: str
  _usage: Usage = field(default_factory=Usage, init=False)
  _parts_manager: ModelResponsePartsManager = field(default_factory=ModelResponsePartsManager, init=False)
  _event_iterator: AsyncIterator[ModelResponseStreamEvent] | None = field(default=None, init=False)
  def __aiter__(self) -> AsyncIterator[ModelResponseStreamEvent]:
"""Stream the response as an async iterable of [`ModelResponseStreamEvent`][pydantic_ai.messages.ModelResponseStreamEvent]s."""
    if self._event_iterator is None:
      self._event_iterator = self._get_event_iterator()
    return self._event_iterator
  @abstractmethod
  async def _get_event_iterator(self) -> AsyncIterator[ModelResponseStreamEvent]:
"""Return an async iterator of [`ModelResponseStreamEvent`][pydantic_ai.messages.ModelResponseStreamEvent]s.
    This method should be implemented by subclasses to translate the vendor-specific stream of events into
    pydantic_ai-format events.
    """
    raise NotImplementedError()
    # noinspection PyUnreachableCode
    yield
  def get(self) -> ModelResponse:
"""Build a [`ModelResponse`][pydantic_ai.messages.ModelResponse] from the data received from the stream so far."""
    return ModelResponse(
      parts=self._parts_manager.get_parts(), model_name=self._model_name, timestamp=self.timestamp()
    )
  def model_name(self) -> str:
"""Get the model name of the response."""
    return self._model_name
  def usage(self) -> Usage:
"""Get the usage of the response so far. This will not be the final usage until the stream is exhausted."""
    return self._usage
  @abstractmethod
  def timestamp(self) -> datetime:
"""Get the timestamp of the response."""
    raise NotImplementedError()

```
  
---|---  
####  __aiter__
```
__aiter__() -> AsyncIterator[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.AsyncIterator> "collections.abc.AsyncIterator")[ModelResponseStreamEvent[](https://ai.pydantic.dev/api/models/base/messages/#pydantic_ai.messages.ModelResponseStreamEvent> "pydantic_ai.messages.ModelResponseStreamEvent")]

```

Stream the response as an async iterable of `ModelResponseStreamEvent`[](https://ai.pydantic.dev/api/models/base/messages/#pydantic_ai.messages.ModelResponseStreamEvent>)s.
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`
```
217
218
219
220
221
```
| ```
def __aiter__(self) -> AsyncIterator[ModelResponseStreamEvent]:
"""Stream the response as an async iterable of [`ModelResponseStreamEvent`][pydantic_ai.messages.ModelResponseStreamEvent]s."""
  if self._event_iterator is None:
    self._event_iterator = self._get_event_iterator()
  return self._event_iterator

```
  
---|---  
####  get
```
get() -> ModelResponse[](https://ai.pydantic.dev/api/models/base/messages/#pydantic_ai.messages.ModelResponse> "pydantic_ai.messages.ModelResponse")

```

Build a `ModelResponse`[](https://ai.pydantic.dev/api/models/base/messages/#pydantic_ai.messages.ModelResponse>) from the data received from the stream so far.
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`
```
234
235
236
237
238
```
| ```
def get(self) -> ModelResponse:
"""Build a [`ModelResponse`][pydantic_ai.messages.ModelResponse] from the data received from the stream so far."""
  return ModelResponse(
    parts=self._parts_manager.get_parts(), model_name=self._model_name, timestamp=self.timestamp()
  )

```
  
---|---  
####  model_name
```
model_name() -> str[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

Get the model name of the response.
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`
```
240
241
242
```
| ```
def model_name(self) -> str:
"""Get the model name of the response."""
  return self._model_name

```
  
---|---  
####  usage
```
usage() -> Usage[](https://ai.pydantic.dev/api/models/base/usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage")

```

Get the usage of the response so far. This will not be the final usage until the stream is exhausted.
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`
```
244
245
246
```
| ```
def usage(self) -> Usage:
"""Get the usage of the response so far. This will not be the final usage until the stream is exhausted."""
  return self._usage

```
  
---|---  
####  timestamp `abstractmethod`
```
timestamp() -> datetime[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/datetime.html#datetime.datetime> "datetime.datetime")

```

Get the timestamp of the response.
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`
```
248
249
250
251
```
| ```
@abstractmethod
def timestamp(self) -> datetime:
"""Get the timestamp of the response."""
  raise NotImplementedError()

```
  
---|---  
###  ALLOW_MODEL_REQUESTS `module-attribute`
```
ALLOW_MODEL_REQUESTS = True

```

Whether to allow requests to models.
This global setting allows you to disable request to most models, e.g. to make sure you don't accidentally make costly requests to a model during tests.
The testing models `TestModel`[](https://ai.pydantic.dev/api/models/base/<../test/#pydantic_ai.models.test.TestModel>) and `FunctionModel`[](https://ai.pydantic.dev/api/models/base/<../function/#pydantic_ai.models.function.FunctionModel>) are no affected by this setting.
###  check_allow_model_requests
```
check_allow_model_requests() -> None

```

Check if model requests are allowed.
If you're defining your own models that have costs or latency associated with their use, you should call this in `Model.agent_model`[](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.Model.agent_model>).
Raises:
Type | Description  
---|---  
`RuntimeError[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/exceptions.html#RuntimeError>)` |  If model requests are not allowed.  
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`
```
265
266
267
268
269
270
271
272
273
274
275
```
| ```
def check_allow_model_requests() -> None:
"""Check if model requests are allowed.
  If you're defining your own models that have costs or latency associated with their use, you should call this in
  [`Model.agent_model`][pydantic_ai.models.Model.agent_model].
  Raises:
    RuntimeError: If model requests are not allowed.
  """
  if not ALLOW_MODEL_REQUESTS:
    raise RuntimeError('Model requests are not allowed, since ALLOW_MODEL_REQUESTS is False')

```
  
---|---  
###  override_allow_model_requests
```
override_allow_model_requests(
  allow_model_requests: bool[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/functions.html#bool>),
) -> Iterator[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Iterator> "collections.abc.Iterator")[None]

```

Context manager to temporarily override `ALLOW_MODEL_REQUESTS`[](https://ai.pydantic.dev/api/models/base/<#pydantic_ai.models.ALLOW_MODEL_REQUESTS>).
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`allow_model_requests` |  `bool[](https://ai.pydantic.dev/api/models/base/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to allow model requests within the context. |  _required_  
Source code in `pydantic_ai_slim/pydantic_ai/models/__init__.py`
```
278
279
280
281
282
283
284
285
286
287
288
289
290
291
```
| ```
@contextmanager
def override_allow_model_requests(allow_model_requests: bool) -> Iterator[None]:
"""Context manager to temporarily override [`ALLOW_MODEL_REQUESTS`][pydantic_ai.models.ALLOW_MODEL_REQUESTS].
  Args:
    allow_model_requests: Whether to allow model requests within the context.
  """
  global ALLOW_MODEL_REQUESTS
  old_value = ALLOW_MODEL_REQUESTS
  ALLOW_MODEL_REQUESTS = allow_model_requests # pyright: ignore[reportConstantRedefinition]
  try:
    yield
  finally:
    ALLOW_MODEL_REQUESTS = old_value # pyright: ignore[reportConstantRedefinition]

```
  
---|---  
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_models_cohere.md
================
[ Skip to content ](https://ai.pydantic.dev/api/models/cohere/<#pydantic_aimodelscohere>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/cohere/..> "PydanticAI")
PydanticAI 
pydantic_ai.models.cohere 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/cohere/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/cohere/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/cohere/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/models/cohere/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/models/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/models/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/models/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/models/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/models/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/models/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/models/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/models/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/models/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/models/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/models/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/models/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/models/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/models/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/models/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/models/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/models/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/models/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/models/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/models/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/models/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/models/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/models/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/models/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/models/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/models/cohere/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/models/cohere/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/models/cohere/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/models/cohere/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/models/cohere/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/models/cohere/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/models/cohere/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/models/cohere/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/models/cohere/<../base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/models/cohere/<../openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/models/cohere/<../anthropic/>)
    * pydantic_ai.models.cohere  [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/models/cohere/<./>) Table of contents 
      * [ Setup  ](https://ai.pydantic.dev/api/models/cohere/<#setup>)
        * [ cohere  ](https://ai.pydantic.dev/api/models/cohere/<#pydantic_ai.models.cohere>)
        * [ NamedCohereModels  ](https://ai.pydantic.dev/api/models/cohere/<#pydantic_ai.models.cohere.NamedCohereModels>)
        * [ CohereModelSettings  ](https://ai.pydantic.dev/api/models/cohere/<#pydantic_ai.models.cohere.CohereModelSettings>)
        * [ CohereModel  ](https://ai.pydantic.dev/api/models/cohere/<#pydantic_ai.models.cohere.CohereModel>)
          * [ __init__  ](https://ai.pydantic.dev/api/models/cohere/<#pydantic_ai.models.cohere.CohereModel.__init__>)
        * [ CohereAgentModel  ](https://ai.pydantic.dev/api/models/cohere/<#pydantic_ai.models.cohere.CohereAgentModel>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/models/cohere/<../gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/models/cohere/<../vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/models/cohere/<../groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/models/cohere/<../mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/models/cohere/<../test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/models/cohere/<../function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/models/cohere/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/models/cohere/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/models/cohere/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/models/cohere/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/models/cohere/pydantic_graph/exceptions/>)


Table of contents 
  * [ Setup  ](https://ai.pydantic.dev/api/models/cohere/<#setup>)
    * [ cohere  ](https://ai.pydantic.dev/api/models/cohere/<#pydantic_ai.models.cohere>)
    * [ NamedCohereModels  ](https://ai.pydantic.dev/api/models/cohere/<#pydantic_ai.models.cohere.NamedCohereModels>)
    * [ CohereModelSettings  ](https://ai.pydantic.dev/api/models/cohere/<#pydantic_ai.models.cohere.CohereModelSettings>)
    * [ CohereModel  ](https://ai.pydantic.dev/api/models/cohere/<#pydantic_ai.models.cohere.CohereModel>)
      * [ __init__  ](https://ai.pydantic.dev/api/models/cohere/<#pydantic_ai.models.cohere.CohereModel.__init__>)
    * [ CohereAgentModel  ](https://ai.pydantic.dev/api/models/cohere/<#pydantic_ai.models.cohere.CohereAgentModel>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/models/cohere/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/models/cohere/agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/models/cohere/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/models/cohere/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_ai.models.cohere`
## Setup
For details on how to set up authentication with this model, see [model configuration for Cohere](https://ai.pydantic.dev/api/models/models/#cohere>).
###  NamedCohereModels `module-attribute`
```
NamedCohereModels = Literal[](https://ai.pydantic.dev/api/models/cohere/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")[
  "c4ai-aya-expanse-32b",
  "c4ai-aya-expanse-8b",
  "command",
  "command-light",
  "command-light-nightly",
  "command-nightly",
  "command-r",
  "command-r-03-2024",
  "command-r-08-2024",
  "command-r-plus",
  "command-r-plus-04-2024",
  "command-r-plus-08-2024",
  "command-r7b-12-2024",
]

```

Latest / most popular named Cohere models.
###  CohereModelSettings
Bases: `ModelSettings[](https://ai.pydantic.dev/api/models/cohere/settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings")`
Settings used for a Cohere model request.
Source code in `pydantic_ai_slim/pydantic_ai/models/cohere.py`
```
75
76
```
| ```
class CohereModelSettings(ModelSettings):
"""Settings used for a Cohere model request."""

```
  
---|---  
###  CohereModel `dataclass`
Bases: `Model[](https://ai.pydantic.dev/api/models/cohere/<../base/#pydantic_ai.models.Model> "pydantic_ai.models.Model")`
A model that uses the Cohere API.
Internally, this uses the [Cohere Python client](https://ai.pydantic.dev/api/models/cohere/<https:/github.com/cohere-ai/cohere-python>) to interact with the API.
Apart from `__init__`, all methods are private or match those of the base class.
Source code in `pydantic_ai_slim/pydantic_ai/models/cohere.py`
```
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
```
| ```
@dataclass(init=False)
class CohereModel(Model):
"""A model that uses the Cohere API.
  Internally, this uses the [Cohere Python client](
  https://github.com/cohere-ai/cohere-python) to interact with the API.
  Apart from `__init__`, all methods are private or match those of the base class.
  """
  model_name: CohereModelName
  client: AsyncClientV2 = field(repr=False)
  def __init__(
    self,
    model_name: CohereModelName,
    *,
    api_key: str | None = None,
    cohere_client: AsyncClientV2 | None = None,
    http_client: AsyncHTTPClient | None = None,
  ):
"""Initialize an Cohere model.
    Args:
      model_name: The name of the Cohere model to use. List of model names
        available [here](https://docs.cohere.com/docs/models#command).
      api_key: The API key to use for authentication, if not provided, the
        `CO_API_KEY` environment variable will be used if available.
      cohere_client: An existing Cohere async client to use. If provided,
        `api_key` and `http_client` must be `None`.
      http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
    """
    self.model_name: CohereModelName = model_name
    if cohere_client is not None:
      assert http_client is None, 'Cannot provide both `cohere_client` and `http_client`'
      assert api_key is None, 'Cannot provide both `cohere_client` and `api_key`'
      self.client = cohere_client
    else:
      self.client = AsyncClientV2(api_key=api_key, httpx_client=http_client) # type: ignore
  async def agent_model(
    self,
    *,
    function_tools: list[ToolDefinition],
    allow_text_result: bool,
    result_tools: list[ToolDefinition],
  ) -> AgentModel:
    check_allow_model_requests()
    tools = [self._map_tool_definition(r) for r in function_tools]
    if result_tools:
      tools += [self._map_tool_definition(r) for r in result_tools]
    return CohereAgentModel(
      self.client,
      self.model_name,
      allow_text_result,
      tools,
    )
  def name(self) -> str:
    return f'cohere:{self.model_name}'
  @staticmethod
  def _map_tool_definition(f: ToolDefinition) -> ToolV2:
    return ToolV2(
      type='function',
      function=ToolV2Function(
        name=f.name,
        description=f.description,
        parameters=f.parameters_json_schema,
      ),
    )

```
  
---|---  
####  __init__
```
__init__(
  model_name: CohereModelName,
  *,
  api_key: str[](https://ai.pydantic.dev/api/models/cohere/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None,
  cohere_client: AsyncClientV2 | None = None,
  http_client: AsyncClient | None = None
)

```

Initialize an Cohere model.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`model_name` |  `CohereModelName` |  The name of the Cohere model to use. List of model names available [here](https://ai.pydantic.dev/api/models/cohere/<https:/docs.cohere.com/docs/models#command>). |  _required_  
`api_key` |  `str[](https://ai.pydantic.dev/api/models/cohere/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The API key to use for authentication, if not provided, the `CO_API_KEY` environment variable will be used if available. |  `None`  
`cohere_client` |  `AsyncClientV2 | None` |  An existing Cohere async client to use. If provided, `api_key` and `http_client` must be `None`. |  `None`  
`http_client` |  `AsyncClient | None` |  An existing `httpx.AsyncClient` to use for making HTTP requests. |  `None`  
Source code in `pydantic_ai_slim/pydantic_ai/models/cohere.py`
```
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
```
| ```
def __init__(
  self,
  model_name: CohereModelName,
  *,
  api_key: str | None = None,
  cohere_client: AsyncClientV2 | None = None,
  http_client: AsyncHTTPClient | None = None,
):
"""Initialize an Cohere model.
  Args:
    model_name: The name of the Cohere model to use. List of model names
      available [here](https://docs.cohere.com/docs/models#command).
    api_key: The API key to use for authentication, if not provided, the
      `CO_API_KEY` environment variable will be used if available.
    cohere_client: An existing Cohere async client to use. If provided,
      `api_key` and `http_client` must be `None`.
    http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
  """
  self.model_name: CohereModelName = model_name
  if cohere_client is not None:
    assert http_client is None, 'Cannot provide both `cohere_client` and `http_client`'
    assert api_key is None, 'Cannot provide both `cohere_client` and `api_key`'
    self.client = cohere_client
  else:
    self.client = AsyncClientV2(api_key=api_key, httpx_client=http_client) # type: ignore

```
  
---|---  
###  CohereAgentModel `dataclass`
Bases: `AgentModel[](https://ai.pydantic.dev/api/models/cohere/<../base/#pydantic_ai.models.AgentModel> "pydantic_ai.models.AgentModel")`
Implementation of `AgentModel` for Cohere models.
Source code in `pydantic_ai_slim/pydantic_ai/models/cohere.py`
```
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
```
| ```
@dataclass
class CohereAgentModel(AgentModel):
"""Implementation of `AgentModel` for Cohere models."""
  client: AsyncClientV2
  model_name: CohereModelName
  allow_text_result: bool
  tools: list[ToolV2]
  async def request(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> tuple[ModelResponse, result.Usage]:
    response = await self._chat(messages, cast(CohereModelSettings, model_settings or {}))
    return self._process_response(response), _map_usage(response)
  async def _chat(
    self,
    messages: list[ModelMessage],
    model_settings: CohereModelSettings,
  ) -> ChatResponse:
    cohere_messages = list(chain(*(self._map_message(m) for m in messages)))
    return await self.client.chat(
      model=self.model_name,
      messages=cohere_messages,
      tools=self.tools or OMIT,
      max_tokens=model_settings.get('max_tokens', OMIT),
      temperature=model_settings.get('temperature', OMIT),
      p=model_settings.get('top_p', OMIT),
      seed=model_settings.get('seed', OMIT),
      presence_penalty=model_settings.get('presence_penalty', OMIT),
      frequency_penalty=model_settings.get('frequency_penalty', OMIT),
    )
  def _process_response(self, response: ChatResponse) -> ModelResponse:
"""Process a non-streamed response, and prepare a message to return."""
    parts: list[ModelResponsePart] = []
    if response.message.content is not None and len(response.message.content) > 0:
      # While Cohere's API returns a list, it only does that for future proofing
      # and currently only one item is being returned.
      choice = response.message.content[0]
      parts.append(TextPart(choice.text))
    for c in response.message.tool_calls or []:
      if c.function and c.function.name and c.function.arguments:
        parts.append(
          ToolCallPart(
            tool_name=c.function.name,
            args=c.function.arguments,
            tool_call_id=c.id,
          )
        )
    return ModelResponse(parts=parts, model_name=self.model_name)
  @classmethod
  def _map_message(cls, message: ModelMessage) -> Iterable[ChatMessageV2]:
"""Just maps a `pydantic_ai.Message` to a `cohere.ChatMessageV2`."""
    if isinstance(message, ModelRequest):
      yield from cls._map_user_message(message)
    elif isinstance(message, ModelResponse):
      texts: list[str] = []
      tool_calls: list[ToolCallV2] = []
      for item in message.parts:
        if isinstance(item, TextPart):
          texts.append(item.content)
        elif isinstance(item, ToolCallPart):
          tool_calls.append(_map_tool_call(item))
        else:
          assert_never(item)
      message_param = AssistantChatMessageV2(role='assistant')
      if texts:
        message_param.content = [TextAssistantMessageContentItem(text='\n\n'.join(texts))]
      if tool_calls:
        message_param.tool_calls = tool_calls
      yield message_param
    else:
      assert_never(message)
  @classmethod
  def _map_user_message(cls, message: ModelRequest) -> Iterable[ChatMessageV2]:
    for part in message.parts:
      if isinstance(part, SystemPromptPart):
        yield SystemChatMessageV2(role='system', content=part.content)
      elif isinstance(part, UserPromptPart):
        yield UserChatMessageV2(role='user', content=part.content)
      elif isinstance(part, ToolReturnPart):
        yield ToolChatMessageV2(
          role='tool',
          tool_call_id=_guard_tool_call_id(t=part, model_source='Cohere'),
          content=part.model_response_str(),
        )
      elif isinstance(part, RetryPromptPart):
        if part.tool_name is None:
          yield UserChatMessageV2(role='user', content=part.model_response())
        else:
          yield ToolChatMessageV2(
            role='tool',
            tool_call_id=_guard_tool_call_id(t=part, model_source='Cohere'),
            content=part.model_response(),
          )
      else:
        assert_never(part)

```
  
---|---  
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_models_function.md
================
[ Skip to content ](https://ai.pydantic.dev/api/models/function/<#pydantic_aimodelsfunction>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/function/..> "PydanticAI")
PydanticAI 
pydantic_ai.models.function 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/function/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/function/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/function/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/models/function/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/models/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/models/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/models/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/models/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/models/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/models/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/models/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/models/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/models/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/models/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/models/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/models/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/models/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/models/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/models/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/models/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/models/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/models/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/models/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/models/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/models/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/models/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/models/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/models/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/models/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/models/function/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/models/function/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/models/function/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/models/function/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/models/function/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/models/function/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/models/function/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/models/function/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/models/function/<../base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/models/function/<../openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/models/function/<../anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/models/function/<../cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/models/function/<../gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/models/function/<../vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/models/function/<../groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/models/function/<../mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/models/function/<../test/>)
    * pydantic_ai.models.function  [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/models/function/<./>) Table of contents 
      * [ function  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function>)
      * [ FunctionModel  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionModel>)
        * [ __init__  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionModel.__init__>)
      * [ AgentInfo  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.AgentInfo>)
        * [ function_tools  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.AgentInfo.function_tools>)
        * [ allow_text_result  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.AgentInfo.allow_text_result>)
        * [ result_tools  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.AgentInfo.result_tools>)
        * [ model_settings  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.AgentInfo.model_settings>)
      * [ DeltaToolCall  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.DeltaToolCall>)
        * [ name  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.DeltaToolCall.name>)
        * [ json_args  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.DeltaToolCall.json_args>)
      * [ DeltaToolCalls  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.DeltaToolCalls>)
      * [ FunctionDef  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionDef>)
      * [ StreamFunctionDef  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.StreamFunctionDef>)
      * [ FunctionAgentModel  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionAgentModel>)
      * [ FunctionStreamedResponse  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionStreamedResponse>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/models/function/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/models/function/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/models/function/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/models/function/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/models/function/pydantic_graph/exceptions/>)


Table of contents 
  * [ function  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function>)
  * [ FunctionModel  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionModel>)
    * [ __init__  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionModel.__init__>)
  * [ AgentInfo  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.AgentInfo>)
    * [ function_tools  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.AgentInfo.function_tools>)
    * [ allow_text_result  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.AgentInfo.allow_text_result>)
    * [ result_tools  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.AgentInfo.result_tools>)
    * [ model_settings  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.AgentInfo.model_settings>)
  * [ DeltaToolCall  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.DeltaToolCall>)
    * [ name  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.DeltaToolCall.name>)
    * [ json_args  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.DeltaToolCall.json_args>)
  * [ DeltaToolCalls  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.DeltaToolCalls>)
  * [ FunctionDef  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionDef>)
  * [ StreamFunctionDef  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.StreamFunctionDef>)
  * [ FunctionAgentModel  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionAgentModel>)
  * [ FunctionStreamedResponse  ](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionStreamedResponse>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/models/function/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/models/function/agent/>)


# `pydantic_ai.models.function`
A model controlled by a local function.
`FunctionModel`[](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionModel>) is similar to `TestModel`[](https://ai.pydantic.dev/api/models/function/<../test/>), but allows greater control over the model's behavior.
Its primary use case is for more advanced unit testing than is possible with `TestModel`.
Here's a minimal example:
function_model_usage.py```
from pydantic_ai import Agent
from pydantic_ai.messages import ModelMessage, ModelResponse, TextPart
from pydantic_ai.models.function import FunctionModel, AgentInfo
my_agent = Agent('openai:gpt-4o')

async def model_function(
  messages: list[ModelMessage], info: AgentInfo
) -> ModelResponse:
  print(messages)
"""
  [
    ModelRequest(
      parts=[
        UserPromptPart(
          content='Testing my agent...',
          timestamp=datetime.datetime(...),
          part_kind='user-prompt',
        )
      ],
      kind='request',
    )
  ]
  """
  print(info)
"""
  AgentInfo(
    function_tools=[], allow_text_result=True, result_tools=[], model_settings=None
  )
  """
  return ModelResponse(parts=[TextPart('hello world')])

async def test_my_agent():
"""Unit test for my_agent, to be run by pytest."""
  with my_agent.override(model=FunctionModel(model_function)):
    result = await my_agent.run('Testing my agent...')
    assert result.data == 'hello world'

```

See [Unit testing with `FunctionModel`](https://ai.pydantic.dev/api/models/testing-evals/#unit-testing-with-functionmodel>) for detailed documentation.
###  FunctionModel `dataclass`
Bases: `Model[](https://ai.pydantic.dev/api/models/function/<../base/#pydantic_ai.models.Model> "pydantic_ai.models.Model")`
A model controlled by a local function.
Apart from `__init__`, all methods are private or match those of the base class.
Source code in `pydantic_ai_slim/pydantic_ai/models/function.py`
```
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
```
| ```
@dataclass(init=False)
class FunctionModel(Model):
"""A model controlled by a local function.
  Apart from `__init__`, all methods are private or match those of the base class.
  """
  function: FunctionDef | None = None
  stream_function: StreamFunctionDef | None = None
  @overload
  def __init__(self, function: FunctionDef) -> None: ...
  @overload
  def __init__(self, *, stream_function: StreamFunctionDef) -> None: ...
  @overload
  def __init__(self, function: FunctionDef, *, stream_function: StreamFunctionDef) -> None: ...
  def __init__(self, function: FunctionDef | None = None, *, stream_function: StreamFunctionDef | None = None):
"""Initialize a `FunctionModel`.
    Either `function` or `stream_function` must be provided, providing both is allowed.
    Args:
      function: The function to call for non-streamed requests.
      stream_function: The function to call for streamed requests.
    """
    if function is None and stream_function is None:
      raise TypeError('Either `function` or `stream_function` must be provided')
    self.function = function
    self.stream_function = stream_function
  async def agent_model(
    self,
    *,
    function_tools: list[ToolDefinition],
    allow_text_result: bool,
    result_tools: list[ToolDefinition],
  ) -> AgentModel:
    return FunctionAgentModel(
      self.function,
      self.stream_function,
      AgentInfo(function_tools, allow_text_result, result_tools, None),
    )
  def name(self) -> str:
    function_name = self.function.__name__ if self.function is not None else ''
    stream_function_name = self.stream_function.__name__ if self.stream_function is not None else ''
    return f'function:{function_name}:{stream_function_name}'

```
  
---|---  
####  __init__
```
__init__(function: FunctionDef[](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionDef> "pydantic_ai.models.function.FunctionDef")) -> None

```

```
__init__(*, stream_function: StreamFunctionDef[](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.StreamFunctionDef> "pydantic_ai.models.function.StreamFunctionDef")) -> None

```

```
__init__(
  function: FunctionDef[](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionDef> "pydantic_ai.models.function.FunctionDef"),
  *,
  stream_function: StreamFunctionDef[](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.StreamFunctionDef> "pydantic_ai.models.function.StreamFunctionDef")
) -> None

```

```
__init__(
  function: FunctionDef[](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionDef> "pydantic_ai.models.function.FunctionDef") | None = None,
  *,
  stream_function: StreamFunctionDef[](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.StreamFunctionDef> "pydantic_ai.models.function.StreamFunctionDef") | None = None
)

```

Initialize a `FunctionModel`.
Either `function` or `stream_function` must be provided, providing both is allowed.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`function` |  `FunctionDef[](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionDef> "pydantic_ai.models.function.FunctionDef") | None` |  The function to call for non-streamed requests. |  `None`  
`stream_function` |  `StreamFunctionDef[](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.StreamFunctionDef> "pydantic_ai.models.function.StreamFunctionDef") | None` |  The function to call for streamed requests. |  `None`  
Source code in `pydantic_ai_slim/pydantic_ai/models/function.py`
```
52
53
54
55
56
57
58
59
60
61
62
63
64
```
| ```
def __init__(self, function: FunctionDef | None = None, *, stream_function: StreamFunctionDef | None = None):
"""Initialize a `FunctionModel`.
  Either `function` or `stream_function` must be provided, providing both is allowed.
  Args:
    function: The function to call for non-streamed requests.
    stream_function: The function to call for streamed requests.
  """
  if function is None and stream_function is None:
    raise TypeError('Either `function` or `stream_function` must be provided')
  self.function = function
  self.stream_function = stream_function

```
  
---|---  
###  AgentInfo `dataclass`
Information about an agent.
This is passed as the second to functions used within `FunctionModel`[](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionModel>).
Source code in `pydantic_ai_slim/pydantic_ai/models/function.py`
```
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
```
| ```
@dataclass(frozen=True)
class AgentInfo:
"""Information about an agent.
  This is passed as the second to functions used within [`FunctionModel`][pydantic_ai.models.function.FunctionModel].
  """
  function_tools: list[ToolDefinition]
"""The function tools available on this agent.
  These are the tools registered via the [`tool`][pydantic_ai.Agent.tool] and
  [`tool_plain`][pydantic_ai.Agent.tool_plain] decorators.
  """
  allow_text_result: bool
"""Whether a plain text result is allowed."""
  result_tools: list[ToolDefinition]
"""The tools that can called as the final result of the run."""
  model_settings: ModelSettings | None
"""The model settings passed to the run call."""

```
  
---|---  
####  function_tools `instance-attribute`
```
function_tools: list[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/stdtypes.html#list>)[ToolDefinition[](https://ai.pydantic.dev/api/models/function/tools/#pydantic_ai.tools.ToolDefinition> "pydantic_ai.tools.ToolDefinition")]

```

The function tools available on this agent.
These are the tools registered via the `tool`[](https://ai.pydantic.dev/api/models/function/agent/#pydantic_ai.agent.Agent.tool>) and `tool_plain`[](https://ai.pydantic.dev/api/models/function/agent/#pydantic_ai.agent.Agent.tool_plain>) decorators.
####  allow_text_result `instance-attribute`
```
allow_text_result: bool[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/functions.html#bool>)

```

Whether a plain text result is allowed.
####  result_tools `instance-attribute`
```
result_tools: list[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/stdtypes.html#list>)[ToolDefinition[](https://ai.pydantic.dev/api/models/function/tools/#pydantic_ai.tools.ToolDefinition> "pydantic_ai.tools.ToolDefinition")]

```

The tools that can called as the final result of the run.
####  model_settings `instance-attribute`
```
model_settings: ModelSettings[](https://ai.pydantic.dev/api/models/function/settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None

```

The model settings passed to the run call.
###  DeltaToolCall `dataclass`
Incremental change to a tool call.
Used to describe a chunk when streaming structured responses.
Source code in `pydantic_ai_slim/pydantic_ai/models/function.py`
```
106
107
108
109
110
111
112
113
114
115
116
```
| ```
@dataclass
class DeltaToolCall:
"""Incremental change to a tool call.
  Used to describe a chunk when streaming structured responses.
  """
  name: str | None = None
"""Incremental change to the name of the tool."""
  json_args: str | None = None
"""Incremental change to the arguments as JSON"""

```
  
---|---  
####  name `class-attribute` `instance-attribute`
```
name: str[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None

```

Incremental change to the name of the tool.
####  json_args `class-attribute` `instance-attribute`
```
json_args: str[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None

```

Incremental change to the arguments as JSON
###  DeltaToolCalls `module-attribute`
```
DeltaToolCalls: TypeAlias[](https://ai.pydantic.dev/api/models/function/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.TypeAlias> "typing_extensions.TypeAlias") = dict[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/stdtypes.html#dict>)[int[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/functions.html#int>), DeltaToolCall[](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.DeltaToolCall> "pydantic_ai.models.function.DeltaToolCall")]

```

A mapping of tool call IDs to incremental changes.
###  FunctionDef `module-attribute`
```
FunctionDef: TypeAlias[](https://ai.pydantic.dev/api/models/function/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.TypeAlias> "typing_extensions.TypeAlias") = Callable[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[
  [list[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/models/function/messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")], AgentInfo[](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.AgentInfo> "pydantic_ai.models.function.AgentInfo")],
  Union[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/typing.html#typing.Union> "typing.Union")[ModelResponse[](https://ai.pydantic.dev/api/models/function/messages/#pydantic_ai.messages.ModelResponse> "pydantic_ai.messages.ModelResponse"), Awaitable[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Awaitable> "collections.abc.Awaitable")[ModelResponse[](https://ai.pydantic.dev/api/models/function/messages/#pydantic_ai.messages.ModelResponse> "pydantic_ai.messages.ModelResponse")]],
]

```

A function used to generate a non-streamed response.
###  StreamFunctionDef `module-attribute`
```
StreamFunctionDef: TypeAlias[](https://ai.pydantic.dev/api/models/function/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.TypeAlias> "typing_extensions.TypeAlias") = Callable[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[
  [list[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/models/function/messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")], AgentInfo[](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.AgentInfo> "pydantic_ai.models.function.AgentInfo")],
  AsyncIterator[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.AsyncIterator> "collections.abc.AsyncIterator")[Union[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/typing.html#typing.Union> "typing.Union")[str[](https://ai.pydantic.dev/api/models/function/<https:/docs.python.org/3/library/stdtypes.html#str>), DeltaToolCalls[](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.DeltaToolCalls> "pydantic_ai.models.function.DeltaToolCalls")]],
]

```

A function used to generate a streamed response.
While this is defined as having return type of `AsyncIterator[Union[str, DeltaToolCalls]]`, it should really be considered as `Union[AsyncIterator[str], AsyncIterator[DeltaToolCalls]`,
E.g. you need to yield all text or all `DeltaToolCalls`, not mix them.
###  FunctionAgentModel `dataclass`
Bases: `AgentModel[](https://ai.pydantic.dev/api/models/function/<../base/#pydantic_ai.models.AgentModel> "pydantic_ai.models.AgentModel")`
Implementation of `AgentModel` for [FunctionModel](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionModel>).
Source code in `pydantic_ai_slim/pydantic_ai/models/function.py`
```
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
```
| ```
@dataclass
class FunctionAgentModel(AgentModel):
"""Implementation of `AgentModel` for [FunctionModel][pydantic_ai.models.function.FunctionModel]."""
  function: FunctionDef | None
  stream_function: StreamFunctionDef | None
  agent_info: AgentInfo
  async def request(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> tuple[ModelResponse, usage.Usage]:
    agent_info = replace(self.agent_info, model_settings=model_settings)
    assert self.function is not None, 'FunctionModel must receive a `function` to support non-streamed requests'
    model_name = f'function:{self.function.__name__}'
    if inspect.iscoroutinefunction(self.function):
      response = await self.function(messages, agent_info)
    else:
      response_ = await _utils.run_in_executor(self.function, messages, agent_info)
      assert isinstance(response_, ModelResponse), response_
      response = response_
    response.model_name = model_name
    # TODO is `messages` right here? Should it just be new messages?
    return response, _estimate_usage(chain(messages, [response]))
  @asynccontextmanager
  async def request_stream(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> AsyncIterator[StreamedResponse]:
    assert (
      self.stream_function is not None
    ), 'FunctionModel must receive a `stream_function` to support streamed requests'
    model_name = f'function:{self.stream_function.__name__}'
    response_stream = PeekableAsyncStream(self.stream_function(messages, self.agent_info))
    first = await response_stream.peek()
    if isinstance(first, _utils.Unset):
      raise ValueError('Stream function must return at least one item')
    yield FunctionStreamedResponse(_model_name=model_name, _iter=response_stream)

```
  
---|---  
###  FunctionStreamedResponse `dataclass`
Bases: `StreamedResponse[](https://ai.pydantic.dev/api/models/function/<../base/#pydantic_ai.models.StreamedResponse> "pydantic_ai.models.StreamedResponse")`
Implementation of `StreamedResponse` for [FunctionModel](https://ai.pydantic.dev/api/models/function/<#pydantic_ai.models.function.FunctionModel>).
Source code in `pydantic_ai_slim/pydantic_ai/models/function.py`
```
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
```
| ```
@dataclass
class FunctionStreamedResponse(StreamedResponse):
"""Implementation of `StreamedResponse` for [FunctionModel][pydantic_ai.models.function.FunctionModel]."""
  _iter: AsyncIterator[str | DeltaToolCalls]
  _timestamp: datetime = field(default_factory=_utils.now_utc)
  def __post_init__(self):
    self._usage += _estimate_usage([])
  async def _get_event_iterator(self) -> AsyncIterator[ModelResponseStreamEvent]:
    async for item in self._iter:
      if isinstance(item, str):
        response_tokens = _estimate_string_tokens(item)
        self._usage += usage.Usage(response_tokens=response_tokens, total_tokens=response_tokens)
        yield self._parts_manager.handle_text_delta(vendor_part_id='content', content=item)
      else:
        delta_tool_calls = item
        for dtc_index, delta_tool_call in delta_tool_calls.items():
          if delta_tool_call.json_args:
            response_tokens = _estimate_string_tokens(delta_tool_call.json_args)
            self._usage += usage.Usage(response_tokens=response_tokens, total_tokens=response_tokens)
          maybe_event = self._parts_manager.handle_tool_call_delta(
            vendor_part_id=dtc_index,
            tool_name=delta_tool_call.name,
            args=delta_tool_call.json_args,
            tool_call_id=None,
          )
          if maybe_event is not None:
            yield maybe_event
  def timestamp(self) -> datetime:
    return self._timestamp

```
  
---|---  
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_models_gemini.md
================
[ Skip to content ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_aimodelsgemini>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/gemini/..> "PydanticAI")
PydanticAI 
pydantic_ai.models.gemini 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/gemini/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/gemini/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/gemini/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/models/gemini/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/models/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/models/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/models/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/models/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/models/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/models/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/models/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/models/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/models/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/models/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/models/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/models/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/models/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/models/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/models/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/models/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/models/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/models/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/models/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/models/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/models/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/models/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/models/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/models/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/models/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/models/gemini/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/models/gemini/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/models/gemini/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/models/gemini/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/models/gemini/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/models/gemini/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/models/gemini/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/models/gemini/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/models/gemini/<../base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/models/gemini/<../openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/models/gemini/<../anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/models/gemini/<../cohere/>)
    * pydantic_ai.models.gemini  [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/models/gemini/<./>) Table of contents 
      * [ Setup  ](https://ai.pydantic.dev/api/models/gemini/<#setup>)
        * [ gemini  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini>)
        * [ GeminiModelName  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.GeminiModelName>)
        * [ GeminiModelSettings  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.GeminiModelSettings>)
        * [ GeminiModel  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.GeminiModel>)
          * [ __init__  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.GeminiModel.__init__>)
        * [ AuthProtocol  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.AuthProtocol>)
        * [ ApiKeyAuth  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.ApiKeyAuth>)
        * [ GeminiAgentModel  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.GeminiAgentModel>)
        * [ GeminiStreamedResponse  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.GeminiStreamedResponse>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/models/gemini/<../vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/models/gemini/<../groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/models/gemini/<../mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/models/gemini/<../test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/models/gemini/<../function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/models/gemini/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/models/gemini/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/models/gemini/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/models/gemini/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/models/gemini/pydantic_graph/exceptions/>)


Table of contents 
  * [ Setup  ](https://ai.pydantic.dev/api/models/gemini/<#setup>)
    * [ gemini  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini>)
    * [ GeminiModelName  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.GeminiModelName>)
    * [ GeminiModelSettings  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.GeminiModelSettings>)
    * [ GeminiModel  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.GeminiModel>)
      * [ __init__  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.GeminiModel.__init__>)
    * [ AuthProtocol  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.AuthProtocol>)
    * [ ApiKeyAuth  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.ApiKeyAuth>)
    * [ GeminiAgentModel  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.GeminiAgentModel>)
    * [ GeminiStreamedResponse  ](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.GeminiStreamedResponse>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/models/gemini/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/models/gemini/agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/models/gemini/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/models/gemini/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_ai.models.gemini`
Custom interface to the `generativelanguage.googleapis.com` API using [HTTPX](https://ai.pydantic.dev/api/models/gemini/<https:/www.python-httpx.org/>) and [Pydantic](https://ai.pydantic.dev/api/models/gemini/<https:/docs.pydantic.dev/latest/>).
The Google SDK for interacting with the `generativelanguage.googleapis.com` API `google-generativeai`[](https://ai.pydantic.dev/api/models/gemini/<https:/ai.google.dev/gemini-api/docs/quickstart?lang=python>) reads like it was written by a Java developer who thought they knew everything about OOP, spent 30 minutes trying to learn Python, gave up and decided to build the library to prove how horrible Python is. It also doesn't use httpx for HTTP requests, and tries to implement tool calling itself, but doesn't use Pydantic or equivalent for validation.
We therefore implement support for the API directly.
Despite these shortcomings, the Gemini model is actually quite powerful and very fast.
## Setup
For details on how to set up authentication with this model, see [model configuration for Gemini](https://ai.pydantic.dev/api/models/models/#gemini>).
###  GeminiModelName `module-attribute`
```
GeminiModelName = Literal[](https://ai.pydantic.dev/api/models/gemini/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")[
  "gemini-1.5-flash",
  "gemini-1.5-flash-8b",
  "gemini-1.5-pro",
  "gemini-1.0-pro",
  "gemini-2.0-flash-exp",
]

```

Named Gemini models.
See [the Gemini API docs](https://ai.pydantic.dev/api/models/gemini/<https:/ai.google.dev/gemini-api/docs/models/gemini#model-variations>) for a full list.
###  GeminiModelSettings
Bases: `ModelSettings[](https://ai.pydantic.dev/api/models/gemini/settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings")`
Settings used for a Gemini model request.
Source code in `pydantic_ai_slim/pydantic_ai/models/gemini.py`
```
51
52
```
| ```
class GeminiModelSettings(ModelSettings):
"""Settings used for a Gemini model request."""

```
  
---|---  
###  GeminiModel `dataclass`
Bases: `Model[](https://ai.pydantic.dev/api/models/gemini/<../base/#pydantic_ai.models.Model> "pydantic_ai.models.Model")`
A model that uses Gemini via `generativelanguage.googleapis.com` API.
This is implemented from scratch rather than using a dedicated SDK, good API documentation is available [here](https://ai.pydantic.dev/api/models/gemini/<https:/ai.google.dev/api>).
Apart from `__init__`, all methods are private or match those of the base class.
Source code in `pydantic_ai_slim/pydantic_ai/models/gemini.py`
```
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
```
| ```
@dataclass(init=False)
class GeminiModel(Model):
"""A model that uses Gemini via `generativelanguage.googleapis.com` API.
  This is implemented from scratch rather than using a dedicated SDK, good API documentation is
  available [here](https://ai.google.dev/api).
  Apart from `__init__`, all methods are private or match those of the base class.
  """
  model_name: GeminiModelName
  auth: AuthProtocol
  http_client: AsyncHTTPClient
  url: str
  def __init__(
    self,
    model_name: GeminiModelName,
    *,
    api_key: str | None = None,
    http_client: AsyncHTTPClient | None = None,
    url_template: str = 'https://generativelanguage.googleapis.com/v1beta/models/{model}:',
  ):
"""Initialize a Gemini model.
    Args:
      model_name: The name of the model to use.
      api_key: The API key to use for authentication, if not provided, the `GEMINI_API_KEY` environment variable
        will be used if available.
      http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
      url_template: The URL template to use for making requests, you shouldn't need to change this,
        docs [here](https://ai.google.dev/gemini-api/docs/quickstart?lang=rest#make-first-request),
        `model` is substituted with the model name, and `function` is added to the end of the URL.
    """
    self.model_name = model_name
    if api_key is None:
      if env_api_key := os.getenv('GEMINI_API_KEY'):
        api_key = env_api_key
      else:
        raise exceptions.UserError('API key must be provided or set in the GEMINI_API_KEY environment variable')
    self.auth = ApiKeyAuth(api_key)
    self.http_client = http_client or cached_async_http_client()
    self.url = url_template.format(model=model_name)
  async def agent_model(
    self,
    *,
    function_tools: list[ToolDefinition],
    allow_text_result: bool,
    result_tools: list[ToolDefinition],
  ) -> GeminiAgentModel:
    check_allow_model_requests()
    return GeminiAgentModel(
      http_client=self.http_client,
      model_name=self.model_name,
      auth=self.auth,
      url=self.url,
      function_tools=function_tools,
      allow_text_result=allow_text_result,
      result_tools=result_tools,
    )
  def name(self) -> str:
    return f'google-gla:{self.model_name}'

```
  
---|---  
####  __init__
```
__init__(
  model_name: GeminiModelName[](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.GeminiModelName> "pydantic_ai.models.gemini.GeminiModelName"),
  *,
  api_key: str[](https://ai.pydantic.dev/api/models/gemini/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None,
  http_client: AsyncClient | None = None,
  url_template: str[](https://ai.pydantic.dev/api/models/gemini/<https:/docs.python.org/3/library/stdtypes.html#str>) = "https://generativelanguage.googleapis.com/v1beta/models/{model}:"
)

```

Initialize a Gemini model.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`model_name` |  `GeminiModelName[](https://ai.pydantic.dev/api/models/gemini/<#pydantic_ai.models.gemini.GeminiModelName> "pydantic_ai.models.gemini.GeminiModelName")` |  The name of the model to use. |  _required_  
`api_key` |  `str[](https://ai.pydantic.dev/api/models/gemini/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The API key to use for authentication, if not provided, the `GEMINI_API_KEY` environment variable will be used if available. |  `None`  
`http_client` |  `AsyncClient | None` |  An existing `httpx.AsyncClient` to use for making HTTP requests. |  `None`  
`url_template` |  `str[](https://ai.pydantic.dev/api/models/gemini/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  The URL template to use for making requests, you shouldn't need to change this, docs [here](https://ai.pydantic.dev/api/models/gemini/<https:/ai.google.dev/gemini-api/docs/quickstart?lang=rest#make-first-request>), `model` is substituted with the model name, and `function` is added to the end of the URL. |  `'https://generativelanguage.googleapis.com/v1beta/models/{model}:'`  
Source code in `pydantic_ai_slim/pydantic_ai/models/gemini.py`
```
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
```
| ```
def __init__(
  self,
  model_name: GeminiModelName,
  *,
  api_key: str | None = None,
  http_client: AsyncHTTPClient | None = None,
  url_template: str = 'https://generativelanguage.googleapis.com/v1beta/models/{model}:',
):
"""Initialize a Gemini model.
  Args:
    model_name: The name of the model to use.
    api_key: The API key to use for authentication, if not provided, the `GEMINI_API_KEY` environment variable
      will be used if available.
    http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
    url_template: The URL template to use for making requests, you shouldn't need to change this,
      docs [here](https://ai.google.dev/gemini-api/docs/quickstart?lang=rest#make-first-request),
      `model` is substituted with the model name, and `function` is added to the end of the URL.
  """
  self.model_name = model_name
  if api_key is None:
    if env_api_key := os.getenv('GEMINI_API_KEY'):
      api_key = env_api_key
    else:
      raise exceptions.UserError('API key must be provided or set in the GEMINI_API_KEY environment variable')
  self.auth = ApiKeyAuth(api_key)
  self.http_client = http_client or cached_async_http_client()
  self.url = url_template.format(model=model_name)

```
  
---|---  
###  AuthProtocol
Bases: `Protocol[](https://ai.pydantic.dev/api/models/gemini/<https:/docs.python.org/3/library/typing.html#typing.Protocol> "typing.Protocol")`
Abstract definition for Gemini authentication.
Source code in `pydantic_ai_slim/pydantic_ai/models/gemini.py`
```
123
124
125
126
```
| ```
class AuthProtocol(Protocol):
"""Abstract definition for Gemini authentication."""
  async def headers(self) -> dict[str, str]: ...

```
  
---|---  
###  ApiKeyAuth `dataclass`
Authentication using an API key for the `X-Goog-Api-Key` header.
Source code in `pydantic_ai_slim/pydantic_ai/models/gemini.py`
```
129
130
131
132
133
134
135
136
137
```
| ```
@dataclass
class ApiKeyAuth:
"""Authentication using an API key for the `X-Goog-Api-Key` header."""
  api_key: str
  async def headers(self) -> dict[str, str]:
    # https://cloud.google.com/docs/authentication/api-keys-use#using-with-rest
    return {'X-Goog-Api-Key': self.api_key}

```
  
---|---  
###  GeminiAgentModel `dataclass`
Bases: `AgentModel[](https://ai.pydantic.dev/api/models/gemini/<../base/#pydantic_ai.models.AgentModel> "pydantic_ai.models.AgentModel")`
Implementation of `AgentModel` for Gemini models.
Source code in `pydantic_ai_slim/pydantic_ai/models/gemini.py`
```
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
```
| ```
@dataclass(init=False)
class GeminiAgentModel(AgentModel):
"""Implementation of `AgentModel` for Gemini models."""
  http_client: AsyncHTTPClient
  model_name: GeminiModelName
  auth: AuthProtocol
  tools: _GeminiTools | None
  tool_config: _GeminiToolConfig | None
  url: str
  def __init__(
    self,
    http_client: AsyncHTTPClient,
    model_name: GeminiModelName,
    auth: AuthProtocol,
    url: str,
    function_tools: list[ToolDefinition],
    allow_text_result: bool,
    result_tools: list[ToolDefinition],
  ):
    tools = [_function_from_abstract_tool(t) for t in function_tools]
    if result_tools:
      tools += [_function_from_abstract_tool(t) for t in result_tools]
    if allow_text_result:
      tool_config = None
    else:
      tool_config = _tool_config([t['name'] for t in tools])
    self.http_client = http_client
    self.model_name = model_name
    self.auth = auth
    self.tools = _GeminiTools(function_declarations=tools) if tools else None
    self.tool_config = tool_config
    self.url = url
  async def request(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> tuple[ModelResponse, usage.Usage]:
    async with self._make_request(
      messages, False, cast(GeminiModelSettings, model_settings or {})
    ) as http_response:
      response = _gemini_response_ta.validate_json(await http_response.aread())
    return self._process_response(response), _metadata_as_usage(response)
  @asynccontextmanager
  async def request_stream(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> AsyncIterator[StreamedResponse]:
    async with self._make_request(messages, True, cast(GeminiModelSettings, model_settings or {})) as http_response:
      yield await self._process_streamed_response(http_response)
  @asynccontextmanager
  async def _make_request(
    self, messages: list[ModelMessage], streamed: bool, model_settings: GeminiModelSettings
  ) -> AsyncIterator[HTTPResponse]:
    sys_prompt_parts, contents = self._message_to_gemini_content(messages)
    request_data = _GeminiRequest(contents=contents)
    if sys_prompt_parts:
      request_data['system_instruction'] = _GeminiTextContent(role='user', parts=sys_prompt_parts)
    if self.tools is not None:
      request_data['tools'] = self.tools
    if self.tool_config is not None:
      request_data['tool_config'] = self.tool_config
    generation_config: _GeminiGenerationConfig = {}
    if model_settings:
      if (max_tokens := model_settings.get('max_tokens')) is not None:
        generation_config['max_output_tokens'] = max_tokens
      if (temperature := model_settings.get('temperature')) is not None:
        generation_config['temperature'] = temperature
      if (top_p := model_settings.get('top_p')) is not None:
        generation_config['top_p'] = top_p
      if (presence_penalty := model_settings.get('presence_penalty')) is not None:
        generation_config['presence_penalty'] = presence_penalty
      if (frequency_penalty := model_settings.get('frequency_penalty')) is not None:
        generation_config['frequency_penalty'] = frequency_penalty
    if generation_config:
      request_data['generation_config'] = generation_config
    url = self.url + ('streamGenerateContent' if streamed else 'generateContent')
    headers = {
      'Content-Type': 'application/json',
      'User-Agent': get_user_agent(),
      **await self.auth.headers(),
    }
    request_json = _gemini_request_ta.dump_json(request_data, by_alias=True)
    async with self.http_client.stream(
      'POST',
      url,
      content=request_json,
      headers=headers,
      timeout=model_settings.get('timeout', USE_CLIENT_DEFAULT),
    ) as r:
      if r.status_code != 200:
        await r.aread()
        raise exceptions.UnexpectedModelBehavior(f'Unexpected response from gemini {r.status_code}', r.text)
      yield r
  def _process_response(self, response: _GeminiResponse) -> ModelResponse:
    if len(response['candidates']) != 1:
      raise UnexpectedModelBehavior('Expected exactly one candidate in Gemini response')
    parts = response['candidates'][0]['content']['parts']
    return _process_response_from_parts(parts, model_name=self.model_name)
  async def _process_streamed_response(self, http_response: HTTPResponse) -> StreamedResponse:
"""Process a streamed response, and prepare a streaming response to return."""
    aiter_bytes = http_response.aiter_bytes()
    start_response: _GeminiResponse | None = None
    content = bytearray()
    async for chunk in aiter_bytes:
      content.extend(chunk)
      responses = _gemini_streamed_response_ta.validate_json(
        content,
        experimental_allow_partial='trailing-strings',
      )
      if responses:
        last = responses[-1]
        if last['candidates'] and last['candidates'][0]['content']['parts']:
          start_response = last
          break
    if start_response is None:
      raise UnexpectedModelBehavior('Streamed response ended without content or tool calls')
    return GeminiStreamedResponse(_model_name=self.model_name, _content=content, _stream=aiter_bytes)
  @classmethod
  def _message_to_gemini_content(
    cls, messages: list[ModelMessage]
  ) -> tuple[list[_GeminiTextPart], list[_GeminiContent]]:
    sys_prompt_parts: list[_GeminiTextPart] = []
    contents: list[_GeminiContent] = []
    for m in messages:
      if isinstance(m, ModelRequest):
        message_parts: list[_GeminiPartUnion] = []
        for part in m.parts:
          if isinstance(part, SystemPromptPart):
            sys_prompt_parts.append(_GeminiTextPart(text=part.content))
          elif isinstance(part, UserPromptPart):
            message_parts.append(_GeminiTextPart(text=part.content))
          elif isinstance(part, ToolReturnPart):
            message_parts.append(_response_part_from_response(part.tool_name, part.model_response_object()))
          elif isinstance(part, RetryPromptPart):
            if part.tool_name is None:
              message_parts.append(_GeminiTextPart(text=part.model_response()))
            else:
              response = {'call_error': part.model_response()}
              message_parts.append(_response_part_from_response(part.tool_name, response))
          else:
            assert_never(part)
        if message_parts:
          contents.append(_GeminiContent(role='user', parts=message_parts))
      elif isinstance(m, ModelResponse):
        contents.append(_content_model_response(m))
      else:
        assert_never(m)
    return sys_prompt_parts, contents

```
  
---|---  
###  GeminiStreamedResponse `dataclass`
Bases: `StreamedResponse[](https://ai.pydantic.dev/api/models/gemini/<../base/#pydantic_ai.models.StreamedResponse> "pydantic_ai.models.StreamedResponse")`
Implementation of `StreamedResponse` for the Gemini model.
Source code in `pydantic_ai_slim/pydantic_ai/models/gemini.py`
```
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
```
| ```
@dataclass
class GeminiStreamedResponse(StreamedResponse):
"""Implementation of `StreamedResponse` for the Gemini model."""
  _content: bytearray
  _stream: AsyncIterator[bytes]
  _timestamp: datetime = field(default_factory=_utils.now_utc, init=False)
  async def _get_event_iterator(self) -> AsyncIterator[ModelResponseStreamEvent]:
    async for gemini_response in self._get_gemini_responses():
      candidate = gemini_response['candidates'][0]
      gemini_part: _GeminiPartUnion
      for gemini_part in candidate['content']['parts']:
        if 'text' in gemini_part:
          # Using vendor_part_id=None means we can produce multiple text parts if their deltas are sprinkled
          # amongst the tool call deltas
          yield self._parts_manager.handle_text_delta(vendor_part_id=None, content=gemini_part['text'])
        elif 'function_call' in gemini_part:
          # Here, we assume all function_call parts are complete and don't have deltas.
          # We do this by assigning a unique randomly generated "vendor_part_id".
          # We need to confirm whether this is actually true, but if it isn't, we can still handle it properly
          # it would just be a bit more complicated. And we'd need to confirm the intended semantics.
          maybe_event = self._parts_manager.handle_tool_call_delta(
            vendor_part_id=uuid4(),
            tool_name=gemini_part['function_call']['name'],
            args=gemini_part['function_call']['args'],
            tool_call_id=None,
          )
          if maybe_event is not None:
            yield maybe_event
        else:
          assert 'function_response' in gemini_part, f'Unexpected part: {gemini_part}'
  async def _get_gemini_responses(self) -> AsyncIterator[_GeminiResponse]:
    # This method exists to ensure we only yield completed items, so we don't need to worry about
    # partial gemini responses, which would make everything more complicated
    gemini_responses: list[_GeminiResponse] = []
    current_gemini_response_index = 0
    # Right now, there are some circumstances where we will have information that could be yielded sooner than it is
    # But changing that would make things a lot more complicated.
    async for chunk in self._stream:
      self._content.extend(chunk)
      gemini_responses = _gemini_streamed_response_ta.validate_json(
        self._content,
        experimental_allow_partial='trailing-strings',
      )
      # The idea: yield only up to the latest response, which might still be partial.
      # Note that if the latest response is complete, we could yield it immediately, but there's not a good
      # allow_partial API to determine if the last item in the list is complete.
      responses_to_yield = gemini_responses[:-1]
      for r in responses_to_yield[current_gemini_response_index:]:
        current_gemini_response_index += 1
        self._usage += _metadata_as_usage(r)
        yield r
    # Now yield the final response, which should be complete
    if gemini_responses:
      r = gemini_responses[-1]
      self._usage += _metadata_as_usage(r)
      yield r
  def timestamp(self) -> datetime:
    return self._timestamp

```
  
---|---  
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_models_groq.md
================
[ Skip to content ](https://ai.pydantic.dev/api/models/groq/<#pydantic_aimodelsgroq>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/groq/..> "PydanticAI")
PydanticAI 
pydantic_ai.models.groq 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/groq/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/groq/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/groq/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/models/groq/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/models/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/models/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/models/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/models/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/models/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/models/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/models/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/models/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/models/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/models/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/models/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/models/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/models/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/models/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/models/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/models/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/models/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/models/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/models/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/models/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/models/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/models/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/models/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/models/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/models/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/models/groq/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/models/groq/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/models/groq/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/models/groq/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/models/groq/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/models/groq/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/models/groq/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/models/groq/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/models/groq/<../base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/models/groq/<../openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/models/groq/<../anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/models/groq/<../cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/models/groq/<../gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/models/groq/<../vertexai/>)
    * pydantic_ai.models.groq  [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/models/groq/<./>) Table of contents 
      * [ Setup  ](https://ai.pydantic.dev/api/models/groq/<#setup>)
        * [ groq  ](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq>)
        * [ GroqModelName  ](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq.GroqModelName>)
        * [ GroqModelSettings  ](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq.GroqModelSettings>)
        * [ GroqModel  ](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq.GroqModel>)
          * [ __init__  ](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq.GroqModel.__init__>)
        * [ GroqAgentModel  ](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq.GroqAgentModel>)
        * [ GroqStreamedResponse  ](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq.GroqStreamedResponse>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/models/groq/<../mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/models/groq/<../test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/models/groq/<../function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/models/groq/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/models/groq/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/models/groq/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/models/groq/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/models/groq/pydantic_graph/exceptions/>)


Table of contents 
  * [ Setup  ](https://ai.pydantic.dev/api/models/groq/<#setup>)
    * [ groq  ](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq>)
    * [ GroqModelName  ](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq.GroqModelName>)
    * [ GroqModelSettings  ](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq.GroqModelSettings>)
    * [ GroqModel  ](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq.GroqModel>)
      * [ __init__  ](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq.GroqModel.__init__>)
    * [ GroqAgentModel  ](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq.GroqAgentModel>)
    * [ GroqStreamedResponse  ](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq.GroqStreamedResponse>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/models/groq/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/models/groq/agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/models/groq/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/models/groq/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_ai.models.groq`
## Setup
For details on how to set up authentication with this model, see [model configuration for Groq](https://ai.pydantic.dev/api/models/models/#groq>).
###  GroqModelName `module-attribute`
```
GroqModelName = Literal[](https://ai.pydantic.dev/api/models/groq/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")[
  "llama-3.3-70b-versatile",
  "llama-3.3-70b-specdec",
  "llama-3.1-8b-instant",
  "llama-3.2-1b-preview",
  "llama-3.2-3b-preview",
  "llama-3.2-11b-vision-preview",
  "llama-3.2-90b-vision-preview",
  "llama3-70b-8192",
  "llama3-8b-8192",
  "mixtral-8x7b-32768",
  "gemma2-9b-it",
]

```

Named Groq models.
See [the Groq docs](https://ai.pydantic.dev/api/models/groq/<https:/console.groq.com/docs/models>) for a full list.
###  GroqModelSettings
Bases: `ModelSettings[](https://ai.pydantic.dev/api/models/groq/settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings")`
Settings used for a Groq model request.
Source code in `pydantic_ai_slim/pydantic_ai/models/groq.py`
```
67
68
```
| ```
class GroqModelSettings(ModelSettings):
"""Settings used for a Groq model request."""

```
  
---|---  
###  GroqModel `dataclass`
Bases: `Model[](https://ai.pydantic.dev/api/models/groq/<../base/#pydantic_ai.models.Model> "pydantic_ai.models.Model")`
A model that uses the Groq API.
Internally, this uses the [Groq Python client](https://ai.pydantic.dev/api/models/groq/<https:/github.com/groq/groq-python>) to interact with the API.
Apart from `__init__`, all methods are private or match those of the base class.
Source code in `pydantic_ai_slim/pydantic_ai/models/groq.py`
```
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
```
| ```
@dataclass(init=False)
class GroqModel(Model):
"""A model that uses the Groq API.
  Internally, this uses the [Groq Python client](https://github.com/groq/groq-python) to interact with the API.
  Apart from `__init__`, all methods are private or match those of the base class.
  """
  model_name: GroqModelName
  client: AsyncGroq = field(repr=False)
  def __init__(
    self,
    model_name: GroqModelName,
    *,
    api_key: str | None = None,
    groq_client: AsyncGroq | None = None,
    http_client: AsyncHTTPClient | None = None,
  ):
"""Initialize a Groq model.
    Args:
      model_name: The name of the Groq model to use. List of model names available
        [here](https://console.groq.com/docs/models).
      api_key: The API key to use for authentication, if not provided, the `GROQ_API_KEY` environment variable
        will be used if available.
      groq_client: An existing
        [`AsyncGroq`](https://github.com/groq/groq-python?tab=readme-ov-file#async-usage)
        client to use, if provided, `api_key` and `http_client` must be `None`.
      http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
    """
    self.model_name = model_name
    if groq_client is not None:
      assert http_client is None, 'Cannot provide both `groq_client` and `http_client`'
      assert api_key is None, 'Cannot provide both `groq_client` and `api_key`'
      self.client = groq_client
    elif http_client is not None:
      self.client = AsyncGroq(api_key=api_key, http_client=http_client)
    else:
      self.client = AsyncGroq(api_key=api_key, http_client=cached_async_http_client())
  async def agent_model(
    self,
    *,
    function_tools: list[ToolDefinition],
    allow_text_result: bool,
    result_tools: list[ToolDefinition],
  ) -> AgentModel:
    check_allow_model_requests()
    tools = [self._map_tool_definition(r) for r in function_tools]
    if result_tools:
      tools += [self._map_tool_definition(r) for r in result_tools]
    return GroqAgentModel(
      self.client,
      self.model_name,
      allow_text_result,
      tools,
    )
  def name(self) -> str:
    return f'groq:{self.model_name}'
  @staticmethod
  def _map_tool_definition(f: ToolDefinition) -> chat.ChatCompletionToolParam:
    return {
      'type': 'function',
      'function': {
        'name': f.name,
        'description': f.description,
        'parameters': f.parameters_json_schema,
      },
    }

```
  
---|---  
####  __init__
```
__init__(
  model_name: GroqModelName[](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq.GroqModelName> "pydantic_ai.models.groq.GroqModelName"),
  *,
  api_key: str[](https://ai.pydantic.dev/api/models/groq/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None,
  groq_client: AsyncGroq | None = None,
  http_client: AsyncClient | None = None
)

```

Initialize a Groq model.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`model_name` |  `GroqModelName[](https://ai.pydantic.dev/api/models/groq/<#pydantic_ai.models.groq.GroqModelName> "pydantic_ai.models.groq.GroqModelName")` |  The name of the Groq model to use. List of model names available [here](https://ai.pydantic.dev/api/models/groq/<https:/console.groq.com/docs/models>). |  _required_  
`api_key` |  `str[](https://ai.pydantic.dev/api/models/groq/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The API key to use for authentication, if not provided, the `GROQ_API_KEY` environment variable will be used if available. |  `None`  
`groq_client` |  `AsyncGroq | None` |  An existing `AsyncGroq`[](https://ai.pydantic.dev/api/models/groq/<https:/github.com/groq/groq-python?tab=readme-ov-file#async-usage>) client to use, if provided, `api_key` and `http_client` must be `None`. |  `None`  
`http_client` |  `AsyncClient | None` |  An existing `httpx.AsyncClient` to use for making HTTP requests. |  `None`  
Source code in `pydantic_ai_slim/pydantic_ai/models/groq.py`
```
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
```
| ```
def __init__(
  self,
  model_name: GroqModelName,
  *,
  api_key: str | None = None,
  groq_client: AsyncGroq | None = None,
  http_client: AsyncHTTPClient | None = None,
):
"""Initialize a Groq model.
  Args:
    model_name: The name of the Groq model to use. List of model names available
      [here](https://console.groq.com/docs/models).
    api_key: The API key to use for authentication, if not provided, the `GROQ_API_KEY` environment variable
      will be used if available.
    groq_client: An existing
      [`AsyncGroq`](https://github.com/groq/groq-python?tab=readme-ov-file#async-usage)
      client to use, if provided, `api_key` and `http_client` must be `None`.
    http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
  """
  self.model_name = model_name
  if groq_client is not None:
    assert http_client is None, 'Cannot provide both `groq_client` and `http_client`'
    assert api_key is None, 'Cannot provide both `groq_client` and `api_key`'
    self.client = groq_client
  elif http_client is not None:
    self.client = AsyncGroq(api_key=api_key, http_client=http_client)
  else:
    self.client = AsyncGroq(api_key=api_key, http_client=cached_async_http_client())

```
  
---|---  
###  GroqAgentModel `dataclass`
Bases: `AgentModel[](https://ai.pydantic.dev/api/models/groq/<../base/#pydantic_ai.models.AgentModel> "pydantic_ai.models.AgentModel")`
Implementation of `AgentModel` for Groq models.
Source code in `pydantic_ai_slim/pydantic_ai/models/groq.py`
```
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
```
| ```
@dataclass
class GroqAgentModel(AgentModel):
"""Implementation of `AgentModel` for Groq models."""
  client: AsyncGroq
  model_name: str
  allow_text_result: bool
  tools: list[chat.ChatCompletionToolParam]
  async def request(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> tuple[ModelResponse, usage.Usage]:
    response = await self._completions_create(messages, False, cast(GroqModelSettings, model_settings or {}))
    return self._process_response(response), _map_usage(response)
  @asynccontextmanager
  async def request_stream(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> AsyncIterator[StreamedResponse]:
    response = await self._completions_create(messages, True, cast(GroqModelSettings, model_settings or {}))
    async with response:
      yield await self._process_streamed_response(response)
  @overload
  async def _completions_create(
    self, messages: list[ModelMessage], stream: Literal[True], model_settings: GroqModelSettings
  ) -> AsyncStream[ChatCompletionChunk]:
    pass
  @overload
  async def _completions_create(
    self, messages: list[ModelMessage], stream: Literal[False], model_settings: GroqModelSettings
  ) -> chat.ChatCompletion:
    pass
  async def _completions_create(
    self, messages: list[ModelMessage], stream: bool, model_settings: GroqModelSettings
  ) -> chat.ChatCompletion | AsyncStream[ChatCompletionChunk]:
    # standalone function to make it easier to override
    if not self.tools:
      tool_choice: Literal['none', 'required', 'auto'] | None = None
    elif not self.allow_text_result:
      tool_choice = 'required'
    else:
      tool_choice = 'auto'
    groq_messages = list(chain(*(self._map_message(m) for m in messages)))
    return await self.client.chat.completions.create(
      model=str(self.model_name),
      messages=groq_messages,
      n=1,
      parallel_tool_calls=model_settings.get('parallel_tool_calls', NOT_GIVEN),
      tools=self.tools or NOT_GIVEN,
      tool_choice=tool_choice or NOT_GIVEN,
      stream=stream,
      max_tokens=model_settings.get('max_tokens', NOT_GIVEN),
      temperature=model_settings.get('temperature', NOT_GIVEN),
      top_p=model_settings.get('top_p', NOT_GIVEN),
      timeout=model_settings.get('timeout', NOT_GIVEN),
      seed=model_settings.get('seed', NOT_GIVEN),
      presence_penalty=model_settings.get('presence_penalty', NOT_GIVEN),
      frequency_penalty=model_settings.get('frequency_penalty', NOT_GIVEN),
      logit_bias=model_settings.get('logit_bias', NOT_GIVEN),
    )
  def _process_response(self, response: chat.ChatCompletion) -> ModelResponse:
"""Process a non-streamed response, and prepare a message to return."""
    timestamp = datetime.fromtimestamp(response.created, tz=timezone.utc)
    choice = response.choices[0]
    items: list[ModelResponsePart] = []
    if choice.message.content is not None:
      items.append(TextPart(content=choice.message.content))
    if choice.message.tool_calls is not None:
      for c in choice.message.tool_calls:
        items.append(ToolCallPart(tool_name=c.function.name, args=c.function.arguments, tool_call_id=c.id))
    return ModelResponse(items, model_name=self.model_name, timestamp=timestamp)
  async def _process_streamed_response(self, response: AsyncStream[ChatCompletionChunk]) -> GroqStreamedResponse:
"""Process a streamed response, and prepare a streaming response to return."""
    peekable_response = _utils.PeekableAsyncStream(response)
    first_chunk = await peekable_response.peek()
    if isinstance(first_chunk, _utils.Unset):
      raise UnexpectedModelBehavior('Streamed response ended without content or tool calls')
    return GroqStreamedResponse(
      _response=peekable_response,
      _model_name=self.model_name,
      _timestamp=datetime.fromtimestamp(first_chunk.created, tz=timezone.utc),
    )
  @classmethod
  def _map_message(cls, message: ModelMessage) -> Iterable[chat.ChatCompletionMessageParam]:
"""Just maps a `pydantic_ai.Message` to a `groq.types.ChatCompletionMessageParam`."""
    if isinstance(message, ModelRequest):
      yield from cls._map_user_message(message)
    elif isinstance(message, ModelResponse):
      texts: list[str] = []
      tool_calls: list[chat.ChatCompletionMessageToolCallParam] = []
      for item in message.parts:
        if isinstance(item, TextPart):
          texts.append(item.content)
        elif isinstance(item, ToolCallPart):
          tool_calls.append(_map_tool_call(item))
        else:
          assert_never(item)
      message_param = chat.ChatCompletionAssistantMessageParam(role='assistant')
      if texts:
        # Note: model responses from this model should only have one text item, so the following
        # shouldn't merge multiple texts into one unless you switch models between runs:
        message_param['content'] = '\n\n'.join(texts)
      if tool_calls:
        message_param['tool_calls'] = tool_calls
      yield message_param
    else:
      assert_never(message)
  @classmethod
  def _map_user_message(cls, message: ModelRequest) -> Iterable[chat.ChatCompletionMessageParam]:
    for part in message.parts:
      if isinstance(part, SystemPromptPart):
        yield chat.ChatCompletionSystemMessageParam(role='system', content=part.content)
      elif isinstance(part, UserPromptPart):
        yield chat.ChatCompletionUserMessageParam(role='user', content=part.content)
      elif isinstance(part, ToolReturnPart):
        yield chat.ChatCompletionToolMessageParam(
          role='tool',
          tool_call_id=_guard_tool_call_id(t=part, model_source='Groq'),
          content=part.model_response_str(),
        )
      elif isinstance(part, RetryPromptPart):
        if part.tool_name is None:
          yield chat.ChatCompletionUserMessageParam(role='user', content=part.model_response())
        else:
          yield chat.ChatCompletionToolMessageParam(
            role='tool',
            tool_call_id=_guard_tool_call_id(t=part, model_source='Groq'),
            content=part.model_response(),
          )

```
  
---|---  
###  GroqStreamedResponse `dataclass`
Bases: `StreamedResponse[](https://ai.pydantic.dev/api/models/groq/<../base/#pydantic_ai.models.StreamedResponse> "pydantic_ai.models.StreamedResponse")`
Implementation of `StreamedResponse` for Groq models.
Source code in `pydantic_ai_slim/pydantic_ai/models/groq.py`
```
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
```
| ```
@dataclass
class GroqStreamedResponse(StreamedResponse):
"""Implementation of `StreamedResponse` for Groq models."""
  _response: AsyncIterable[ChatCompletionChunk]
  _timestamp: datetime
  async def _get_event_iterator(self) -> AsyncIterator[ModelResponseStreamEvent]:
    async for chunk in self._response:
      self._usage += _map_usage(chunk)
      try:
        choice = chunk.choices[0]
      except IndexError:
        continue
      # Handle the text part of the response
      content = choice.delta.content
      if content is not None:
        yield self._parts_manager.handle_text_delta(vendor_part_id='content', content=content)
      # Handle the tool calls
      for dtc in choice.delta.tool_calls or []:
        maybe_event = self._parts_manager.handle_tool_call_delta(
          vendor_part_id=dtc.index,
          tool_name=dtc.function and dtc.function.name,
          args=dtc.function and dtc.function.arguments,
          tool_call_id=dtc.id,
        )
        if maybe_event is not None:
          yield maybe_event
  def timestamp(self) -> datetime:
    return self._timestamp

```
  
---|---  
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_models_mistral.md
================
[ Skip to content ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_aimodelsmistral>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/mistral/..> "PydanticAI")
PydanticAI 
pydantic_ai.models.mistral 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/mistral/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/mistral/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/mistral/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/models/mistral/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/models/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/models/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/models/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/models/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/models/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/models/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/models/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/models/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/models/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/models/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/models/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/models/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/models/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/models/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/models/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/models/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/models/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/models/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/models/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/models/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/models/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/models/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/models/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/models/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/models/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/models/mistral/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/models/mistral/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/models/mistral/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/models/mistral/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/models/mistral/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/models/mistral/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/models/mistral/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/models/mistral/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/models/mistral/<../base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/models/mistral/<../openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/models/mistral/<../anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/models/mistral/<../cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/models/mistral/<../gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/models/mistral/<../vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/models/mistral/<../groq/>)
    * pydantic_ai.models.mistral  [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/models/mistral/<./>) Table of contents 
      * [ Setup  ](https://ai.pydantic.dev/api/models/mistral/<#setup>)
        * [ mistral  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral>)
        * [ NamedMistralModels  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.NamedMistralModels>)
        * [ MistralModelName  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralModelName>)
        * [ MistralModelSettings  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralModelSettings>)
        * [ MistralModel  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralModel>)
          * [ __init__  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralModel.__init__>)
          * [ agent_model  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralModel.agent_model>)
        * [ MistralAgentModel  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralAgentModel>)
          * [ request  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralAgentModel.request>)
          * [ request_stream  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralAgentModel.request_stream>)
        * [ MistralStreamedResponse  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralStreamedResponse>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/models/mistral/<../test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/models/mistral/<../function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/models/mistral/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/models/mistral/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/models/mistral/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/models/mistral/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/models/mistral/pydantic_graph/exceptions/>)


Table of contents 
  * [ Setup  ](https://ai.pydantic.dev/api/models/mistral/<#setup>)
    * [ mistral  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral>)
    * [ NamedMistralModels  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.NamedMistralModels>)
    * [ MistralModelName  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralModelName>)
    * [ MistralModelSettings  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralModelSettings>)
    * [ MistralModel  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralModel>)
      * [ __init__  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralModel.__init__>)
      * [ agent_model  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralModel.agent_model>)
    * [ MistralAgentModel  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralAgentModel>)
      * [ request  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralAgentModel.request>)
      * [ request_stream  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralAgentModel.request_stream>)
    * [ MistralStreamedResponse  ](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralStreamedResponse>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/models/mistral/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/models/mistral/agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/models/mistral/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/models/mistral/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_ai.models.mistral`
## Setup
For details on how to set up authentication with this model, see [model configuration for Mistral](https://ai.pydantic.dev/api/models/models/#mistral>).
###  NamedMistralModels `module-attribute`
```
NamedMistralModels = Literal[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")[
  "mistral-large-latest",
  "mistral-small-latest",
  "codestral-latest",
  "mistral-moderation-latest",
]

```

Latest / most popular named Mistral models.
###  MistralModelName `module-attribute`
```
MistralModelName = Union[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/typing.html#typing.Union> "typing.Union")[NamedMistralModels[](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.NamedMistralModels> "pydantic_ai.models.mistral.NamedMistralModels"), str[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/stdtypes.html#str>)]

```

Possible Mistral model names.
Since Mistral supports a variety of date-stamped models, we explicitly list the most popular models but allow any name in the type hints. Since [the Mistral docs](https://ai.pydantic.dev/api/models/mistral/<https:/docs.mistral.ai/getting-started/models/models_overview/>) for a full list.
###  MistralModelSettings
Bases: `ModelSettings[](https://ai.pydantic.dev/api/models/mistral/settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings")`
Settings used for a Mistral model request.
Source code in `pydantic_ai_slim/pydantic_ai/models/mistral.py`
```
87
88
```
| ```
class MistralModelSettings(ModelSettings):
"""Settings used for a Mistral model request."""

```
  
---|---  
###  MistralModel `dataclass`
Bases: `Model[](https://ai.pydantic.dev/api/models/mistral/<../base/#pydantic_ai.models.Model> "pydantic_ai.models.Model")`
A model that uses Mistral.
Internally, this uses the [Mistral Python client](https://ai.pydantic.dev/api/models/mistral/<https:/github.com/mistralai/client-python>) to interact with the API.
[API Documentation](https://ai.pydantic.dev/api/models/mistral/<https:/docs.mistral.ai/>)
Source code in `pydantic_ai_slim/pydantic_ai/models/mistral.py`
```
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
```
| ```
@dataclass(init=False)
class MistralModel(Model):
"""A model that uses Mistral.
  Internally, this uses the [Mistral Python client](https://github.com/mistralai/client-python) to interact with the API.
  [API Documentation](https://docs.mistral.ai/)
  """
  model_name: MistralModelName
  client: Mistral = field(repr=False)
  def __init__(
    self,
    model_name: MistralModelName,
    *,
    api_key: str | Callable[[], str | None] | None = None,
    client: Mistral | None = None,
    http_client: AsyncHTTPClient | None = None,
  ):
"""Initialize a Mistral model.
    Args:
      model_name: The name of the model to use.
      api_key: The API key to use for authentication, if unset uses `MISTRAL_API_KEY` environment variable.
      client: An existing `Mistral` client to use, if provided, `api_key` and `http_client` must be `None`.
      http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
    """
    self.model_name = model_name
    if client is not None:
      assert http_client is None, 'Cannot provide both `mistral_client` and `http_client`'
      assert api_key is None, 'Cannot provide both `mistral_client` and `api_key`'
      self.client = client
    else:
      api_key = os.getenv('MISTRAL_API_KEY') if api_key is None else api_key
      self.client = Mistral(api_key=api_key, async_client=http_client or cached_async_http_client())
  async def agent_model(
    self,
    *,
    function_tools: list[ToolDefinition],
    allow_text_result: bool,
    result_tools: list[ToolDefinition],
  ) -> AgentModel:
"""Create an agent model, this is called for each step of an agent run from Pydantic AI call."""
    check_allow_model_requests()
    return MistralAgentModel(
      self.client,
      self.model_name,
      allow_text_result,
      function_tools,
      result_tools,
    )
  def name(self) -> str:
    return f'mistral:{self.model_name}'

```
  
---|---  
####  __init__
```
__init__(
  model_name: MistralModelName[](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralModelName> "pydantic_ai.models.mistral.MistralModelName"),
  *,
  api_key: str[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/stdtypes.html#str>) | Callable[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[], str[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/stdtypes.html#str>) | None] | None = None,
  client: Mistral | None = None,
  http_client: AsyncClient | None = None
)

```

Initialize a Mistral model.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`model_name` |  `MistralModelName[](https://ai.pydantic.dev/api/models/mistral/<#pydantic_ai.models.mistral.MistralModelName> "pydantic_ai.models.mistral.MistralModelName")` |  The name of the model to use. |  _required_  
`api_key` |  `str[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/stdtypes.html#str>) | Callable[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[], str[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/stdtypes.html#str>) | None] | None` |  The API key to use for authentication, if unset uses `MISTRAL_API_KEY` environment variable. |  `None`  
`client` |  `Mistral | None` |  An existing `Mistral` client to use, if provided, `api_key` and `http_client` must be `None`. |  `None`  
`http_client` |  `AsyncClient | None` |  An existing `httpx.AsyncClient` to use for making HTTP requests. |  `None`  
Source code in `pydantic_ai_slim/pydantic_ai/models/mistral.py`
```
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
```
| ```
def __init__(
  self,
  model_name: MistralModelName,
  *,
  api_key: str | Callable[[], str | None] | None = None,
  client: Mistral | None = None,
  http_client: AsyncHTTPClient | None = None,
):
"""Initialize a Mistral model.
  Args:
    model_name: The name of the model to use.
    api_key: The API key to use for authentication, if unset uses `MISTRAL_API_KEY` environment variable.
    client: An existing `Mistral` client to use, if provided, `api_key` and `http_client` must be `None`.
    http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
  """
  self.model_name = model_name
  if client is not None:
    assert http_client is None, 'Cannot provide both `mistral_client` and `http_client`'
    assert api_key is None, 'Cannot provide both `mistral_client` and `api_key`'
    self.client = client
  else:
    api_key = os.getenv('MISTRAL_API_KEY') if api_key is None else api_key
    self.client = Mistral(api_key=api_key, async_client=http_client or cached_async_http_client())

```
  
---|---  
####  agent_model `async`
```
agent_model(
  *,
  function_tools: list[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/stdtypes.html#list>)[ToolDefinition[](https://ai.pydantic.dev/api/models/mistral/tools/#pydantic_ai.tools.ToolDefinition> "pydantic_ai.tools.ToolDefinition")],
  allow_text_result: bool[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/functions.html#bool>),
  result_tools: list[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/stdtypes.html#list>)[ToolDefinition[](https://ai.pydantic.dev/api/models/mistral/tools/#pydantic_ai.tools.ToolDefinition> "pydantic_ai.tools.ToolDefinition")]
) -> AgentModel[](https://ai.pydantic.dev/api/models/mistral/<../base/#pydantic_ai.models.AgentModel> "pydantic_ai.models.AgentModel")

```

Create an agent model, this is called for each step of an agent run from Pydantic AI call.
Source code in `pydantic_ai_slim/pydantic_ai/models/mistral.py`
```
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
```
| ```
async def agent_model(
  self,
  *,
  function_tools: list[ToolDefinition],
  allow_text_result: bool,
  result_tools: list[ToolDefinition],
) -> AgentModel:
"""Create an agent model, this is called for each step of an agent run from Pydantic AI call."""
  check_allow_model_requests()
  return MistralAgentModel(
    self.client,
    self.model_name,
    allow_text_result,
    function_tools,
    result_tools,
  )

```
  
---|---  
###  MistralAgentModel `dataclass`
Bases: `AgentModel[](https://ai.pydantic.dev/api/models/mistral/<../base/#pydantic_ai.models.AgentModel> "pydantic_ai.models.AgentModel")`
Implementation of `AgentModel` for Mistral models.
Source code in `pydantic_ai_slim/pydantic_ai/models/mistral.py`
```
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439
440
441
442
443
444
445
```
| ```
@dataclass
class MistralAgentModel(AgentModel):
"""Implementation of `AgentModel` for Mistral models."""
  client: Mistral
  model_name: MistralModelName
  allow_text_result: bool
  function_tools: list[ToolDefinition]
  result_tools: list[ToolDefinition]
  json_mode_schema_prompt: str = """Answer in JSON Object, respect the format:\n```\n{schema}\n```\n"""
  async def request(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> tuple[ModelResponse, Usage]:
"""Make a non-streaming request to the model from Pydantic AI call."""
    response = await self._completions_create(messages, cast(MistralModelSettings, model_settings or {}))
    return self._process_response(response), _map_usage(response)
  @asynccontextmanager
  async def request_stream(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> AsyncIterator[StreamedResponse]:
"""Make a streaming request to the model from Pydantic AI call."""
    response = await self._stream_completions_create(messages, cast(MistralModelSettings, model_settings or {}))
    async with response:
      yield await self._process_streamed_response(self.result_tools, response)
  async def _completions_create(
    self, messages: list[ModelMessage], model_settings: MistralModelSettings
  ) -> MistralChatCompletionResponse:
"""Make a non-streaming request to the model."""
    response = await self.client.chat.complete_async(
      model=str(self.model_name),
      messages=list(chain(*(self._map_message(m) for m in messages))),
      n=1,
      tools=self._map_function_and_result_tools_definition() or UNSET,
      tool_choice=self._get_tool_choice(),
      stream=False,
      max_tokens=model_settings.get('max_tokens', UNSET),
      temperature=model_settings.get('temperature', UNSET),
      top_p=model_settings.get('top_p', 1),
      timeout_ms=self._get_timeout_ms(model_settings.get('timeout')),
      random_seed=model_settings.get('seed', UNSET),
    )
    assert response, 'A unexpected empty response from Mistral.'
    return response
  async def _stream_completions_create(
    self,
    messages: list[ModelMessage],
    model_settings: MistralModelSettings,
  ) -> MistralEventStreamAsync[MistralCompletionEvent]:
"""Create a streaming completion request to the Mistral model."""
    response: MistralEventStreamAsync[MistralCompletionEvent] | None
    mistral_messages = list(chain(*(self._map_message(m) for m in messages)))
    if self.result_tools and self.function_tools or self.function_tools:
      # Function Calling
      response = await self.client.chat.stream_async(
        model=str(self.model_name),
        messages=mistral_messages,
        n=1,
        tools=self._map_function_and_result_tools_definition() or UNSET,
        tool_choice=self._get_tool_choice(),
        temperature=model_settings.get('temperature', UNSET),
        top_p=model_settings.get('top_p', 1),
        max_tokens=model_settings.get('max_tokens', UNSET),
        timeout_ms=self._get_timeout_ms(model_settings.get('timeout')),
        presence_penalty=model_settings.get('presence_penalty'),
        frequency_penalty=model_settings.get('frequency_penalty'),
      )
    elif self.result_tools:
      # Json Mode
      parameters_json_schemas = [tool.parameters_json_schema for tool in self.result_tools]
      user_output_format_message = self._generate_user_output_format(parameters_json_schemas)
      mistral_messages.append(user_output_format_message)
      response = await self.client.chat.stream_async(
        model=str(self.model_name),
        messages=mistral_messages,
        response_format={'type': 'json_object'},
        stream=True,
      )
    else:
      # Stream Mode
      response = await self.client.chat.stream_async(
        model=str(self.model_name),
        messages=mistral_messages,
        stream=True,
      )
    assert response, 'A unexpected empty response from Mistral.'
    return response
  def _get_tool_choice(self) -> MistralToolChoiceEnum | None:
"""Get tool choice for the model.
    - "auto": Default mode. Model decides if it uses the tool or not.
    - "any": Select any tool.
    - "none": Prevents tool use.
    - "required": Forces tool use.
    """
    if not self.function_tools and not self.result_tools:
      return None
    elif not self.allow_text_result:
      return 'required'
    else:
      return 'auto'
  def _map_function_and_result_tools_definition(self) -> list[MistralTool] | None:
"""Map function and result tools to MistralTool format.
    Returns None if both function_tools and result_tools are empty.
    """
    all_tools: list[ToolDefinition] = self.function_tools + self.result_tools
    tools = [
      MistralTool(
        function=MistralFunction(name=r.name, parameters=r.parameters_json_schema, description=r.description)
      )
      for r in all_tools
    ]
    return tools if tools else None
  def _process_response(self, response: MistralChatCompletionResponse) -> ModelResponse:
"""Process a non-streamed response, and prepare a message to return."""
    assert response.choices, 'Unexpected empty response choice.'
    if response.created:
      timestamp = datetime.fromtimestamp(response.created, tz=timezone.utc)
    else:
      timestamp = _now_utc()
    choice = response.choices[0]
    content = choice.message.content
    tool_calls = choice.message.tool_calls
    parts: list[ModelResponsePart] = []
    if text := _map_content(content):
      parts.append(TextPart(content=text))
    if isinstance(tool_calls, list):
      for tool_call in tool_calls:
        tool = _map_mistral_to_pydantic_tool_call(tool_call=tool_call)
        parts.append(tool)
    return ModelResponse(parts, model_name=self.model_name, timestamp=timestamp)
  async def _process_streamed_response(
    self,
    result_tools: list[ToolDefinition],
    response: MistralEventStreamAsync[MistralCompletionEvent],
  ) -> StreamedResponse:
"""Process a streamed response, and prepare a streaming response to return."""
    peekable_response = _utils.PeekableAsyncStream(response)
    first_chunk = await peekable_response.peek()
    if isinstance(first_chunk, _utils.Unset):
      raise UnexpectedModelBehavior('Streamed response ended without content or tool calls')
    if first_chunk.data.created:
      timestamp = datetime.fromtimestamp(first_chunk.data.created, tz=timezone.utc)
    else:
      timestamp = datetime.now(tz=timezone.utc)
    return MistralStreamedResponse(
      _response=peekable_response,
      _model_name=self.model_name,
      _timestamp=timestamp,
      _result_tools={c.name: c for c in result_tools},
    )
  @staticmethod
  def _map_to_mistral_tool_call(t: ToolCallPart) -> MistralToolCall:
"""Maps a pydantic-ai ToolCall to a MistralToolCall."""
    return MistralToolCall(
      id=t.tool_call_id,
      type='function',
      function=MistralFunctionCall(name=t.tool_name, arguments=t.args),
    )
  def _generate_user_output_format(self, schemas: list[dict[str, Any]]) -> MistralUserMessage:
"""Get a message with an example of the expected output format."""
    examples: list[dict[str, Any]] = []
    for schema in schemas:
      typed_dict_definition: dict[str, Any] = {}
      for key, value in schema.get('properties', {}).items():
        typed_dict_definition[key] = self._get_python_type(value)
      examples.append(typed_dict_definition)
    example_schema = examples[0] if len(examples) == 1 else examples
    return MistralUserMessage(content=self.json_mode_schema_prompt.format(schema=example_schema))
  @classmethod
  def _get_python_type(cls, value: dict[str, Any]) -> str:
"""Return a string representation of the Python type for a single JSON schema property.
    This function handles recursion for nested arrays/objects and `anyOf`.
    """
    # 1) Handle anyOf first, because it's a different schema structure
    if any_of := value.get('anyOf'):
      # Simplistic approach: pick the first option in anyOf
      # (In reality, you'd possibly want to merge or union types)
      return f'Optional[{cls._get_python_type(any_of[0])}]'
    # 2) If we have a top-level "type" field
    value_type = value.get('type')
    if not value_type:
      # No explicit type; fallback
      return 'Any'
    # 3) Direct simple type mapping (string, integer, float, bool, None)
    if value_type in SIMPLE_JSON_TYPE_MAPPING and value_type != 'array' and value_type != 'object':
      return SIMPLE_JSON_TYPE_MAPPING[value_type]
    # 4) Array: Recursively get the item type
    if value_type == 'array':
      items = value.get('items', {})
      return f'list[{cls._get_python_type(items)}]'
    # 5) Object: Check for additionalProperties
    if value_type == 'object':
      additional_properties = value.get('additionalProperties', {})
      additional_properties_type = additional_properties.get('type')
      if (
        additional_properties_type in SIMPLE_JSON_TYPE_MAPPING
        and additional_properties_type != 'array'
        and additional_properties_type != 'object'
      ):
        # dict[str, bool/int/float/etc...]
        return f'dict[str, {SIMPLE_JSON_TYPE_MAPPING[additional_properties_type]}]'
      elif additional_properties_type == 'array':
        array_items = additional_properties.get('items', {})
        return f'dict[str, list[{cls._get_python_type(array_items)}]]'
      elif additional_properties_type == 'object':
        # nested dictionary of unknown shape
        return 'dict[str, dict[str, Any]]'
      else:
        # If no additionalProperties type or something else, default to a generic dict
        return 'dict[str, Any]'
    # 6) Fallback
    return 'Any'
  @staticmethod
  def _get_timeout_ms(timeout: Timeout | float | None) -> int | None:
"""Convert a timeout to milliseconds."""
    if timeout is None:
      return None
    if isinstance(timeout, float):
      return int(1000 * timeout)
    raise NotImplementedError('Timeout object is not yet supported for MistralModel.')
  @classmethod
  def _map_user_message(cls, message: ModelRequest) -> Iterable[MistralMessages]:
    for part in message.parts:
      if isinstance(part, SystemPromptPart):
        yield MistralSystemMessage(content=part.content)
      elif isinstance(part, UserPromptPart):
        yield MistralUserMessage(content=part.content)
      elif isinstance(part, ToolReturnPart):
        yield MistralToolMessage(
          tool_call_id=part.tool_call_id,
          content=part.model_response_str(),
        )
      elif isinstance(part, RetryPromptPart):
        if part.tool_name is None:
          yield MistralUserMessage(content=part.model_response())
        else:
          yield MistralToolMessage(
            tool_call_id=part.tool_call_id,
            content=part.model_response(),
          )
      else:
        assert_never(part)
  @classmethod
  def _map_message(cls, message: ModelMessage) -> Iterable[MistralMessages]:
"""Just maps a `pydantic_ai.Message` to a `MistralMessage`."""
    if isinstance(message, ModelRequest):
      yield from cls._map_user_message(message)
    elif isinstance(message, ModelResponse):
      content_chunks: list[MistralContentChunk] = []
      tool_calls: list[MistralToolCall] = []
      for part in message.parts:
        if isinstance(part, TextPart):
          content_chunks.append(MistralTextChunk(text=part.content))
        elif isinstance(part, ToolCallPart):
          tool_calls.append(cls._map_to_mistral_tool_call(part))
        else:
          assert_never(part)
      yield MistralAssistantMessage(content=content_chunks, tool_calls=tool_calls)
    else:
      assert_never(message)

```
  
---|---  
####  request `async`
```
request(
  messages: list[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/models/mistral/messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")],
  model_settings: ModelSettings[](https://ai.pydantic.dev/api/models/mistral/settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None,
) -> tuple[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/stdtypes.html#tuple>)[ModelResponse[](https://ai.pydantic.dev/api/models/mistral/messages/#pydantic_ai.messages.ModelResponse> "pydantic_ai.messages.ModelResponse"), Usage[](https://ai.pydantic.dev/api/models/mistral/usage/#pydantic_ai.usage.Usage> "pydantic_ai.result.Usage")]

```

Make a non-streaming request to the model from Pydantic AI call.
Source code in `pydantic_ai_slim/pydantic_ai/models/mistral.py`
```
163
164
165
166
167
168
```
| ```
async def request(
  self, messages: list[ModelMessage], model_settings: ModelSettings | None
) -> tuple[ModelResponse, Usage]:
"""Make a non-streaming request to the model from Pydantic AI call."""
  response = await self._completions_create(messages, cast(MistralModelSettings, model_settings or {}))
  return self._process_response(response), _map_usage(response)

```
  
---|---  
####  request_stream `async`
```
request_stream(
  messages: list[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/models/mistral/messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")],
  model_settings: ModelSettings[](https://ai.pydantic.dev/api/models/mistral/settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings") | None,
) -> AsyncIterator[](https://ai.pydantic.dev/api/models/mistral/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.AsyncIterator> "collections.abc.AsyncIterator")[StreamedResponse[](https://ai.pydantic.dev/api/models/mistral/<../base/#pydantic_ai.models.StreamedResponse> "pydantic_ai.models.StreamedResponse")]

```

Make a streaming request to the model from Pydantic AI call.
Source code in `pydantic_ai_slim/pydantic_ai/models/mistral.py`
```
170
171
172
173
174
175
176
177
```
| ```
@asynccontextmanager
async def request_stream(
  self, messages: list[ModelMessage], model_settings: ModelSettings | None
) -> AsyncIterator[StreamedResponse]:
"""Make a streaming request to the model from Pydantic AI call."""
  response = await self._stream_completions_create(messages, cast(MistralModelSettings, model_settings or {}))
  async with response:
    yield await self._process_streamed_response(self.result_tools, response)

```
  
---|---  
###  MistralStreamedResponse `dataclass`
Bases: `StreamedResponse[](https://ai.pydantic.dev/api/models/mistral/<../base/#pydantic_ai.models.StreamedResponse> "pydantic_ai.models.StreamedResponse")`
Implementation of `StreamedResponse` for Mistral models.
Source code in `pydantic_ai_slim/pydantic_ai/models/mistral.py`
```
451
452
453
454
455
456
457
458
459
460
461
462
463
464
465
466
467
468
469
470
471
472
473
474
475
476
477
478
479
480
481
482
483
484
485
486
487
488
489
490
491
492
493
494
495
496
497
498
499
500
501
502
503
504
505
506
507
508
509
510
511
512
513
514
515
516
517
518
519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
```
| ```
@dataclass
class MistralStreamedResponse(StreamedResponse):
"""Implementation of `StreamedResponse` for Mistral models."""
  _response: AsyncIterable[MistralCompletionEvent]
  _timestamp: datetime
  _result_tools: dict[str, ToolDefinition]
  _delta_content: str = field(default='', init=False)
  async def _get_event_iterator(self) -> AsyncIterator[ModelResponseStreamEvent]:
    chunk: MistralCompletionEvent
    async for chunk in self._response:
      self._usage += _map_usage(chunk.data)
      try:
        choice = chunk.data.choices[0]
      except IndexError:
        continue
      # Handle the text part of the response
      content = choice.delta.content
      text = _map_content(content)
      if text:
        # Attempt to produce a result tool call from the received text
        if self._result_tools:
          self._delta_content += text
          maybe_tool_call_part = self._try_get_result_tool_from_text(self._delta_content, self._result_tools)
          if maybe_tool_call_part:
            yield self._parts_manager.handle_tool_call_part(
              vendor_part_id='result',
              tool_name=maybe_tool_call_part.tool_name,
              args=maybe_tool_call_part.args_as_dict(),
              tool_call_id=maybe_tool_call_part.tool_call_id,
            )
        else:
          yield self._parts_manager.handle_text_delta(vendor_part_id='content', content=text)
      # Handle the explicit tool calls
      for index, dtc in enumerate(choice.delta.tool_calls or []):
        # It seems that mistral just sends full tool calls, so we just use them directly, rather than building
        yield self._parts_manager.handle_tool_call_part(
          vendor_part_id=index, tool_name=dtc.function.name, args=dtc.function.arguments, tool_call_id=dtc.id
        )
  def timestamp(self) -> datetime:
    return self._timestamp
  @staticmethod
  def _try_get_result_tool_from_text(text: str, result_tools: dict[str, ToolDefinition]) -> ToolCallPart | None:
    output_json: dict[str, Any] | None = pydantic_core.from_json(text, allow_partial='trailing-strings')
    if output_json:
      for result_tool in result_tools.values():
        # NOTE: Additional verification to prevent JSON validation to crash in `_result.py`
        # Ensures required parameters in the JSON schema are respected, especially for stream-based return types.
        # Example with BaseModel and required fields.
        if not MistralStreamedResponse._validate_required_json_schema(
          output_json, result_tool.parameters_json_schema
        ):
          continue
        # The following part_id will be thrown away
        return ToolCallPart(tool_name=result_tool.name, args=output_json)
  @staticmethod
  def _validate_required_json_schema(json_dict: dict[str, Any], json_schema: dict[str, Any]) -> bool:
"""Validate that all required parameters in the JSON schema are present in the JSON dictionary."""
    required_params = json_schema.get('required', [])
    properties = json_schema.get('properties', {})
    for param in required_params:
      if param not in json_dict:
        return False
      param_schema = properties.get(param, {})
      param_type = param_schema.get('type')
      param_items_type = param_schema.get('items', {}).get('type')
      if param_type == 'array' and param_items_type:
        if not isinstance(json_dict[param], list):
          return False
        for item in json_dict[param]:
          if not isinstance(item, VALID_JSON_TYPE_MAPPING[param_items_type]):
            return False
      elif param_type and not isinstance(json_dict[param], VALID_JSON_TYPE_MAPPING[param_type]):
        return False
      if isinstance(json_dict[param], dict) and 'properties' in param_schema:
        nested_schema = param_schema
        if not MistralStreamedResponse._validate_required_json_schema(json_dict[param], nested_schema):
          return False
    return True

```
  
---|---  
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_models_openai.md
================
[ Skip to content ](https://ai.pydantic.dev/api/models/openai/<#pydantic_aimodelsopenai>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/openai/..> "PydanticAI")
PydanticAI 
pydantic_ai.models.openai 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/openai/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/openai/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/openai/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/models/openai/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/models/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/models/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/models/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/models/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/models/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/models/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/models/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/models/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/models/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/models/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/models/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/models/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/models/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/models/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/models/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/models/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/models/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/models/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/models/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/models/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/models/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/models/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/models/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/models/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/models/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/models/openai/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/models/openai/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/models/openai/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/models/openai/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/models/openai/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/models/openai/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/models/openai/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/models/openai/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/models/openai/<../base/>)
    * pydantic_ai.models.openai  [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/models/openai/<./>) Table of contents 
      * [ Setup  ](https://ai.pydantic.dev/api/models/openai/<#setup>)
        * [ openai  ](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai>)
        * [ OpenAIModelName  ](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai.OpenAIModelName>)
        * [ OpenAIModelSettings  ](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai.OpenAIModelSettings>)
        * [ OpenAIModel  ](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai.OpenAIModel>)
          * [ __init__  ](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai.OpenAIModel.__init__>)
        * [ OpenAIAgentModel  ](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai.OpenAIAgentModel>)
        * [ OpenAIStreamedResponse  ](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai.OpenAIStreamedResponse>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/models/openai/<../anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/models/openai/<../cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/models/openai/<../gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/models/openai/<../vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/models/openai/<../groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/models/openai/<../mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/models/openai/<../test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/models/openai/<../function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/models/openai/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/models/openai/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/models/openai/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/models/openai/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/models/openai/pydantic_graph/exceptions/>)


Table of contents 
  * [ Setup  ](https://ai.pydantic.dev/api/models/openai/<#setup>)
    * [ openai  ](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai>)
    * [ OpenAIModelName  ](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai.OpenAIModelName>)
    * [ OpenAIModelSettings  ](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai.OpenAIModelSettings>)
    * [ OpenAIModel  ](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai.OpenAIModel>)
      * [ __init__  ](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai.OpenAIModel.__init__>)
    * [ OpenAIAgentModel  ](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai.OpenAIAgentModel>)
    * [ OpenAIStreamedResponse  ](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai.OpenAIStreamedResponse>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/models/openai/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/models/openai/agent/>)


# `pydantic_ai.models.openai`
## Setup
For details on how to set up authentication with this model, see [model configuration for OpenAI](https://ai.pydantic.dev/api/models/models/#openai>).
###  OpenAIModelName `module-attribute`
```
OpenAIModelName = Union[](https://ai.pydantic.dev/api/models/openai/<https:/docs.python.org/3/library/typing.html#typing.Union> "typing.Union")[ChatModel, str[](https://ai.pydantic.dev/api/models/openai/<https:/docs.python.org/3/library/stdtypes.html#str>)]

```

Using this more broad type for the model name instead of the ChatModel definition allows this model to be used more easily with other model types (ie, Ollama, Deepseek)
###  OpenAIModelSettings
Bases: `ModelSettings[](https://ai.pydantic.dev/api/models/openai/settings/#pydantic_ai.settings.ModelSettings> "pydantic_ai.settings.ModelSettings")`
Settings used for an OpenAI model request.
Source code in `pydantic_ai_slim/pydantic_ai/models/openai.py`
```
57
58
```
| ```
class OpenAIModelSettings(ModelSettings):
"""Settings used for an OpenAI model request."""

```
  
---|---  
###  OpenAIModel `dataclass`
Bases: `Model[](https://ai.pydantic.dev/api/models/openai/<../base/#pydantic_ai.models.Model> "pydantic_ai.models.Model")`
A model that uses the OpenAI API.
Internally, this uses the [OpenAI Python client](https://ai.pydantic.dev/api/models/openai/<https:/github.com/openai/openai-python>) to interact with the API.
Apart from `__init__`, all methods are private or match those of the base class.
Source code in `pydantic_ai_slim/pydantic_ai/models/openai.py`
```
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
```
| ```
@dataclass(init=False)
class OpenAIModel(Model):
"""A model that uses the OpenAI API.
  Internally, this uses the [OpenAI Python client](https://github.com/openai/openai-python) to interact with the API.
  Apart from `__init__`, all methods are private or match those of the base class.
  """
  model_name: OpenAIModelName
  client: AsyncOpenAI = field(repr=False)
  system_prompt_role: OpenAISystemPromptRole | None = field(default=None)
  def __init__(
    self,
    model_name: OpenAIModelName,
    *,
    base_url: str | None = None,
    api_key: str | None = None,
    openai_client: AsyncOpenAI | None = None,
    http_client: AsyncHTTPClient | None = None,
    system_prompt_role: OpenAISystemPromptRole | None = None,
  ):
"""Initialize an OpenAI model.
    Args:
      model_name: The name of the OpenAI model to use. List of model names available
        [here](https://github.com/openai/openai-python/blob/v1.54.3/src/openai/types/chat_model.py#L7)
        (Unfortunately, despite being ask to do so, OpenAI do not provide `.inv` files for their API).
      base_url: The base url for the OpenAI requests. If not provided, the `OPENAI_BASE_URL` environment variable
        will be used if available. Otherwise, defaults to OpenAI's base url.
      api_key: The API key to use for authentication, if not provided, the `OPENAI_API_KEY` environment variable
        will be used if available.
      openai_client: An existing
        [`AsyncOpenAI`](https://github.com/openai/openai-python?tab=readme-ov-file#async-usage)
        client to use. If provided, `base_url`, `api_key`, and `http_client` must be `None`.
      http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
      system_prompt_role: The role to use for the system prompt message. If not provided, defaults to `'system'`.
        In the future, this may be inferred from the model name.
    """
    self.model_name: OpenAIModelName = model_name
    if openai_client is not None:
      assert http_client is None, 'Cannot provide both `openai_client` and `http_client`'
      assert base_url is None, 'Cannot provide both `openai_client` and `base_url`'
      assert api_key is None, 'Cannot provide both `openai_client` and `api_key`'
      self.client = openai_client
    elif http_client is not None:
      self.client = AsyncOpenAI(base_url=base_url, api_key=api_key, http_client=http_client)
    else:
      self.client = AsyncOpenAI(base_url=base_url, api_key=api_key, http_client=cached_async_http_client())
    self.system_prompt_role = system_prompt_role
  async def agent_model(
    self,
    *,
    function_tools: list[ToolDefinition],
    allow_text_result: bool,
    result_tools: list[ToolDefinition],
  ) -> AgentModel:
    check_allow_model_requests()
    tools = [self._map_tool_definition(r) for r in function_tools]
    if result_tools:
      tools += [self._map_tool_definition(r) for r in result_tools]
    return OpenAIAgentModel(
      self.client,
      self.model_name,
      allow_text_result,
      tools,
      self.system_prompt_role,
    )
  def name(self) -> str:
    return f'openai:{self.model_name}'
  @staticmethod
  def _map_tool_definition(f: ToolDefinition) -> chat.ChatCompletionToolParam:
    return {
      'type': 'function',
      'function': {
        'name': f.name,
        'description': f.description,
        'parameters': f.parameters_json_schema,
      },
    }

```
  
---|---  
####  __init__
```
__init__(
  model_name: OpenAIModelName[](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai.OpenAIModelName> "pydantic_ai.models.openai.OpenAIModelName"),
  *,
  base_url: str[](https://ai.pydantic.dev/api/models/openai/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None,
  api_key: str[](https://ai.pydantic.dev/api/models/openai/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None,
  openai_client: AsyncOpenAI | None = None,
  http_client: AsyncClient | None = None,
  system_prompt_role: OpenAISystemPromptRole | None = None
)

```

Initialize an OpenAI model.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`model_name` |  `OpenAIModelName[](https://ai.pydantic.dev/api/models/openai/<#pydantic_ai.models.openai.OpenAIModelName> "pydantic_ai.models.openai.OpenAIModelName")` |  The name of the OpenAI model to use. List of model names available [here](https://ai.pydantic.dev/api/models/openai/<https:/github.com/openai/openai-python/blob/v1.54.3/src/openai/types/chat_model.py#L7>) (Unfortunately, despite being ask to do so, OpenAI do not provide `.inv` files for their API). |  _required_  
`base_url` |  `str[](https://ai.pydantic.dev/api/models/openai/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The base url for the OpenAI requests. If not provided, the `OPENAI_BASE_URL` environment variable will be used if available. Otherwise, defaults to OpenAI's base url. |  `None`  
`api_key` |  `str[](https://ai.pydantic.dev/api/models/openai/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The API key to use for authentication, if not provided, the `OPENAI_API_KEY` environment variable will be used if available. |  `None`  
`openai_client` |  `AsyncOpenAI | None` |  An existing `AsyncOpenAI`[](https://ai.pydantic.dev/api/models/openai/<https:/github.com/openai/openai-python?tab=readme-ov-file#async-usage>) client to use. If provided, `base_url`, `api_key`, and `http_client` must be `None`. |  `None`  
`http_client` |  `AsyncClient | None` |  An existing `httpx.AsyncClient` to use for making HTTP requests. |  `None`  
`system_prompt_role` |  `OpenAISystemPromptRole | None` |  The role to use for the system prompt message. If not provided, defaults to `'system'`. In the future, this may be inferred from the model name. |  `None`  
Source code in `pydantic_ai_slim/pydantic_ai/models/openai.py`
```
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
```
| ```
def __init__(
  self,
  model_name: OpenAIModelName,
  *,
  base_url: str | None = None,
  api_key: str | None = None,
  openai_client: AsyncOpenAI | None = None,
  http_client: AsyncHTTPClient | None = None,
  system_prompt_role: OpenAISystemPromptRole | None = None,
):
"""Initialize an OpenAI model.
  Args:
    model_name: The name of the OpenAI model to use. List of model names available
      [here](https://github.com/openai/openai-python/blob/v1.54.3/src/openai/types/chat_model.py#L7)
      (Unfortunately, despite being ask to do so, OpenAI do not provide `.inv` files for their API).
    base_url: The base url for the OpenAI requests. If not provided, the `OPENAI_BASE_URL` environment variable
      will be used if available. Otherwise, defaults to OpenAI's base url.
    api_key: The API key to use for authentication, if not provided, the `OPENAI_API_KEY` environment variable
      will be used if available.
    openai_client: An existing
      [`AsyncOpenAI`](https://github.com/openai/openai-python?tab=readme-ov-file#async-usage)
      client to use. If provided, `base_url`, `api_key`, and `http_client` must be `None`.
    http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
    system_prompt_role: The role to use for the system prompt message. If not provided, defaults to `'system'`.
      In the future, this may be inferred from the model name.
  """
  self.model_name: OpenAIModelName = model_name
  if openai_client is not None:
    assert http_client is None, 'Cannot provide both `openai_client` and `http_client`'
    assert base_url is None, 'Cannot provide both `openai_client` and `base_url`'
    assert api_key is None, 'Cannot provide both `openai_client` and `api_key`'
    self.client = openai_client
  elif http_client is not None:
    self.client = AsyncOpenAI(base_url=base_url, api_key=api_key, http_client=http_client)
  else:
    self.client = AsyncOpenAI(base_url=base_url, api_key=api_key, http_client=cached_async_http_client())
  self.system_prompt_role = system_prompt_role

```
  
---|---  
###  OpenAIAgentModel `dataclass`
Bases: `AgentModel[](https://ai.pydantic.dev/api/models/openai/<../base/#pydantic_ai.models.AgentModel> "pydantic_ai.models.AgentModel")`
Implementation of `AgentModel` for OpenAI models.
Source code in `pydantic_ai_slim/pydantic_ai/models/openai.py`
```
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
```
| ```
@dataclass
class OpenAIAgentModel(AgentModel):
"""Implementation of `AgentModel` for OpenAI models."""
  client: AsyncOpenAI
  model_name: OpenAIModelName
  allow_text_result: bool
  tools: list[chat.ChatCompletionToolParam]
  system_prompt_role: OpenAISystemPromptRole | None
  async def request(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> tuple[ModelResponse, usage.Usage]:
    response = await self._completions_create(messages, False, cast(OpenAIModelSettings, model_settings or {}))
    return self._process_response(response), _map_usage(response)
  @asynccontextmanager
  async def request_stream(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> AsyncIterator[StreamedResponse]:
    response = await self._completions_create(messages, True, cast(OpenAIModelSettings, model_settings or {}))
    async with response:
      yield await self._process_streamed_response(response)
  @overload
  async def _completions_create(
    self, messages: list[ModelMessage], stream: Literal[True], model_settings: OpenAIModelSettings
  ) -> AsyncStream[ChatCompletionChunk]:
    pass
  @overload
  async def _completions_create(
    self, messages: list[ModelMessage], stream: Literal[False], model_settings: OpenAIModelSettings
  ) -> chat.ChatCompletion:
    pass
  async def _completions_create(
    self, messages: list[ModelMessage], stream: bool, model_settings: OpenAIModelSettings
  ) -> chat.ChatCompletion | AsyncStream[ChatCompletionChunk]:
    # standalone function to make it easier to override
    if not self.tools:
      tool_choice: Literal['none', 'required', 'auto'] | None = None
    elif not self.allow_text_result:
      tool_choice = 'required'
    else:
      tool_choice = 'auto'
    openai_messages = list(chain(*(self._map_message(m) for m in messages)))
    return await self.client.chat.completions.create(
      model=self.model_name,
      messages=openai_messages,
      n=1,
      parallel_tool_calls=model_settings.get('parallel_tool_calls', NOT_GIVEN),
      tools=self.tools or NOT_GIVEN,
      tool_choice=tool_choice or NOT_GIVEN,
      stream=stream,
      stream_options={'include_usage': True} if stream else NOT_GIVEN,
      max_tokens=model_settings.get('max_tokens', NOT_GIVEN),
      temperature=model_settings.get('temperature', NOT_GIVEN),
      top_p=model_settings.get('top_p', NOT_GIVEN),
      timeout=model_settings.get('timeout', NOT_GIVEN),
      seed=model_settings.get('seed', NOT_GIVEN),
      presence_penalty=model_settings.get('presence_penalty', NOT_GIVEN),
      frequency_penalty=model_settings.get('frequency_penalty', NOT_GIVEN),
      logit_bias=model_settings.get('logit_bias', NOT_GIVEN),
    )
  def _process_response(self, response: chat.ChatCompletion) -> ModelResponse:
"""Process a non-streamed response, and prepare a message to return."""
    timestamp = datetime.fromtimestamp(response.created, tz=timezone.utc)
    choice = response.choices[0]
    items: list[ModelResponsePart] = []
    if choice.message.content is not None:
      items.append(TextPart(choice.message.content))
    if choice.message.tool_calls is not None:
      for c in choice.message.tool_calls:
        items.append(ToolCallPart(c.function.name, c.function.arguments, c.id))
    return ModelResponse(items, model_name=self.model_name, timestamp=timestamp)
  async def _process_streamed_response(self, response: AsyncStream[ChatCompletionChunk]) -> OpenAIStreamedResponse:
"""Process a streamed response, and prepare a streaming response to return."""
    peekable_response = _utils.PeekableAsyncStream(response)
    first_chunk = await peekable_response.peek()
    if isinstance(first_chunk, _utils.Unset):
      raise UnexpectedModelBehavior('Streamed response ended without content or tool calls')
    return OpenAIStreamedResponse(
      _model_name=self.model_name,
      _response=peekable_response,
      _timestamp=datetime.fromtimestamp(first_chunk.created, tz=timezone.utc),
    )
  def _map_message(self, message: ModelMessage) -> Iterable[chat.ChatCompletionMessageParam]:
"""Just maps a `pydantic_ai.Message` to a `openai.types.ChatCompletionMessageParam`."""
    if isinstance(message, ModelRequest):
      yield from self._map_user_message(message)
    elif isinstance(message, ModelResponse):
      texts: list[str] = []
      tool_calls: list[chat.ChatCompletionMessageToolCallParam] = []
      for item in message.parts:
        if isinstance(item, TextPart):
          texts.append(item.content)
        elif isinstance(item, ToolCallPart):
          tool_calls.append(_map_tool_call(item))
        else:
          assert_never(item)
      message_param = chat.ChatCompletionAssistantMessageParam(role='assistant')
      if texts:
        # Note: model responses from this model should only have one text item, so the following
        # shouldn't merge multiple texts into one unless you switch models between runs:
        message_param['content'] = '\n\n'.join(texts)
      if tool_calls:
        message_param['tool_calls'] = tool_calls
      yield message_param
    else:
      assert_never(message)
  def _map_user_message(self, message: ModelRequest) -> Iterable[chat.ChatCompletionMessageParam]:
    for part in message.parts:
      if isinstance(part, SystemPromptPart):
        if self.system_prompt_role == 'developer':
          yield chat.ChatCompletionDeveloperMessageParam(role='developer', content=part.content)
        elif self.system_prompt_role == 'user':
          yield chat.ChatCompletionUserMessageParam(role='user', content=part.content)
        else:
          yield chat.ChatCompletionSystemMessageParam(role='system', content=part.content)
      elif isinstance(part, UserPromptPart):
        yield chat.ChatCompletionUserMessageParam(role='user', content=part.content)
      elif isinstance(part, ToolReturnPart):
        yield chat.ChatCompletionToolMessageParam(
          role='tool',
          tool_call_id=_guard_tool_call_id(t=part, model_source='OpenAI'),
          content=part.model_response_str(),
        )
      elif isinstance(part, RetryPromptPart):
        if part.tool_name is None:
          yield chat.ChatCompletionUserMessageParam(role='user', content=part.model_response())
        else:
          yield chat.ChatCompletionToolMessageParam(
            role='tool',
            tool_call_id=_guard_tool_call_id(t=part, model_source='OpenAI'),
            content=part.model_response(),
          )
      else:
        assert_never(part)

```
  
---|---  
###  OpenAIStreamedResponse `dataclass`
Bases: `StreamedResponse[](https://ai.pydantic.dev/api/models/openai/<../base/#pydantic_ai.models.StreamedResponse> "pydantic_ai.models.StreamedResponse")`
Implementation of `StreamedResponse` for OpenAI models.
Source code in `pydantic_ai_slim/pydantic_ai/models/openai.py`
```
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
```
| ```
@dataclass
class OpenAIStreamedResponse(StreamedResponse):
"""Implementation of `StreamedResponse` for OpenAI models."""
  _response: AsyncIterable[ChatCompletionChunk]
  _timestamp: datetime
  async def _get_event_iterator(self) -> AsyncIterator[ModelResponseStreamEvent]:
    async for chunk in self._response:
      self._usage += _map_usage(chunk)
      try:
        choice = chunk.choices[0]
      except IndexError:
        continue
      # Handle the text part of the response
      content = choice.delta.content
      if content is not None:
        yield self._parts_manager.handle_text_delta(vendor_part_id='content', content=content)
      for dtc in choice.delta.tool_calls or []:
        maybe_event = self._parts_manager.handle_tool_call_delta(
          vendor_part_id=dtc.index,
          tool_name=dtc.function and dtc.function.name,
          args=dtc.function and dtc.function.arguments,
          tool_call_id=dtc.id,
        )
        if maybe_event is not None:
          yield maybe_event
  def timestamp(self) -> datetime:
    return self._timestamp

```
  
---|---  
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_models_test.md
================
[ Skip to content ](https://ai.pydantic.dev/api/models/test/<#pydantic_aimodelstest>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/test/..> "PydanticAI")
PydanticAI 
pydantic_ai.models.test 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/test/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/test/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/test/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/models/test/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/models/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/models/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/models/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/models/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/models/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/models/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/models/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/models/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/models/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/models/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/models/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/models/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/models/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/models/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/models/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/models/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/models/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/models/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/models/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/models/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/models/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/models/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/models/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/models/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/models/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/models/test/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/models/test/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/models/test/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/models/test/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/models/test/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/models/test/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/models/test/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/models/test/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/models/test/<../base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/models/test/<../openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/models/test/<../anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/models/test/<../cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/models/test/<../gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/models/test/<../vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/models/test/<../groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/models/test/<../mistral/>)
    * pydantic_ai.models.test  [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/models/test/<./>) Table of contents 
      * [ test  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test>)
      * [ TestModel  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel>)
        * [ call_tools  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel.call_tools>)
        * [ custom_result_text  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel.custom_result_text>)
        * [ custom_result_args  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel.custom_result_args>)
        * [ seed  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel.seed>)
        * [ agent_model_function_tools  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel.agent_model_function_tools>)
        * [ agent_model_allow_text_result  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel.agent_model_allow_text_result>)
        * [ agent_model_result_tools  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel.agent_model_result_tools>)
      * [ TestAgentModel  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestAgentModel>)
      * [ TestStreamedResponse  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestStreamedResponse>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/models/test/<../function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/models/test/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/models/test/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/models/test/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/models/test/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/models/test/pydantic_graph/exceptions/>)


Table of contents 
  * [ test  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test>)
  * [ TestModel  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel>)
    * [ call_tools  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel.call_tools>)
    * [ custom_result_text  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel.custom_result_text>)
    * [ custom_result_args  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel.custom_result_args>)
    * [ seed  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel.seed>)
    * [ agent_model_function_tools  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel.agent_model_function_tools>)
    * [ agent_model_allow_text_result  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel.agent_model_allow_text_result>)
    * [ agent_model_result_tools  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestModel.agent_model_result_tools>)
  * [ TestAgentModel  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestAgentModel>)
  * [ TestStreamedResponse  ](https://ai.pydantic.dev/api/models/test/<#pydantic_ai.models.test.TestStreamedResponse>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/models/test/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/models/test/agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/models/test/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/models/test/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_ai.models.test`
Utility model for quickly testing apps built with PydanticAI.
Here's a minimal example:
test_model_usage.py```
from pydantic_ai import Agent
from pydantic_ai.models.test import TestModel
my_agent = Agent('openai:gpt-4o', system_prompt='...')

async def test_my_agent():
"""Unit test for my_agent, to be run by pytest."""
  m = TestModel()
  with my_agent.override(model=m):
    result = await my_agent.run('Testing my agent...')
    assert result.data == 'success (no tool calls)'
  assert m.agent_model_function_tools == []

```

See [Unit testing with `TestModel`](https://ai.pydantic.dev/api/models/testing-evals/#unit-testing-with-testmodel>) for detailed documentation.
###  TestModel `dataclass`
Bases: `Model[](https://ai.pydantic.dev/api/models/test/<../base/#pydantic_ai.models.Model> "pydantic_ai.models.Model")`
A model specifically for testing purposes.
This will (by default) call all tools in the agent, then return a tool response if possible, otherwise a plain response.
How useful this model is will vary significantly.
Apart from `__init__` derived by the `dataclass` decorator, all methods are private or match those of the base class.
Source code in `pydantic_ai_slim/pydantic_ai/models/test.py`
```
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
```
| ```
@dataclass
class TestModel(Model):
"""A model specifically for testing purposes.
  This will (by default) call all tools in the agent, then return a tool response if possible,
  otherwise a plain response.
  How useful this model is will vary significantly.
  Apart from `__init__` derived by the `dataclass` decorator, all methods are private or match those
  of the base class.
  """
  # NOTE: Avoid test discovery by pytest.
  __test__ = False
  call_tools: list[str] | Literal['all'] = 'all'
"""List of tools to call. If `'all'`, all tools will be called."""
  custom_result_text: str | None = None
"""If set, this text is returned as the final result."""
  custom_result_args: Any | None = None
"""If set, these args will be passed to the result tool."""
  seed: int = 0
"""Seed for generating random data."""
  agent_model_function_tools: list[ToolDefinition] | None = field(default=None, init=False)
"""Definition of function tools passed to the model.
  This is set when the model is called, so will reflect the function tools from the last step of the last run.
  """
  agent_model_allow_text_result: bool | None = field(default=None, init=False)
"""Whether plain text responses from the model are allowed.
  This is set when the model is called, so will reflect the value from the last step of the last run.
  """
  agent_model_result_tools: list[ToolDefinition] | None = field(default=None, init=False)
"""Definition of result tools passed to the model.
  This is set when the model is called, so will reflect the result tools from the last step of the last run.
  """
  async def agent_model(
    self,
    *,
    function_tools: list[ToolDefinition],
    allow_text_result: bool,
    result_tools: list[ToolDefinition],
  ) -> AgentModel:
    self.agent_model_function_tools = function_tools
    self.agent_model_allow_text_result = allow_text_result
    self.agent_model_result_tools = result_tools
    if self.call_tools == 'all':
      tool_calls = [(r.name, r) for r in function_tools]
    else:
      function_tools_lookup = {t.name: t for t in function_tools}
      tools_to_call = (function_tools_lookup[name] for name in self.call_tools)
      tool_calls = [(r.name, r) for r in tools_to_call]
    if self.custom_result_text is not None:
      assert allow_text_result, 'Plain response not allowed, but `custom_result_text` is set.'
      assert self.custom_result_args is None, 'Cannot set both `custom_result_text` and `custom_result_args`.'
      result: _TextResult | _FunctionToolResult = _TextResult(self.custom_result_text)
    elif self.custom_result_args is not None:
      assert result_tools is not None, 'No result tools provided, but `custom_result_args` is set.'
      result_tool = result_tools[0]
      if k := result_tool.outer_typed_dict_key:
        result = _FunctionToolResult({k: self.custom_result_args})
      else:
        result = _FunctionToolResult(self.custom_result_args)
    elif allow_text_result:
      result = _TextResult(None)
    elif result_tools:
      result = _FunctionToolResult(None)
    else:
      result = _TextResult(None)
    return TestAgentModel(tool_calls, result, result_tools, self.seed)
  def name(self) -> str:
    return 'test-model'

```
  
---|---  
####  call_tools `class-attribute` `instance-attribute`
```
call_tools: list[](https://ai.pydantic.dev/api/models/test/<https:/docs.python.org/3/library/stdtypes.html#list>)[str[](https://ai.pydantic.dev/api/models/test/<https:/docs.python.org/3/library/stdtypes.html#str>)] | Literal[](https://ai.pydantic.dev/api/models/test/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['all'] = 'all'

```

List of tools to call. If `'all'`, all tools will be called.
####  custom_result_text `class-attribute` `instance-attribute`
```
custom_result_text: str[](https://ai.pydantic.dev/api/models/test/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None

```

If set, this text is returned as the final result.
####  custom_result_args `class-attribute` `instance-attribute`
```
custom_result_args: Any[](https://ai.pydantic.dev/api/models/test/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any") | None = None

```

If set, these args will be passed to the result tool.
####  seed `class-attribute` `instance-attribute`
```
seed: int[](https://ai.pydantic.dev/api/models/test/<https:/docs.python.org/3/library/functions.html#int>) = 0

```

Seed for generating random data.
####  agent_model_function_tools `class-attribute` `instance-attribute`
```
agent_model_function_tools: list[](https://ai.pydantic.dev/api/models/test/<https:/docs.python.org/3/library/stdtypes.html#list>)[ToolDefinition[](https://ai.pydantic.dev/api/models/test/tools/#pydantic_ai.tools.ToolDefinition> "pydantic_ai.tools.ToolDefinition")] | None = (
  field[](https://ai.pydantic.dev/api/models/test/<https:/docs.python.org/3/library/dataclasses.html#dataclasses.field> "dataclasses.field")(default=None, init=False)
)

```

Definition of function tools passed to the model.
This is set when the model is called, so will reflect the function tools from the last step of the last run.
####  agent_model_allow_text_result `class-attribute` `instance-attribute`
```
agent_model_allow_text_result: bool[](https://ai.pydantic.dev/api/models/test/<https:/docs.python.org/3/library/functions.html#bool>) | None = field[](https://ai.pydantic.dev/api/models/test/<https:/docs.python.org/3/library/dataclasses.html#dataclasses.field> "dataclasses.field")(
  default=None, init=False
)

```

Whether plain text responses from the model are allowed.
This is set when the model is called, so will reflect the value from the last step of the last run.
####  agent_model_result_tools `class-attribute` `instance-attribute`
```
agent_model_result_tools: list[](https://ai.pydantic.dev/api/models/test/<https:/docs.python.org/3/library/stdtypes.html#list>)[ToolDefinition[](https://ai.pydantic.dev/api/models/test/tools/#pydantic_ai.tools.ToolDefinition> "pydantic_ai.tools.ToolDefinition")] | None = (
  field[](https://ai.pydantic.dev/api/models/test/<https:/docs.python.org/3/library/dataclasses.html#dataclasses.field> "dataclasses.field")(default=None, init=False)
)

```

Definition of result tools passed to the model.
This is set when the model is called, so will reflect the result tools from the last step of the last run.
###  TestAgentModel `dataclass`
Bases: `AgentModel[](https://ai.pydantic.dev/api/models/test/<../base/#pydantic_ai.models.AgentModel> "pydantic_ai.models.AgentModel")`
Implementation of `AgentModel` for testing purposes.
Source code in `pydantic_ai_slim/pydantic_ai/models/test.py`
```
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
```
| ```
@dataclass
class TestAgentModel(AgentModel):
"""Implementation of `AgentModel` for testing purposes."""
  # NOTE: Avoid test discovery by pytest.
  __test__ = False
  tool_calls: list[tuple[str, ToolDefinition]]
  # left means the text is plain text; right means it's a function call
  result: _TextResult | _FunctionToolResult
  result_tools: list[ToolDefinition]
  seed: int
  model_name: str = 'test'
  async def request(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> tuple[ModelResponse, Usage]:
    model_response = self._request(messages, model_settings)
    usage = _estimate_usage([*messages, model_response])
    return model_response, usage
  @asynccontextmanager
  async def request_stream(
    self, messages: list[ModelMessage], model_settings: ModelSettings | None
  ) -> AsyncIterator[StreamedResponse]:
    model_response = self._request(messages, model_settings)
    yield TestStreamedResponse(_model_name=self.model_name, _structured_response=model_response, _messages=messages)
  def gen_tool_args(self, tool_def: ToolDefinition) -> Any:
    return _JsonSchemaTestData(tool_def.parameters_json_schema, self.seed).generate()
  def _request(self, messages: list[ModelMessage], model_settings: ModelSettings | None) -> ModelResponse:
    # if there are tools, the first thing we want to do is call all of them
    if self.tool_calls and not any(isinstance(m, ModelResponse) for m in messages):
      return ModelResponse(
        parts=[ToolCallPart(name, self.gen_tool_args(args)) for name, args in self.tool_calls],
        model_name=self.model_name,
      )
    if messages:
      last_message = messages[-1]
      assert isinstance(last_message, ModelRequest), 'Expected last message to be a `ModelRequest`.'
      # check if there are any retry prompts, if so retry them
      new_retry_names = {p.tool_name for p in last_message.parts if isinstance(p, RetryPromptPart)}
      if new_retry_names:
        # Handle retries for both function tools and result tools
        # Check function tools first
        retry_parts: list[ModelResponsePart] = [
          ToolCallPart(name, self.gen_tool_args(args))
          for name, args in self.tool_calls
          if name in new_retry_names
        ]
        # Check result tools
        if self.result_tools:
          retry_parts.extend(
            [
              ToolCallPart(
                tool.name,
                self.result.value
                if isinstance(self.result, _FunctionToolResult) and self.result.value is not None
                else self.gen_tool_args(tool),
              )
              for tool in self.result_tools
              if tool.name in new_retry_names
            ]
          )
        return ModelResponse(parts=retry_parts, model_name=self.model_name)
    if isinstance(self.result, _TextResult):
      if (response_text := self.result.value) is None:
        # build up details of tool responses
        output: dict[str, Any] = {}
        for message in messages:
          if isinstance(message, ModelRequest):
            for part in message.parts:
              if isinstance(part, ToolReturnPart):
                output[part.tool_name] = part.content
        if output:
          return ModelResponse(
            parts=[TextPart(pydantic_core.to_json(output).decode())], model_name=self.model_name
          )
        else:
          return ModelResponse(parts=[TextPart('success (no tool calls)')], model_name=self.model_name)
      else:
        return ModelResponse(parts=[TextPart(response_text)], model_name=self.model_name)
    else:
      assert self.result_tools, 'No result tools provided'
      custom_result_args = self.result.value
      result_tool = self.result_tools[self.seed % len(self.result_tools)]
      if custom_result_args is not None:
        return ModelResponse(
          parts=[ToolCallPart(result_tool.name, custom_result_args)], model_name=self.model_name
        )
      else:
        response_args = self.gen_tool_args(result_tool)
        return ModelResponse(parts=[ToolCallPart(result_tool.name, response_args)], model_name=self.model_name)

```
  
---|---  
###  TestStreamedResponse `dataclass`
Bases: `StreamedResponse[](https://ai.pydantic.dev/api/models/test/<../base/#pydantic_ai.models.StreamedResponse> "pydantic_ai.models.StreamedResponse")`
A structured response that streams test data.
Source code in `pydantic_ai_slim/pydantic_ai/models/test.py`
```
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
```
| ```
@dataclass
class TestStreamedResponse(StreamedResponse):
"""A structured response that streams test data."""
  _structured_response: ModelResponse
  _messages: InitVar[Iterable[ModelMessage]]
  _timestamp: datetime = field(default_factory=_utils.now_utc, init=False)
  def __post_init__(self, _messages: Iterable[ModelMessage]):
    self._usage = _estimate_usage(_messages)
  async def _get_event_iterator(self) -> AsyncIterator[ModelResponseStreamEvent]:
    for i, part in enumerate(self._structured_response.parts):
      if isinstance(part, TextPart):
        text = part.content
        *words, last_word = text.split(' ')
        words = [f'{word} ' for word in words]
        words.append(last_word)
        if len(words) == 1 and len(text) > 2:
          mid = len(text) // 2
          words = [text[:mid], text[mid:]]
        self._usage += _get_string_usage('')
        yield self._parts_manager.handle_text_delta(vendor_part_id=i, content='')
        for word in words:
          self._usage += _get_string_usage(word)
          yield self._parts_manager.handle_text_delta(vendor_part_id=i, content=word)
      else:
        yield self._parts_manager.handle_tool_call_part(
          vendor_part_id=i, tool_name=part.tool_name, args=part.args, tool_call_id=part.tool_call_id
        )
  def timestamp(self) -> datetime:
    return self._timestamp

```
  
---|---  
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_models_vertexai.md
================
[ Skip to content ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_aimodelsvertexai>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/vertexai/..> "PydanticAI")
PydanticAI 
pydantic_ai.models.vertexai 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/vertexai/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/models/vertexai/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/models/vertexai/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/models/vertexai/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/models/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/models/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/models/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/models/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/models/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/models/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/models/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/models/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/models/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/models/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/models/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/models/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/models/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/models/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/models/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/models/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/models/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/models/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/models/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/models/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/models/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/models/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/models/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/models/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/models/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/models/vertexai/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/models/vertexai/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/models/vertexai/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/models/vertexai/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/models/vertexai/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/models/vertexai/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/models/vertexai/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/models/vertexai/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/models/vertexai/<../base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/models/vertexai/<../openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/models/vertexai/<../anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/models/vertexai/<../cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/models/vertexai/<../gemini/>)
    * pydantic_ai.models.vertexai  [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/models/vertexai/<./>) Table of contents 
      * [ Setup  ](https://ai.pydantic.dev/api/models/vertexai/<#setup>)
      * [ Example Usage  ](https://ai.pydantic.dev/api/models/vertexai/<#example-usage>)
        * [ vertexai  ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai>)
        * [ VERTEX_AI_URL_TEMPLATE  ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VERTEX_AI_URL_TEMPLATE>)
        * [ VertexAIModel  ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VertexAIModel>)
          * [ __init__  ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VertexAIModel.__init__>)
          * [ ainit  ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VertexAIModel.ainit>)
        * [ BearerTokenAuth  ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.BearerTokenAuth>)
        * [ VertexAiRegion  ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VertexAiRegion>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/models/vertexai/<../groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/models/vertexai/<../mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/models/vertexai/<../test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/models/vertexai/<../function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/models/vertexai/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/models/vertexai/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/models/vertexai/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/models/vertexai/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/models/vertexai/pydantic_graph/exceptions/>)


Table of contents 
  * [ Setup  ](https://ai.pydantic.dev/api/models/vertexai/<#setup>)
  * [ Example Usage  ](https://ai.pydantic.dev/api/models/vertexai/<#example-usage>)
    * [ vertexai  ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai>)
    * [ VERTEX_AI_URL_TEMPLATE  ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VERTEX_AI_URL_TEMPLATE>)
    * [ VertexAIModel  ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VertexAIModel>)
      * [ __init__  ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VertexAIModel.__init__>)
      * [ ainit  ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VertexAIModel.ainit>)
    * [ BearerTokenAuth  ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.BearerTokenAuth>)
    * [ VertexAiRegion  ](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VertexAiRegion>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/models/vertexai/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/models/vertexai/agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/models/vertexai/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/models/vertexai/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_ai.models.vertexai`
Custom interface to the `*-aiplatform.googleapis.com` API for Gemini models.
This model uses `GeminiAgentModel`[](https://ai.pydantic.dev/api/models/vertexai/<../gemini/#pydantic_ai.models.gemini.GeminiAgentModel>) with just the URL and auth method changed from `GeminiModel`[](https://ai.pydantic.dev/api/models/vertexai/<../gemini/#pydantic_ai.models.gemini.GeminiModel>), it relies on the VertexAI `generateContent`[](https://ai.pydantic.dev/api/models/vertexai/<https:/cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/generateContent>) and `streamGenerateContent`[](https://ai.pydantic.dev/api/models/vertexai/<https:/cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/streamGenerateContent>) function endpoints having the same schemas as the equivalent [Gemini endpoints](https://ai.pydantic.dev/api/models/vertexai/<../gemini/#pydantic_ai.models.gemini.GeminiModel>).
## Setup
For details on how to set up authentication with this model as well as a comparison with the `generativelanguage.googleapis.com` API used by `GeminiModel`[](https://ai.pydantic.dev/api/models/vertexai/<../gemini/#pydantic_ai.models.gemini.GeminiModel>), see [model configuration for Gemini via VertexAI](https://ai.pydantic.dev/api/models/models/#gemini-via-vertexai>).
## Example Usage
With the default google project already configured in your environment using "application default credentials":
vertex_example_env.py```
from pydantic_ai import Agent
from pydantic_ai.models.vertexai import VertexAIModel
model = VertexAIModel('gemini-1.5-flash')
agent = Agent(model)
result = agent.run_sync('Tell me a joke.')
print(result.data)
#> Did you hear about the toothpaste scandal? They called it Colgate.

```

Or using a service account JSON file:
vertex_example_service_account.py```
from pydantic_ai import Agent
from pydantic_ai.models.vertexai import VertexAIModel
model = VertexAIModel(
  'gemini-1.5-flash',
  service_account_file='path/to/service-account.json',
)
agent = Agent(model)
result = agent.run_sync('Tell me a joke.')
print(result.data)
#> Did you hear about the toothpaste scandal? They called it Colgate.

```

###  VERTEX_AI_URL_TEMPLATE `module-attribute`
```
VERTEX_AI_URL_TEMPLATE = "https://{region}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{region}/publishers/{model_publisher}/models/{model}:"

```

URL template for Vertex AI.
See `generateContent`[ docs](https://ai.pydantic.dev/api/models/vertexai/<https:/cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/generateContent>) and `streamGenerateContent`[ docs](https://ai.pydantic.dev/api/models/vertexai/<https:/cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/streamGenerateContent>) for more information.
The template is used thus:
  * `region` is substituted with the `region` argument, see [available regions](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VertexAiRegion>)
  * `model_publisher` is substituted with the `model_publisher` argument
  * `model` is substituted with the `model_name` argument
  * `project_id` is substituted with the `project_id` from auth/credentials
  * `function` (`generateContent` or `streamGenerateContent`) is added to the end of the URL


###  VertexAIModel `dataclass`
Bases: `Model[](https://ai.pydantic.dev/api/models/vertexai/<../base/#pydantic_ai.models.Model> "pydantic_ai.models.Model")`
A model that uses Gemini via the `*-aiplatform.googleapis.com` VertexAI API.
Source code in `pydantic_ai_slim/pydantic_ai/models/vertexai.py`
```
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
```
| ```
@dataclass(init=False)
class VertexAIModel(Model):
"""A model that uses Gemini via the `*-aiplatform.googleapis.com` VertexAI API."""
  model_name: GeminiModelName
  service_account_file: Path | str | None
  project_id: str | None
  region: VertexAiRegion
  model_publisher: Literal['google']
  http_client: AsyncHTTPClient
  url_template: str
  auth: BearerTokenAuth | None
  url: str | None
  # TODO __init__ can be removed once we drop 3.9 and we can set kw_only correctly on the dataclass
  def __init__(
    self,
    model_name: GeminiModelName,
    *,
    service_account_file: Path | str | None = None,
    project_id: str | None = None,
    region: VertexAiRegion = 'us-central1',
    model_publisher: Literal['google'] = 'google',
    http_client: AsyncHTTPClient | None = None,
    url_template: str = VERTEX_AI_URL_TEMPLATE,
  ):
"""Initialize a Vertex AI Gemini model.
    Args:
      model_name: The name of the model to use. I couldn't find a list of supported Google models, in VertexAI
        so for now this uses the same models as the [Gemini model][pydantic_ai.models.gemini.GeminiModel].
      service_account_file: Path to a service account file.
        If not provided, the default environment credentials will be used.
      project_id: The project ID to use, if not provided it will be taken from the credentials.
      region: The region to make requests to.
      model_publisher: The model publisher to use, I couldn't find a good list of available publishers,
        and from trial and error it seems non-google models don't work with the `generateContent` and
        `streamGenerateContent` functions, hence only `google` is currently supported.
        Please create an issue or PR if you know how to use other publishers.
      http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
      url_template: URL template for Vertex AI, see
        [`VERTEX_AI_URL_TEMPLATE` docs][pydantic_ai.models.vertexai.VERTEX_AI_URL_TEMPLATE]
        for more information.
    """
    self.model_name = model_name
    self.service_account_file = service_account_file
    self.project_id = project_id
    self.region = region
    self.model_publisher = model_publisher
    self.http_client = http_client or cached_async_http_client()
    self.url_template = url_template
    self.auth = None
    self.url = None
  async def agent_model(
    self,
    *,
    function_tools: list[ToolDefinition],
    allow_text_result: bool,
    result_tools: list[ToolDefinition],
  ) -> GeminiAgentModel:
    check_allow_model_requests()
    url, auth = await self.ainit()
    return GeminiAgentModel(
      http_client=self.http_client,
      model_name=self.model_name,
      auth=auth,
      url=url,
      function_tools=function_tools,
      allow_text_result=allow_text_result,
      result_tools=result_tools,
    )
  async def ainit(self) -> tuple[str, BearerTokenAuth]:
"""Initialize the model, setting the URL and auth.
    This will raise an error if authentication fails.
    """
    if self.url is not None and self.auth is not None:
      return self.url, self.auth
    if self.service_account_file is not None:
      creds: BaseCredentials | ServiceAccountCredentials = _creds_from_file(self.service_account_file)
      assert creds.project_id is None or isinstance(creds.project_id, str)
      creds_project_id: str | None = creds.project_id
      creds_source = 'service account file'
    else:
      creds, creds_project_id = await _async_google_auth()
      creds_source = '`google.auth.default()`'
    if self.project_id is None:
      if creds_project_id is None:
        raise UserError(f'No project_id provided and none found in {creds_source}')
      project_id = creds_project_id
    else:
      if creds_project_id is not None and self.project_id != creds_project_id:
        raise UserError(
          f'The project_id you provided does not match the one from {creds_source}: '
          f'{self.project_id!r} != {creds_project_id!r}'
        )
      project_id = self.project_id
    self.url = url = self.url_template.format(
      region=self.region,
      project_id=project_id,
      model_publisher=self.model_publisher,
      model=self.model_name,
    )
    self.auth = auth = BearerTokenAuth(creds)
    return url, auth
  def name(self) -> str:
    return f'google-vertex:{self.model_name}'

```
  
---|---  
####  __init__
```
__init__(
  model_name: GeminiModelName[](https://ai.pydantic.dev/api/models/vertexai/<../gemini/#pydantic_ai.models.gemini.GeminiModelName> "pydantic_ai.models.gemini.GeminiModelName"),
  *,
  service_account_file: Path[](https://ai.pydantic.dev/api/models/vertexai/<https:/docs.python.org/3/library/pathlib.html#pathlib.Path> "pathlib.Path") | str[](https://ai.pydantic.dev/api/models/vertexai/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None,
  project_id: str[](https://ai.pydantic.dev/api/models/vertexai/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None,
  region: VertexAiRegion[](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VertexAiRegion> "pydantic_ai.models.vertexai.VertexAiRegion") = "us-central1",
  model_publisher: Literal[](https://ai.pydantic.dev/api/models/vertexai/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")["google"] = "google",
  http_client: AsyncClient | None = None,
  url_template: str[](https://ai.pydantic.dev/api/models/vertexai/<https:/docs.python.org/3/library/stdtypes.html#str>) = VERTEX_AI_URL_TEMPLATE[](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VERTEX_AI_URL_TEMPLATE> "pydantic_ai.models.vertexai.VERTEX_AI_URL_TEMPLATE")
)

```

Initialize a Vertex AI Gemini model.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`model_name` |  `GeminiModelName[](https://ai.pydantic.dev/api/models/vertexai/<../gemini/#pydantic_ai.models.gemini.GeminiModelName> "pydantic_ai.models.gemini.GeminiModelName")` |  The name of the model to use. I couldn't find a list of supported Google models, in VertexAI so for now this uses the same models as the [Gemini model](https://ai.pydantic.dev/api/models/vertexai/<../gemini/#pydantic_ai.models.gemini.GeminiModel>). |  _required_  
`service_account_file` |  `Path[](https://ai.pydantic.dev/api/models/vertexai/<https:/docs.python.org/3/library/pathlib.html#pathlib.Path> "pathlib.Path") | str[](https://ai.pydantic.dev/api/models/vertexai/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  Path to a service account file. If not provided, the default environment credentials will be used. |  `None`  
`project_id` |  `str[](https://ai.pydantic.dev/api/models/vertexai/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The project ID to use, if not provided it will be taken from the credentials. |  `None`  
`region` |  `VertexAiRegion[](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VertexAiRegion> "pydantic_ai.models.vertexai.VertexAiRegion")` |  The region to make requests to. |  `'us-central1'`  
`model_publisher` |  `Literal[](https://ai.pydantic.dev/api/models/vertexai/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['google']` |  The model publisher to use, I couldn't find a good list of available publishers, and from trial and error it seems non-google models don't work with the `generateContent` and `streamGenerateContent` functions, hence only `google` is currently supported. Please create an issue or PR if you know how to use other publishers. |  `'google'`  
`http_client` |  `AsyncClient | None` |  An existing `httpx.AsyncClient` to use for making HTTP requests. |  `None`  
`url_template` |  `str[](https://ai.pydantic.dev/api/models/vertexai/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  URL template for Vertex AI, see `VERTEX_AI_URL_TEMPLATE`[ docs](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VERTEX_AI_URL_TEMPLATE>) for more information. |  `VERTEX_AI_URL_TEMPLATE[](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.VERTEX_AI_URL_TEMPLATE> "pydantic_ai.models.vertexai.VERTEX_AI_URL_TEMPLATE")`  
Source code in `pydantic_ai_slim/pydantic_ai/models/vertexai.py`
```
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
```
| ```
def __init__(
  self,
  model_name: GeminiModelName,
  *,
  service_account_file: Path | str | None = None,
  project_id: str | None = None,
  region: VertexAiRegion = 'us-central1',
  model_publisher: Literal['google'] = 'google',
  http_client: AsyncHTTPClient | None = None,
  url_template: str = VERTEX_AI_URL_TEMPLATE,
):
"""Initialize a Vertex AI Gemini model.
  Args:
    model_name: The name of the model to use. I couldn't find a list of supported Google models, in VertexAI
      so for now this uses the same models as the [Gemini model][pydantic_ai.models.gemini.GeminiModel].
    service_account_file: Path to a service account file.
      If not provided, the default environment credentials will be used.
    project_id: The project ID to use, if not provided it will be taken from the credentials.
    region: The region to make requests to.
    model_publisher: The model publisher to use, I couldn't find a good list of available publishers,
      and from trial and error it seems non-google models don't work with the `generateContent` and
      `streamGenerateContent` functions, hence only `google` is currently supported.
      Please create an issue or PR if you know how to use other publishers.
    http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
    url_template: URL template for Vertex AI, see
      [`VERTEX_AI_URL_TEMPLATE` docs][pydantic_ai.models.vertexai.VERTEX_AI_URL_TEMPLATE]
      for more information.
  """
  self.model_name = model_name
  self.service_account_file = service_account_file
  self.project_id = project_id
  self.region = region
  self.model_publisher = model_publisher
  self.http_client = http_client or cached_async_http_client()
  self.url_template = url_template
  self.auth = None
  self.url = None

```
  
---|---  
####  ainit `async`
```
ainit() -> tuple[](https://ai.pydantic.dev/api/models/vertexai/<https:/docs.python.org/3/library/stdtypes.html#tuple>)[str[](https://ai.pydantic.dev/api/models/vertexai/<https:/docs.python.org/3/library/stdtypes.html#str>), BearerTokenAuth[](https://ai.pydantic.dev/api/models/vertexai/<#pydantic_ai.models.vertexai.BearerTokenAuth> "pydantic_ai.models.vertexai.BearerTokenAuth")]

```

Initialize the model, setting the URL and auth.
This will raise an error if authentication fails.
Source code in `pydantic_ai_slim/pydantic_ai/models/vertexai.py`
```
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
```
| ```
async def ainit(self) -> tuple[str, BearerTokenAuth]:
"""Initialize the model, setting the URL and auth.
  This will raise an error if authentication fails.
  """
  if self.url is not None and self.auth is not None:
    return self.url, self.auth
  if self.service_account_file is not None:
    creds: BaseCredentials | ServiceAccountCredentials = _creds_from_file(self.service_account_file)
    assert creds.project_id is None or isinstance(creds.project_id, str)
    creds_project_id: str | None = creds.project_id
    creds_source = 'service account file'
  else:
    creds, creds_project_id = await _async_google_auth()
    creds_source = '`google.auth.default()`'
  if self.project_id is None:
    if creds_project_id is None:
      raise UserError(f'No project_id provided and none found in {creds_source}')
    project_id = creds_project_id
  else:
    if creds_project_id is not None and self.project_id != creds_project_id:
      raise UserError(
        f'The project_id you provided does not match the one from {creds_source}: '
        f'{self.project_id!r} != {creds_project_id!r}'
      )
    project_id = self.project_id
  self.url = url = self.url_template.format(
    region=self.region,
    project_id=project_id,
    model_publisher=self.model_publisher,
    model=self.model_name,
  )
  self.auth = auth = BearerTokenAuth(creds)
  return url, auth

```
  
---|---  
###  BearerTokenAuth `dataclass`
Authentication using a bearer token generated by google-auth.
Source code in `pydantic_ai_slim/pydantic_ai/models/vertexai.py`
```
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
```
| ```
@dataclass
class BearerTokenAuth:
"""Authentication using a bearer token generated by google-auth."""
  credentials: BaseCredentials | ServiceAccountCredentials
  token_created: datetime | None = field(default=None, init=False)
  async def headers(self) -> dict[str, str]:
    if self.credentials.token is None or self._token_expired():
      await run_in_executor(self._refresh_token)
      self.token_created = datetime.now()
    return {'Authorization': f'Bearer {self.credentials.token}'}
  def _token_expired(self) -> bool:
    if self.token_created is None:
      return True
    else:
      return (datetime.now() - self.token_created) > MAX_TOKEN_AGE
  def _refresh_token(self) -> str:
    self.credentials.refresh(Request())
    assert isinstance(self.credentials.token, str), f'Expected token to be a string, got {self.credentials.token}'
    return self.credentials.token

```
  
---|---  
###  VertexAiRegion `module-attribute`
```
VertexAiRegion = Literal[](https://ai.pydantic.dev/api/models/vertexai/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")[
  "us-central1",
  "us-east1",
  "us-east4",
  "us-south1",
  "us-west1",
  "us-west2",
  "us-west3",
  "us-west4",
  "us-east5",
  "europe-central2",
  "europe-north1",
  "europe-southwest1",
  "europe-west1",
  "europe-west2",
  "europe-west3",
  "europe-west4",
  "europe-west6",
  "europe-west8",
  "europe-west9",
  "europe-west12",
  "africa-south1",
  "asia-east1",
  "asia-east2",
  "asia-northeast1",
  "asia-northeast2",
  "asia-northeast3",
  "asia-south1",
  "asia-southeast1",
  "asia-southeast2",
  "australia-southeast1",
  "australia-southeast2",
  "me-central1",
  "me-central2",
  "me-west1",
  "northamerica-northeast1",
  "northamerica-northeast2",
  "southamerica-east1",
  "southamerica-west1",
]

```

Regions available for Vertex AI.
More details [here](https://ai.pydantic.dev/api/models/vertexai/<https:/cloud.google.com/vertex-ai/docs/reference/rest#rest_endpoints>).
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_parameters.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/api/parameters/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/api/parameters/<../..>)
  * [ Quick Start ](https://docs.crawl4ai.com/api/parameters/core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/api/parameters/<#>)


  * [Home](https://docs.crawl4ai.com/api/parameters/<../..>)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/api/parameters/core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/api/parameters/core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/api/parameters/core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/api/parameters/blog/>)
    * [Changelog](https://docs.crawl4ai.com/api/parameters/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/api/parameters/core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/api/parameters/core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/api/parameters/core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/api/parameters/core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/api/parameters/core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/api/parameters/core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/api/parameters/core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/api/parameters/core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/api/parameters/core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/api/parameters/core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/api/parameters/advanced/advanced-features/>)
    * [File Downloading](https://docs.crawl4ai.com/api/parameters/advanced/file-downloading/>)
    * [Lazy Loading](https://docs.crawl4ai.com/api/parameters/advanced/lazy-loading/>)
    * [Hooks & Auth](https://docs.crawl4ai.com/api/parameters/advanced/hooks-auth/>)
    * [Proxy & Security](https://docs.crawl4ai.com/api/parameters/advanced/proxy-security/>)
    * [Session Management](https://docs.crawl4ai.com/api/parameters/advanced/session-management/>)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/api/parameters/advanced/multi-url-crawling/>)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/api/parameters/advanced/crawl-dispatcher/>)
    * [Identity Based Crawling](https://docs.crawl4ai.com/api/parameters/advanced/identity-based-crawling/>)
    * [SSL Certificate](https://docs.crawl4ai.com/api/parameters/advanced/ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/api/parameters/extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/api/parameters/extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/api/parameters/extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/api/parameters/extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/api/parameters/<../async-webcrawler/>)
    * [arun()](https://docs.crawl4ai.com/api/parameters/<../arun/>)
    * [arun_many()](https://docs.crawl4ai.com/api/parameters/<../arun_many/>)
    * Browser & Crawler Config
    * [CrawlResult](https://docs.crawl4ai.com/api/parameters/<../crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/api/parameters/<../strategies/>)


  * [1. BrowserConfig – Controlling the Browser](https://docs.crawl4ai.com/api/parameters/<#1-browserconfig-controlling-the-browser>)
  * [1.1 Parameter Highlights](https://docs.crawl4ai.com/api/parameters/<#11-parameter-highlights>)
  * [2. CrawlerRunConfig – Controlling Each Crawl](https://docs.crawl4ai.com/api/parameters/<#2-crawlerrunconfig-controlling-each-crawl>)
  * [2.1 Parameter Highlights](https://docs.crawl4ai.com/api/parameters/<#21-parameter-highlights>)
  * [2.2 Helper Methods](https://docs.crawl4ai.com/api/parameters/<#22-helper-methods>)
  * [2.3 Example Usage](https://docs.crawl4ai.com/api/parameters/<#23-example-usage>)
  * [3. Putting It All Together](https://docs.crawl4ai.com/api/parameters/<#3-putting-it-all-together>)


# 1. **BrowserConfig** – Controlling the Browser
`BrowserConfig` focuses on **how** the browser is launched and behaves. This includes headless mode, proxies, user agents, and other environment tweaks.
```
from crawl4ai import AsyncWebCrawler, BrowserConfig
browser_cfg = BrowserConfig(
  browser_type="chromium",
  headless=True,
  viewport_width=1280,
  viewport_height=720,
  proxy="http://user:pass@proxy:8080",
  user_agent="Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome/116.0.0.0 Safari/537.36",
)

```

## 1.1 Parameter Highlights
**Parameter** | **Type / Default** | **What It Does**  
---|---|---  
**`browser_type`**| `"chromium"` , `"firefox"`, `"webkit"`_(default:`"chromium"`)_ | Which browser engine to use. `"chromium"` is typical for many sites, `"firefox"` or `"webkit"` for specialized tests.  
**`headless`**| `bool` (default: `True`) | Headless means no visible UI. `False` is handy for debugging.  
**`viewport_width`**| `int` (default: `1080`) | Initial page width (in px). Useful for testing responsive layouts.  
**`viewport_height`**| `int` (default: `600`) | Initial page height (in px).  
**`proxy`**| `str` (default: `None`) | Single-proxy URL if you want all traffic to go through it, e.g. `"http://user:pass@proxy:8080"`.  
**`proxy_config`**| `dict` (default: `None`) | For advanced or multi-proxy needs, specify details like `{"server": "...", "username": "...", ...}`.  
**`use_persistent_context`**| `bool` (default: `False`) | If `True`, uses a **persistent** browser context (keep cookies, sessions across runs). Also sets `use_managed_browser=True`.  
**`user_data_dir`**| `str or None` (default: `None`) | Directory to store user data (profiles, cookies). Must be set if you want permanent sessions.  
**`ignore_https_errors`**| `bool` (default: `True`) | If `True`, continues despite invalid certificates (common in dev/staging).  
**`java_script_enabled`**| `bool` (default: `True`) | Disable if you want no JS overhead, or if only static content is needed.  
**`cookies`**| `list` (default: `[]`) | Pre-set cookies, each a dict like `{"name": "session", "value": "...", "url": "..."}`.  
**`headers`**| `dict` (default: `{}`) | Extra HTTP headers for every request, e.g. `{"Accept-Language": "en-US"}`.  
**`user_agent`**| `str` (default: Chrome-based UA) | Your custom or random user agent. `user_agent_mode="random"` can shuffle it.  
**`light_mode`**| `bool` (default: `False`) | Disables some background features for performance gains.  
**`text_mode`**| `bool` (default: `False`) | If `True`, tries to disable images/other heavy content for speed.  
**`use_managed_browser`**| `bool` (default: `False`) | For advanced “managed” interactions (debugging, CDP usage). Typically set automatically if persistent context is on.  
**`extra_args`**| `list` (default: `[]`) | Additional flags for the underlying browser process, e.g. `["--disable-extensions"]`.  
**Tips** : - Set `headless=False` to visually **debug** how pages load or how interactions proceed. - If you need **authentication** storage or repeated sessions, consider `use_persistent_context=True` and specify `user_data_dir`. - For large pages, you might need a bigger `viewport_width` and `viewport_height` to handle dynamic content.
# 2. **CrawlerRunConfig** – Controlling Each Crawl
While `BrowserConfig` sets up the **environment** , `CrawlerRunConfig` details **how** each **crawl operation** should behave: caching, content filtering, link or domain blocking, timeouts, JavaScript code, etc.
```
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig
run_cfg = CrawlerRunConfig(
  wait_for="css:.main-content",
  word_count_threshold=15,
  excluded_tags=["nav", "footer"],
  exclude_external_links=True,
  stream=True, # Enable streaming for arun_many()
)

```

## 2.1 Parameter Highlights
We group them by category. 
### A) **Content Processing**
**Parameter** | **Type / Default** | **What It Does**  
---|---|---  
**`word_count_threshold`**| `int` (default: ~200) | Skips text blocks below X words. Helps ignore trivial sections.  
**`extraction_strategy`**| `ExtractionStrategy` (default: None) | If set, extracts structured data (CSS-based, LLM-based, etc.).  
**`markdown_generator`**| `MarkdownGenerationStrategy` (None) | If you want specialized markdown output (citations, filtering, chunking, etc.).  
**`content_filter`**| `RelevantContentFilter` (None) | Filters out irrelevant text blocks. E.g., `PruningContentFilter` or `BM25ContentFilter`.  
**`css_selector`**| `str` (None) | Retains only the part of the page matching this selector.  
**`excluded_tags`**| `list` (None) | Removes entire tags (e.g. `["script", "style"]`).  
**`excluded_selector`**| `str` (None) | Like `css_selector` but to exclude. E.g. `"#ads, .tracker"`.  
**`only_text`**| `bool` (False) | If `True`, tries to extract text-only content.  
**`prettiify`**| `bool` (False) | If `True`, beautifies final HTML (slower, purely cosmetic).  
**`keep_data_attributes`**| `bool` (False) | If `True`, preserve `data-*` attributes in cleaned HTML.  
**`remove_forms`**| `bool` (False) | If `True`, remove all `<form>` elements.  
### B) **Caching & Session**
**Parameter** | **Type / Default** | **What It Does**  
---|---|---  
**`cache_mode`**| `CacheMode or None` | Controls how caching is handled (`ENABLED`, `BYPASS`, `DISABLED`, etc.). If `None`, typically defaults to `ENABLED`.  
**`session_id`**| `str or None` | Assign a unique ID to reuse a single browser session across multiple `arun()` calls.  
**`bypass_cache`**| `bool` (False) | If `True`, acts like `CacheMode.BYPASS`.  
**`disable_cache`**| `bool` (False) | If `True`, acts like `CacheMode.DISABLED`.  
**`no_cache_read`**| `bool` (False) | If `True`, acts like `CacheMode.WRITE_ONLY` (writes cache but never reads).  
**`no_cache_write`**| `bool` (False) | If `True`, acts like `CacheMode.READ_ONLY` (reads cache but never writes).  
Use these for controlling whether you read or write from a local content cache. Handy for large batch crawls or repeated site visits.
### C) **Page Navigation & Timing**
**Parameter** | **Type / Default** | **What It Does**  
---|---|---  
**`wait_until`**| `str` (domcontentloaded) | Condition for navigation to “complete”. Often `"networkidle"` or `"domcontentloaded"`.  
**`page_timeout`**| `int` (60000 ms) | Timeout for page navigation or JS steps. Increase for slow sites.  
**`wait_for`**| `str or None` | Wait for a CSS (`"css:selector"`) or JS (`"js:() => bool"`) condition before content extraction.  
**`wait_for_images`**| `bool` (False) | Wait for images to load before finishing. Slows down if you only want text.  
**`delay_before_return_html`**| `float` (0.1) | Additional pause (seconds) before final HTML is captured. Good for last-second updates.  
**`check_robots_txt`**| `bool` (False) | Whether to check and respect robots.txt rules before crawling. If True, caches robots.txt for efficiency.  
**`mean_delay`**and**`max_range`**| `float` (0.1, 0.3) | If you call `arun_many()`, these define random delay intervals between crawls, helping avoid detection or rate limits.  
**`semaphore_count`**| `int` (5) | Max concurrency for `arun_many()`. Increase if you have resources for parallel crawls.  
### D) **Page Interaction**
**Parameter** | **Type / Default** | **What It Does**  
---|---|---  
**`js_code`**| `str or list[str]` (None) | JavaScript to run after load. E.g. `"document.querySelector('button')?.click();"`.  
**`js_only`**| `bool` (False) | If `True`, indicates we’re reusing an existing session and only applying JS. No full reload.  
**`ignore_body_visibility`**| `bool` (True) | Skip checking if `<body>` is visible. Usually best to keep `True`.  
**`scan_full_page`**| `bool` (False) | If `True`, auto-scroll the page to load dynamic content (infinite scroll).  
**`scroll_delay`**| `float` (0.2) | Delay between scroll steps if `scan_full_page=True`.  
**`process_iframes`**| `bool` (False) | Inlines iframe content for single-page extraction.  
**`remove_overlay_elements`**| `bool` (False) | Removes potential modals/popups blocking the main content.  
**`simulate_user`**| `bool` (False) | Simulate user interactions (mouse movements) to avoid bot detection.  
**`override_navigator`**| `bool` (False) | Override `navigator` properties in JS for stealth.  
**`magic`**| `bool` (False) | Automatic handling of popups/consent banners. Experimental.  
**`adjust_viewport_to_content`**| `bool` (False) | Resizes viewport to match page content height.  
If your page is a single-page app with repeated JS updates, set `js_only=True` in subsequent calls, plus a `session_id` for reusing the same tab.
### E) **Media Handling**
**Parameter** | **Type / Default** | **What It Does**  
---|---|---  
**`screenshot`**| `bool` (False) | Capture a screenshot (base64) in `result.screenshot`.  
**`screenshot_wait_for`**| `float or None` | Extra wait time before the screenshot.  
**`screenshot_height_threshold`**| `int` (~20000) | If the page is taller than this, alternate screenshot strategies are used.  
**`pdf`**| `bool` (False) | If `True`, returns a PDF in `result.pdf`.  
**`image_description_min_word_threshold`**| `int` (~50) | Minimum words for an image’s alt text or description to be considered valid.  
**`image_score_threshold`**| `int` (~3) | Filter out low-scoring images. The crawler scores images by relevance (size, context, etc.).  
**`exclude_external_images`**| `bool` (False) | Exclude images from other domains.  
### F) **Link/Domain Handling**
**Parameter** | **Type / Default** | **What It Does**  
---|---|---  
**`exclude_social_media_domains`**| `list` (e.g. Facebook/Twitter) | A default list can be extended. Any link to these domains is removed from final output.  
**`exclude_external_links`**| `bool` (False) | Removes all links pointing outside the current domain.  
**`exclude_social_media_links`**| `bool` (False) | Strips links specifically to social sites (like Facebook or Twitter).  
**`exclude_domains`**| `list` ([]) | Provide a custom list of domains to exclude (like `["ads.com", "trackers.io"]`).  
Use these for link-level content filtering (often to keep crawls “internal” or to remove spammy domains).
### G) **Rate Limiting & Resource Management**
**Parameter** | **Type / Default** | **What It Does**  
---|---|---  
**`enable_rate_limiting`**| `bool` (default: `False`) | Enable intelligent rate limiting for multiple URLs  
**`rate_limit_config`**| `RateLimitConfig` (default: `None`) | Configuration for rate limiting behavior  
The `RateLimitConfig` class has these fields:
**Field** | **Type / Default** | **What It Does**  
---|---|---  
**`base_delay`**| `Tuple[float, float]` (1.0, 3.0) | Random delay range between requests to the same domain  
**`max_delay`**| `float` (60.0) | Maximum delay after rate limit detection  
**`max_retries`**| `int` (3) | Number of retries before giving up on rate-limited requests  
**`rate_limit_codes`**| `List[int]` ([429, 503]) | HTTP status codes that trigger rate limiting behavior  
**Parameter** | **Type / Default** | **What It Does**  
---|---|---  
**`memory_threshold_percent`**| `float` (70.0) | Maximum memory usage before pausing new crawls  
**`check_interval`**| `float` (1.0) | How often to check system resources (in seconds)  
**`max_session_permit`**| `int` (20) | Maximum number of concurrent crawl sessions  
**`display_mode`**| `str` (`None`, "DETAILED", "AGGREGATED") | How to display progress information  
### H) **Debug & Logging**
**Parameter** | **Type / Default** | **What It Does**  
---|---|---  
**`verbose`**| `bool` (True) | Prints logs detailing each step of crawling, interactions, or errors.  
**`log_console`**| `bool` (False) | Logs the page’s JavaScript console output if you want deeper JS debugging.  
## 2.2 Helper Methods
Both `BrowserConfig` and `CrawlerRunConfig` provide a `clone()` method to create modified copies:
```
# Create a base configuration
base_config = CrawlerRunConfig(
  cache_mode=CacheMode.ENABLED,
  word_count_threshold=200
)
# Create variations using clone()
stream_config = base_config.clone(stream=True)
no_cache_config = base_config.clone(
  cache_mode=CacheMode.BYPASS,
  stream=True
)

```

The `clone()` method is particularly useful when you need slightly different configurations for different use cases, without modifying the original config.
## 2.3 Example Usage
```
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode, RateLimitConfig
async def main():
  # Configure the browser
  browser_cfg = BrowserConfig(
    headless=False,
    viewport_width=1280,
    viewport_height=720,
    proxy="http://user:pass@myproxy:8080",
    text_mode=True
  )
  # Configure the run
  run_cfg = CrawlerRunConfig(
    cache_mode=CacheMode.BYPASS,
    session_id="my_session",
    css_selector="main.article",
    excluded_tags=["script", "style"],
    exclude_external_links=True,
    wait_for="css:.article-loaded",
    screenshot=True,
    enable_rate_limiting=True,
    rate_limit_config=RateLimitConfig(
      base_delay=(1.0, 3.0),
      max_delay=60.0,
      max_retries=3,
      rate_limit_codes=[429, 503]
    ),
    memory_threshold_percent=70.0,
    check_interval=1.0,
    max_session_permit=20,
    display_mode="DETAILED",
    stream=True
  )
  async with AsyncWebCrawler(config=browser_cfg) as crawler:
    result = await crawler.arun(
      url="https://example.com/news",
      config=run_cfg
    )
    if result.success:
      print("Final cleaned_html length:", len(result.cleaned_html))
      if result.screenshot:
        print("Screenshot captured (base64, length):", len(result.screenshot))
    else:
      print("Crawl failed:", result.error_message)
if __name__ == "__main__":
  asyncio.run(main())
## 2.4 Compliance & Ethics
| **Parameter**     | **Type / Default**   | **What It Does**                                                  |
|-----------------------|-------------------------|----------------------------------------------------------------------------------------------------------------------|
| **`check_robots_txt`**| `bool` (False)     | When True, checks and respects robots.txt rules before crawling. Uses efficient caching with SQLite backend.     |
| **`user_agent`**   | `str` (None)      | User agent string to identify your crawler. Used for robots.txt checking when enabled.                |
```python
run_config = CrawlerRunConfig(
  check_robots_txt=True, # Enable robots.txt compliance
  user_agent="MyBot/1.0" # Identify your crawler
)

```

## 3. Putting It All Together
  * **Use** `BrowserConfig` for **global** browser settings: engine, headless, proxy, user agent. 
  * **Use** `CrawlerRunConfig` for each crawl’s **context** : how to filter content, handle caching, wait for dynamic elements, or run JS. 
  * **Pass** both configs to `AsyncWebCrawler` (the `BrowserConfig`) and then to `arun()` (the `CrawlerRunConfig`). 


```
# Create a modified copy with the clone() method
stream_cfg = run_cfg.clone(
  stream=True,
  cache_mode=CacheMode.BYPASS
)

```

Site built with [MkDocs](https://docs.crawl4ai.com/api/parameters/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/api/parameters/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/api_pydantic_graph_exceptions.md
================
[ Skip to content ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<#pydantic_graphexceptions>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/..> "PydanticAI")
PydanticAI 
pydantic_graph.exceptions 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/pydantic_graph/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/pydantic_graph/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/pydantic_graph/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/pydantic_graph/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/pydantic_graph/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/pydantic_graph/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/pydantic_graph/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/pydantic_graph/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/pydantic_graph/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/pydantic_graph/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/pydantic_graph/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/pydantic_graph/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/pydantic_graph/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/pydantic_graph/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/pydantic_graph/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/pydantic_graph/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/pydantic_graph/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/pydantic_graph/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/pydantic_graph/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/pydantic_graph/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/pydantic_graph/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/pydantic_graph/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/pydantic_graph/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/pydantic_graph/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/pydantic_graph/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<../graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<../nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<../state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<../mermaid/>)
    * pydantic_graph.exceptions  [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<./>) Table of contents 
      * [ exceptions  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<#pydantic_graph.exceptions>)
      * [ GraphSetupError  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<#pydantic_graph.exceptions.GraphSetupError>)
        * [ message  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<#pydantic_graph.exceptions.GraphSetupError.message>)
      * [ GraphRuntimeError  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<#pydantic_graph.exceptions.GraphRuntimeError>)
        * [ message  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<#pydantic_graph.exceptions.GraphRuntimeError.message>)


Table of contents 
  * [ exceptions  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<#pydantic_graph.exceptions>)
  * [ GraphSetupError  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<#pydantic_graph.exceptions.GraphSetupError>)
    * [ message  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<#pydantic_graph.exceptions.GraphSetupError.message>)
  * [ GraphRuntimeError  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<#pydantic_graph.exceptions.GraphRuntimeError>)
    * [ message  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<#pydantic_graph.exceptions.GraphRuntimeError.message>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_graph.exceptions`
###  GraphSetupError
Bases: `TypeError[](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<https:/docs.python.org/3/library/exceptions.html#TypeError>)`
Error caused by an incorrectly configured graph.
Source code in `pydantic_graph/pydantic_graph/exceptions.py`
```
1
2
3
4
5
6
7
8
9
```
| ```
class GraphSetupError(TypeError):
"""Error caused by an incorrectly configured graph."""
  message: str
"""Description of the mistake."""
  def __init__(self, message: str):
    self.message = message
    super().__init__(message)

```
  
---|---  
####  message `instance-attribute`
```
message: str[](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<https:/docs.python.org/3/library/stdtypes.html#str>) = message[](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<#pydantic_graph.exceptions.GraphSetupError.message> "pydantic_graph.exceptions.GraphSetupError.message")

```

Description of the mistake.
###  GraphRuntimeError
Bases: `RuntimeError[](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<https:/docs.python.org/3/library/exceptions.html#RuntimeError>)`
Error caused by an issue during graph execution.
Source code in `pydantic_graph/pydantic_graph/exceptions.py`
```
12
13
14
15
16
17
18
19
20
```
| ```
class GraphRuntimeError(RuntimeError):
"""Error caused by an issue during graph execution."""
  message: str
"""The error message."""
  def __init__(self, message: str):
    self.message = message
    super().__init__(message)

```
  
---|---  
####  message `instance-attribute`
```
message: str[](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<https:/docs.python.org/3/library/stdtypes.html#str>) = message[](https://ai.pydantic.dev/api/pydantic_graph/exceptions/<#pydantic_graph.exceptions.GraphRuntimeError.message> "pydantic_graph.exceptions.GraphRuntimeError.message")

```

The error message.
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_pydantic_graph_graph.md
================
[ Skip to content ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/pydantic_graph/graph/..> "PydanticAI")
PydanticAI 
pydantic_graph 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/pydantic_graph/graph/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/pydantic_graph/graph/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/pydantic_graph/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/pydantic_graph/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/pydantic_graph/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/pydantic_graph/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/pydantic_graph/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/pydantic_graph/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/pydantic_graph/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/pydantic_graph/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/pydantic_graph/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/pydantic_graph/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/pydantic_graph/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/pydantic_graph/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/pydantic_graph/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/pydantic_graph/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/pydantic_graph/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/pydantic_graph/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/pydantic_graph/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/pydantic_graph/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/pydantic_graph/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/pydantic_graph/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/pydantic_graph/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/pydantic_graph/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/pydantic_graph/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/pydantic_graph/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/pydantic_graph/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/pydantic_graph/graph/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/pydantic_graph/graph/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/pydantic_graph/graph/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/pydantic_graph/graph/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/pydantic_graph/graph/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/pydantic_graph/graph/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/pydantic_graph/graph/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/pydantic_graph/graph/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/pydantic_graph/graph/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/pydantic_graph/graph/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/pydantic_graph/graph/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/pydantic_graph/graph/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/pydantic_graph/graph/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/pydantic_graph/graph/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/pydantic_graph/graph/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/pydantic_graph/graph/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/pydantic_graph/graph/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/pydantic_graph/graph/models/function/>)
    * pydantic_graph  [ pydantic_graph  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<./>) Table of contents 
      * [ graph  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph>)
      * [ Graph  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph>)
        * [ __init__  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.__init__>)
        * [ run  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.run>)
        * [ run_sync  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.run_sync>)
        * [ next  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.next>)
        * [ dump_history  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.dump_history>)
        * [ load_history  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.load_history>)
        * [ mermaid_code  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.mermaid_code>)
        * [ mermaid_image  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.mermaid_image>)
        * [ mermaid_save  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.mermaid_save>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<../exceptions/>)


Table of contents 
  * [ graph  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph>)
  * [ Graph  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph>)
    * [ __init__  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.__init__>)
    * [ run  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.run>)
    * [ run_sync  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.run_sync>)
    * [ next  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.next>)
    * [ dump_history  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.dump_history>)
    * [ load_history  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.load_history>)
    * [ mermaid_code  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.mermaid_code>)
    * [ mermaid_image  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.mermaid_image>)
    * [ mermaid_save  ](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.mermaid_save>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/pydantic_graph/graph/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/pydantic_graph/graph/agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_graph`
###  Graph `dataclass`
Bases: `Generic[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/typing.html#typing.Generic> "typing.Generic")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")]`
Definition of a graph.
In `pydantic-graph`, a graph is a collection of nodes that can be run in sequence. The nodes define their outgoing edges — e.g. which nodes may be run next, and thereby the structure of the graph.
Here's a very simple example of a graph which increments a number by 1, but makes sure the number is never 42 at the end.
never_42.py```
from __future__ import annotations
from dataclasses import dataclass
from pydantic_graph import BaseNode, End, Graph, GraphRunContext
@dataclass
class MyState:
  number: int
@dataclass
class Increment(BaseNode[MyState]):
  async def run(self, ctx: GraphRunContext) -> Check42:
    ctx.state.number += 1
    return Check42()
@dataclass
class Check42(BaseNode[MyState, None, int]):
  async def run(self, ctx: GraphRunContext) -> Increment | End[int]:
    if ctx.state.number == 42:
      return Increment()
    else:
      return End(ctx.state.number)
never_42_graph = Graph(nodes=(Increment, Check42))

```

_(This example is complete, it can be run "as is")_
See `run`[](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.run>) For an example of running graph, and `mermaid_code`[](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.mermaid_code>) for an example of generating a mermaid diagram from the graph.
Source code in `pydantic_graph/pydantic_graph/graph.py`
```
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439
440
441
442
443
444
445
446
447
448
449
450
451
452
453
454
455
456
457
458
459
460
461
462
463
464
465
466
467
468
469
470
471
472
473
474
475
476
477
478
479
480
481
482
483
484
485
486
487
488
489
490
491
492
493
494
495
496
497
498
499
500
501
502
503
504
505
506
507
508
509
510
511
512
```
| ```
@dataclass(init=False)
class Graph(Generic[StateT, DepsT, RunEndT]):
"""Definition of a graph.
  In `pydantic-graph`, a graph is a collection of nodes that can be run in sequence. The nodes define
  their outgoing edges — e.g. which nodes may be run next, and thereby the structure of the graph.
  Here's a very simple example of a graph which increments a number by 1, but makes sure the number is never
  42 at the end.
  ```py {title="never_42.py" noqa="I001" py="3.10"}
  from __future__ import annotations
  from dataclasses import dataclass
  from pydantic_graph import BaseNode, End, Graph, GraphRunContext
  @dataclass
  class MyState:
    number: int
  @dataclass
  class Increment(BaseNode[MyState]):
    async def run(self, ctx: GraphRunContext) -> Check42:
      ctx.state.number += 1
      return Check42()
  @dataclass
  class Check42(BaseNode[MyState, None, int]):
    async def run(self, ctx: GraphRunContext) -> Increment | End[int]:
      if ctx.state.number == 42:
        return Increment()
      else:
        return End(ctx.state.number)
  never_42_graph = Graph(nodes=(Increment, Check42))
  ```
  _(This example is complete, it can be run "as is")_
  See [`run`][pydantic_graph.graph.Graph.run] For an example of running graph, and
  [`mermaid_code`][pydantic_graph.graph.Graph.mermaid_code] for an example of generating a mermaid diagram
  from the graph.
  """
  name: str | None
  node_defs: dict[str, NodeDef[StateT, DepsT, RunEndT]]
  snapshot_state: Callable[[StateT], StateT]
  _state_type: type[StateT] | _utils.Unset = field(repr=False)
  _run_end_type: type[RunEndT] | _utils.Unset = field(repr=False)
  _auto_instrument: bool = field(repr=False)
  def __init__(
    self,
    *,
    nodes: Sequence[type[BaseNode[StateT, DepsT, RunEndT]]],
    name: str | None = None,
    state_type: type[StateT] | _utils.Unset = _utils.UNSET,
    run_end_type: type[RunEndT] | _utils.Unset = _utils.UNSET,
    snapshot_state: Callable[[StateT], StateT] = deep_copy_state,
    auto_instrument: bool = True,
  ):
"""Create a graph from a sequence of nodes.
    Args:
      nodes: The nodes which make up the graph, nodes need to be unique and all be generic in the same
        state type.
      name: Optional name for the graph, if not provided the name will be inferred from the calling frame
        on the first call to a graph method.
      state_type: The type of the state for the graph, this can generally be inferred from `nodes`.
      run_end_type: The type of the result of running the graph, this can generally be inferred from `nodes`.
      snapshot_state: A function to snapshot the state of the graph, this is used in
        [`NodeStep`][pydantic_graph.state.NodeStep] and [`EndStep`][pydantic_graph.state.EndStep] to record
        the state before each step.
      auto_instrument: Whether to create a span for the graph run and the execution of each node's run method.
    """
    self.name = name
    self._state_type = state_type
    self._run_end_type = run_end_type
    self._auto_instrument = auto_instrument
    self.snapshot_state = snapshot_state
    parent_namespace = _utils.get_parent_namespace(inspect.currentframe())
    self.node_defs: dict[str, NodeDef[StateT, DepsT, RunEndT]] = {}
    for node in nodes:
      self._register_node(node, parent_namespace)
    self._validate_edges()
  async def run(
    self: Graph[StateT, DepsT, T],
    start_node: BaseNode[StateT, DepsT, T],
    *,
    state: StateT = None,
    deps: DepsT = None,
    infer_name: bool = True,
  ) -> tuple[T, list[HistoryStep[StateT, T]]]:
"""Run the graph from a starting node until it ends.
    Args:
      start_node: the first node to run, since the graph definition doesn't define the entry point in the graph,
        you need to provide the starting node.
      state: The initial state of the graph.
      deps: The dependencies of the graph.
      infer_name: Whether to infer the graph name from the calling frame.
    Returns:
      The result type from ending the run and the history of the run.
    Here's an example of running the graph from [above][pydantic_graph.graph.Graph]:
```py {title="run_never_42.py" noqa="I001" py="3.10"}
    from never_42 import Increment, MyState, never_42_graph
    async def main():
      state = MyState(1)
      _, history = await never_42_graph.run(Increment(), state=state)
      print(state)
      #> MyState(number=2)
      print(len(history))
      #> 3
      state = MyState(41)
      _, history = await never_42_graph.run(Increment(), state=state)
      print(state)
      #> MyState(number=43)
      print(len(history))
      #> 5
```
    """
    if infer_name and self.name is None:
      self._infer_name(inspect.currentframe())
    history: list[HistoryStep[StateT, T]] = []
    with ExitStack() as stack:
      run_span: logfire_api.LogfireSpan | None = None
      if self._auto_instrument:
        run_span = stack.enter_context(
          _logfire.span(
            '{graph_name} run {start=}',
            graph_name=self.name or 'graph',
            start=start_node,
          )
        )
    while True:
      next_node = await self.next(start_node, history, state=state, deps=deps, infer_name=False)
      if isinstance(next_node, End):
        history.append(EndStep(result=next_node))
        if run_span is not None:
          run_span.set_attribute('history', history)
        return next_node.data, history
      elif isinstance(next_node, BaseNode):
        start_node = next_node
      else:
        if TYPE_CHECKING:
          typing_extensions.assert_never(next_node)
        else:
          raise exceptions.GraphRuntimeError(
            f'Invalid node return type: `{type(next_node).__name__}`. Expected `BaseNode` or `End`.'
          )
  def run_sync(
    self: Graph[StateT, DepsT, T],
    start_node: BaseNode[StateT, DepsT, T],
    *,
    state: StateT = None,
    deps: DepsT = None,
    infer_name: bool = True,
  ) -> tuple[T, list[HistoryStep[StateT, T]]]:
"""Run the graph synchronously.
    This is a convenience method that wraps [`self.run`][pydantic_graph.Graph.run] with `loop.run_until_complete(...)`.
    You therefore can't use this method inside async code or if there's an active event loop.
    Args:
      start_node: the first node to run, since the graph definition doesn't define the entry point in the graph,
        you need to provide the starting node.
      state: The initial state of the graph.
      deps: The dependencies of the graph.
      infer_name: Whether to infer the graph name from the calling frame.
    Returns:
      The result type from ending the run and the history of the run.
    """
    if infer_name and self.name is None:
      self._infer_name(inspect.currentframe())
    return asyncio.get_event_loop().run_until_complete(
      self.run(start_node, state=state, deps=deps, infer_name=False)
    )
  async def next(
    self: Graph[StateT, DepsT, T],
    node: BaseNode[StateT, DepsT, T],
    history: list[HistoryStep[StateT, T]],
    *,
    state: StateT = None,
    deps: DepsT = None,
    infer_name: bool = True,
  ) -> BaseNode[StateT, DepsT, Any] | End[T]:
"""Run a node in the graph and return the next node to run.
    Args:
      node: The node to run.
      history: The history of the graph run so far. NOTE: this will be mutated to add the new step.
      state: The current state of the graph.
      deps: The dependencies of the graph.
      infer_name: Whether to infer the graph name from the calling frame.
    Returns:
      The next node to run or [`End`][pydantic_graph.nodes.End] if the graph has finished.
    """
    if infer_name and self.name is None:
      self._infer_name(inspect.currentframe())
    node_id = node.get_id()
    if node_id not in self.node_defs:
      raise exceptions.GraphRuntimeError(f'Node `{node}` is not in the graph.')
    with ExitStack() as stack:
      if self._auto_instrument:
        stack.enter_context(_logfire.span('run node {node_id}', node_id=node_id, node=node))
      ctx = GraphRunContext(state, deps)
      start_ts = _utils.now_utc()
      start = perf_counter()
      next_node = await node.run(ctx)
      duration = perf_counter() - start
    history.append(
      NodeStep(state=state, node=node, start_ts=start_ts, duration=duration, snapshot_state=self.snapshot_state)
    )
    return next_node
  def dump_history(
    self: Graph[StateT, DepsT, T], history: list[HistoryStep[StateT, T]], *, indent: int | None = None
  ) -> bytes:
"""Dump the history of a graph run as JSON.
    Args:
      history: The history of the graph run.
      indent: The number of spaces to indent the JSON.
    Returns:
      The JSON representation of the history.
    """
    return self.history_type_adapter.dump_json(history, indent=indent)
  def load_history(self, json_bytes: str | bytes | bytearray) -> list[HistoryStep[StateT, RunEndT]]:
"""Load the history of a graph run from JSON.
    Args:
      json_bytes: The JSON representation of the history.
    Returns:
      The history of the graph run.
    """
    return self.history_type_adapter.validate_json(json_bytes)
  @cached_property
  def history_type_adapter(self) -> pydantic.TypeAdapter[list[HistoryStep[StateT, RunEndT]]]:
    nodes = [node_def.node for node_def in self.node_defs.values()]
    state_t = self._get_state_type()
    end_t = self._get_run_end_type()
    token = nodes_schema_var.set(nodes)
    try:
      ta = pydantic.TypeAdapter(list[Annotated[HistoryStep[state_t, end_t], pydantic.Discriminator('kind')]])
    finally:
      nodes_schema_var.reset(token)
    return ta
  def mermaid_code(
    self,
    *,
    start_node: Sequence[mermaid.NodeIdent] | mermaid.NodeIdent | None = None,
    title: str | None | typing_extensions.Literal[False] = None,
    edge_labels: bool = True,
    notes: bool = True,
    highlighted_nodes: Sequence[mermaid.NodeIdent] | mermaid.NodeIdent | None = None,
    highlight_css: str = mermaid.DEFAULT_HIGHLIGHT_CSS,
    infer_name: bool = True,
    direction: mermaid.StateDiagramDirection | None = None,
  ) -> str:
"""Generate a diagram representing the graph as [mermaid](https://mermaid.js.org/) diagram.
    This method calls [`pydantic_graph.mermaid.generate_code`][pydantic_graph.mermaid.generate_code].
    Args:
      start_node: The node or nodes which can start the graph.
      title: The title of the diagram, use `False` to not include a title.
      edge_labels: Whether to include edge labels.
      notes: Whether to include notes on each node.
      highlighted_nodes: Optional node or nodes to highlight.
      highlight_css: The CSS to use for highlighting nodes.
      infer_name: Whether to infer the graph name from the calling frame.
      direction: The direction of flow.
    Returns:
      The mermaid code for the graph, which can then be rendered as a diagram.
    Here's an example of generating a diagram for the graph from [above][pydantic_graph.graph.Graph]:
```py {title="never_42.py" py="3.10"}
    from never_42 import Increment, never_42_graph
    print(never_42_graph.mermaid_code(start_node=Increment))
    '''
    ---
    title: never_42_graph
    ---
    stateDiagram-v2
     [*] --> Increment
     Increment --> Check42
     Check42 --> Increment
     Check42 --> [*]
    '''
```
    The rendered diagram will look like this:
```mermaid
    ---
    title: never_42_graph
    ---
    stateDiagram-v2
     [*] --> Increment
     Increment --> Check42
     Check42 --> Increment
     Check42 --> [*]
```
    """
    if infer_name and self.name is None:
      self._infer_name(inspect.currentframe())
    if title is None and self.name:
      title = self.name
    return mermaid.generate_code(
      self,
      start_node=start_node,
      highlighted_nodes=highlighted_nodes,
      highlight_css=highlight_css,
      title=title or None,
      edge_labels=edge_labels,
      notes=notes,
      direction=direction,
    )
  def mermaid_image(
    self, infer_name: bool = True, **kwargs: typing_extensions.Unpack[mermaid.MermaidConfig]
  ) -> bytes:
"""Generate a diagram representing the graph as an image.
    The format and diagram can be customized using `kwargs`,
    see [`pydantic_graph.mermaid.MermaidConfig`][pydantic_graph.mermaid.MermaidConfig].
    !!! note "Uses external service"
      This method makes a request to [mermaid.ink](https://mermaid.ink) to render the image, `mermaid.ink`
      is a free service not affiliated with Pydantic.
    Args:
      infer_name: Whether to infer the graph name from the calling frame.
      **kwargs: Additional arguments to pass to `mermaid.request_image`.
    Returns:
      The image bytes.
    """
    if infer_name and self.name is None:
      self._infer_name(inspect.currentframe())
    if 'title' not in kwargs and self.name:
      kwargs['title'] = self.name
    return mermaid.request_image(self, **kwargs)
  def mermaid_save(
    self, path: Path | str, /, *, infer_name: bool = True, **kwargs: typing_extensions.Unpack[mermaid.MermaidConfig]
  ) -> None:
"""Generate a diagram representing the graph and save it as an image.
    The format and diagram can be customized using `kwargs`,
    see [`pydantic_graph.mermaid.MermaidConfig`][pydantic_graph.mermaid.MermaidConfig].
    !!! note "Uses external service"
      This method makes a request to [mermaid.ink](https://mermaid.ink) to render the image, `mermaid.ink`
      is a free service not affiliated with Pydantic.
    Args:
      path: The path to save the image to.
      infer_name: Whether to infer the graph name from the calling frame.
      **kwargs: Additional arguments to pass to `mermaid.save_image`.
    """
    if infer_name and self.name is None:
      self._infer_name(inspect.currentframe())
    if 'title' not in kwargs and self.name:
      kwargs['title'] = self.name
    mermaid.save_image(path, self, **kwargs)
  def _get_state_type(self) -> type[StateT]:
    if _utils.is_set(self._state_type):
      return self._state_type
    for node_def in self.node_defs.values():
      for base in typing_extensions.get_original_bases(node_def.node):
        if typing_extensions.get_origin(base) is BaseNode:
          args = typing_extensions.get_args(base)
          if args:
            return args[0]
          # break the inner (bases) loop
          break
    # state defaults to None, so use that if we can't infer it
    return type(None) # pyright: ignore[reportReturnType]
  def _get_run_end_type(self) -> type[RunEndT]:
    if _utils.is_set(self._run_end_type):
      return self._run_end_type
    for node_def in self.node_defs.values():
      for base in typing_extensions.get_original_bases(node_def.node):
        if typing_extensions.get_origin(base) is BaseNode:
          args = typing_extensions.get_args(base)
          if len(args) == 3:
            t = args[2]
            if not _utils.is_never(t):
              return t
          # break the inner (bases) loop
          break
    raise exceptions.GraphSetupError('Could not infer run end type from nodes, please set `run_end_type`.')
  def _register_node(
    self: Graph[StateT, DepsT, T],
    node: type[BaseNode[StateT, DepsT, T]],
    parent_namespace: dict[str, Any] | None,
  ) -> None:
    node_id = node.get_id()
    if existing_node := self.node_defs.get(node_id):
      raise exceptions.GraphSetupError(
        f'Node ID `{node_id}` is not unique — found on {existing_node.node} and {node}'
      )
    else:
      self.node_defs[node_id] = node.get_node_def(parent_namespace)
  def _validate_edges(self):
    known_node_ids = self.node_defs.keys()
    bad_edges: dict[str, list[str]] = {}
    for node_id, node_def in self.node_defs.items():
      for edge in node_def.next_node_edges.keys():
        if edge not in known_node_ids:
          bad_edges.setdefault(edge, []).append(f'`{node_id}`')
    if bad_edges:
      bad_edges_list = [f'`{k}` is referenced by {_utils.comma_and(v)}' for k, v in bad_edges.items()]
      if len(bad_edges_list) == 1:
        raise exceptions.GraphSetupError(f'{bad_edges_list[0]} but not included in the graph.')
      else:
        b = '\n'.join(f' {be}' for be in bad_edges_list)
        raise exceptions.GraphSetupError(
          f'Nodes are referenced in the graph but not included in the graph:\n{b}'
        )
  def _infer_name(self, function_frame: types.FrameType | None) -> None:
"""Infer the agent name from the call frame.
    Usage should be `self._infer_name(inspect.currentframe())`.
    Copied from `Agent`.
    """
    assert self.name is None, 'Name already set'
    if function_frame is not None and (parent_frame := function_frame.f_back): # pragma: no branch
      for name, item in parent_frame.f_locals.items():
        if item is self:
          self.name = name
          return
      if parent_frame.f_locals != parent_frame.f_globals:
        # if we couldn't find the agent in locals and globals are a different dict, try globals
        for name, item in parent_frame.f_globals.items():
          if item is self:
            self.name = name
            return

```
  
---|---  
####  __init__
```
__init__(
  *,
  nodes: Sequence[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[type[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#type>)[BaseNode[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.BaseNode> "pydantic_graph.nodes.BaseNode")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")]]],
  name: str[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None,
  state_type: type[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#type>)[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")] | Unset = UNSET,
  run_end_type: type[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#type>)[RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")] | Unset = UNSET,
  snapshot_state: Callable[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[
    [StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")], StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")
  ] = deep_copy_state[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.deep_copy_state> "pydantic_graph.state.deep_copy_state"),
  auto_instrument: bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>) = True
)

```

Create a graph from a sequence of nodes.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`nodes` |  `Sequence[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[type[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#type>)[BaseNode[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.BaseNode> "pydantic_graph.nodes.BaseNode")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")]]]` |  The nodes which make up the graph, nodes need to be unique and all be generic in the same state type. |  _required_  
`name` |  `str[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  Optional name for the graph, if not provided the name will be inferred from the calling frame on the first call to a graph method. |  `None`  
`state_type` |  `type[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#type>)[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")] | Unset` |  The type of the state for the graph, this can generally be inferred from `nodes`. |  `UNSET`  
`run_end_type` |  `type[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#type>)[RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")] | Unset` |  The type of the result of running the graph, this can generally be inferred from `nodes`. |  `UNSET`  
`snapshot_state` |  `Callable[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")], StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")]` |  A function to snapshot the state of the graph, this is used in `NodeStep`[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.NodeStep>) and `EndStep`[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.EndStep>) to record the state before each step. |  `deep_copy_state[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.deep_copy_state> "pydantic_graph.state.deep_copy_state")`  
`auto_instrument` |  `bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to create a span for the graph run and the execution of each node's run method. |  `True`  
Source code in `pydantic_graph/pydantic_graph/graph.py`
```
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
```
| ```
def __init__(
  self,
  *,
  nodes: Sequence[type[BaseNode[StateT, DepsT, RunEndT]]],
  name: str | None = None,
  state_type: type[StateT] | _utils.Unset = _utils.UNSET,
  run_end_type: type[RunEndT] | _utils.Unset = _utils.UNSET,
  snapshot_state: Callable[[StateT], StateT] = deep_copy_state,
  auto_instrument: bool = True,
):
"""Create a graph from a sequence of nodes.
  Args:
    nodes: The nodes which make up the graph, nodes need to be unique and all be generic in the same
      state type.
    name: Optional name for the graph, if not provided the name will be inferred from the calling frame
      on the first call to a graph method.
    state_type: The type of the state for the graph, this can generally be inferred from `nodes`.
    run_end_type: The type of the result of running the graph, this can generally be inferred from `nodes`.
    snapshot_state: A function to snapshot the state of the graph, this is used in
      [`NodeStep`][pydantic_graph.state.NodeStep] and [`EndStep`][pydantic_graph.state.EndStep] to record
      the state before each step.
    auto_instrument: Whether to create a span for the graph run and the execution of each node's run method.
  """
  self.name = name
  self._state_type = state_type
  self._run_end_type = run_end_type
  self._auto_instrument = auto_instrument
  self.snapshot_state = snapshot_state
  parent_namespace = _utils.get_parent_namespace(inspect.currentframe())
  self.node_defs: dict[str, NodeDef[StateT, DepsT, RunEndT]] = {}
  for node in nodes:
    self._register_node(node, parent_namespace)
  self._validate_edges()

```
  
---|---  
####  run `async`
```
run(
  start_node: BaseNode[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.BaseNode> "pydantic_graph.nodes.BaseNode")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), T],
  *,
  state: StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT") = None,
  deps: DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT") = None,
  infer_name: bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>) = True
) -> tuple[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#tuple>)[T, list[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#list>)[HistoryStep[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.HistoryStep> "pydantic_graph.state.HistoryStep")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), T]]]

```

Run the graph from a starting node until it ends.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`start_node` |  `BaseNode[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.BaseNode> "pydantic_graph.nodes.BaseNode")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), T]` |  the first node to run, since the graph definition doesn't define the entry point in the graph, you need to provide the starting node. |  _required_  
`state` |  `StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")` |  The initial state of the graph. |  `None`  
`deps` |  `DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT")` |  The dependencies of the graph. |  `None`  
`infer_name` |  `bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to infer the graph name from the calling frame. |  `True`  
Returns:
Type | Description  
---|---  
`tuple[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#tuple>)[T, list[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#list>)[HistoryStep[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.HistoryStep> "pydantic_graph.state.HistoryStep")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), T]]]` |  The result type from ending the run and the history of the run.  
Here's an example of running the graph from [above](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph>):
run_never_42.py```
from never_42 import Increment, MyState, never_42_graph
async def main():
  state = MyState(1)
  _, history = await never_42_graph.run(Increment(), state=state)
  print(state)
  #> MyState(number=2)
  print(len(history))
  #> 3
  state = MyState(41)
  _, history = await never_42_graph.run(Increment(), state=state)
  print(state)
  #> MyState(number=43)
  print(len(history))
  #> 5

```

Source code in `pydantic_graph/pydantic_graph/graph.py`
```
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
```
| ```
async def run(
  self: Graph[StateT, DepsT, T],
  start_node: BaseNode[StateT, DepsT, T],
  *,
  state: StateT = None,
  deps: DepsT = None,
  infer_name: bool = True,
) -> tuple[T, list[HistoryStep[StateT, T]]]:
"""Run the graph from a starting node until it ends.
  Args:
    start_node: the first node to run, since the graph definition doesn't define the entry point in the graph,
      you need to provide the starting node.
    state: The initial state of the graph.
    deps: The dependencies of the graph.
    infer_name: Whether to infer the graph name from the calling frame.
  Returns:
    The result type from ending the run and the history of the run.
  Here's an example of running the graph from [above][pydantic_graph.graph.Graph]:
  ```py {title="run_never_42.py" noqa="I001" py="3.10"}
  from never_42 import Increment, MyState, never_42_graph
  async def main():
    state = MyState(1)
    _, history = await never_42_graph.run(Increment(), state=state)
    print(state)
    #> MyState(number=2)
    print(len(history))
    #> 3
    state = MyState(41)
    _, history = await never_42_graph.run(Increment(), state=state)
    print(state)
    #> MyState(number=43)
    print(len(history))
    #> 5
  ```
  """
  if infer_name and self.name is None:
    self._infer_name(inspect.currentframe())
  history: list[HistoryStep[StateT, T]] = []
  with ExitStack() as stack:
    run_span: logfire_api.LogfireSpan | None = None
    if self._auto_instrument:
      run_span = stack.enter_context(
        _logfire.span(
          '{graph_name} run {start=}',
          graph_name=self.name or 'graph',
          start=start_node,
        )
      )
  while True:
    next_node = await self.next(start_node, history, state=state, deps=deps, infer_name=False)
    if isinstance(next_node, End):
      history.append(EndStep(result=next_node))
      if run_span is not None:
        run_span.set_attribute('history', history)
      return next_node.data, history
    elif isinstance(next_node, BaseNode):
      start_node = next_node
    else:
      if TYPE_CHECKING:
        typing_extensions.assert_never(next_node)
      else:
        raise exceptions.GraphRuntimeError(
          f'Invalid node return type: `{type(next_node).__name__}`. Expected `BaseNode` or `End`.'
        )

```
  
---|---  
####  run_sync
```
run_sync(
  start_node: BaseNode[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.BaseNode> "pydantic_graph.nodes.BaseNode")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), T],
  *,
  state: StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT") = None,
  deps: DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT") = None,
  infer_name: bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>) = True
) -> tuple[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#tuple>)[T, list[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#list>)[HistoryStep[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.HistoryStep> "pydantic_graph.state.HistoryStep")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), T]]]

```

Run the graph synchronously.
This is a convenience method that wraps `self.run`[](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph.run>) with `loop.run_until_complete(...)`. You therefore can't use this method inside async code or if there's an active event loop.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`start_node` |  `BaseNode[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.BaseNode> "pydantic_graph.nodes.BaseNode")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), T]` |  the first node to run, since the graph definition doesn't define the entry point in the graph, you need to provide the starting node. |  _required_  
`state` |  `StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")` |  The initial state of the graph. |  `None`  
`deps` |  `DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT")` |  The dependencies of the graph. |  `None`  
`infer_name` |  `bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to infer the graph name from the calling frame. |  `True`  
Returns:
Type | Description  
---|---  
`tuple[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#tuple>)[T, list[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#list>)[HistoryStep[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.HistoryStep> "pydantic_graph.state.HistoryStep")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), T]]]` |  The result type from ending the run and the history of the run.  
Source code in `pydantic_graph/pydantic_graph/graph.py`
```
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
```
| ```
def run_sync(
  self: Graph[StateT, DepsT, T],
  start_node: BaseNode[StateT, DepsT, T],
  *,
  state: StateT = None,
  deps: DepsT = None,
  infer_name: bool = True,
) -> tuple[T, list[HistoryStep[StateT, T]]]:
"""Run the graph synchronously.
  This is a convenience method that wraps [`self.run`][pydantic_graph.Graph.run] with `loop.run_until_complete(...)`.
  You therefore can't use this method inside async code or if there's an active event loop.
  Args:
    start_node: the first node to run, since the graph definition doesn't define the entry point in the graph,
      you need to provide the starting node.
    state: The initial state of the graph.
    deps: The dependencies of the graph.
    infer_name: Whether to infer the graph name from the calling frame.
  Returns:
    The result type from ending the run and the history of the run.
  """
  if infer_name and self.name is None:
    self._infer_name(inspect.currentframe())
  return asyncio.get_event_loop().run_until_complete(
    self.run(start_node, state=state, deps=deps, infer_name=False)
  )

```
  
---|---  
####  next `async`
```
next(
  node: BaseNode[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.BaseNode> "pydantic_graph.nodes.BaseNode")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), T],
  history: list[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#list>)[HistoryStep[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.HistoryStep> "pydantic_graph.state.HistoryStep")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), T]],
  *,
  state: StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT") = None,
  deps: DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT") = None,
  infer_name: bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>) = True
) -> BaseNode[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.BaseNode> "pydantic_graph.nodes.BaseNode")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), Any[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")] | End[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.End> "pydantic_graph.nodes.End")[T]

```

Run a node in the graph and return the next node to run.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`node` |  `BaseNode[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.BaseNode> "pydantic_graph.nodes.BaseNode")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), T]` |  The node to run. |  _required_  
`history` |  `list[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#list>)[HistoryStep[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.HistoryStep> "pydantic_graph.state.HistoryStep")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), T]]` |  The history of the graph run so far. NOTE: this will be mutated to add the new step. |  _required_  
`state` |  `StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")` |  The current state of the graph. |  `None`  
`deps` |  `DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT")` |  The dependencies of the graph. |  `None`  
`infer_name` |  `bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to infer the graph name from the calling frame. |  `True`  
Returns:
Type | Description  
---|---  
`BaseNode[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.BaseNode> "pydantic_graph.nodes.BaseNode")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), Any[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")] | End[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.End> "pydantic_graph.nodes.End")[T]` |  The next node to run or `End`[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.End>) if the graph has finished.  
Source code in `pydantic_graph/pydantic_graph/graph.py`
```
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
```
| ```
async def next(
  self: Graph[StateT, DepsT, T],
  node: BaseNode[StateT, DepsT, T],
  history: list[HistoryStep[StateT, T]],
  *,
  state: StateT = None,
  deps: DepsT = None,
  infer_name: bool = True,
) -> BaseNode[StateT, DepsT, Any] | End[T]:
"""Run a node in the graph and return the next node to run.
  Args:
    node: The node to run.
    history: The history of the graph run so far. NOTE: this will be mutated to add the new step.
    state: The current state of the graph.
    deps: The dependencies of the graph.
    infer_name: Whether to infer the graph name from the calling frame.
  Returns:
    The next node to run or [`End`][pydantic_graph.nodes.End] if the graph has finished.
  """
  if infer_name and self.name is None:
    self._infer_name(inspect.currentframe())
  node_id = node.get_id()
  if node_id not in self.node_defs:
    raise exceptions.GraphRuntimeError(f'Node `{node}` is not in the graph.')
  with ExitStack() as stack:
    if self._auto_instrument:
      stack.enter_context(_logfire.span('run node {node_id}', node_id=node_id, node=node))
    ctx = GraphRunContext(state, deps)
    start_ts = _utils.now_utc()
    start = perf_counter()
    next_node = await node.run(ctx)
    duration = perf_counter() - start
  history.append(
    NodeStep(state=state, node=node, start_ts=start_ts, duration=duration, snapshot_state=self.snapshot_state)
  )
  return next_node

```
  
---|---  
####  dump_history
```
dump_history(
  history: list[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#list>)[HistoryStep[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.HistoryStep> "pydantic_graph.state.HistoryStep")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), T]],
  *,
  indent: int[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#int>) | None = None
) -> bytes[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#bytes>)

```

Dump the history of a graph run as JSON.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`history` |  `list[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#list>)[HistoryStep[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.HistoryStep> "pydantic_graph.state.HistoryStep")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), T]]` |  The history of the graph run. |  _required_  
`indent` |  `int[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#int>) | None` |  The number of spaces to indent the JSON. |  `None`  
Returns:
Type | Description  
---|---  
`bytes[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#bytes>)` |  The JSON representation of the history.  
Source code in `pydantic_graph/pydantic_graph/graph.py`
```
271
272
273
274
275
276
277
278
279
280
281
282
283
```
| ```
def dump_history(
  self: Graph[StateT, DepsT, T], history: list[HistoryStep[StateT, T]], *, indent: int | None = None
) -> bytes:
"""Dump the history of a graph run as JSON.
  Args:
    history: The history of the graph run.
    indent: The number of spaces to indent the JSON.
  Returns:
    The JSON representation of the history.
  """
  return self.history_type_adapter.dump_json(history, indent=indent)

```
  
---|---  
####  load_history
```
load_history(
  json_bytes: str[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#str>) | bytes[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#bytes>) | bytearray[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#bytearray>),
) -> list[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#list>)[HistoryStep[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.HistoryStep> "pydantic_graph.state.HistoryStep")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")]]

```

Load the history of a graph run from JSON.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`json_bytes` |  `str[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#str>) | bytes[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#bytes>) | bytearray[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#bytearray>)` |  The JSON representation of the history. |  _required_  
Returns:
Type | Description  
---|---  
`list[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#list>)[HistoryStep[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.HistoryStep> "pydantic_graph.state.HistoryStep")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")]]` |  The history of the graph run.  
Source code in `pydantic_graph/pydantic_graph/graph.py`
```
285
286
287
288
289
290
291
292
293
294
```
| ```
def load_history(self, json_bytes: str | bytes | bytearray) -> list[HistoryStep[StateT, RunEndT]]:
"""Load the history of a graph run from JSON.
  Args:
    json_bytes: The JSON representation of the history.
  Returns:
    The history of the graph run.
  """
  return self.history_type_adapter.validate_json(json_bytes)

```
  
---|---  
####  mermaid_code
```
mermaid_code(
  *,
  start_node: (
    Sequence[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent")] | NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent") | None
  ) = None,
  title: str[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#str>) | None | Literal[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.Literal> "typing_extensions.Literal")[False] = None,
  edge_labels: bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>) = True,
  notes: bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>) = True,
  highlighted_nodes: (
    Sequence[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent")] | NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent") | None
  ) = None,
  highlight_css: str[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#str>) = DEFAULT_HIGHLIGHT_CSS[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.DEFAULT_HIGHLIGHT_CSS> "pydantic_graph.mermaid.DEFAULT_HIGHLIGHT_CSS"),
  infer_name: bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>) = True,
  direction: StateDiagramDirection[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.StateDiagramDirection> "pydantic_graph.mermaid.StateDiagramDirection") | None = None
) -> str[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

Generate a diagram representing the graph as [mermaid](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/mermaid.js.org/>) diagram.
This method calls `pydantic_graph.mermaid.generate_code`[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.generate_code>).
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`start_node` |  `Sequence[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent")] | NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent") | None` |  The node or nodes which can start the graph. |  `None`  
`title` |  `str[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#str>) | None | Literal[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.Literal> "typing_extensions.Literal")[False]` |  The title of the diagram, use `False` to not include a title. |  `None`  
`edge_labels` |  `bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to include edge labels. |  `True`  
`notes` |  `bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to include notes on each node. |  `True`  
`highlighted_nodes` |  `Sequence[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent")] | NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent") | None` |  Optional node or nodes to highlight. |  `None`  
`highlight_css` |  `str[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  The CSS to use for highlighting nodes. |  `DEFAULT_HIGHLIGHT_CSS[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.DEFAULT_HIGHLIGHT_CSS> "pydantic_graph.mermaid.DEFAULT_HIGHLIGHT_CSS")`  
`infer_name` |  `bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to infer the graph name from the calling frame. |  `True`  
`direction` |  `StateDiagramDirection[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.StateDiagramDirection> "pydantic_graph.mermaid.StateDiagramDirection") | None` |  The direction of flow. |  `None`  
Returns:
Type | Description  
---|---  
`str[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  The mermaid code for the graph, which can then be rendered as a diagram.  
Here's an example of generating a diagram for the graph from [above](https://ai.pydantic.dev/api/pydantic_graph/graph/<#pydantic_graph.graph.Graph>):
never_42.py```
from never_42 import Increment, never_42_graph
print(never_42_graph.mermaid_code(start_node=Increment))
'''
---
title: never_42_graph
---
stateDiagram-v2
 [*] --> Increment
 Increment --> Check42
 Check42 --> Increment
 Check42 --> [*]
'''

```

The rendered diagram will look like this:
```
---
title: never_42_graph
---
stateDiagram-v2
 [*] --> Increment
 Increment --> Check42
 Check42 --> Increment
 Check42 --> [*]
```
Source code in `pydantic_graph/pydantic_graph/graph.py`
```
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
```
| ```
def mermaid_code(
  self,
  *,
  start_node: Sequence[mermaid.NodeIdent] | mermaid.NodeIdent | None = None,
  title: str | None | typing_extensions.Literal[False] = None,
  edge_labels: bool = True,
  notes: bool = True,
  highlighted_nodes: Sequence[mermaid.NodeIdent] | mermaid.NodeIdent | None = None,
  highlight_css: str = mermaid.DEFAULT_HIGHLIGHT_CSS,
  infer_name: bool = True,
  direction: mermaid.StateDiagramDirection | None = None,
) -> str:
"""Generate a diagram representing the graph as [mermaid](https://mermaid.js.org/) diagram.
  This method calls [`pydantic_graph.mermaid.generate_code`][pydantic_graph.mermaid.generate_code].
  Args:
    start_node: The node or nodes which can start the graph.
    title: The title of the diagram, use `False` to not include a title.
    edge_labels: Whether to include edge labels.
    notes: Whether to include notes on each node.
    highlighted_nodes: Optional node or nodes to highlight.
    highlight_css: The CSS to use for highlighting nodes.
    infer_name: Whether to infer the graph name from the calling frame.
    direction: The direction of flow.
  Returns:
    The mermaid code for the graph, which can then be rendered as a diagram.
  Here's an example of generating a diagram for the graph from [above][pydantic_graph.graph.Graph]:
  ```py {title="never_42.py" py="3.10"}
  from never_42 import Increment, never_42_graph
  print(never_42_graph.mermaid_code(start_node=Increment))
  '''
  ---
  title: never_42_graph
  ---
  stateDiagram-v2
   [*] --> Increment
   Increment --> Check42
   Check42 --> Increment
   Check42 --> [*]
  '''
  ```
  The rendered diagram will look like this:
  ```mermaid
  ---
  title: never_42_graph
  ---
  stateDiagram-v2
   [*] --> Increment
   Increment --> Check42
   Check42 --> Increment
   Check42 --> [*]
  ```
  """
  if infer_name and self.name is None:
    self._infer_name(inspect.currentframe())
  if title is None and self.name:
    title = self.name
  return mermaid.generate_code(
    self,
    start_node=start_node,
    highlighted_nodes=highlighted_nodes,
    highlight_css=highlight_css,
    title=title or None,
    edge_labels=edge_labels,
    notes=notes,
    direction=direction,
  )

```
  
---|---  
####  mermaid_image
```
mermaid_image(
  infer_name: bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>) = True, **kwargs: Unpack[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.Unpack> "typing_extensions.Unpack")[MermaidConfig[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.MermaidConfig> "pydantic_graph.mermaid.MermaidConfig")]
) -> bytes[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#bytes>)

```

Generate a diagram representing the graph as an image.
The format and diagram can be customized using `kwargs`, see `pydantic_graph.mermaid.MermaidConfig`[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.MermaidConfig>).
Uses external service
This method makes a request to [mermaid.ink](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/mermaid.ink>) to render the image, `mermaid.ink` is a free service not affiliated with Pydantic.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`infer_name` |  `bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to infer the graph name from the calling frame. |  `True`  
`**kwargs` |  `Unpack[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.Unpack> "typing_extensions.Unpack")[MermaidConfig[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.MermaidConfig> "pydantic_graph.mermaid.MermaidConfig")]` |  Additional arguments to pass to `mermaid.request_image`. |  `{}`  
Returns:
Type | Description  
---|---  
`bytes[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#bytes>)` |  The image bytes.  
Source code in `pydantic_graph/pydantic_graph/graph.py`
```
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
```
| ```
def mermaid_image(
  self, infer_name: bool = True, **kwargs: typing_extensions.Unpack[mermaid.MermaidConfig]
) -> bytes:
"""Generate a diagram representing the graph as an image.
  The format and diagram can be customized using `kwargs`,
  see [`pydantic_graph.mermaid.MermaidConfig`][pydantic_graph.mermaid.MermaidConfig].
  !!! note "Uses external service"
    This method makes a request to [mermaid.ink](https://mermaid.ink) to render the image, `mermaid.ink`
    is a free service not affiliated with Pydantic.
  Args:
    infer_name: Whether to infer the graph name from the calling frame.
    **kwargs: Additional arguments to pass to `mermaid.request_image`.
  Returns:
    The image bytes.
  """
  if infer_name and self.name is None:
    self._infer_name(inspect.currentframe())
  if 'title' not in kwargs and self.name:
    kwargs['title'] = self.name
  return mermaid.request_image(self, **kwargs)

```
  
---|---  
####  mermaid_save
```
mermaid_save(
  path: Path[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/pathlib.html#pathlib.Path> "pathlib.Path") | str[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#str>),
  /,
  *,
  infer_name: bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>) = True,
  **kwargs: Unpack[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.Unpack> "typing_extensions.Unpack")[MermaidConfig[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.MermaidConfig> "pydantic_graph.mermaid.MermaidConfig")],
) -> None

```

Generate a diagram representing the graph and save it as an image.
The format and diagram can be customized using `kwargs`, see `pydantic_graph.mermaid.MermaidConfig`[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.MermaidConfig>).
Uses external service
This method makes a request to [mermaid.ink](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/mermaid.ink>) to render the image, `mermaid.ink` is a free service not affiliated with Pydantic.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`path` |  `Path[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/pathlib.html#pathlib.Path> "pathlib.Path") | str[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  The path to save the image to. |  _required_  
`infer_name` |  `bool[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to infer the graph name from the calling frame. |  `True`  
`**kwargs` |  `Unpack[](https://ai.pydantic.dev/api/pydantic_graph/graph/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.Unpack> "typing_extensions.Unpack")[MermaidConfig[](https://ai.pydantic.dev/api/pydantic_graph/graph/<../mermaid/#pydantic_graph.mermaid.MermaidConfig> "pydantic_graph.mermaid.MermaidConfig")]` |  Additional arguments to pass to `mermaid.save_image`. |  `{}`  
Source code in `pydantic_graph/pydantic_graph/graph.py`
```
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
```
| ```
def mermaid_save(
  self, path: Path | str, /, *, infer_name: bool = True, **kwargs: typing_extensions.Unpack[mermaid.MermaidConfig]
) -> None:
"""Generate a diagram representing the graph and save it as an image.
  The format and diagram can be customized using `kwargs`,
  see [`pydantic_graph.mermaid.MermaidConfig`][pydantic_graph.mermaid.MermaidConfig].
  !!! note "Uses external service"
    This method makes a request to [mermaid.ink](https://mermaid.ink) to render the image, `mermaid.ink`
    is a free service not affiliated with Pydantic.
  Args:
    path: The path to save the image to.
    infer_name: Whether to infer the graph name from the calling frame.
    **kwargs: Additional arguments to pass to `mermaid.save_image`.
  """
  if infer_name and self.name is None:
    self._infer_name(inspect.currentframe())
  if 'title' not in kwargs and self.name:
    kwargs['title'] = self.name
  mermaid.save_image(path, self, **kwargs)

```
  
---|---  
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_pydantic_graph_mermaid.md
================
[ Skip to content ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graphmermaid>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/..> "PydanticAI")
PydanticAI 
pydantic_graph.mermaid 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/pydantic_graph/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/pydantic_graph/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/pydantic_graph/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/pydantic_graph/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/pydantic_graph/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/pydantic_graph/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/pydantic_graph/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/pydantic_graph/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/pydantic_graph/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/pydantic_graph/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/pydantic_graph/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/pydantic_graph/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/pydantic_graph/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/pydantic_graph/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/pydantic_graph/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/pydantic_graph/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/pydantic_graph/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/pydantic_graph/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/pydantic_graph/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/pydantic_graph/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/pydantic_graph/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/pydantic_graph/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/pydantic_graph/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/pydantic_graph/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/pydantic_graph/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<../graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<../nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<../state/>)
    * pydantic_graph.mermaid  [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<./>) Table of contents 
      * [ mermaid  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid>)
      * [ DEFAULT_HIGHLIGHT_CSS  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.DEFAULT_HIGHLIGHT_CSS>)
      * [ StateDiagramDirection  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.StateDiagramDirection>)
      * [ generate_code  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.generate_code>)
      * [ request_image  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.request_image>)
      * [ save_image  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.save_image>)
      * [ MermaidConfig  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig>)
        * [ start_node  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.start_node>)
        * [ highlighted_nodes  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.highlighted_nodes>)
        * [ highlight_css  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.highlight_css>)
        * [ title  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.title>)
        * [ edge_labels  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.edge_labels>)
        * [ notes  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.notes>)
        * [ image_type  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.image_type>)
        * [ pdf_fit  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.pdf_fit>)
        * [ pdf_landscape  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.pdf_landscape>)
        * [ pdf_paper  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.pdf_paper>)
        * [ background_color  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.background_color>)
        * [ theme  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.theme>)
        * [ width  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.width>)
        * [ height  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.height>)
        * [ scale  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.scale>)
        * [ httpx_client  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.httpx_client>)
        * [ direction  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.direction>)
      * [ NodeIdent  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.NodeIdent>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<../exceptions/>)


Table of contents 
  * [ mermaid  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid>)
  * [ DEFAULT_HIGHLIGHT_CSS  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.DEFAULT_HIGHLIGHT_CSS>)
  * [ StateDiagramDirection  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.StateDiagramDirection>)
  * [ generate_code  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.generate_code>)
  * [ request_image  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.request_image>)
  * [ save_image  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.save_image>)
  * [ MermaidConfig  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig>)
    * [ start_node  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.start_node>)
    * [ highlighted_nodes  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.highlighted_nodes>)
    * [ highlight_css  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.highlight_css>)
    * [ title  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.title>)
    * [ edge_labels  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.edge_labels>)
    * [ notes  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.notes>)
    * [ image_type  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.image_type>)
    * [ pdf_fit  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.pdf_fit>)
    * [ pdf_landscape  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.pdf_landscape>)
    * [ pdf_paper  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.pdf_paper>)
    * [ background_color  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.background_color>)
    * [ theme  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.theme>)
    * [ width  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.width>)
    * [ height  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.height>)
    * [ scale  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.scale>)
    * [ httpx_client  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.httpx_client>)
    * [ direction  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig.direction>)
  * [ NodeIdent  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.NodeIdent>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_graph.mermaid`
###  DEFAULT_HIGHLIGHT_CSS `module-attribute`
```
DEFAULT_HIGHLIGHT_CSS = 'fill:#fdff32'

```

The default CSS to use for highlighting nodes.
###  StateDiagramDirection `module-attribute`
```
StateDiagramDirection = Literal[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['TB', 'LR', 'RL', 'BT']

```

Used to specify the direction of the state diagram generated by mermaid.
  * `'TB'`: Top to bottom, this is the default for mermaid charts.
  * `'LR'`: Left to right
  * `'RL'`: Right to left
  * `'BT'`: Bottom to top


###  generate_code
```
generate_code(
  graph: Graph[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<../graph/#pydantic_graph.graph.Graph> "pydantic_graph.graph.Graph")[Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"), Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"), Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")],
  /,
  *,
  start_node: (
    Sequence[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent")] | NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent") | None
  ) = None,
  highlighted_nodes: (
    Sequence[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent")] | NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent") | None
  ) = None,
  highlight_css: str[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/stdtypes.html#str>) = DEFAULT_HIGHLIGHT_CSS[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.DEFAULT_HIGHLIGHT_CSS> "pydantic_graph.mermaid.DEFAULT_HIGHLIGHT_CSS"),
  title: str[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None,
  edge_labels: bool[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/functions.html#bool>) = True,
  notes: bool[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/functions.html#bool>) = True,
  direction: StateDiagramDirection[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.StateDiagramDirection> "pydantic_graph.mermaid.StateDiagramDirection") | None,
) -> str[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

Generate [Mermaid state diagram](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/mermaid.js.org/syntax/stateDiagram.html>) code for a graph.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`graph` |  `Graph[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<../graph/#pydantic_graph.graph.Graph> "pydantic_graph.graph.Graph")[Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"), Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"), Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")]` |  The graph to generate the image for. |  _required_  
`start_node` |  `Sequence[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent")] | NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent") | None` |  Identifiers of nodes that start the graph. |  `None`  
`highlighted_nodes` |  `Sequence[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent")] | NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent") | None` |  Identifiers of nodes to highlight. |  `None`  
`highlight_css` |  `str[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  CSS to use for highlighting nodes. |  `DEFAULT_HIGHLIGHT_CSS[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.DEFAULT_HIGHLIGHT_CSS> "pydantic_graph.mermaid.DEFAULT_HIGHLIGHT_CSS")`  
`title` |  `str[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The title of the diagram. |  `None`  
`edge_labels` |  `bool[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to include edge labels in the diagram. |  `True`  
`notes` |  `bool[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/functions.html#bool>)` |  Whether to include notes in the diagram. |  `True`  
`direction` |  `StateDiagramDirection[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.StateDiagramDirection> "pydantic_graph.mermaid.StateDiagramDirection") | None` |  The direction of flow. |  _required_  
Returns:
Type | Description  
---|---  
`str[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  The Mermaid code for the graph.  
Source code in `pydantic_graph/pydantic_graph/mermaid.py`
```
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
```
| ```
def generate_code( # noqa: C901
  graph: Graph[Any, Any, Any],
  /,
  *,
  start_node: Sequence[NodeIdent] | NodeIdent | None = None,
  highlighted_nodes: Sequence[NodeIdent] | NodeIdent | None = None,
  highlight_css: str = DEFAULT_HIGHLIGHT_CSS,
  title: str | None = None,
  edge_labels: bool = True,
  notes: bool = True,
  direction: StateDiagramDirection | None,
) -> str:
"""Generate [Mermaid state diagram](https://mermaid.js.org/syntax/stateDiagram.html) code for a graph.
  Args:
    graph: The graph to generate the image for.
    start_node: Identifiers of nodes that start the graph.
    highlighted_nodes: Identifiers of nodes to highlight.
    highlight_css: CSS to use for highlighting nodes.
    title: The title of the diagram.
    edge_labels: Whether to include edge labels in the diagram.
    notes: Whether to include notes in the diagram.
    direction: The direction of flow.

  Returns:
    The Mermaid code for the graph.
  """
  start_node_ids = set(_node_ids(start_node or ()))
  for node_id in start_node_ids:
    if node_id not in graph.node_defs:
      raise LookupError(f'Start node "{node_id}" is not in the graph.')
  lines: list[str] = []
  if title:
    lines = ['---', f'title: {title}', '---']
  lines.append('stateDiagram-v2')
  if direction is not None:
    lines.append(f' direction {direction}')
  for node_id, node_def in graph.node_defs.items():
    # we use round brackets (rounded box) for nodes other than the start and end
    if node_id in start_node_ids:
      lines.append(f' [*] --> {node_id}')
    if node_def.returns_base_node:
      for next_node_id in graph.node_defs:
        lines.append(f' {node_id} --> {next_node_id}')
    else:
      for next_node_id, edge in node_def.next_node_edges.items():
        line = f' {node_id} --> {next_node_id}'
        if edge_labels and edge.label:
          line += f': {edge.label}'
        lines.append(line)
    if end_edge := node_def.end_edge:
      line = f' {node_id} --> [*]'
      if edge_labels and end_edge.label:
        line += f': {end_edge.label}'
      lines.append(line)
    if notes and node_def.note:
      lines.append(f' note right of {node_id}')
      # mermaid doesn't like multiple paragraphs in a note, and shows if so
      clean_docs = re.sub('\n{2,}', '\n', node_def.note)
      lines.append(indent(clean_docs, '  '))
      lines.append(' end note')
  if highlighted_nodes:
    lines.append('')
    lines.append(f'classDef highlighted {highlight_css}')
    for node_id in _node_ids(highlighted_nodes):
      if node_id not in graph.node_defs:
        raise LookupError(f'Highlighted node "{node_id}" is not in the graph.')
      lines.append(f'class {node_id} highlighted')
  return '\n'.join(lines)

```
  
---|---  
###  request_image
```
request_image(
  graph: Graph[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<../graph/#pydantic_graph.graph.Graph> "pydantic_graph.graph.Graph")[Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"), Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"), Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")],
  /,
  **kwargs: Unpack[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.Unpack> "typing_extensions.Unpack")[MermaidConfig[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig> "pydantic_graph.mermaid.MermaidConfig")],
) -> bytes[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/stdtypes.html#bytes>)

```

Generate an image of a Mermaid diagram using [mermaid.ink](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/mermaid.ink>).
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`graph` |  `Graph[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<../graph/#pydantic_graph.graph.Graph> "pydantic_graph.graph.Graph")[Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"), Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"), Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")]` |  The graph to generate the image for. |  _required_  
`**kwargs` |  `Unpack[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.Unpack> "typing_extensions.Unpack")[MermaidConfig[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig> "pydantic_graph.mermaid.MermaidConfig")]` |  Additional parameters to configure mermaid chart generation. |  `{}`  
Returns:
Type | Description  
---|---  
`bytes[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/stdtypes.html#bytes>)` |  The image data.  
Source code in `pydantic_graph/pydantic_graph/mermaid.py`
```
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
```
| ```
def request_image(
  graph: Graph[Any, Any, Any],
  /,
  **kwargs: Unpack[MermaidConfig],
) -> bytes:
"""Generate an image of a Mermaid diagram using [mermaid.ink](https://mermaid.ink).
  Args:
    graph: The graph to generate the image for.
    **kwargs: Additional parameters to configure mermaid chart generation.
  Returns:
    The image data.
  """
  code = generate_code(
    graph,
    start_node=kwargs.get('start_node'),
    highlighted_nodes=kwargs.get('highlighted_nodes'),
    highlight_css=kwargs.get('highlight_css', DEFAULT_HIGHLIGHT_CSS),
    title=kwargs.get('title'),
    edge_labels=kwargs.get('edge_labels', True),
    notes=kwargs.get('notes', True),
    direction=kwargs.get('direction'),
  )
  code_base64 = base64.b64encode(code.encode()).decode()
  params: dict[str, str | float] = {}
  if kwargs.get('image_type') == 'pdf':
    url = f'https://mermaid.ink/pdf/{code_base64}'
    if kwargs.get('pdf_fit'):
      params['fit'] = ''
    if kwargs.get('pdf_landscape'):
      params['landscape'] = ''
    if pdf_paper := kwargs.get('pdf_paper'):
      params['paper'] = pdf_paper
  elif kwargs.get('image_type') == 'svg':
    url = f'https://mermaid.ink/svg/{code_base64}'
  else:
    url = f'https://mermaid.ink/img/{code_base64}'
    if image_type := kwargs.get('image_type'):
      params['type'] = image_type
  if background_color := kwargs.get('background_color'):
    params['bgColor'] = background_color
  if theme := kwargs.get('theme'):
    params['theme'] = theme
  if width := kwargs.get('width'):
    params['width'] = width
  if height := kwargs.get('height'):
    params['height'] = height
  if scale := kwargs.get('scale'):
    params['scale'] = scale
  httpx_client = kwargs.get('httpx_client') or httpx.Client()
  response = httpx_client.get(url, params=params)
  if not response.is_success:
    raise httpx.HTTPStatusError(
      f'{response.status_code} error generating image:\n{response.text}',
      request=response.request,
      response=response,
    )
  return response.content

```
  
---|---  
###  save_image
```
save_image(
  path: Path[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/pathlib.html#pathlib.Path> "pathlib.Path") | str[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/stdtypes.html#str>),
  graph: Graph[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<../graph/#pydantic_graph.graph.Graph> "pydantic_graph.graph.Graph")[Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"), Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"), Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")],
  /,
  **kwargs: Unpack[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.Unpack> "typing_extensions.Unpack")[MermaidConfig[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig> "pydantic_graph.mermaid.MermaidConfig")],
) -> None

```

Generate an image of a Mermaid diagram using [mermaid.ink](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/mermaid.ink>) and save it to a local file.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`path` |  `Path[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/pathlib.html#pathlib.Path> "pathlib.Path") | str[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/stdtypes.html#str>)` |  The path to save the image to. |  _required_  
`graph` |  `Graph[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<../graph/#pydantic_graph.graph.Graph> "pydantic_graph.graph.Graph")[Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"), Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"), Any[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")]` |  The graph to generate the image for. |  _required_  
`**kwargs` |  `Unpack[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.Unpack> "typing_extensions.Unpack")[MermaidConfig[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.MermaidConfig> "pydantic_graph.mermaid.MermaidConfig")]` |  Additional parameters to configure mermaid chart generation. |  `{}`  
Source code in `pydantic_graph/pydantic_graph/mermaid.py`
```
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
```
| ```
def save_image(
  path: Path | str,
  graph: Graph[Any, Any, Any],
  /,
  **kwargs: Unpack[MermaidConfig],
) -> None:
"""Generate an image of a Mermaid diagram using [mermaid.ink](https://mermaid.ink) and save it to a local file.
  Args:
    path: The path to save the image to.
    graph: The graph to generate the image for.
    **kwargs: Additional parameters to configure mermaid chart generation.
  """
  if isinstance(path, str):
    path = Path(path)
  if 'image_type' not in kwargs:
    ext = path.suffix.lower()[1:]
    # no need to check for .jpeg/.jpg, as it is the default
    if ext in ('png', 'webp', 'svg', 'pdf'):
      kwargs['image_type'] = ext
  image_data = request_image(graph, **kwargs)
  path.write_bytes(image_data)

```
  
---|---  
###  MermaidConfig
Bases: `TypedDict[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.TypedDict> "typing_extensions.TypedDict")`
Parameters to configure mermaid chart generation.
Source code in `pydantic_graph/pydantic_graph/mermaid.py`
```
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
```
| ```
class MermaidConfig(TypedDict, total=False):
"""Parameters to configure mermaid chart generation."""
  start_node: Sequence[NodeIdent] | NodeIdent
"""Identifiers of nodes that start the graph."""
  highlighted_nodes: Sequence[NodeIdent] | NodeIdent
"""Identifiers of nodes to highlight."""
  highlight_css: str
"""CSS to use for highlighting nodes."""
  title: str | None
"""The title of the diagram."""
  edge_labels: bool
"""Whether to include edge labels in the diagram."""
  notes: bool
"""Whether to include notes on nodes in the diagram, defaults to true."""
  image_type: Literal['jpeg', 'png', 'webp', 'svg', 'pdf']
"""The image type to generate. If unspecified, the default behavior is `'jpeg'`."""
  pdf_fit: bool
"""When using image_type='pdf', whether to fit the diagram to the PDF page."""
  pdf_landscape: bool
"""When using image_type='pdf', whether to use landscape orientation for the PDF.
  This has no effect if using `pdf_fit`.
  """
  pdf_paper: Literal['letter', 'legal', 'tabloid', 'ledger', 'a0', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6']
"""When using image_type='pdf', the paper size of the PDF."""
  background_color: str
"""The background color of the diagram.
  If None, the default transparent background is used. The color value is interpreted as a hexadecimal color
  code by default (and should not have a leading '#'), but you can also use named colors by prefixing the
  value with `'!'`. For example, valid choices include `background_color='!white'` or `background_color='FF0000'`.
  """
  theme: Literal['default', 'neutral', 'dark', 'forest']
"""The theme of the diagram. Defaults to 'default'."""
  width: int
"""The width of the diagram."""
  height: int
"""The height of the diagram."""
  scale: Annotated[float, Ge(1), Le(3)]
"""The scale of the diagram.
  The scale must be a number between 1 and 3, and you can only set a scale if one or both of width and height are set.
  """
  httpx_client: httpx.Client
"""An HTTPX client to use for requests, mostly for testing purposes."""
  direction: StateDiagramDirection
"""The direction of the state diagram."""

```
  
---|---  
####  start_node `instance-attribute`
```
start_node: Sequence[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent")] | NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent")

```

Identifiers of nodes that start the graph.
####  highlighted_nodes `instance-attribute`
```
highlighted_nodes: Sequence[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Sequence> "collections.abc.Sequence")[NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent")] | NodeIdent[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.NodeIdent> "pydantic_graph.mermaid.NodeIdent")

```

Identifiers of nodes to highlight.
####  highlight_css `instance-attribute`
```
highlight_css: str[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

CSS to use for highlighting nodes.
####  title `instance-attribute`
```
title: str[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/stdtypes.html#str>) | None

```

The title of the diagram.
####  edge_labels `instance-attribute`
```
edge_labels: bool[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/functions.html#bool>)

```

Whether to include edge labels in the diagram.
####  notes `instance-attribute`
```
notes: bool[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/functions.html#bool>)

```

Whether to include notes on nodes in the diagram, defaults to true.
####  image_type `instance-attribute`
```
image_type: Literal[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['jpeg', 'png', 'webp', 'svg', 'pdf']

```

The image type to generate. If unspecified, the default behavior is `'jpeg'`.
####  pdf_fit `instance-attribute`
```
pdf_fit: bool[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/functions.html#bool>)

```

When using image_type='pdf', whether to fit the diagram to the PDF page.
####  pdf_landscape `instance-attribute`
```
pdf_landscape: bool[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/functions.html#bool>)

```

When using image_type='pdf', whether to use landscape orientation for the PDF.
This has no effect if using `pdf_fit`.
####  pdf_paper `instance-attribute`
```
pdf_paper: Literal[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")[
  "letter",
  "legal",
  "tabloid",
  "ledger",
  "a0",
  "a1",
  "a2",
  "a3",
  "a4",
  "a5",
  "a6",
]

```

When using image_type='pdf', the paper size of the PDF.
####  background_color `instance-attribute`
```
background_color: str[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

The background color of the diagram.
If None, the default transparent background is used. The color value is interpreted as a hexadecimal color code by default (and should not have a leading '#'), but you can also use named colors by prefixing the value with `'!'`. For example, valid choices include `background_color='!white'` or `background_color='FF0000'`.
####  theme `instance-attribute`
```
theme: Literal[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['default', 'neutral', 'dark', 'forest']

```

The theme of the diagram. Defaults to 'default'.
####  width `instance-attribute`
```
width: int[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/functions.html#int>)

```

The width of the diagram.
####  height `instance-attribute`
```
height: int[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/functions.html#int>)

```

The height of the diagram.
####  scale `instance-attribute`
```
scale: Annotated[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/typing.html#typing.Annotated> "typing.Annotated")[float[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/docs.python.org/3/library/functions.html#float>), Ge(1), Le(3)]

```

The scale of the diagram.
The scale must be a number between 1 and 3, and you can only set a scale if one or both of width and height are set.
####  httpx_client `instance-attribute`
```
httpx_client: Client

```

An HTTPX client to use for requests, mostly for testing purposes.
####  direction `instance-attribute`
```
direction: StateDiagramDirection[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<#pydantic_graph.mermaid.StateDiagramDirection> "pydantic_graph.mermaid.StateDiagramDirection")

```

The direction of the state diagram.
###  NodeIdent `module-attribute`
```
NodeIdent: TypeAlias[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.TypeAlias> "typing_extensions.TypeAlias") = (
  "type[BaseNode[Any, Any, Any]] | BaseNode[Any, Any, Any] | str"
)

```

A type alias for a node identifier.
This can be:
  * A node instance (instance of a subclass of `BaseNode`[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<../nodes/#pydantic_graph.nodes.BaseNode>)).
  * A node class (subclass of `BaseNode`[](https://ai.pydantic.dev/api/pydantic_graph/mermaid/<../nodes/#pydantic_graph.nodes.BaseNode>)).
  * A string representing the node ID.


© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_pydantic_graph_nodes.md
================
[ Skip to content ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graphnodes>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/pydantic_graph/nodes/..> "PydanticAI")
PydanticAI 
pydantic_graph.nodes 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/pydantic_graph/nodes/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/pydantic_graph/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/pydantic_graph/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/pydantic_graph/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/pydantic_graph/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/pydantic_graph/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/pydantic_graph/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/pydantic_graph/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/pydantic_graph/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/pydantic_graph/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/pydantic_graph/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/pydantic_graph/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/pydantic_graph/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/pydantic_graph/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/pydantic_graph/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/pydantic_graph/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/pydantic_graph/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/pydantic_graph/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/pydantic_graph/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/pydantic_graph/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/pydantic_graph/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/pydantic_graph/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/pydantic_graph/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/pydantic_graph/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/pydantic_graph/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/pydantic_graph/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<../graph/>)
    * pydantic_graph.nodes  [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<./>) Table of contents 
      * [ nodes  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes>)
      * [ GraphRunContext  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.GraphRunContext>)
        * [ state  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.GraphRunContext.state>)
        * [ deps  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.GraphRunContext.deps>)
      * [ BaseNode  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode>)
        * [ docstring_notes  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode.docstring_notes>)
        * [ run  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode.run>)
        * [ get_id  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode.get_id>)
        * [ get_note  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode.get_note>)
        * [ get_node_def  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode.get_node_def>)
      * [ End  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.End>)
        * [ data  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.End.data>)
      * [ Edge  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.Edge>)
        * [ label  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.Edge.label>)
      * [ DepsT  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.DepsT>)
      * [ RunEndT  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.RunEndT>)
      * [ NodeRunEndT  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.NodeRunEndT>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<../state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<../mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<../exceptions/>)


Table of contents 
  * [ nodes  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes>)
  * [ GraphRunContext  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.GraphRunContext>)
    * [ state  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.GraphRunContext.state>)
    * [ deps  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.GraphRunContext.deps>)
  * [ BaseNode  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode>)
    * [ docstring_notes  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode.docstring_notes>)
    * [ run  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode.run>)
    * [ get_id  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode.get_id>)
    * [ get_note  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode.get_note>)
    * [ get_node_def  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode.get_node_def>)
  * [ End  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.End>)
    * [ data  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.End.data>)
  * [ Edge  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.Edge>)
    * [ label  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.Edge.label>)
  * [ DepsT  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.DepsT>)
  * [ RunEndT  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.RunEndT>)
  * [ NodeRunEndT  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.NodeRunEndT>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_graph.nodes`
###  GraphRunContext `dataclass`
Bases: `Generic[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/docs.python.org/3/library/typing.html#typing.Generic> "typing.Generic")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT")]`
Context for a graph.
Source code in `pydantic_graph/pydantic_graph/nodes.py`
```
27
28
29
30
31
32
33
34
```
| ```
@dataclass
class GraphRunContext(Generic[StateT, DepsT]):
"""Context for a graph."""
  state: StateT
"""The state of the graph."""
  deps: DepsT
"""Dependencies for the graph."""

```
  
---|---  
####  state `instance-attribute`
```
state: StateT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")

```

The state of the graph.
####  deps `instance-attribute`
```
deps: DepsT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT")

```

Dependencies for the graph.
###  BaseNode
Bases: `ABC[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/docs.python.org/3/library/abc.html#abc.ABC> "abc.ABC")`, `Generic[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/docs.python.org/3/library/typing.html#typing.Generic> "typing.Generic")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), NodeRunEndT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.NodeRunEndT> "pydantic_graph.nodes.NodeRunEndT")]`
Base class for a node.
Source code in `pydantic_graph/pydantic_graph/nodes.py`
```
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
```
| ```
class BaseNode(ABC, Generic[StateT, DepsT, NodeRunEndT]):
"""Base class for a node."""
  docstring_notes: ClassVar[bool] = False
"""Set to `True` to generate mermaid diagram notes from the class's docstring.
  While this can add valuable information to the diagram, it can make diagrams harder to view, hence
  it is disabled by default. You can also customise notes overriding the
  [`get_note`][pydantic_graph.nodes.BaseNode.get_note] method.
  """
  @abstractmethod
  async def run(self, ctx: GraphRunContext[StateT, DepsT]) -> BaseNode[StateT, DepsT, Any] | End[NodeRunEndT]:
"""Run the node.
    This is an abstract method that must be implemented by subclasses.
    !!! note "Return types used at runtime"
      The return type of this method are read by `pydantic_graph` at runtime and used to define which
      nodes can be called next in the graph. This is displayed in [mermaid diagrams](mermaid.md)
      and enforced when running the graph.
    Args:
      ctx: The graph context.
    Returns:
      The next node to run or [`End`][pydantic_graph.nodes.End] to signal the end of the graph.
    """
    ...
  @classmethod
  @cache
  def get_id(cls) -> str:
"""Get the ID of the node."""
    return cls.__name__
  @classmethod
  def get_note(cls) -> str | None:
"""Get a note about the node to render on mermaid charts.
    By default, this returns a note only if [`docstring_notes`][pydantic_graph.nodes.BaseNode.docstring_notes]
    is `True`. You can override this method to customise the node notes.
    """
    if not cls.docstring_notes:
      return None
    docstring = cls.__doc__
    # dataclasses get an automatic docstring which is just their signature, we don't want that
    if docstring and is_dataclass(cls) and docstring.startswith(f'{cls.__name__}('):
      docstring = None
    if docstring:
      # remove indentation from docstring
      import inspect
      docstring = inspect.cleandoc(docstring)
    return docstring
  @classmethod
  def get_node_def(cls, local_ns: dict[str, Any] | None) -> NodeDef[StateT, DepsT, NodeRunEndT]:
"""Get the node definition."""
    type_hints = get_type_hints(cls.run, localns=local_ns, include_extras=True)
    try:
      return_hint = type_hints['return']
    except KeyError as e:
      raise exceptions.GraphSetupError(f'Node {cls} is missing a return type hint on its `run` method') from e
    next_node_edges: dict[str, Edge] = {}
    end_edge: Edge | None = None
    returns_base_node: bool = False
    for return_type in _utils.get_union_args(return_hint):
      return_type, annotations = _utils.unpack_annotated(return_type)
      edge = next((a for a in annotations if isinstance(a, Edge)), Edge(None))
      return_type_origin = get_origin(return_type) or return_type
      if return_type_origin is End:
        end_edge = edge
      elif return_type_origin is BaseNode:
        # TODO: Should we disallow this?
        returns_base_node = True
      elif issubclass(return_type_origin, BaseNode):
        next_node_edges[return_type.get_id()] = edge
      else:
        raise exceptions.GraphSetupError(f'Invalid return type: {return_type}')
    return NodeDef(
      cls,
      cls.get_id(),
      cls.get_note(),
      next_node_edges,
      end_edge,
      returns_base_node,
    )

```
  
---|---  
####  docstring_notes `class-attribute`
```
docstring_notes: bool[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/docs.python.org/3/library/functions.html#bool>) = False

```

Set to `True` to generate mermaid diagram notes from the class's docstring.
While this can add valuable information to the diagram, it can make diagrams harder to view, hence it is disabled by default. You can also customise notes overriding the `get_note`[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode.get_note>) method.
####  run `abstractmethod` `async`
```
run(
  ctx: GraphRunContext[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.GraphRunContext> "pydantic_graph.nodes.GraphRunContext")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT")]
) -> BaseNode[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode> "pydantic_graph.nodes.BaseNode")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), Any[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")] | End[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.End> "pydantic_graph.nodes.End")[NodeRunEndT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.NodeRunEndT> "pydantic_graph.nodes.NodeRunEndT")]

```

Run the node.
This is an abstract method that must be implemented by subclasses.
Return types used at runtime
The return type of this method are read by `pydantic_graph` at runtime and used to define which nodes can be called next in the graph. This is displayed in [mermaid diagrams](https://ai.pydantic.dev/api/pydantic_graph/nodes/<../mermaid/>) and enforced when running the graph.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`ctx` |  `GraphRunContext[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.GraphRunContext> "pydantic_graph.nodes.GraphRunContext")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT")]` |  The graph context. |  _required_  
Returns:
Type | Description  
---|---  
`BaseNode[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode> "pydantic_graph.nodes.BaseNode")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), Any[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")] | End[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.End> "pydantic_graph.nodes.End")[NodeRunEndT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.NodeRunEndT> "pydantic_graph.nodes.NodeRunEndT")]` |  The next node to run or `End`[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.End>) to signal the end of the graph.  
Source code in `pydantic_graph/pydantic_graph/nodes.py`
```
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
```
| ```
@abstractmethod
async def run(self, ctx: GraphRunContext[StateT, DepsT]) -> BaseNode[StateT, DepsT, Any] | End[NodeRunEndT]:
"""Run the node.
  This is an abstract method that must be implemented by subclasses.
  !!! note "Return types used at runtime"
    The return type of this method are read by `pydantic_graph` at runtime and used to define which
    nodes can be called next in the graph. This is displayed in [mermaid diagrams](mermaid.md)
    and enforced when running the graph.
  Args:
    ctx: The graph context.
  Returns:
    The next node to run or [`End`][pydantic_graph.nodes.End] to signal the end of the graph.
  """
  ...

```
  
---|---  
####  get_id `cached` `classmethod`
```
get_id() -> str[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

Get the ID of the node.
Source code in `pydantic_graph/pydantic_graph/nodes.py`
```
67
68
69
70
71
```
| ```
@classmethod
@cache
def get_id(cls) -> str:
"""Get the ID of the node."""
  return cls.__name__

```
  
---|---  
####  get_note `classmethod`
```
get_note() -> str[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/docs.python.org/3/library/stdtypes.html#str>) | None

```

Get a note about the node to render on mermaid charts.
By default, this returns a note only if `docstring_notes`[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode.docstring_notes>) is `True`. You can override this method to customise the node notes.
Source code in `pydantic_graph/pydantic_graph/nodes.py`
```
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
```
| ```
@classmethod
def get_note(cls) -> str | None:
"""Get a note about the node to render on mermaid charts.
  By default, this returns a note only if [`docstring_notes`][pydantic_graph.nodes.BaseNode.docstring_notes]
  is `True`. You can override this method to customise the node notes.
  """
  if not cls.docstring_notes:
    return None
  docstring = cls.__doc__
  # dataclasses get an automatic docstring which is just their signature, we don't want that
  if docstring and is_dataclass(cls) and docstring.startswith(f'{cls.__name__}('):
    docstring = None
  if docstring:
    # remove indentation from docstring
    import inspect
    docstring = inspect.cleandoc(docstring)
  return docstring

```
  
---|---  
####  get_node_def `classmethod`
```
get_node_def(
  local_ns: dict[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/docs.python.org/3/library/stdtypes.html#dict>)[str[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/docs.python.org/3/library/stdtypes.html#str>), Any[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")] | None
) -> NodeDef[StateT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<../state/#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), DepsT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.DepsT> "pydantic_graph.nodes.DepsT"), NodeRunEndT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.NodeRunEndT> "pydantic_graph.nodes.NodeRunEndT")]

```

Get the node definition.
Source code in `pydantic_graph/pydantic_graph/nodes.py`
```
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
```
| ```
@classmethod
def get_node_def(cls, local_ns: dict[str, Any] | None) -> NodeDef[StateT, DepsT, NodeRunEndT]:
"""Get the node definition."""
  type_hints = get_type_hints(cls.run, localns=local_ns, include_extras=True)
  try:
    return_hint = type_hints['return']
  except KeyError as e:
    raise exceptions.GraphSetupError(f'Node {cls} is missing a return type hint on its `run` method') from e
  next_node_edges: dict[str, Edge] = {}
  end_edge: Edge | None = None
  returns_base_node: bool = False
  for return_type in _utils.get_union_args(return_hint):
    return_type, annotations = _utils.unpack_annotated(return_type)
    edge = next((a for a in annotations if isinstance(a, Edge)), Edge(None))
    return_type_origin = get_origin(return_type) or return_type
    if return_type_origin is End:
      end_edge = edge
    elif return_type_origin is BaseNode:
      # TODO: Should we disallow this?
      returns_base_node = True
    elif issubclass(return_type_origin, BaseNode):
      next_node_edges[return_type.get_id()] = edge
    else:
      raise exceptions.GraphSetupError(f'Invalid return type: {return_type}')
  return NodeDef(
    cls,
    cls.get_id(),
    cls.get_note(),
    next_node_edges,
    end_edge,
    returns_base_node,
  )

```
  
---|---  
###  End `dataclass`
Bases: `Generic[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/docs.python.org/3/library/typing.html#typing.Generic> "typing.Generic")[RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")]`
Type to return from a node to signal the end of the graph.
Source code in `pydantic_graph/pydantic_graph/nodes.py`
```
129
130
131
132
133
134
```
| ```
@dataclass
class End(Generic[RunEndT]):
"""Type to return from a node to signal the end of the graph."""
  data: RunEndT
"""Data to return from the graph."""

```
  
---|---  
####  data `instance-attribute`
```
data: RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")

```

Data to return from the graph.
###  Edge `dataclass`
Annotation to apply a label to an edge in a graph.
Source code in `pydantic_graph/pydantic_graph/nodes.py`
```
137
138
139
140
141
142
```
| ```
@dataclass
class Edge:
"""Annotation to apply a label to an edge in a graph."""
  label: str | None
"""Label for the edge."""

```
  
---|---  
####  label `instance-attribute`
```
label: str[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/docs.python.org/3/library/stdtypes.html#str>) | None

```

Label for the edge.
###  DepsT `module-attribute`
```
DepsT = TypeVar('DepsT', default=None, contravariant=True)

```

Type variable for the dependencies of a graph and node.
###  RunEndT `module-attribute`
```
RunEndT = TypeVar('RunEndT', covariant=True, default=None)

```

Covariant type variable for the return type of a graph `run`[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<../graph/#pydantic_graph.graph.Graph.run>).
###  NodeRunEndT `module-attribute`
```
NodeRunEndT = TypeVar(
  "NodeRunEndT", covariant=True, default=Never[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.Never> "typing_extensions.Never")
)

```

Covariant type variable for the return type of a node `run`[](https://ai.pydantic.dev/api/pydantic_graph/nodes/<#pydantic_graph.nodes.BaseNode.run>).
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_pydantic_graph_state.md
================
[ Skip to content ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graphstate>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/pydantic_graph/state/..> "PydanticAI")
PydanticAI 
pydantic_graph.state 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/pydantic_graph/state/..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/pydantic_graph/state/..>)
  * [ Installation  ](https://ai.pydantic.dev/api/pydantic_graph/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/pydantic_graph/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/pydantic_graph/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/pydantic_graph/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/pydantic_graph/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/pydantic_graph/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/pydantic_graph/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/pydantic_graph/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/pydantic_graph/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/pydantic_graph/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/pydantic_graph/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/pydantic_graph/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/pydantic_graph/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/pydantic_graph/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/pydantic_graph/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/pydantic_graph/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/pydantic_graph/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/pydantic_graph/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/pydantic_graph/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/pydantic_graph/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/pydantic_graph/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/pydantic_graph/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/pydantic_graph/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/pydantic_graph/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/pydantic_graph/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/pydantic_graph/state/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/pydantic_graph/state/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/pydantic_graph/state/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/pydantic_graph/state/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/pydantic_graph/state/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/pydantic_graph/state/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/pydantic_graph/state/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/pydantic_graph/state/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/pydantic_graph/state/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/pydantic_graph/state/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/pydantic_graph/state/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/pydantic_graph/state/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/pydantic_graph/state/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/pydantic_graph/state/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/pydantic_graph/state/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/pydantic_graph/state/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/pydantic_graph/state/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/pydantic_graph/state/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/pydantic_graph/state/<../graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/pydantic_graph/state/<../nodes/>)
    * pydantic_graph.state  [ pydantic_graph.state  ](https://ai.pydantic.dev/api/pydantic_graph/state/<./>) Table of contents 
      * [ state  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state>)
      * [ StateT  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.StateT>)
      * [ deep_copy_state  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.deep_copy_state>)
      * [ NodeStep  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep>)
        * [ state  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.state>)
        * [ node  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.node>)
        * [ start_ts  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.start_ts>)
        * [ duration  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.duration>)
        * [ kind  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.kind>)
        * [ snapshot_state  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.snapshot_state>)
        * [ data_snapshot  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.data_snapshot>)
      * [ EndStep  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.EndStep>)
        * [ result  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.EndStep.result>)
        * [ ts  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.EndStep.ts>)
        * [ kind  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.EndStep.kind>)
        * [ data_snapshot  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.EndStep.data_snapshot>)
      * [ HistoryStep  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.HistoryStep>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/pydantic_graph/state/<../mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/pydantic_graph/state/<../exceptions/>)


Table of contents 
  * [ state  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state>)
  * [ StateT  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.StateT>)
  * [ deep_copy_state  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.deep_copy_state>)
  * [ NodeStep  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep>)
    * [ state  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.state>)
    * [ node  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.node>)
    * [ start_ts  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.start_ts>)
    * [ duration  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.duration>)
    * [ kind  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.kind>)
    * [ snapshot_state  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.snapshot_state>)
    * [ data_snapshot  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.data_snapshot>)
  * [ EndStep  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.EndStep>)
    * [ result  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.EndStep.result>)
    * [ ts  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.EndStep.ts>)
    * [ kind  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.EndStep.kind>)
    * [ data_snapshot  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.EndStep.data_snapshot>)
  * [ HistoryStep  ](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.HistoryStep>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/pydantic_graph/state/..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/pydantic_graph/state/agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_graph.state`
###  StateT `module-attribute`
```
StateT = TypeVar('StateT', default=None)

```

Type variable for the state in a graph.
###  deep_copy_state
```
deep_copy_state(state: StateT[](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")) -> StateT[](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")

```

Default method for snapshotting the state in a graph run, uses `copy.deepcopy`[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/copy.html#copy.deepcopy>).
Source code in `pydantic_graph/pydantic_graph/state.py`
```
24
25
26
27
28
29
```
| ```
def deep_copy_state(state: StateT) -> StateT:
"""Default method for snapshotting the state in a graph run, uses [`copy.deepcopy`][copy.deepcopy]."""
  if state is None:
    return state
  else:
    return copy.deepcopy(state)

```
  
---|---  
###  NodeStep `dataclass`
Bases: `Generic[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/typing.html#typing.Generic> "typing.Generic")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/state/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")]`
History step describing the execution of a node in a graph.
Source code in `pydantic_graph/pydantic_graph/state.py`
```
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
```
| ```
@dataclass
class NodeStep(Generic[StateT, RunEndT]):
"""History step describing the execution of a node in a graph."""
  state: StateT
"""The state of the graph after the node has been run."""
  node: Annotated[BaseNode[StateT, Any, RunEndT], CustomNodeSchema()]
"""The node that was run."""
  start_ts: datetime = field(default_factory=_utils.now_utc)
"""The timestamp when the node started running."""
  duration: float | None = None
"""The duration of the node run in seconds."""
  kind: Literal['node'] = 'node'
"""The kind of history step, can be used as a discriminator when deserializing history."""
  # TODO waiting for https://github.com/pydantic/pydantic/issues/11264, should be an InitVar
  snapshot_state: Annotated[Callable[[StateT], StateT], pydantic.Field(exclude=True, repr=False)] = field(
    default=deep_copy_state, repr=False
  )
"""Function to snapshot the state of the graph."""
  def __post_init__(self):
    # Copy the state to prevent it from being modified by other code
    self.state = self.snapshot_state(self.state)
  def data_snapshot(self) -> BaseNode[StateT, Any, RunEndT]:
"""Returns a deep copy of [`self.node`][pydantic_graph.state.NodeStep.node].
    Useful for summarizing history.
    """
    return copy.deepcopy(self.node)

```
  
---|---  
####  state `instance-attribute`
```
state: StateT[](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")

```

The state of the graph after the node has been run.
####  node `instance-attribute`
```
node: Annotated[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/typing.html#typing.Annotated> "typing.Annotated")[
  BaseNode[](https://ai.pydantic.dev/api/pydantic_graph/state/<../nodes/#pydantic_graph.nodes.BaseNode> "pydantic_graph.nodes.BaseNode")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), Any[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"), RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/state/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")], CustomNodeSchema()
]

```

The node that was run.
####  start_ts `class-attribute` `instance-attribute`
```
start_ts: datetime[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/datetime.html#datetime.datetime> "datetime.datetime") = field[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/dataclasses.html#dataclasses.field> "dataclasses.field")(default_factory=now_utc)

```

The timestamp when the node started running.
####  duration `class-attribute` `instance-attribute`
```
duration: float[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/functions.html#float>) | None = None

```

The duration of the node run in seconds.
####  kind `class-attribute` `instance-attribute`
```
kind: Literal[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['node'] = 'node'

```

The kind of history step, can be used as a discriminator when deserializing history.
####  snapshot_state `class-attribute` `instance-attribute`
```
snapshot_state: Annotated[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/typing.html#typing.Annotated> "typing.Annotated")[
  Callable[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[StateT[](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")], StateT[](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.StateT> "pydantic_graph.state.StateT")],
  Field[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.pydantic.dev/latest/api/fields/#pydantic.fields.Field> "pydantic.Field")(exclude=True, repr=False),
] = field[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/dataclasses.html#dataclasses.field> "dataclasses.field")(default=deep_copy_state[](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.deep_copy_state> "pydantic_graph.state.deep_copy_state"), repr=False)

```

Function to snapshot the state of the graph.
####  data_snapshot
```
data_snapshot() -> BaseNode[](https://ai.pydantic.dev/api/pydantic_graph/state/<../nodes/#pydantic_graph.nodes.BaseNode> "pydantic_graph.nodes.BaseNode")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), Any[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any"), RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/state/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")]

```

Returns a deep copy of `self.node`[](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep.node>).
Useful for summarizing history.
Source code in `pydantic_graph/pydantic_graph/state.py`
```
56
57
58
59
60
61
```
| ```
def data_snapshot(self) -> BaseNode[StateT, Any, RunEndT]:
"""Returns a deep copy of [`self.node`][pydantic_graph.state.NodeStep.node].
  Useful for summarizing history.
  """
  return copy.deepcopy(self.node)

```
  
---|---  
###  EndStep `dataclass`
Bases: `Generic[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/typing.html#typing.Generic> "typing.Generic")[RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/state/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")]`
History step describing the end of a graph run.
Source code in `pydantic_graph/pydantic_graph/state.py`
```
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
```
| ```
@dataclass
class EndStep(Generic[RunEndT]):
"""History step describing the end of a graph run."""
  result: End[RunEndT]
"""The result of the graph run."""
  ts: datetime = field(default_factory=_utils.now_utc)
"""The timestamp when the graph run ended."""
  kind: Literal['end'] = 'end'
"""The kind of history step, can be used as a discriminator when deserializing history."""
  def data_snapshot(self) -> End[RunEndT]:
"""Returns a deep copy of [`self.result`][pydantic_graph.state.EndStep.result].
    Useful for summarizing history.
    """
    return copy.deepcopy(self.result)

```
  
---|---  
####  result `instance-attribute`
```
result: End[](https://ai.pydantic.dev/api/pydantic_graph/state/<../nodes/#pydantic_graph.nodes.End> "pydantic_graph.nodes.End")[RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/state/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")]

```

The result of the graph run.
####  ts `class-attribute` `instance-attribute`
```
ts: datetime[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/datetime.html#datetime.datetime> "datetime.datetime") = field[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/dataclasses.html#dataclasses.field> "dataclasses.field")(default_factory=now_utc)

```

The timestamp when the graph run ended.
####  kind `class-attribute` `instance-attribute`
```
kind: Literal[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")['end'] = 'end'

```

The kind of history step, can be used as a discriminator when deserializing history.
####  data_snapshot
```
data_snapshot() -> End[](https://ai.pydantic.dev/api/pydantic_graph/state/<../nodes/#pydantic_graph.nodes.End> "pydantic_graph.nodes.End")[RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/state/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")]

```

Returns a deep copy of `self.result`[](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.EndStep.result>).
Useful for summarizing history.
Source code in `pydantic_graph/pydantic_graph/state.py`
```
75
76
77
78
79
80
```
| ```
def data_snapshot(self) -> End[RunEndT]:
"""Returns a deep copy of [`self.result`][pydantic_graph.state.EndStep.result].
  Useful for summarizing history.
  """
  return copy.deepcopy(self.result)

```
  
---|---  
###  HistoryStep `module-attribute`
```
HistoryStep = Union[](https://ai.pydantic.dev/api/pydantic_graph/state/<https:/docs.python.org/3/library/typing.html#typing.Union> "typing.Union")[
  NodeStep[](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.NodeStep> "pydantic_graph.state.NodeStep")[StateT[](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.StateT> "pydantic_graph.state.StateT"), RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/state/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")], EndStep[](https://ai.pydantic.dev/api/pydantic_graph/state/<#pydantic_graph.state.EndStep> "pydantic_graph.state.EndStep")[RunEndT[](https://ai.pydantic.dev/api/pydantic_graph/state/<../nodes/#pydantic_graph.nodes.RunEndT> "pydantic_graph.nodes.RunEndT")]
]

```

A step in the history of a graph run.
`Graph.run`[](https://ai.pydantic.dev/api/pydantic_graph/state/<../graph/#pydantic_graph.graph.Graph.run>) returns a list of these steps describing the execution of the graph, together with the run return value.
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_result.md
================
[ Skip to content ](https://ai.pydantic.dev/api/result/<#pydantic_airesult>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/result/<../..> "PydanticAI")
PydanticAI 
pydantic_ai.result 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/result/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/result/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/result/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/result/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/api/result/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/result/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/result/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/result/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/result/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/result/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/result/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/result/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/result/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/result/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/result/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/result/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/result/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/result/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/result/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/result/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/result/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/result/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/result/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/result/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/result/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/result/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/result/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/result/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/result/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/result/<../agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/result/<../tools/>)
    * pydantic_ai.result  [ pydantic_ai.result  ](https://ai.pydantic.dev/api/result/<./>) Table of contents 
      * [ result  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result>)
      * [ ResultDataT_inv  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT_inv>)
      * [ ResultDataT  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT>)
      * [ ResultValidatorFunc  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultValidatorFunc>)
      * [ RunResult  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult>)
        * [ all_messages_json  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult.all_messages_json>)
        * [ new_messages  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult.new_messages>)
        * [ new_messages_json  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult.new_messages_json>)
        * [ data  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult.data>)
        * [ usage  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult.usage>)
        * [ all_messages  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult.all_messages>)
      * [ StreamedRunResult  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult>)
        * [ all_messages  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.all_messages>)
        * [ all_messages_json  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.all_messages_json>)
        * [ new_messages  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.new_messages>)
        * [ new_messages_json  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.new_messages_json>)
        * [ is_complete  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.is_complete>)
        * [ stream  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.stream>)
        * [ stream_text  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.stream_text>)
        * [ stream_structured  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.stream_structured>)
        * [ get_data  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.get_data>)
        * [ usage  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.usage>)
        * [ timestamp  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.timestamp>)
        * [ validate_structured_result  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.validate_structured_result>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/result/<../messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/result/<../exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/result/<../settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/result/<../usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/result/<../format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/result/<../models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/result/<../models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/result/<../models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/result/<../models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/result/<../models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/result/<../models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/result/<../models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/result/<../models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/result/<../models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/result/<../models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/result/<../pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/result/<../pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/result/<../pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/result/<../pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/result/<../pydantic_graph/exceptions/>)


Table of contents 
  * [ result  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result>)
  * [ ResultDataT_inv  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT_inv>)
  * [ ResultDataT  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT>)
  * [ ResultValidatorFunc  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultValidatorFunc>)
  * [ RunResult  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult>)
    * [ all_messages_json  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult.all_messages_json>)
    * [ new_messages  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult.new_messages>)
    * [ new_messages_json  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult.new_messages_json>)
    * [ data  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult.data>)
    * [ usage  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult.usage>)
    * [ all_messages  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult.all_messages>)
  * [ StreamedRunResult  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult>)
    * [ all_messages  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.all_messages>)
    * [ all_messages_json  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.all_messages_json>)
    * [ new_messages  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.new_messages>)
    * [ new_messages_json  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.new_messages_json>)
    * [ is_complete  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.is_complete>)
    * [ stream  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.stream>)
    * [ stream_text  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.stream_text>)
    * [ stream_structured  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.stream_structured>)
    * [ get_data  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.get_data>)
    * [ usage  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.usage>)
    * [ timestamp  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.timestamp>)
    * [ validate_structured_result  ](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.validate_structured_result>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/result/<../..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/result/<../agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/result/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/result/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_ai.result`
###  ResultDataT_inv `module-attribute`
```
ResultDataT_inv = TypeVar('ResultDataT_inv', default=str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>))

```

An invariant type variable for the result data of a model.
We need to use an invariant typevar for `ResultValidator` and `ResultValidatorFunc` because the result data type is used in both the input and output of a `ResultValidatorFunc`. This can theoretically lead to some issues assuming that types possessing ResultValidator's are covariant in the result data type, but in practice this is rarely an issue, and changing it would have negative consequences for the ergonomics of the library.
At some point, it may make sense to change the input to ResultValidatorFunc to be `Any` or `object` as doing that would resolve these potential variance issues.
###  ResultDataT `module-attribute`
```
ResultDataT = TypeVar(
  "ResultDataT", default=str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>), covariant=True
)

```

Covariant type variable for the result data type of a run.
###  ResultValidatorFunc `module-attribute`
```
ResultValidatorFunc = Union[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/typing.html#typing.Union> "typing.Union")[
  Callable[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Callable> "collections.abc.Callable")[
    [RunContext[](https://ai.pydantic.dev/api/result/<../tools/#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/result/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")], ResultDataT_inv[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT_inv> "pydantic_ai.result.ResultDataT_inv")],
    ResultDataT_inv[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT_inv> "pydantic_ai.result.ResultDataT_inv"),
  ],
  Callable[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Callable> "collections.abc.Callable")[
    [RunContext[](https://ai.pydantic.dev/api/result/<../tools/#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/result/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")], ResultDataT_inv[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT_inv> "pydantic_ai.result.ResultDataT_inv")],
    Awaitable[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Awaitable> "collections.abc.Awaitable")[ResultDataT_inv[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT_inv> "pydantic_ai.result.ResultDataT_inv")],
  ],
  Callable[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Callable> "collections.abc.Callable")[[ResultDataT_inv[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT_inv> "pydantic_ai.result.ResultDataT_inv")], ResultDataT_inv[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT_inv> "pydantic_ai.result.ResultDataT_inv")],
  Callable[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Callable> "collections.abc.Callable")[[ResultDataT_inv[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT_inv> "pydantic_ai.result.ResultDataT_inv")], Awaitable[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Awaitable> "collections.abc.Awaitable")[ResultDataT_inv[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT_inv> "pydantic_ai.result.ResultDataT_inv")]],
]

```

A function that always takes and returns the same type of data (which is the result type of an agent run), and:
  * may or may not take `RunContext`[](https://ai.pydantic.dev/api/result/<../tools/#pydantic_ai.tools.RunContext>) as a first argument
  * may or may not be async


Usage `ResultValidatorFunc[AgentDepsT, T]`.
###  RunResult `dataclass`
Bases: `_BaseRunResult[ResultDataT[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]`
Result of a non-streamed run.
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
```
| ```
@dataclass
class RunResult(_BaseRunResult[ResultDataT]):
"""Result of a non-streamed run."""
  data: ResultDataT
"""Data from the final response in the run."""
  _result_tool_name: str | None
  _usage: Usage
  def usage(self) -> Usage:
"""Return the usage of the whole run."""
    return self._usage
  def all_messages(self, *, result_tool_return_content: str | None = None) -> list[_messages.ModelMessage]:
"""Return the history of _messages.
    Args:
      result_tool_return_content: The return content of the tool call to set in the last message.
        This provides a convenient way to modify the content of the result tool call if you want to continue
        the conversation and want to set the response to the result tool call. If `None`, the last message will
        not be modified.
    Returns:
      List of messages.
    """
    if result_tool_return_content is not None:
      return self._set_result_tool_return(result_tool_return_content)
    else:
      return self._all_messages
  def _set_result_tool_return(self, return_content: str) -> list[_messages.ModelMessage]:
"""Set return content for the result tool.
    Useful if you want to continue the conversation and want to set the response to the result tool call.
    """
    if not self._result_tool_name:
      raise ValueError('Cannot set result tool return content when the return type is `str`.')
    messages = deepcopy(self._all_messages)
    last_message = messages[-1]
    for part in last_message.parts:
      if isinstance(part, _messages.ToolReturnPart) and part.tool_name == self._result_tool_name:
        part.content = return_content
        return messages
    raise LookupError(f'No tool call found with tool name {self._result_tool_name!r}.')

```
  
---|---  
####  all_messages_json
```
all_messages_json(
  *, result_tool_return_content: str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None
) -> bytes[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#bytes>)

```

Return all messages from `all_messages`[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.all_messages>) as JSON bytes.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`result_tool_return_content` |  `str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The return content of the tool call to set in the last message. This provides a convenient way to modify the content of the result tool call if you want to continue the conversation and want to set the response to the result tool call. If `None`, the last message will not be modified. |  `None`  
Returns:
Type | Description  
---|---  
`bytes[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#bytes>)` |  JSON bytes representing the messages.  
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
```
| ```
def all_messages_json(self, *, result_tool_return_content: str | None = None) -> bytes:
"""Return all messages from [`all_messages`][pydantic_ai.result._BaseRunResult.all_messages] as JSON bytes.
  Args:
    result_tool_return_content: The return content of the tool call to set in the last message.
      This provides a convenient way to modify the content of the result tool call if you want to continue
      the conversation and want to set the response to the result tool call. If `None`, the last message will
      not be modified.
  Returns:
    JSON bytes representing the messages.
  """
  return _messages.ModelMessagesTypeAdapter.dump_json(
    self.all_messages(result_tool_return_content=result_tool_return_content)
  )

```
  
---|---  
####  new_messages
```
new_messages(
  *, result_tool_return_content: str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None
) -> list[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/result/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")]

```

Return new messages associated with this run.
Messages from older runs are excluded.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`result_tool_return_content` |  `str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The return content of the tool call to set in the last message. This provides a convenient way to modify the content of the result tool call if you want to continue the conversation and want to set the response to the result tool call. If `None`, the last message will not be modified. |  `None`  
Returns:
Type | Description  
---|---  
`list[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/result/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")]` |  List of new messages.  
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
```
| ```
def new_messages(self, *, result_tool_return_content: str | None = None) -> list[_messages.ModelMessage]:
"""Return new messages associated with this run.
  Messages from older runs are excluded.
  Args:
    result_tool_return_content: The return content of the tool call to set in the last message.
      This provides a convenient way to modify the content of the result tool call if you want to continue
      the conversation and want to set the response to the result tool call. If `None`, the last message will
      not be modified.
  Returns:
    List of new messages.
  """
  return self.all_messages(result_tool_return_content=result_tool_return_content)[self._new_message_index :]

```
  
---|---  
####  new_messages_json
```
new_messages_json(
  *, result_tool_return_content: str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None
) -> bytes[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#bytes>)

```

Return new messages from `new_messages`[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult.new_messages>) as JSON bytes.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`result_tool_return_content` |  `str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The return content of the tool call to set in the last message. This provides a convenient way to modify the content of the result tool call if you want to continue the conversation and want to set the response to the result tool call. If `None`, the last message will not be modified. |  `None`  
Returns:
Type | Description  
---|---  
`bytes[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#bytes>)` |  JSON bytes representing the new messages.  
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
```
| ```
def new_messages_json(self, *, result_tool_return_content: str | None = None) -> bytes:
"""Return new messages from [`new_messages`][pydantic_ai.result._BaseRunResult.new_messages] as JSON bytes.
  Args:
    result_tool_return_content: The return content of the tool call to set in the last message.
      This provides a convenient way to modify the content of the result tool call if you want to continue
      the conversation and want to set the response to the result tool call. If `None`, the last message will
      not be modified.
  Returns:
    JSON bytes representing the new messages.
  """
  return _messages.ModelMessagesTypeAdapter.dump_json(
    self.new_messages(result_tool_return_content=result_tool_return_content)
  )

```
  
---|---  
####  data `instance-attribute`
```
data: ResultDataT[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")

```

Data from the final response in the run.
####  usage
```
usage() -> Usage[](https://ai.pydantic.dev/api/result/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage")

```

Return the usage of the whole run.
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
144
145
146
```
| ```
def usage(self) -> Usage:
"""Return the usage of the whole run."""
  return self._usage

```
  
---|---  
####  all_messages
```
all_messages(
  *, result_tool_return_content: str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None
) -> list[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/result/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")]

```

Return the history of _messages.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`result_tool_return_content` |  `str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The return content of the tool call to set in the last message. This provides a convenient way to modify the content of the result tool call if you want to continue the conversation and want to set the response to the result tool call. If `None`, the last message will not be modified. |  `None`  
Returns:
Type | Description  
---|---  
`list[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/result/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")]` |  List of messages.  
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
```
| ```
def all_messages(self, *, result_tool_return_content: str | None = None) -> list[_messages.ModelMessage]:
"""Return the history of _messages.
  Args:
    result_tool_return_content: The return content of the tool call to set in the last message.
      This provides a convenient way to modify the content of the result tool call if you want to continue
      the conversation and want to set the response to the result tool call. If `None`, the last message will
      not be modified.
  Returns:
    List of messages.
  """
  if result_tool_return_content is not None:
    return self._set_result_tool_return(result_tool_return_content)
  else:
    return self._all_messages

```
  
---|---  
###  StreamedRunResult `dataclass`
Bases: `_BaseRunResult[ResultDataT[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]`, `Generic[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/typing.html#typing.Generic> "typing.Generic")[AgentDepsT[](https://ai.pydantic.dev/api/result/<../tools/#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), ResultDataT[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]`
Result of a streamed run that returns structured data via a tool call.
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
```
| ```
@dataclass
class StreamedRunResult(_BaseRunResult[ResultDataT], Generic[AgentDepsT, ResultDataT]):
"""Result of a streamed run that returns structured data via a tool call."""
  _usage_limits: UsageLimits | None
  _stream_response: models.StreamedResponse
  _result_schema: _result.ResultSchema[ResultDataT] | None
  _run_ctx: RunContext[AgentDepsT]
  _result_validators: list[_result.ResultValidator[AgentDepsT, ResultDataT]]
  _result_tool_name: str | None
  _on_complete: Callable[[], Awaitable[None]]
  is_complete: bool = field(default=False, init=False)
"""Whether the stream has all been received.
  This is set to `True` when one of
  [`stream`][pydantic_ai.result.StreamedRunResult.stream],
  [`stream_text`][pydantic_ai.result.StreamedRunResult.stream_text],
  [`stream_structured`][pydantic_ai.result.StreamedRunResult.stream_structured] or
  [`get_data`][pydantic_ai.result.StreamedRunResult.get_data] completes.
  """
  async def stream(self, *, debounce_by: float | None = 0.1) -> AsyncIterator[ResultDataT]:
"""Stream the response as an async iterable.
    The pydantic validator for structured data will be called in
    [partial mode](https://docs.pydantic.dev/dev/concepts/experimental/#partial-validation)
    on each iteration.
    Args:
      debounce_by: by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing.
        Debouncing is particularly important for long structured responses to reduce the overhead of
        performing validation as each token is received.
    Returns:
      An async iterable of the response data.
    """
    async for structured_message, is_last in self.stream_structured(debounce_by=debounce_by):
      result = await self.validate_structured_result(structured_message, allow_partial=not is_last)
      yield result
  async def stream_text(self, *, delta: bool = False, debounce_by: float | None = 0.1) -> AsyncIterator[str]:
"""Stream the text result as an async iterable.
    !!! note
      Result validators will NOT be called on the text result if `delta=True`.
    Args:
      delta: if `True`, yield each chunk of text as it is received, if `False` (default), yield the full text
        up to the current point.
      debounce_by: by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing.
        Debouncing is particularly important for long structured responses to reduce the overhead of
        performing validation as each token is received.
    """
    if self._result_schema and not self._result_schema.allow_text_result:
      raise exceptions.UserError('stream_text() can only be used with text responses')
    usage_checking_stream = _get_usage_checking_stream_response(
      self._stream_response, self._usage_limits, self.usage
    )
    # Define a "merged" version of the iterator that will yield items that have already been retrieved
    # and items that we receive while streaming. We define a dedicated async iterator for this so we can
    # pass the combined stream to the group_by_temporal function within `_stream_text_deltas` below.
    async def _stream_text_deltas_ungrouped() -> AsyncIterator[tuple[str, int]]:
      # if the response currently has any parts with content, yield those before streaming
      msg = self._stream_response.get()
      for i, part in enumerate(msg.parts):
        if isinstance(part, _messages.TextPart) and part.content:
          yield part.content, i
      async for event in usage_checking_stream:
        if (
          isinstance(event, _messages.PartStartEvent)
          and isinstance(event.part, _messages.TextPart)
          and event.part.content
        ):
          yield event.part.content, event.index
        elif (
          isinstance(event, _messages.PartDeltaEvent)
          and isinstance(event.delta, _messages.TextPartDelta)
          and event.delta.content_delta
        ):
          yield event.delta.content_delta, event.index
    async def _stream_text_deltas() -> AsyncIterator[str]:
      async with _utils.group_by_temporal(_stream_text_deltas_ungrouped(), debounce_by) as group_iter:
        async for items in group_iter:
          yield ''.join([content for content, _ in items])
    with _logfire.span('response stream text') as lf_span:
      if delta:
        async for text in _stream_text_deltas():
          yield text
      else:
        # a quick benchmark shows it's faster to build up a string with concat when we're
        # yielding at each step
        deltas: list[str] = []
        combined_validated_text = ''
        async for text in _stream_text_deltas():
          deltas.append(text)
          combined_text = ''.join(deltas)
          combined_validated_text = await self._validate_text_result(combined_text)
          yield combined_validated_text
        lf_span.set_attribute('combined_text', combined_validated_text)
        await self._marked_completed(
          _messages.ModelResponse(
            parts=[_messages.TextPart(combined_validated_text)],
            model_name=self._stream_response.model_name(),
          )
        )
  async def stream_structured(
    self, *, debounce_by: float | None = 0.1
  ) -> AsyncIterator[tuple[_messages.ModelResponse, bool]]:
"""Stream the response as an async iterable of Structured LLM Messages.
    Args:
      debounce_by: by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing.
        Debouncing is particularly important for long structured responses to reduce the overhead of
        performing validation as each token is received.
    Returns:
      An async iterable of the structured response message and whether that is the last message.
    """
    usage_checking_stream = _get_usage_checking_stream_response(
      self._stream_response, self._usage_limits, self.usage
    )
    with _logfire.span('response stream structured') as lf_span:
      # if the message currently has any parts with content, yield before streaming
      msg = self._stream_response.get()
      for part in msg.parts:
        if part.has_content():
          yield msg, False
          break
      async with _utils.group_by_temporal(usage_checking_stream, debounce_by) as group_iter:
        async for _events in group_iter:
          msg = self._stream_response.get()
          yield msg, False
        msg = self._stream_response.get()
        yield msg, True
        # TODO: Should this now be `final_response` instead of `structured_response`?
        lf_span.set_attribute('structured_response', msg)
        await self._marked_completed(msg)
  async def get_data(self) -> ResultDataT:
"""Stream the whole response, validate and return it."""
    usage_checking_stream = _get_usage_checking_stream_response(
      self._stream_response, self._usage_limits, self.usage
    )
    async for _ in usage_checking_stream:
      pass
    message = self._stream_response.get()
    await self._marked_completed(message)
    return await self.validate_structured_result(message)
  def usage(self) -> Usage:
"""Return the usage of the whole run.
    !!! note
      This won't return the full usage until the stream is finished.
    """
    return self._run_ctx.usage + self._stream_response.usage()
  def timestamp(self) -> datetime:
"""Get the timestamp of the response."""
    return self._stream_response.timestamp()
  async def validate_structured_result(
    self, message: _messages.ModelResponse, *, allow_partial: bool = False
  ) -> ResultDataT:
"""Validate a structured result message."""
    if self._result_schema is not None and self._result_tool_name is not None:
      match = self._result_schema.find_named_tool(message.parts, self._result_tool_name)
      if match is None:
        raise exceptions.UnexpectedModelBehavior(
          f'Invalid response, unable to find tool: {self._result_schema.tool_names()}'
        )
      call, result_tool = match
      result_data = result_tool.validate(call, allow_partial=allow_partial, wrap_validation_errors=False)
      for validator in self._result_validators:
        result_data = await validator.validate(result_data, call, self._run_ctx)
      return result_data
    else:
      text = '\n\n'.join(x.content for x in message.parts if isinstance(x, _messages.TextPart))
      for validator in self._result_validators:
        text = await validator.validate(
          text,
          None,
          self._run_ctx,
        )
      # Since there is no result tool, we can assume that str is compatible with ResultDataT
      return cast(ResultDataT, text)
  async def _validate_text_result(self, text: str) -> str:
    for validator in self._result_validators:
      text = await validator.validate(
        text,
        None,
        self._run_ctx,
      )
    return text
  async def _marked_completed(self, message: _messages.ModelResponse) -> None:
    self.is_complete = True
    self._all_messages.append(message)
    await self._on_complete()

```
  
---|---  
####  all_messages
```
all_messages(
  *, result_tool_return_content: str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None
) -> list[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/result/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")]

```

Return the history of _messages.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`result_tool_return_content` |  `str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The return content of the tool call to set in the last message. This provides a convenient way to modify the content of the result tool call if you want to continue the conversation and want to set the response to the result tool call. If `None`, the last message will not be modified. |  `None`  
Returns:
Type | Description  
---|---  
`list[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/result/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")]` |  List of messages.  
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
```
| ```
def all_messages(self, *, result_tool_return_content: str | None = None) -> list[_messages.ModelMessage]:
"""Return the history of _messages.
  Args:
    result_tool_return_content: The return content of the tool call to set in the last message.
      This provides a convenient way to modify the content of the result tool call if you want to continue
      the conversation and want to set the response to the result tool call. If `None`, the last message will
      not be modified.
  Returns:
    List of messages.
  """
  # this is a method to be consistent with the other methods
  if result_tool_return_content is not None:
    raise NotImplementedError('Setting result tool return content is not supported for this result type.')
  return self._all_messages

```
  
---|---  
####  all_messages_json
```
all_messages_json(
  *, result_tool_return_content: str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None
) -> bytes[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#bytes>)

```

Return all messages from `all_messages`[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.all_messages>) as JSON bytes.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`result_tool_return_content` |  `str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The return content of the tool call to set in the last message. This provides a convenient way to modify the content of the result tool call if you want to continue the conversation and want to set the response to the result tool call. If `None`, the last message will not be modified. |  `None`  
Returns:
Type | Description  
---|---  
`bytes[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#bytes>)` |  JSON bytes representing the messages.  
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
```
| ```
def all_messages_json(self, *, result_tool_return_content: str | None = None) -> bytes:
"""Return all messages from [`all_messages`][pydantic_ai.result._BaseRunResult.all_messages] as JSON bytes.
  Args:
    result_tool_return_content: The return content of the tool call to set in the last message.
      This provides a convenient way to modify the content of the result tool call if you want to continue
      the conversation and want to set the response to the result tool call. If `None`, the last message will
      not be modified.
  Returns:
    JSON bytes representing the messages.
  """
  return _messages.ModelMessagesTypeAdapter.dump_json(
    self.all_messages(result_tool_return_content=result_tool_return_content)
  )

```
  
---|---  
####  new_messages
```
new_messages(
  *, result_tool_return_content: str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None
) -> list[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/result/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")]

```

Return new messages associated with this run.
Messages from older runs are excluded.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`result_tool_return_content` |  `str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The return content of the tool call to set in the last message. This provides a convenient way to modify the content of the result tool call if you want to continue the conversation and want to set the response to the result tool call. If `None`, the last message will not be modified. |  `None`  
Returns:
Type | Description  
---|---  
`list[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/result/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")]` |  List of new messages.  
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
```
| ```
def new_messages(self, *, result_tool_return_content: str | None = None) -> list[_messages.ModelMessage]:
"""Return new messages associated with this run.
  Messages from older runs are excluded.
  Args:
    result_tool_return_content: The return content of the tool call to set in the last message.
      This provides a convenient way to modify the content of the result tool call if you want to continue
      the conversation and want to set the response to the result tool call. If `None`, the last message will
      not be modified.
  Returns:
    List of new messages.
  """
  return self.all_messages(result_tool_return_content=result_tool_return_content)[self._new_message_index :]

```
  
---|---  
####  new_messages_json
```
new_messages_json(
  *, result_tool_return_content: str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None
) -> bytes[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#bytes>)

```

Return new messages from `new_messages`[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.RunResult.new_messages>) as JSON bytes.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`result_tool_return_content` |  `str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  The return content of the tool call to set in the last message. This provides a convenient way to modify the content of the result tool call if you want to continue the conversation and want to set the response to the result tool call. If `None`, the last message will not be modified. |  `None`  
Returns:
Type | Description  
---|---  
`bytes[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#bytes>)` |  JSON bytes representing the new messages.  
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
```
| ```
def new_messages_json(self, *, result_tool_return_content: str | None = None) -> bytes:
"""Return new messages from [`new_messages`][pydantic_ai.result._BaseRunResult.new_messages] as JSON bytes.
  Args:
    result_tool_return_content: The return content of the tool call to set in the last message.
      This provides a convenient way to modify the content of the result tool call if you want to continue
      the conversation and want to set the response to the result tool call. If `None`, the last message will
      not be modified.
  Returns:
    JSON bytes representing the new messages.
  """
  return _messages.ModelMessagesTypeAdapter.dump_json(
    self.new_messages(result_tool_return_content=result_tool_return_content)
  )

```
  
---|---  
####  is_complete `class-attribute` `instance-attribute`
```
is_complete: bool[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/functions.html#bool>) = field[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/dataclasses.html#dataclasses.field> "dataclasses.field")(default=False, init=False)

```

Whether the stream has all been received.
This is set to `True` when one of `stream`[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.stream>), `stream_text`[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.stream_text>), `stream_structured`[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.stream_structured>) or `get_data`[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.StreamedRunResult.get_data>) completes.
####  stream `async`
```
stream(
  *, debounce_by: float[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/functions.html#float>) | None = 0.1
) -> AsyncIterator[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.AsyncIterator> "collections.abc.AsyncIterator")[ResultDataT[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]

```

Stream the response as an async iterable.
The pydantic validator for structured data will be called in [partial mode](https://ai.pydantic.dev/api/result/<https:/docs.pydantic.dev/dev/concepts/experimental/#partial-validation>) on each iteration.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`debounce_by` |  `float[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/functions.html#float>) | None` |  by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing. Debouncing is particularly important for long structured responses to reduce the overhead of performing validation as each token is received. |  `0.1`  
Returns:
Type | Description  
---|---  
`AsyncIterator[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.AsyncIterator> "collections.abc.AsyncIterator")[ResultDataT[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")]` |  An async iterable of the response data.  
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
```
| ```
async def stream(self, *, debounce_by: float | None = 0.1) -> AsyncIterator[ResultDataT]:
"""Stream the response as an async iterable.
  The pydantic validator for structured data will be called in
  [partial mode](https://docs.pydantic.dev/dev/concepts/experimental/#partial-validation)
  on each iteration.
  Args:
    debounce_by: by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing.
      Debouncing is particularly important for long structured responses to reduce the overhead of
      performing validation as each token is received.
  Returns:
    An async iterable of the response data.
  """
  async for structured_message, is_last in self.stream_structured(debounce_by=debounce_by):
    result = await self.validate_structured_result(structured_message, allow_partial=not is_last)
    yield result

```
  
---|---  
####  stream_text `async`
```
stream_text(
  *, delta: bool[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/functions.html#bool>) = False, debounce_by: float[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/functions.html#float>) | None = 0.1
) -> AsyncIterator[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.AsyncIterator> "collections.abc.AsyncIterator")[str[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#str>)]

```

Stream the text result as an async iterable.
Note
Result validators will NOT be called on the text result if `delta=True`.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`delta` |  `bool[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/functions.html#bool>)` |  if `True`, yield each chunk of text as it is received, if `False` (default), yield the full text up to the current point. |  `False`  
`debounce_by` |  `float[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/functions.html#float>) | None` |  by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing. Debouncing is particularly important for long structured responses to reduce the overhead of performing validation as each token is received. |  `0.1`  
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
```
| ```
async def stream_text(self, *, delta: bool = False, debounce_by: float | None = 0.1) -> AsyncIterator[str]:
"""Stream the text result as an async iterable.
  !!! note
    Result validators will NOT be called on the text result if `delta=True`.
  Args:
    delta: if `True`, yield each chunk of text as it is received, if `False` (default), yield the full text
      up to the current point.
    debounce_by: by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing.
      Debouncing is particularly important for long structured responses to reduce the overhead of
      performing validation as each token is received.
  """
  if self._result_schema and not self._result_schema.allow_text_result:
    raise exceptions.UserError('stream_text() can only be used with text responses')
  usage_checking_stream = _get_usage_checking_stream_response(
    self._stream_response, self._usage_limits, self.usage
  )
  # Define a "merged" version of the iterator that will yield items that have already been retrieved
  # and items that we receive while streaming. We define a dedicated async iterator for this so we can
  # pass the combined stream to the group_by_temporal function within `_stream_text_deltas` below.
  async def _stream_text_deltas_ungrouped() -> AsyncIterator[tuple[str, int]]:
    # if the response currently has any parts with content, yield those before streaming
    msg = self._stream_response.get()
    for i, part in enumerate(msg.parts):
      if isinstance(part, _messages.TextPart) and part.content:
        yield part.content, i
    async for event in usage_checking_stream:
      if (
        isinstance(event, _messages.PartStartEvent)
        and isinstance(event.part, _messages.TextPart)
        and event.part.content
      ):
        yield event.part.content, event.index
      elif (
        isinstance(event, _messages.PartDeltaEvent)
        and isinstance(event.delta, _messages.TextPartDelta)
        and event.delta.content_delta
      ):
        yield event.delta.content_delta, event.index
  async def _stream_text_deltas() -> AsyncIterator[str]:
    async with _utils.group_by_temporal(_stream_text_deltas_ungrouped(), debounce_by) as group_iter:
      async for items in group_iter:
        yield ''.join([content for content, _ in items])
  with _logfire.span('response stream text') as lf_span:
    if delta:
      async for text in _stream_text_deltas():
        yield text
    else:
      # a quick benchmark shows it's faster to build up a string with concat when we're
      # yielding at each step
      deltas: list[str] = []
      combined_validated_text = ''
      async for text in _stream_text_deltas():
        deltas.append(text)
        combined_text = ''.join(deltas)
        combined_validated_text = await self._validate_text_result(combined_text)
        yield combined_validated_text
      lf_span.set_attribute('combined_text', combined_validated_text)
      await self._marked_completed(
        _messages.ModelResponse(
          parts=[_messages.TextPart(combined_validated_text)],
          model_name=self._stream_response.model_name(),
        )
      )

```
  
---|---  
####  stream_structured `async`
```
stream_structured(
  *, debounce_by: float[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/functions.html#float>) | None = 0.1
) -> AsyncIterator[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.AsyncIterator> "collections.abc.AsyncIterator")[tuple[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#tuple>)[ModelResponse[](https://ai.pydantic.dev/api/result/<../messages/#pydantic_ai.messages.ModelResponse> "pydantic_ai.messages.ModelResponse"), bool[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/functions.html#bool>)]]

```

Stream the response as an async iterable of Structured LLM Messages.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`debounce_by` |  `float[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/functions.html#float>) | None` |  by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing. Debouncing is particularly important for long structured responses to reduce the overhead of performing validation as each token is received. |  `0.1`  
Returns:
Type | Description  
---|---  
`AsyncIterator[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.AsyncIterator> "collections.abc.AsyncIterator")[tuple[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/stdtypes.html#tuple>)[ModelResponse[](https://ai.pydantic.dev/api/result/<../messages/#pydantic_ai.messages.ModelResponse> "pydantic_ai.messages.ModelResponse"), bool[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/functions.html#bool>)]]` |  An async iterable of the structured response message and whether that is the last message.  
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
```
| ```
async def stream_structured(
  self, *, debounce_by: float | None = 0.1
) -> AsyncIterator[tuple[_messages.ModelResponse, bool]]:
"""Stream the response as an async iterable of Structured LLM Messages.
  Args:
    debounce_by: by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing.
      Debouncing is particularly important for long structured responses to reduce the overhead of
      performing validation as each token is received.
  Returns:
    An async iterable of the structured response message and whether that is the last message.
  """
  usage_checking_stream = _get_usage_checking_stream_response(
    self._stream_response, self._usage_limits, self.usage
  )
  with _logfire.span('response stream structured') as lf_span:
    # if the message currently has any parts with content, yield before streaming
    msg = self._stream_response.get()
    for part in msg.parts:
      if part.has_content():
        yield msg, False
        break
    async with _utils.group_by_temporal(usage_checking_stream, debounce_by) as group_iter:
      async for _events in group_iter:
        msg = self._stream_response.get()
        yield msg, False
      msg = self._stream_response.get()
      yield msg, True
      # TODO: Should this now be `final_response` instead of `structured_response`?
      lf_span.set_attribute('structured_response', msg)
      await self._marked_completed(msg)

```
  
---|---  
####  get_data `async`
```
get_data() -> ResultDataT[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")

```

Stream the whole response, validate and return it.
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
328
329
330
331
332
333
334
335
336
337
338
```
| ```
async def get_data(self) -> ResultDataT:
"""Stream the whole response, validate and return it."""
  usage_checking_stream = _get_usage_checking_stream_response(
    self._stream_response, self._usage_limits, self.usage
  )
  async for _ in usage_checking_stream:
    pass
  message = self._stream_response.get()
  await self._marked_completed(message)
  return await self.validate_structured_result(message)

```
  
---|---  
####  usage
```
usage() -> Usage[](https://ai.pydantic.dev/api/result/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage")

```

Return the usage of the whole run.
Note
This won't return the full usage until the stream is finished.
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
340
341
342
343
344
345
346
```
| ```
def usage(self) -> Usage:
"""Return the usage of the whole run.
  !!! note
    This won't return the full usage until the stream is finished.
  """
  return self._run_ctx.usage + self._stream_response.usage()

```
  
---|---  
####  timestamp
```
timestamp() -> datetime[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/datetime.html#datetime.datetime> "datetime.datetime")

```

Get the timestamp of the response.
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
348
349
350
```
| ```
def timestamp(self) -> datetime:
"""Get the timestamp of the response."""
  return self._stream_response.timestamp()

```
  
---|---  
####  validate_structured_result `async`
```
validate_structured_result(
  message: ModelResponse[](https://ai.pydantic.dev/api/result/<../messages/#pydantic_ai.messages.ModelResponse> "pydantic_ai.messages.ModelResponse"), *, allow_partial: bool[](https://ai.pydantic.dev/api/result/<https:/docs.python.org/3/library/functions.html#bool>) = False
) -> ResultDataT[](https://ai.pydantic.dev/api/result/<#pydantic_ai.result.ResultDataT> "pydantic_ai.result.ResultDataT")

```

Validate a structured result message.
Source code in `pydantic_ai_slim/pydantic_ai/result.py`
```
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
```
| ```
async def validate_structured_result(
  self, message: _messages.ModelResponse, *, allow_partial: bool = False
) -> ResultDataT:
"""Validate a structured result message."""
  if self._result_schema is not None and self._result_tool_name is not None:
    match = self._result_schema.find_named_tool(message.parts, self._result_tool_name)
    if match is None:
      raise exceptions.UnexpectedModelBehavior(
        f'Invalid response, unable to find tool: {self._result_schema.tool_names()}'
      )
    call, result_tool = match
    result_data = result_tool.validate(call, allow_partial=allow_partial, wrap_validation_errors=False)
    for validator in self._result_validators:
      result_data = await validator.validate(result_data, call, self._run_ctx)
    return result_data
  else:
    text = '\n\n'.join(x.content for x in message.parts if isinstance(x, _messages.TextPart))
    for validator in self._result_validators:
      text = await validator.validate(
        text,
        None,
        self._run_ctx,
      )
    # Since there is no result tool, we can assume that str is compatible with ResultDataT
    return cast(ResultDataT, text)

```
  
---|---  
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_settings.md
================
[ Skip to content ](https://ai.pydantic.dev/api/settings/<#pydantic_aisettings>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/settings/<../..> "PydanticAI")
PydanticAI 
pydantic_ai.settings 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/settings/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/settings/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/settings/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/settings/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/api/settings/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/settings/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/settings/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/settings/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/settings/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/settings/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/settings/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/settings/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/settings/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/settings/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/settings/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/settings/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/settings/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/settings/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/settings/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/settings/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/settings/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/settings/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/settings/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/settings/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/settings/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/settings/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/settings/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/settings/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/settings/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/settings/<../agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/settings/<../tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/settings/<../result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/settings/<../messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/settings/<../exceptions/>)
    * pydantic_ai.settings  [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/settings/<./>) Table of contents 
      * [ settings  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings>)
      * [ ModelSettings  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings>)
        * [ max_tokens  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.max_tokens>)
        * [ temperature  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.temperature>)
        * [ top_p  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.top_p>)
        * [ timeout  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.timeout>)
        * [ parallel_tool_calls  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.parallel_tool_calls>)
        * [ seed  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.seed>)
        * [ presence_penalty  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.presence_penalty>)
        * [ frequency_penalty  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.frequency_penalty>)
        * [ logit_bias  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.logit_bias>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/settings/<../usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/settings/<../format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/settings/<../models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/settings/<../models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/settings/<../models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/settings/<../models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/settings/<../models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/settings/<../models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/settings/<../models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/settings/<../models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/settings/<../models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/settings/<../models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/settings/<../pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/settings/<../pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/settings/<../pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/settings/<../pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/settings/<../pydantic_graph/exceptions/>)


Table of contents 
  * [ settings  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings>)
  * [ ModelSettings  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings>)
    * [ max_tokens  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.max_tokens>)
    * [ temperature  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.temperature>)
    * [ top_p  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.top_p>)
    * [ timeout  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.timeout>)
    * [ parallel_tool_calls  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.parallel_tool_calls>)
    * [ seed  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.seed>)
    * [ presence_penalty  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.presence_penalty>)
    * [ frequency_penalty  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.frequency_penalty>)
    * [ logit_bias  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.logit_bias>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/settings/<../..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/settings/<../agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/settings/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/settings/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_ai.settings`
###  ModelSettings
Bases: `TypedDict[](https://ai.pydantic.dev/api/settings/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.TypedDict> "typing_extensions.TypedDict")`
Settings to configure an LLM.
Here we include only settings which apply to multiple models / model providers, though not all of these settings are supported by all models.
Source code in `pydantic_ai_slim/pydantic_ai/settings.py`
```
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
```
| ```
class ModelSettings(TypedDict, total=False):
"""Settings to configure an LLM.
  Here we include only settings which apply to multiple models / model providers,
  though not all of these settings are supported by all models.
  """
  max_tokens: int
"""The maximum number of tokens to generate before stopping.
  Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq
  * Cohere
  * Mistral
  """
  temperature: float
"""Amount of randomness injected into the response.
  Use `temperature` closer to `0.0` for analytical / multiple choice, and closer to a model's
  maximum `temperature` for creative and generative tasks.
  Note that even with `temperature` of `0.0`, the results will not be fully deterministic.
  Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq
  * Cohere
  * Mistral
  """
  top_p: float
"""An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.
  So 0.1 means only the tokens comprising the top 10% probability mass are considered.
  You should either alter `temperature` or `top_p`, but not both.
  Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq
  * Cohere
  * Mistral
  """
  timeout: float | Timeout
"""Override the client-level default timeout for a request, in seconds.
  Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq
  * Mistral
  """
  parallel_tool_calls: bool
"""Whether to allow parallel tool calls.
  Supported by:
  * OpenAI (some models, not o1)
  * Groq
  * Anthropic
  """
  seed: int
"""The random seed to use for the model, theoretically allowing for deterministic results.
  Supported by:
  * OpenAI
  * Groq
  * Cohere
  * Mistral
  """
  presence_penalty: float
"""Penalize new tokens based on whether they have appeared in the text so far.
  Supported by:
  * OpenAI
  * Groq
  * Cohere
  * Gemini
  * Mistral
  """
  frequency_penalty: float
"""Penalize new tokens based on their existing frequency in the text so far.
  Supported by:
  * OpenAI
  * Groq
  * Cohere
  * Gemini
  * Mistral
  """
  logit_bias: dict[str, int]
"""Modify the likelihood of specified tokens appearing in the completion.
  Supported by:
  * OpenAI
  * Groq
  """

```
  
---|---  
####  max_tokens `instance-attribute`
```
max_tokens: int[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/functions.html#int>)

```

The maximum number of tokens to generate before stopping.
Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq
  * Cohere
  * Mistral


####  temperature `instance-attribute`
```
temperature: float[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/functions.html#float>)

```

Amount of randomness injected into the response.
Use `temperature` closer to `0.0` for analytical / multiple choice, and closer to a model's maximum `temperature` for creative and generative tasks.
Note that even with `temperature` of `0.0`, the results will not be fully deterministic.
Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq
  * Cohere
  * Mistral


####  top_p `instance-attribute`
```
top_p: float[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/functions.html#float>)

```

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.
So 0.1 means only the tokens comprising the top 10% probability mass are considered.
You should either alter `temperature` or `top_p`, but not both.
Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq
  * Cohere
  * Mistral


####  timeout `instance-attribute`
```
timeout: float[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/functions.html#float>) | Timeout

```

Override the client-level default timeout for a request, in seconds.
Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq
  * Mistral


####  parallel_tool_calls `instance-attribute`
```
parallel_tool_calls: bool[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/functions.html#bool>)

```

Whether to allow parallel tool calls.
Supported by: * OpenAI (some models, not o1) * Groq * Anthropic
####  seed `instance-attribute`
```
seed: int[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/functions.html#int>)

```

The random seed to use for the model, theoretically allowing for deterministic results.
Supported by: * OpenAI * Groq * Cohere * Mistral
####  presence_penalty `instance-attribute`
```
presence_penalty: float[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/functions.html#float>)

```

Penalize new tokens based on whether they have appeared in the text so far.
Supported by: * OpenAI * Groq * Cohere * Gemini * Mistral
####  frequency_penalty `instance-attribute`
```
frequency_penalty: float[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/functions.html#float>)

```

Penalize new tokens based on their existing frequency in the text so far.
Supported by: * OpenAI * Groq * Cohere * Gemini * Mistral
####  logit_bias `instance-attribute`
```
logit_bias: dict[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/stdtypes.html#dict>)[str[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/stdtypes.html#str>), int[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/functions.html#int>)]

```

Modify the likelihood of specified tokens appearing in the completion.
Supported by: * OpenAI * Groq
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_tools.md
================
[ Skip to content ](https://ai.pydantic.dev/api/tools/<#pydantic_aitools>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/tools/<../..> "PydanticAI")
PydanticAI 
pydantic_ai.tools 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/tools/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/tools/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/tools/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/tools/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/api/tools/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/tools/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/tools/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/tools/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/tools/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/tools/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/tools/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/tools/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/tools/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/tools/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/tools/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/tools/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/tools/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/tools/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/tools/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/tools/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/tools/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/tools/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/tools/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/tools/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/tools/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/tools/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/tools/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/tools/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/tools/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/tools/<../agent/>)
    * pydantic_ai.tools  [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/tools/<./>) Table of contents 
      * [ tools  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools>)
      * [ AgentDepsT  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT>)
      * [ RunContext  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext>)
        * [ deps  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.deps>)
        * [ model  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.model>)
        * [ usage  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.usage>)
        * [ prompt  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.prompt>)
        * [ messages  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.messages>)
        * [ tool_name  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.tool_name>)
        * [ retry  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.retry>)
        * [ run_step  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.run_step>)
      * [ ToolParams  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolParams>)
      * [ SystemPromptFunc  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.SystemPromptFunc>)
      * [ ToolFuncContext  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolFuncContext>)
      * [ ToolFuncPlain  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolFuncPlain>)
      * [ ToolFuncEither  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolFuncEither>)
      * [ ToolPrepareFunc  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolPrepareFunc>)
      * [ DocstringFormat  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.DocstringFormat>)
      * [ Tool  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.Tool>)
        * [ __init__  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.Tool.__init__>)
        * [ prepare_tool_def  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.Tool.prepare_tool_def>)
        * [ run  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.Tool.run>)
      * [ ObjectJsonSchema  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ObjectJsonSchema>)
      * [ ToolDefinition  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolDefinition>)
        * [ name  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolDefinition.name>)
        * [ description  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolDefinition.description>)
        * [ parameters_json_schema  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolDefinition.parameters_json_schema>)
        * [ outer_typed_dict_key  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolDefinition.outer_typed_dict_key>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/tools/<../result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/tools/<../messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/tools/<../exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/tools/<../settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/tools/<../usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/tools/<../format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/tools/<../models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/tools/<../models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/tools/<../models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/tools/<../models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/tools/<../models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/tools/<../models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/tools/<../models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/tools/<../models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/tools/<../models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/tools/<../models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/tools/<../pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/tools/<../pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/tools/<../pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/tools/<../pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/tools/<../pydantic_graph/exceptions/>)


Table of contents 
  * [ tools  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools>)
  * [ AgentDepsT  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT>)
  * [ RunContext  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext>)
    * [ deps  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.deps>)
    * [ model  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.model>)
    * [ usage  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.usage>)
    * [ prompt  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.prompt>)
    * [ messages  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.messages>)
    * [ tool_name  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.tool_name>)
    * [ retry  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.retry>)
    * [ run_step  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext.run_step>)
  * [ ToolParams  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolParams>)
  * [ SystemPromptFunc  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.SystemPromptFunc>)
  * [ ToolFuncContext  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolFuncContext>)
  * [ ToolFuncPlain  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolFuncPlain>)
  * [ ToolFuncEither  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolFuncEither>)
  * [ ToolPrepareFunc  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolPrepareFunc>)
  * [ DocstringFormat  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.DocstringFormat>)
  * [ Tool  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.Tool>)
    * [ __init__  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.Tool.__init__>)
    * [ prepare_tool_def  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.Tool.prepare_tool_def>)
    * [ run  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.Tool.run>)
  * [ ObjectJsonSchema  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ObjectJsonSchema>)
  * [ ToolDefinition  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolDefinition>)
    * [ name  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolDefinition.name>)
    * [ description  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolDefinition.description>)
    * [ parameters_json_schema  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolDefinition.parameters_json_schema>)
    * [ outer_typed_dict_key  ](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolDefinition.outer_typed_dict_key>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/tools/<../..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/tools/<../agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/tools/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/tools/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_ai.tools`
###  AgentDepsT `module-attribute`
```
AgentDepsT = TypeVar(
  "AgentDepsT", default=None, contravariant=True
)

```

Type variable for agent dependencies.
###  RunContext `dataclass`
Bases: `Generic[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/typing.html#typing.Generic> "typing.Generic")[AgentDepsT[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")]`
Information about the current call.
Source code in `pydantic_ai_slim/pydantic_ai/tools.py`
```
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
```
| ```
@dataclasses.dataclass
class RunContext(Generic[AgentDepsT]):
"""Information about the current call."""
  deps: AgentDepsT
"""Dependencies for the agent."""
  model: models.Model
"""The model used in this run."""
  usage: Usage
"""LLM usage associated with the run."""
  prompt: str
"""The original user prompt passed to the run."""
  messages: list[_messages.ModelMessage] = field(default_factory=list)
"""Messages exchanged in the conversation so far."""
  tool_name: str | None = None
"""Name of the tool being called."""
  retry: int = 0
"""Number of retries so far."""
  run_step: int = 0
"""The current step in the run."""
  def replace_with(
    self, retry: int | None = None, tool_name: str | None | _utils.Unset = _utils.UNSET
  ) -> RunContext[AgentDepsT]:
    # Create a new `RunContext` a new `retry` value and `tool_name`.
    kwargs = {}
    if retry is not None:
      kwargs['retry'] = retry
    if tool_name is not _utils.UNSET:
      kwargs['tool_name'] = tool_name
    return dataclasses.replace(self, **kwargs)

```
  
---|---  
####  deps `instance-attribute`
```
deps: AgentDepsT[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")

```

Dependencies for the agent.
####  model `instance-attribute`
```
model: Model[](https://ai.pydantic.dev/api/tools/<../models/base/#pydantic_ai.models.Model> "pydantic_ai.models.Model")

```

The model used in this run.
####  usage `instance-attribute`
```
usage: Usage[](https://ai.pydantic.dev/api/tools/<../usage/#pydantic_ai.usage.Usage> "pydantic_ai.result.Usage")

```

LLM usage associated with the run.
####  prompt `instance-attribute`
```
prompt: str[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

The original user prompt passed to the run.
####  messages `class-attribute` `instance-attribute`
```
messages: list[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#list>)[ModelMessage[](https://ai.pydantic.dev/api/tools/<../messages/#pydantic_ai.messages.ModelMessage> "pydantic_ai.messages.ModelMessage")] = field[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/dataclasses.html#dataclasses.field> "dataclasses.field")(default_factory=list[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#list>))

```

Messages exchanged in the conversation so far.
####  tool_name `class-attribute` `instance-attribute`
```
tool_name: str[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None

```

Name of the tool being called.
####  retry `class-attribute` `instance-attribute`
```
retry: int[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/functions.html#int>) = 0

```

Number of retries so far.
####  run_step `class-attribute` `instance-attribute`
```
run_step: int[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/functions.html#int>) = 0

```

The current step in the run.
###  ToolParams `module-attribute`
```
ToolParams = ParamSpec[](https://ai.pydantic.dev/api/tools/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.ParamSpec> "typing_extensions.ParamSpec")('ToolParams', default=...)

```

Retrieval function param spec.
###  SystemPromptFunc `module-attribute`
```
SystemPromptFunc = Union[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/typing.html#typing.Union> "typing.Union")[
  Callable[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[RunContext[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")]], str[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#str>)],
  Callable[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[RunContext[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")]], Awaitable[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Awaitable> "collections.abc.Awaitable")[str[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#str>)]],
  Callable[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[], str[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#str>)],
  Callable[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[[], Awaitable[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/collections.abc.html#collections.abc.Awaitable> "collections.abc.Awaitable")[str[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#str>)]],
]

```

A function that may or maybe not take `RunContext` as an argument, and may or may not be async.
Usage `SystemPromptFunc[AgentDepsT]`.
###  ToolFuncContext `module-attribute`
```
ToolFuncContext = Callable[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[
  Concatenate[](https://ai.pydantic.dev/api/tools/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.Concatenate> "typing_extensions.Concatenate")[RunContext[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")], ToolParams[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")], Any[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")
]

```

A tool function that takes `RunContext` as the first argument.
Usage `ToolContextFunc[AgentDepsT, ToolParams]`.
###  ToolFuncPlain `module-attribute`
```
ToolFuncPlain = Callable[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/typing.html#typing.Callable> "typing.Callable")[ToolParams[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams"), Any[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")]

```

A tool function that does not take `RunContext` as the first argument.
Usage `ToolPlainFunc[ToolParams]`.
###  ToolFuncEither `module-attribute`
```
ToolFuncEither = Union[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/typing.html#typing.Union> "typing.Union")[
  ToolFuncContext[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolFuncContext> "pydantic_ai.tools.ToolFuncContext")[AgentDepsT[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT"), ToolParams[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")],
  ToolFuncPlain[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolFuncPlain> "pydantic_ai.tools.ToolFuncPlain")[ToolParams[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolParams> "pydantic_ai.tools.ToolParams")],
]

```

Either kind of tool function.
This is just a union of `ToolFuncContext`[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolFuncContext>) and `ToolFuncPlain`[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolFuncPlain>).
Usage `ToolFuncEither[AgentDepsT, ToolParams]`.
###  ToolPrepareFunc `module-attribute`
```
ToolPrepareFunc: TypeAlias[](https://ai.pydantic.dev/api/tools/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.TypeAlias> "typing_extensions.TypeAlias") = (
  "Callable[[RunContext[AgentDepsT], ToolDefinition], Awaitable[ToolDefinition | None]]"
)

```

Definition of a function that can prepare a tool definition at call time.
See [tool docs](https://ai.pydantic.dev/api/tools/tools/#tool-prepare>) for more information.
Example — here `only_if_42` is valid as a `ToolPrepareFunc`:
```
from typing import Union
from pydantic_ai import RunContext, Tool
from pydantic_ai.tools import ToolDefinition
async def only_if_42(
  ctx: RunContext[int], tool_def: ToolDefinition
) -> Union[ToolDefinition, None]:
  if ctx.deps == 42:
    return tool_def
def hitchhiker(ctx: RunContext[int], answer: str) -> str:
  return f'{ctx.deps}{answer}'
hitchhiker = Tool(hitchhiker, prepare=only_if_42)

```

Usage `ToolPrepareFunc[AgentDepsT]`.
###  DocstringFormat `module-attribute`
```
DocstringFormat = Literal[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/typing.html#typing.Literal> "typing.Literal")[
  "google", "numpy", "sphinx", "auto"
]

```

Supported docstring formats.
  * `'google'` — [Google-style](https://ai.pydantic.dev/api/tools/<https:/google.github.io/styleguide/pyguide.html#381-docstrings>) docstrings.
  * `'numpy'` — [Numpy-style](https://ai.pydantic.dev/api/tools/<https:/numpydoc.readthedocs.io/en/latest/format.html>) docstrings.
  * `'sphinx'` — [Sphinx-style](https://ai.pydantic.dev/api/tools/<https:/sphinx-rtd-tutorial.readthedocs.io/en/latest/docstrings.html#the-sphinx-docstring-format>) docstrings.
  * `'auto'` — Automatically infer the format based on the structure of the docstring.


###  Tool `dataclass`
Bases: `Generic[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/typing.html#typing.Generic> "typing.Generic")[AgentDepsT[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")]`
A tool function for an agent.
Source code in `pydantic_ai_slim/pydantic_ai/tools.py`
```
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
```
| ```
@dataclass(init=False)
class Tool(Generic[AgentDepsT]):
"""A tool function for an agent."""
  function: ToolFuncEither[AgentDepsT]
  takes_ctx: bool
  max_retries: int | None
  name: str
  description: str
  prepare: ToolPrepareFunc[AgentDepsT] | None
  docstring_format: DocstringFormat
  require_parameter_descriptions: bool
  _is_async: bool = field(init=False)
  _single_arg_name: str | None = field(init=False)
  _positional_fields: list[str] = field(init=False)
  _var_positional_field: str | None = field(init=False)
  _validator: SchemaValidator = field(init=False, repr=False)
  _parameters_json_schema: ObjectJsonSchema = field(init=False)
  # TODO: Move this state off the Tool class, which is otherwise stateless.
  #  This should be tracked inside a specific agent run, not the tool.
  current_retry: int = field(default=0, init=False)
  def __init__(
    self,
    function: ToolFuncEither[AgentDepsT],
    *,
    takes_ctx: bool | None = None,
    max_retries: int | None = None,
    name: str | None = None,
    description: str | None = None,
    prepare: ToolPrepareFunc[AgentDepsT] | None = None,
    docstring_format: DocstringFormat = 'auto',
    require_parameter_descriptions: bool = False,
  ):
"""Create a new tool instance.
    Example usage:
```python {noqa="I001"}
    from pydantic_ai import Agent, RunContext, Tool
    async def my_tool(ctx: RunContext[int], x: int, y: int) -> str:
      return f'{ctx.deps} {x} {y}'
    agent = Agent('test', tools=[Tool(my_tool)])
```
    or with a custom prepare method:
```python {noqa="I001"}
    from typing import Union
    from pydantic_ai import Agent, RunContext, Tool
    from pydantic_ai.tools import ToolDefinition
    async def my_tool(ctx: RunContext[int], x: int, y: int) -> str:
      return f'{ctx.deps} {x} {y}'
    async def prep_my_tool(
      ctx: RunContext[int], tool_def: ToolDefinition
    ) -> Union[ToolDefinition, None]:
      # only register the tool if `deps == 42`
      if ctx.deps == 42:
        return tool_def
    agent = Agent('test', tools=[Tool(my_tool, prepare=prep_my_tool)])
```

    Args:
      function: The Python function to call as the tool.
      takes_ctx: Whether the function takes a [`RunContext`][pydantic_ai.tools.RunContext] first argument,
        this is inferred if unset.
      max_retries: Maximum number of retries allowed for this tool, set to the agent default if `None`.
      name: Name of the tool, inferred from the function if `None`.
      description: Description of the tool, inferred from the function if `None`.
      prepare: custom method to prepare the tool definition for each step, return `None` to omit this
        tool from a given step. This is useful if you want to customise a tool at call time,
        or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].
      docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].
        Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.
      require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.
    """
    if takes_ctx is None:
      takes_ctx = _pydantic.takes_ctx(function)
    f = _pydantic.function_schema(function, takes_ctx, docstring_format, require_parameter_descriptions)
    self.function = function
    self.takes_ctx = takes_ctx
    self.max_retries = max_retries
    self.name = name or function.__name__
    self.description = description or f['description']
    self.prepare = prepare
    self.docstring_format = docstring_format
    self.require_parameter_descriptions = require_parameter_descriptions
    self._is_async = inspect.iscoroutinefunction(self.function)
    self._single_arg_name = f['single_arg_name']
    self._positional_fields = f['positional_fields']
    self._var_positional_field = f['var_positional_field']
    self._validator = f['validator']
    self._parameters_json_schema = f['json_schema']
  async def prepare_tool_def(self, ctx: RunContext[AgentDepsT]) -> ToolDefinition | None:
"""Get the tool definition.
    By default, this method creates a tool definition, then either returns it, or calls `self.prepare`
    if it's set.
    Returns:
      return a `ToolDefinition` or `None` if the tools should not be registered for this run.
    """
    tool_def = ToolDefinition(
      name=self.name,
      description=self.description,
      parameters_json_schema=self._parameters_json_schema,
    )
    if self.prepare is not None:
      return await self.prepare(ctx, tool_def)
    else:
      return tool_def
  async def run(
    self, message: _messages.ToolCallPart, run_context: RunContext[AgentDepsT]
  ) -> _messages.ToolReturnPart | _messages.RetryPromptPart:
"""Run the tool function asynchronously."""
    try:
      if isinstance(message.args, str):
        args_dict = self._validator.validate_json(message.args)
      else:
        args_dict = self._validator.validate_python(message.args)
    except ValidationError as e:
      return self._on_error(e, message)
    args, kwargs = self._call_args(args_dict, message, run_context)
    try:
      if self._is_async:
        function = cast(Callable[[Any], Awaitable[str]], self.function)
        response_content = await function(*args, **kwargs)
      else:
        function = cast(Callable[[Any], str], self.function)
        response_content = await _utils.run_in_executor(function, *args, **kwargs)
    except ModelRetry as e:
      return self._on_error(e, message)
    self.current_retry = 0
    return _messages.ToolReturnPart(
      tool_name=message.tool_name,
      content=response_content,
      tool_call_id=message.tool_call_id,
    )
  def _call_args(
    self,
    args_dict: dict[str, Any],
    message: _messages.ToolCallPart,
    run_context: RunContext[AgentDepsT],
  ) -> tuple[list[Any], dict[str, Any]]:
    if self._single_arg_name:
      args_dict = {self._single_arg_name: args_dict}
    ctx = dataclasses.replace(run_context, retry=self.current_retry, tool_name=message.tool_name)
    args = [ctx] if self.takes_ctx else []
    for positional_field in self._positional_fields:
      args.append(args_dict.pop(positional_field))
    if self._var_positional_field:
      args.extend(args_dict.pop(self._var_positional_field))
    return args, args_dict
  def _on_error(
    self, exc: ValidationError | ModelRetry, call_message: _messages.ToolCallPart
  ) -> _messages.RetryPromptPart:
    self.current_retry += 1
    if self.max_retries is None or self.current_retry > self.max_retries:
      raise UnexpectedModelBehavior(f'Tool exceeded max retries count of {self.max_retries}') from exc
    else:
      if isinstance(exc, ValidationError):
        content = exc.errors(include_url=False)
      else:
        content = exc.message
      return _messages.RetryPromptPart(
        tool_name=call_message.tool_name,
        content=content,
        tool_call_id=call_message.tool_call_id,
      )

```
  
---|---  
####  __init__
```
__init__(
  function: ToolFuncEither[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolFuncEither> "pydantic_ai.tools.ToolFuncEither")[AgentDepsT[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")],
  *,
  takes_ctx: bool[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/functions.html#bool>) | None = None,
  max_retries: int[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/functions.html#int>) | None = None,
  name: str[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None,
  description: str[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None,
  prepare: ToolPrepareFunc[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolPrepareFunc> "pydantic_ai.tools.ToolPrepareFunc")[AgentDepsT[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")] | None = None,
  docstring_format: DocstringFormat[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.DocstringFormat> "pydantic_ai.tools.DocstringFormat") = "auto",
  require_parameter_descriptions: bool[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/functions.html#bool>) = False
)

```

Create a new tool instance.
Example usage:
```
from pydantic_ai import Agent, RunContext, Tool
async def my_tool(ctx: RunContext[int], x: int, y: int) -> str:
  return f'{ctx.deps}{x}{y}'
agent = Agent('test', tools=[Tool(my_tool)])

```

or with a custom prepare method:
```
from typing import Union
from pydantic_ai import Agent, RunContext, Tool
from pydantic_ai.tools import ToolDefinition
async def my_tool(ctx: RunContext[int], x: int, y: int) -> str:
  return f'{ctx.deps}{x}{y}'
async def prep_my_tool(
  ctx: RunContext[int], tool_def: ToolDefinition
) -> Union[ToolDefinition, None]:
  # only register the tool if `deps == 42`
  if ctx.deps == 42:
    return tool_def
agent = Agent('test', tools=[Tool(my_tool, prepare=prep_my_tool)])

```

Parameters:
Name | Type | Description | Default  
---|---|---|---  
`function` |  `ToolFuncEither[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolFuncEither> "pydantic_ai.tools.ToolFuncEither")[AgentDepsT[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")]` |  The Python function to call as the tool. |  _required_  
`takes_ctx` |  `bool[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/functions.html#bool>) | None` |  Whether the function takes a `RunContext`[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext>) first argument, this is inferred if unset. |  `None`  
`max_retries` |  `int[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/functions.html#int>) | None` |  Maximum number of retries allowed for this tool, set to the agent default if `None`. |  `None`  
`name` |  `str[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  Name of the tool, inferred from the function if `None`. |  `None`  
`description` |  `str[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#str>) | None` |  Description of the tool, inferred from the function if `None`. |  `None`  
`prepare` |  `ToolPrepareFunc[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolPrepareFunc> "pydantic_ai.tools.ToolPrepareFunc")[AgentDepsT[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")] | None` |  custom method to prepare the tool definition for each step, return `None` to omit this tool from a given step. This is useful if you want to customise a tool at call time, or omit it completely from a step. See `ToolPrepareFunc`[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolPrepareFunc>). |  `None`  
`docstring_format` |  `DocstringFormat[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.DocstringFormat> "pydantic_ai.tools.DocstringFormat")` |  The format of the docstring, see `DocstringFormat`[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.DocstringFormat>). Defaults to `'auto'`, such that the format is inferred from the structure of the docstring. |  `'auto'`  
`require_parameter_descriptions` |  `bool[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/functions.html#bool>)` |  If True, raise an error if a parameter description is missing. Defaults to False. |  `False`  
Source code in `pydantic_ai_slim/pydantic_ai/tools.py`
```
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
```
| ```
def __init__(
  self,
  function: ToolFuncEither[AgentDepsT],
  *,
  takes_ctx: bool | None = None,
  max_retries: int | None = None,
  name: str | None = None,
  description: str | None = None,
  prepare: ToolPrepareFunc[AgentDepsT] | None = None,
  docstring_format: DocstringFormat = 'auto',
  require_parameter_descriptions: bool = False,
):
"""Create a new tool instance.
  Example usage:
  ```python {noqa="I001"}
  from pydantic_ai import Agent, RunContext, Tool
  async def my_tool(ctx: RunContext[int], x: int, y: int) -> str:
    return f'{ctx.deps} {x} {y}'
  agent = Agent('test', tools=[Tool(my_tool)])
  ```
  or with a custom prepare method:
  ```python {noqa="I001"}
  from typing import Union
  from pydantic_ai import Agent, RunContext, Tool
  from pydantic_ai.tools import ToolDefinition
  async def my_tool(ctx: RunContext[int], x: int, y: int) -> str:
    return f'{ctx.deps} {x} {y}'
  async def prep_my_tool(
    ctx: RunContext[int], tool_def: ToolDefinition
  ) -> Union[ToolDefinition, None]:
    # only register the tool if `deps == 42`
    if ctx.deps == 42:
      return tool_def
  agent = Agent('test', tools=[Tool(my_tool, prepare=prep_my_tool)])
  ```

  Args:
    function: The Python function to call as the tool.
    takes_ctx: Whether the function takes a [`RunContext`][pydantic_ai.tools.RunContext] first argument,
      this is inferred if unset.
    max_retries: Maximum number of retries allowed for this tool, set to the agent default if `None`.
    name: Name of the tool, inferred from the function if `None`.
    description: Description of the tool, inferred from the function if `None`.
    prepare: custom method to prepare the tool definition for each step, return `None` to omit this
      tool from a given step. This is useful if you want to customise a tool at call time,
      or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].
    docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].
      Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.
    require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.
  """
  if takes_ctx is None:
    takes_ctx = _pydantic.takes_ctx(function)
  f = _pydantic.function_schema(function, takes_ctx, docstring_format, require_parameter_descriptions)
  self.function = function
  self.takes_ctx = takes_ctx
  self.max_retries = max_retries
  self.name = name or function.__name__
  self.description = description or f['description']
  self.prepare = prepare
  self.docstring_format = docstring_format
  self.require_parameter_descriptions = require_parameter_descriptions
  self._is_async = inspect.iscoroutinefunction(self.function)
  self._single_arg_name = f['single_arg_name']
  self._positional_fields = f['positional_fields']
  self._var_positional_field = f['var_positional_field']
  self._validator = f['validator']
  self._parameters_json_schema = f['json_schema']

```
  
---|---  
####  prepare_tool_def `async`
```
prepare_tool_def(
  ctx: RunContext[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")],
) -> ToolDefinition[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolDefinition> "pydantic_ai.tools.ToolDefinition") | None

```

Get the tool definition.
By default, this method creates a tool definition, then either returns it, or calls `self.prepare` if it's set.
Returns:
Type | Description  
---|---  
`ToolDefinition[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolDefinition> "pydantic_ai.tools.ToolDefinition") | None` |  return a `ToolDefinition` or `None` if the tools should not be registered for this run.  
Source code in `pydantic_ai_slim/pydantic_ai/tools.py`
```
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
```
| ```
async def prepare_tool_def(self, ctx: RunContext[AgentDepsT]) -> ToolDefinition | None:
"""Get the tool definition.
  By default, this method creates a tool definition, then either returns it, or calls `self.prepare`
  if it's set.
  Returns:
    return a `ToolDefinition` or `None` if the tools should not be registered for this run.
  """
  tool_def = ToolDefinition(
    name=self.name,
    description=self.description,
    parameters_json_schema=self._parameters_json_schema,
  )
  if self.prepare is not None:
    return await self.prepare(ctx, tool_def)
  else:
    return tool_def

```
  
---|---  
####  run `async`
```
run(
  message: ToolCallPart[](https://ai.pydantic.dev/api/tools/<../messages/#pydantic_ai.messages.ToolCallPart> "pydantic_ai.messages.ToolCallPart"),
  run_context: RunContext[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.RunContext> "pydantic_ai.tools.RunContext")[AgentDepsT[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.AgentDepsT> "pydantic_ai.tools.AgentDepsT")],
) -> ToolReturnPart[](https://ai.pydantic.dev/api/tools/<../messages/#pydantic_ai.messages.ToolReturnPart> "pydantic_ai.messages.ToolReturnPart") | RetryPromptPart[](https://ai.pydantic.dev/api/tools/<../messages/#pydantic_ai.messages.RetryPromptPart> "pydantic_ai.messages.RetryPromptPart")

```

Run the tool function asynchronously.
Source code in `pydantic_ai_slim/pydantic_ai/tools.py`
```
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
```
| ```
async def run(
  self, message: _messages.ToolCallPart, run_context: RunContext[AgentDepsT]
) -> _messages.ToolReturnPart | _messages.RetryPromptPart:
"""Run the tool function asynchronously."""
  try:
    if isinstance(message.args, str):
      args_dict = self._validator.validate_json(message.args)
    else:
      args_dict = self._validator.validate_python(message.args)
  except ValidationError as e:
    return self._on_error(e, message)
  args, kwargs = self._call_args(args_dict, message, run_context)
  try:
    if self._is_async:
      function = cast(Callable[[Any], Awaitable[str]], self.function)
      response_content = await function(*args, **kwargs)
    else:
      function = cast(Callable[[Any], str], self.function)
      response_content = await _utils.run_in_executor(function, *args, **kwargs)
  except ModelRetry as e:
    return self._on_error(e, message)
  self.current_retry = 0
  return _messages.ToolReturnPart(
    tool_name=message.tool_name,
    content=response_content,
    tool_call_id=message.tool_call_id,
  )

```
  
---|---  
###  ObjectJsonSchema `module-attribute`
```
ObjectJsonSchema: TypeAlias[](https://ai.pydantic.dev/api/tools/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.TypeAlias> "typing_extensions.TypeAlias") = dict[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#dict>)[str[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#str>), Any[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/typing.html#typing.Any> "typing.Any")]

```

Type representing JSON schema of an object, e.g. where `"type": "object"`.
This type is used to define tools parameters (aka arguments) in [ToolDefinition](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ToolDefinition>).
With PEP-728 this should be a TypedDict with `type: Literal['object']`, and `extra_parts=Any`
###  ToolDefinition `dataclass`
Definition of a tool passed to a model.
This is used for both function tools result tools.
Source code in `pydantic_ai_slim/pydantic_ai/tools.py`
```
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
```
| ```
@dataclass
class ToolDefinition:
"""Definition of a tool passed to a model.
  This is used for both function tools result tools.
  """
  name: str
"""The name of the tool."""
  description: str
"""The description of the tool."""
  parameters_json_schema: ObjectJsonSchema
"""The JSON schema for the tool's parameters."""
  outer_typed_dict_key: str | None = None
"""The key in the outer [TypedDict] that wraps a result tool.
  This will only be set for result tools which don't have an `object` JSON schema.
  """

```
  
---|---  
####  name `instance-attribute`
```
name: str[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

The name of the tool.
####  description `instance-attribute`
```
description: str[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#str>)

```

The description of the tool.
####  parameters_json_schema `instance-attribute`
```
parameters_json_schema: ObjectJsonSchema[](https://ai.pydantic.dev/api/tools/<#pydantic_ai.tools.ObjectJsonSchema> "pydantic_ai.tools.ObjectJsonSchema")

```

The JSON schema for the tool's parameters.
####  outer_typed_dict_key `class-attribute` `instance-attribute`
```
outer_typed_dict_key: str[](https://ai.pydantic.dev/api/tools/<https:/docs.python.org/3/library/stdtypes.html#str>) | None = None

```

The key in the outer [TypedDict] that wraps a result tool.
This will only be set for result tools which don't have an `object` JSON schema.
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/api_usage.md
================
[ Skip to content ](https://ai.pydantic.dev/api/usage/<#pydantic_aiusage>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/usage/<../..> "PydanticAI")
PydanticAI 
pydantic_ai.usage 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/usage/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/usage/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/usage/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/usage/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/api/usage/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/usage/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/usage/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/usage/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/usage/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/usage/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/usage/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/usage/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/usage/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/usage/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/usage/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/usage/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/usage/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/api/usage/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/api/usage/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/usage/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/usage/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/usage/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/usage/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/usage/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/usage/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/usage/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/usage/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/usage/examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/api/usage/examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/usage/<../agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/usage/<../tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/usage/<../result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/usage/<../messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/usage/<../exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/usage/<../settings/>)
    * pydantic_ai.usage  [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/usage/<./>) Table of contents 
      * [ usage  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage>)
      * [ Usage  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage>)
        * [ requests  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage.requests>)
        * [ request_tokens  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage.request_tokens>)
        * [ response_tokens  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage.response_tokens>)
        * [ total_tokens  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage.total_tokens>)
        * [ details  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage.details>)
        * [ incr  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage.incr>)
        * [ __add__  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage.__add__>)
      * [ UsageLimits  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits>)
        * [ request_limit  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits.request_limit>)
        * [ request_tokens_limit  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits.request_tokens_limit>)
        * [ response_tokens_limit  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits.response_tokens_limit>)
        * [ total_tokens_limit  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits.total_tokens_limit>)
        * [ has_token_limits  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits.has_token_limits>)
        * [ check_before_request  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits.check_before_request>)
        * [ check_tokens  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits.check_tokens>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/usage/<../format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/usage/<../models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/usage/<../models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/usage/<../models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/usage/<../models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/usage/<../models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/usage/<../models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/usage/<../models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/usage/<../models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/usage/<../models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/usage/<../models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/usage/<../pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/usage/<../pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/api/usage/<../pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/usage/<../pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/usage/<../pydantic_graph/exceptions/>)


Table of contents 
  * [ usage  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage>)
  * [ Usage  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage>)
    * [ requests  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage.requests>)
    * [ request_tokens  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage.request_tokens>)
    * [ response_tokens  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage.response_tokens>)
    * [ total_tokens  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage.total_tokens>)
    * [ details  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage.details>)
    * [ incr  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage.incr>)
    * [ __add__  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage.__add__>)
  * [ UsageLimits  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits>)
    * [ request_limit  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits.request_limit>)
    * [ request_tokens_limit  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits.request_tokens_limit>)
    * [ response_tokens_limit  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits.response_tokens_limit>)
    * [ total_tokens_limit  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits.total_tokens_limit>)
    * [ has_token_limits  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits.has_token_limits>)
    * [ check_before_request  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits.check_before_request>)
    * [ check_tokens  ](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.UsageLimits.check_tokens>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/usage/<../..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/usage/<../agent/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/api/usage/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/api/usage/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# `pydantic_ai.usage`
###  Usage `dataclass`
LLM usage associated with a request or run.
Responsibility for calculating usage is on the model; PydanticAI simply sums the usage information across requests.
You'll need to look up the documentation of the model you're using to convert usage to monetary costs.
Source code in `pydantic_ai_slim/pydantic_ai/usage.py`
```
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
```
| ```
@dataclass
class Usage:
"""LLM usage associated with a request or run.
  Responsibility for calculating usage is on the model; PydanticAI simply sums the usage information across requests.
  You'll need to look up the documentation of the model you're using to convert usage to monetary costs.
  """
  requests: int = 0
"""Number of requests made to the LLM API."""
  request_tokens: int | None = None
"""Tokens used in processing requests."""
  response_tokens: int | None = None
"""Tokens used in generating responses."""
  total_tokens: int | None = None
"""Total tokens used in the whole run, should generally be equal to `request_tokens + response_tokens`."""
  details: dict[str, int] | None = None
"""Any extra details returned by the model."""
  def incr(self, incr_usage: Usage, *, requests: int = 0) -> None:
"""Increment the usage in place.
    Args:
      incr_usage: The usage to increment by.
      requests: The number of requests to increment by in addition to `incr_usage.requests`.
    """
    self.requests += requests
    for f in 'requests', 'request_tokens', 'response_tokens', 'total_tokens':
      self_value = getattr(self, f)
      other_value = getattr(incr_usage, f)
      if self_value is not None or other_value is not None:
        setattr(self, f, (self_value or 0) + (other_value or 0))
    if incr_usage.details:
      self.details = self.details or {}
      for key, value in incr_usage.details.items():
        self.details[key] = self.details.get(key, 0) + value
  def __add__(self, other: Usage) -> Usage:
"""Add two Usages together.
    This is provided so it's trivial to sum usage information from multiple requests and runs.
    """
    new_usage = copy(self)
    new_usage.incr(other)
    return new_usage

```
  
---|---  
####  requests `class-attribute` `instance-attribute`
```
requests: int[](https://ai.pydantic.dev/api/usage/<https:/docs.python.org/3/library/functions.html#int>) = 0

```

Number of requests made to the LLM API.
####  request_tokens `class-attribute` `instance-attribute`
```
request_tokens: int[](https://ai.pydantic.dev/api/usage/<https:/docs.python.org/3/library/functions.html#int>) | None = None

```

Tokens used in processing requests.
####  response_tokens `class-attribute` `instance-attribute`
```
response_tokens: int[](https://ai.pydantic.dev/api/usage/<https:/docs.python.org/3/library/functions.html#int>) | None = None

```

Tokens used in generating responses.
####  total_tokens `class-attribute` `instance-attribute`
```
total_tokens: int[](https://ai.pydantic.dev/api/usage/<https:/docs.python.org/3/library/functions.html#int>) | None = None

```

Total tokens used in the whole run, should generally be equal to `request_tokens + response_tokens`.
####  details `class-attribute` `instance-attribute`
```
details: dict[](https://ai.pydantic.dev/api/usage/<https:/docs.python.org/3/library/stdtypes.html#dict>)[str[](https://ai.pydantic.dev/api/usage/<https:/docs.python.org/3/library/stdtypes.html#str>), int[](https://ai.pydantic.dev/api/usage/<https:/docs.python.org/3/library/functions.html#int>)] | None = None

```

Any extra details returned by the model.
####  incr
```
incr(incr_usage: Usage[](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage"), *, requests: int[](https://ai.pydantic.dev/api/usage/<https:/docs.python.org/3/library/functions.html#int>) = 0) -> None

```

Increment the usage in place.
Parameters:
Name | Type | Description | Default  
---|---|---|---  
`incr_usage` |  `Usage[](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage")` |  The usage to increment by. |  _required_  
`requests` |  `int[](https://ai.pydantic.dev/api/usage/<https:/docs.python.org/3/library/functions.html#int>)` |  The number of requests to increment by in addition to `incr_usage.requests`. |  `0`  
Source code in `pydantic_ai_slim/pydantic_ai/usage.py`
```
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
```
| ```
def incr(self, incr_usage: Usage, *, requests: int = 0) -> None:
"""Increment the usage in place.
  Args:
    incr_usage: The usage to increment by.
    requests: The number of requests to increment by in addition to `incr_usage.requests`.
  """
  self.requests += requests
  for f in 'requests', 'request_tokens', 'response_tokens', 'total_tokens':
    self_value = getattr(self, f)
    other_value = getattr(incr_usage, f)
    if self_value is not None or other_value is not None:
      setattr(self, f, (self_value or 0) + (other_value or 0))
  if incr_usage.details:
    self.details = self.details or {}
    for key, value in incr_usage.details.items():
      self.details[key] = self.details.get(key, 0) + value

```
  
---|---  
####  __add__
```
__add__(other: Usage[](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage")) -> Usage[](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage")

```

Add two Usages together.
This is provided so it's trivial to sum usage information from multiple requests and runs.
Source code in `pydantic_ai_slim/pydantic_ai/usage.py`
```
50
51
52
53
54
55
56
57
```
| ```
def __add__(self, other: Usage) -> Usage:
"""Add two Usages together.
  This is provided so it's trivial to sum usage information from multiple requests and runs.
  """
  new_usage = copy(self)
  new_usage.incr(other)
  return new_usage

```
  
---|---  
###  UsageLimits `dataclass`
Limits on model usage.
The request count is tracked by pydantic_ai, and the request limit is checked before each request to the model. Token counts are provided in responses from the model, and the token limits are checked after each response.
Each of the limits can be set to `None` to disable that limit.
Source code in `pydantic_ai_slim/pydantic_ai/usage.py`
```
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
```
| ```
@dataclass
class UsageLimits:
"""Limits on model usage.
  The request count is tracked by pydantic_ai, and the request limit is checked before each request to the model.
  Token counts are provided in responses from the model, and the token limits are checked after each response.
  Each of the limits can be set to `None` to disable that limit.
  """
  request_limit: int | None = 50
"""The maximum number of requests allowed to the model."""
  request_tokens_limit: int | None = None
"""The maximum number of tokens allowed in requests to the model."""
  response_tokens_limit: int | None = None
"""The maximum number of tokens allowed in responses from the model."""
  total_tokens_limit: int | None = None
"""The maximum number of tokens allowed in requests and responses combined."""
  def has_token_limits(self) -> bool:
"""Returns `True` if this instance places any limits on token counts.
    If this returns `False`, the `check_tokens` method will never raise an error.
    This is useful because if we have token limits, we need to check them after receiving each streamed message.
    If there are no limits, we can skip that processing in the streaming response iterator.
    """
    return any(
      limit is not None
      for limit in (self.request_tokens_limit, self.response_tokens_limit, self.total_tokens_limit)
    )
  def check_before_request(self, usage: Usage) -> None:
"""Raises a `UsageLimitExceeded` exception if the next request would exceed the request_limit."""
    request_limit = self.request_limit
    if request_limit is not None and usage.requests >= request_limit:
      raise UsageLimitExceeded(f'The next request would exceed the request_limit of {request_limit}')
  def check_tokens(self, usage: Usage) -> None:
"""Raises a `UsageLimitExceeded` exception if the usage exceeds any of the token limits."""
    request_tokens = usage.request_tokens or 0
    if self.request_tokens_limit is not None and request_tokens > self.request_tokens_limit:
      raise UsageLimitExceeded(
        f'Exceeded the request_tokens_limit of {self.request_tokens_limit} ({request_tokens=})'
      )
    response_tokens = usage.response_tokens or 0
    if self.response_tokens_limit is not None and response_tokens > self.response_tokens_limit:
      raise UsageLimitExceeded(
        f'Exceeded the response_tokens_limit of {self.response_tokens_limit} ({response_tokens=})'
      )
    total_tokens = usage.total_tokens or 0
    if self.total_tokens_limit is not None and total_tokens > self.total_tokens_limit:
      raise UsageLimitExceeded(f'Exceeded the total_tokens_limit of {self.total_tokens_limit} ({total_tokens=})')

```
  
---|---  
####  request_limit `class-attribute` `instance-attribute`
```
request_limit: int[](https://ai.pydantic.dev/api/usage/<https:/docs.python.org/3/library/functions.html#int>) | None = 50

```

The maximum number of requests allowed to the model.
####  request_tokens_limit `class-attribute` `instance-attribute`
```
request_tokens_limit: int[](https://ai.pydantic.dev/api/usage/<https:/docs.python.org/3/library/functions.html#int>) | None = None

```

The maximum number of tokens allowed in requests to the model.
####  response_tokens_limit `class-attribute` `instance-attribute`
```
response_tokens_limit: int[](https://ai.pydantic.dev/api/usage/<https:/docs.python.org/3/library/functions.html#int>) | None = None

```

The maximum number of tokens allowed in responses from the model.
####  total_tokens_limit `class-attribute` `instance-attribute`
```
total_tokens_limit: int[](https://ai.pydantic.dev/api/usage/<https:/docs.python.org/3/library/functions.html#int>) | None = None

```

The maximum number of tokens allowed in requests and responses combined.
####  has_token_limits
```
has_token_limits() -> bool[](https://ai.pydantic.dev/api/usage/<https:/docs.python.org/3/library/functions.html#bool>)

```

Returns `True` if this instance places any limits on token counts.
If this returns `False`, the `check_tokens` method will never raise an error.
This is useful because if we have token limits, we need to check them after receiving each streamed message. If there are no limits, we can skip that processing in the streaming response iterator.
Source code in `pydantic_ai_slim/pydantic_ai/usage.py`
```
79
80
81
82
83
84
85
86
87
88
89
90
```
| ```
def has_token_limits(self) -> bool:
"""Returns `True` if this instance places any limits on token counts.
  If this returns `False`, the `check_tokens` method will never raise an error.
  This is useful because if we have token limits, we need to check them after receiving each streamed message.
  If there are no limits, we can skip that processing in the streaming response iterator.
  """
  return any(
    limit is not None
    for limit in (self.request_tokens_limit, self.response_tokens_limit, self.total_tokens_limit)
  )

```
  
---|---  
####  check_before_request
```
check_before_request(usage: Usage[](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage")) -> None

```

Raises a `UsageLimitExceeded` exception if the next request would exceed the request_limit.
Source code in `pydantic_ai_slim/pydantic_ai/usage.py`
```
92
93
94
95
96
```
| ```
def check_before_request(self, usage: Usage) -> None:
"""Raises a `UsageLimitExceeded` exception if the next request would exceed the request_limit."""
  request_limit = self.request_limit
  if request_limit is not None and usage.requests >= request_limit:
    raise UsageLimitExceeded(f'The next request would exceed the request_limit of {request_limit}')

```
  
---|---  
####  check_tokens
```
check_tokens(usage: Usage[](https://ai.pydantic.dev/api/usage/<#pydantic_ai.usage.Usage> "pydantic_ai.usage.Usage")) -> None

```

Raises a `UsageLimitExceeded` exception if the usage exceeds any of the token limits.
Source code in `pydantic_ai_slim/pydantic_ai/usage.py`
```
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
```
| ```
def check_tokens(self, usage: Usage) -> None:
"""Raises a `UsageLimitExceeded` exception if the usage exceeds any of the token limits."""
  request_tokens = usage.request_tokens or 0
  if self.request_tokens_limit is not None and request_tokens > self.request_tokens_limit:
    raise UsageLimitExceeded(
      f'Exceeded the request_tokens_limit of {self.request_tokens_limit} ({request_tokens=})'
    )
  response_tokens = usage.response_tokens or 0
  if self.response_tokens_limit is not None and response_tokens > self.response_tokens_limit:
    raise UsageLimitExceeded(
      f'Exceeded the response_tokens_limit of {self.response_tokens_limit} ({response_tokens=})'
    )
  total_tokens = usage.total_tokens or 0
  if self.total_tokens_limit is not None and total_tokens > self.total_tokens_limit:
    raise UsageLimitExceeded(f'Exceeded the total_tokens_limit of {self.total_tokens_limit} ({total_tokens=})')

```
  
---|---  
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/contributing.md
================
[ Skip to content ](https://ai.pydantic.dev/contributing/<#installation-and-setup>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/contributing/<..> "PydanticAI")
PydanticAI 
Contributing 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/contributing/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/contributing/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/contributing/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/contributing/<..>)
  * [ Installation  ](https://ai.pydantic.dev/contributing/<../install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/contributing/<../help/>)
  * Contributing  [ Contributing  ](https://ai.pydantic.dev/contributing/<./>) Table of contents 
    * [ Installation and Setup  ](https://ai.pydantic.dev/contributing/<#installation-and-setup>)
    * [ Running Tests etc.  ](https://ai.pydantic.dev/contributing/<#running-tests-etc>)
    * [ Documentation Changes  ](https://ai.pydantic.dev/contributing/<#documentation-changes>)
    * [ Rules for adding new models to PydanticAI  ](https://ai.pydantic.dev/contributing/<#new-model-rules>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/contributing/<../troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/contributing/<../agents/>)
    * [ Models  ](https://ai.pydantic.dev/contributing/<../models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/contributing/<../dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/contributing/<../tools/>)
    * [ Results  ](https://ai.pydantic.dev/contributing/<../results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/contributing/<../message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/contributing/<../testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/contributing/<../logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/contributing/<../multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/contributing/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/contributing/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/contributing/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/contributing/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/contributing/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/contributing/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/contributing/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/contributing/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/contributing/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/contributing/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/contributing/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/contributing/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/contributing/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/contributing/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/contributing/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/contributing/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/contributing/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/contributing/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/contributing/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/contributing/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/contributing/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/contributing/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/contributing/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/contributing/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/contributing/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/contributing/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/contributing/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/contributing/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/contributing/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/contributing/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/contributing/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/contributing/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/contributing/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/contributing/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/contributing/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Installation and Setup  ](https://ai.pydantic.dev/contributing/<#installation-and-setup>)
  * [ Running Tests etc.  ](https://ai.pydantic.dev/contributing/<#running-tests-etc>)
  * [ Documentation Changes  ](https://ai.pydantic.dev/contributing/<#documentation-changes>)
  * [ Rules for adding new models to PydanticAI  ](https://ai.pydantic.dev/contributing/<#new-model-rules>)


# Contributing
We'd love you to contribute to PydanticAI!
## Installation and Setup
Clone your fork and cd into the repo directory
```
gitclonegit@github.com:<yourusername>/pydantic-ai.git
cdpydantic-ai

```

Install `uv` (version 0.4.30 or later) and `pre-commit`
We use pipx here, for other options see:
  * `uv`[ install docs](https://ai.pydantic.dev/contributing/<https:/docs.astral.sh/uv/getting-started/installation/>)
  * `pre-commit`[ install docs](https://ai.pydantic.dev/contributing/<https:/pre-commit.com/#install>)


To get `pipx` itself, see [these docs](https://ai.pydantic.dev/contributing/<https:/pypa.github.io/pipx/>)
```
pipxinstalluvpre-commit

```

Install `pydantic-ai`, all dependencies and pre-commit hooks
```
makeinstall

```

## Running Tests etc.
We use `make` to manage most commands you'll need to run.
For details on available commands, run:
```
makehelp

```

To run code formatting, linting, static type checks, and tests with coverage report generation, run:
```
make

```

## Documentation Changes
To run the documentation page locally, run:
```
uvrunmkdocsserve

```

## Rules for adding new models to PydanticAI
To avoid an excessive workload for the maintainers of PydanticAI, we can't accept all model contributions, so we're setting the following rules for when we'll accept new models and when we won't. This should hopefully reduce the chances of disappointment and wasted work.
  * To add a new model with an extra dependency, that dependency needs > 500k monthly downloads from PyPI consistently over 3 months or more
  * To add a new model which uses another models logic internally and has no extra dependencies, that model's GitHub org needs > 20k stars in total
  * For any other model that's just a custom URL and API key, we're happy to add a one-paragraph description with a link and instructions on the URL to use
  * For any other model that requires more logic, we recommend you release your own Python package `pydantic-ai-xxx`, which depends on `pydantic-ai-slim`[](https://ai.pydantic.dev/contributing/<../install/#slim-install>) and implements a model that inherits from our `Model`[](https://ai.pydantic.dev/contributing/<../api/models/base/#pydantic_ai.models.Model>) ABC


If you're unsure about adding a model, please [create an issue](https://ai.pydantic.dev/contributing/<https:/github.com/pydantic/pydantic-ai/issues>).
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/dependencies.md
================
[ Skip to content ](https://ai.pydantic.dev/dependencies/<#dependencies>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/dependencies/<..> "PydanticAI")
PydanticAI 
Dependencies 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/dependencies/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/dependencies/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/dependencies/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/dependencies/<..>)
  * [ Installation  ](https://ai.pydantic.dev/dependencies/<../install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/dependencies/<../help/>)
  * [ Contributing  ](https://ai.pydantic.dev/dependencies/<../contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/dependencies/<../troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/dependencies/<../agents/>)
    * [ Models  ](https://ai.pydantic.dev/dependencies/<../models/>)
    * Dependencies  [ Dependencies  ](https://ai.pydantic.dev/dependencies/<./>) Table of contents 
      * [ Defining Dependencies  ](https://ai.pydantic.dev/dependencies/<#defining-dependencies>)
      * [ Accessing Dependencies  ](https://ai.pydantic.dev/dependencies/<#accessing-dependencies>)
        * [ Asynchronous vs. Synchronous dependencies  ](https://ai.pydantic.dev/dependencies/<#asynchronous-vs-synchronous-dependencies>)
      * [ Full Example  ](https://ai.pydantic.dev/dependencies/<#full-example>)
      * [ Overriding Dependencies  ](https://ai.pydantic.dev/dependencies/<#overriding-dependencies>)
      * [ Examples  ](https://ai.pydantic.dev/dependencies/<#examples>)
    * [ Function Tools  ](https://ai.pydantic.dev/dependencies/<../tools/>)
    * [ Results  ](https://ai.pydantic.dev/dependencies/<../results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/dependencies/<../message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/dependencies/<../testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/dependencies/<../logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/dependencies/<../multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/dependencies/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/dependencies/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/dependencies/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/dependencies/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/dependencies/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/dependencies/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/dependencies/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/dependencies/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/dependencies/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/dependencies/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/dependencies/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/dependencies/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/dependencies/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/dependencies/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/dependencies/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/dependencies/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/dependencies/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/dependencies/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/dependencies/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/dependencies/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/dependencies/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/dependencies/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/dependencies/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/dependencies/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/dependencies/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/dependencies/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/dependencies/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/dependencies/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/dependencies/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/dependencies/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/dependencies/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/dependencies/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/dependencies/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/dependencies/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/dependencies/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Defining Dependencies  ](https://ai.pydantic.dev/dependencies/<#defining-dependencies>)
  * [ Accessing Dependencies  ](https://ai.pydantic.dev/dependencies/<#accessing-dependencies>)
    * [ Asynchronous vs. Synchronous dependencies  ](https://ai.pydantic.dev/dependencies/<#asynchronous-vs-synchronous-dependencies>)
  * [ Full Example  ](https://ai.pydantic.dev/dependencies/<#full-example>)
  * [ Overriding Dependencies  ](https://ai.pydantic.dev/dependencies/<#overriding-dependencies>)
  * [ Examples  ](https://ai.pydantic.dev/dependencies/<#examples>)


  1. [ Introduction  ](https://ai.pydantic.dev/dependencies/<..>)
  2. [ Documentation  ](https://ai.pydantic.dev/dependencies/<../agents/>)


# Dependencies
PydanticAI uses a dependency injection system to provide data and services to your agent's [system prompts](https://ai.pydantic.dev/dependencies/<../agents/#system-prompts>), [tools](https://ai.pydantic.dev/dependencies/<../tools/>) and [result validators](https://ai.pydantic.dev/dependencies/<../results/#result-validators-functions>).
Matching PydanticAI's design philosophy, our dependency system tries to use existing best practice in Python development rather than inventing esoteric "magic", this should make dependencies type-safe, understandable easier to test and ultimately easier to deploy in production.
## Defining Dependencies
Dependencies can be any python type. While in simple cases you might be able to pass a single object as a dependency (e.g. an HTTP connection), [dataclasses](https://ai.pydantic.dev/dependencies/<https:/docs.python.org/3/library/dataclasses.html#module-dataclasses>) are generally a convenient container when your dependencies included multiple objects.
Here's an example of defining an agent that requires dependencies.
(**Note:** dependencies aren't actually used in this example, see [Accessing Dependencies](https://ai.pydantic.dev/dependencies/<#accessing-dependencies>) below)
unused_dependencies.py```
from dataclasses import dataclass
import httpx
from pydantic_ai import Agent

@dataclass
class MyDeps: [](https://ai.pydantic.dev/dependencies/<#__code_0_annotation_1>)
  api_key: str
  http_client: httpx.AsyncClient

agent = Agent(
  'openai:gpt-4o',
  deps_type=MyDeps, [](https://ai.pydantic.dev/dependencies/<#__code_0_annotation_2>)
)

async def main():
  async with httpx.AsyncClient() as client:
    deps = MyDeps('foobar', client)
    result = await agent.run(
      'Tell me a joke.',
      deps=deps, 
When running the agent, pass an instance of the dataclass to the deps parameter.
[](https://ai.pydantic.dev/dependencies/<#__code_0_annotation_3>)
    )
    print(result.data)
    #> Did you hear about the toothpaste scandal? They called it Colgate.

```

_(This example is complete, it can be run "as is" — you'll need to add`asyncio.run(main())` to run `main`)_
## Accessing Dependencies
Dependencies are accessed through the `RunContext`[](https://ai.pydantic.dev/dependencies/<../api/tools/#pydantic_ai.tools.RunContext>) type, this should be the first parameter of system prompt functions etc.
system_prompt_dependencies.py```
from dataclasses import dataclass
import httpx
from pydantic_ai import Agent, RunContext

@dataclass
class MyDeps:
  api_key: str
  http_client: httpx.AsyncClient

agent = Agent(
  'openai:gpt-4o',
  deps_type=MyDeps,
)

@agent.system_prompt 
RunContext[](https://ai.pydantic.dev/dependencies/<../api/tools/#pydantic_ai.tools.RunContext>) may optionally be passed to a system_prompt[](https://ai.pydantic.dev/dependencies/<../api/agent/#pydantic_ai.agent.Agent.system_prompt>) function as the only argument.
[](https://ai.pydantic.dev/dependencies/<#__code_1_annotation_1>)
async def get_system_prompt(ctx: RunContext[MyDeps]) -> str: 
RunContext[](https://ai.pydantic.dev/dependencies/<../api/tools/#pydantic_ai.tools.RunContext>) is parameterized with the type of the dependencies, if this type is incorrect, static type checkers will raise an error.
[](https://ai.pydantic.dev/dependencies/<#__code_1_annotation_2>)
  response = await ctx.deps.http_client.get( 
Access dependencies through the .deps[](https://ai.pydantic.dev/dependencies/<../api/tools/#pydantic_ai.tools.RunContext.deps>) attribute.
[](https://ai.pydantic.dev/dependencies/<#__code_1_annotation_3>)
    'https://example.com',
    headers={'Authorization': f'Bearer {ctx.deps.api_key}'}, 
Access dependencies through the .deps[](https://ai.pydantic.dev/dependencies/<../api/tools/#pydantic_ai.tools.RunContext.deps>) attribute.
[](https://ai.pydantic.dev/dependencies/<#__code_1_annotation_4>)
  )
  response.raise_for_status()
  return f'Prompt: {response.text}'

async def main():
  async with httpx.AsyncClient() as client:
    deps = MyDeps('foobar', client)
    result = await agent.run('Tell me a joke.', deps=deps)
    print(result.data)
    #> Did you hear about the toothpaste scandal? They called it Colgate.

```

_(This example is complete, it can be run "as is" — you'll need to add`asyncio.run(main())` to run `main`)_
### Asynchronous vs. Synchronous dependencies
[System prompt functions](https://ai.pydantic.dev/dependencies/<../agents/#system-prompts>), [function tools](https://ai.pydantic.dev/dependencies/<../tools/>) and [result validators](https://ai.pydantic.dev/dependencies/<../results/#result-validators-functions>) are all run in the async context of an agent run.
If these functions are not coroutines (e.g. `async def`) they are called with `run_in_executor`[](https://ai.pydantic.dev/dependencies/<https:/docs.python.org/3/library/asyncio-eventloop.html#asyncio.loop.run_in_executor>) in a thread pool, it's therefore marginally preferable to use `async` methods where dependencies perform IO, although synchronous dependencies should work fine too.
`run` vs. `run_sync` and Asynchronous vs. Synchronous dependencies
Whether you use synchronous or asynchronous dependencies, is completely independent of whether you use `run` or `run_sync` — `run_sync` is just a wrapper around `run` and agents are always run in an async context.
Here's the same example as above, but with a synchronous dependency:
sync_dependencies.py```
from dataclasses import dataclass
import httpx
from pydantic_ai import Agent, RunContext

@dataclass
class MyDeps:
  api_key: str
  http_client: httpx.Client 
Here we use a synchronous httpx.Client instead of an asynchronous httpx.AsyncClient.
[](https://ai.pydantic.dev/dependencies/<#__code_2_annotation_1>)

agent = Agent(
  'openai:gpt-4o',
  deps_type=MyDeps,
)

@agent.system_prompt
def get_system_prompt(ctx: RunContext[MyDeps]) -> str: 
To match the synchronous dependency, the system prompt function is now a plain function, not a coroutine.
[](https://ai.pydantic.dev/dependencies/<#__code_2_annotation_2>)
  response = ctx.deps.http_client.get(
    'https://example.com', headers={'Authorization': f'Bearer {ctx.deps.api_key}'}
  )
  response.raise_for_status()
  return f'Prompt: {response.text}'

async def main():
  deps = MyDeps('foobar', httpx.Client())
  result = await agent.run(
    'Tell me a joke.',
    deps=deps,
  )
  print(result.data)
  #> Did you hear about the toothpaste scandal? They called it Colgate.

```

_(This example is complete, it can be run "as is" — you'll need to add`asyncio.run(main())` to run `main`)_
## Full Example
As well as system prompts, dependencies can be used in [tools](https://ai.pydantic.dev/dependencies/<../tools/>) and [result validators](https://ai.pydantic.dev/dependencies/<../results/#result-validators-functions>).
full_example.py```
from dataclasses import dataclass
import httpx
from pydantic_ai import Agent, ModelRetry, RunContext

@dataclass
class MyDeps:
  api_key: str
  http_client: httpx.AsyncClient

agent = Agent(
  'openai:gpt-4o',
  deps_type=MyDeps,
)

@agent.system_prompt
async def get_system_prompt(ctx: RunContext[MyDeps]) -> str:
  response = await ctx.deps.http_client.get('https://example.com')
  response.raise_for_status()
  return f'Prompt: {response.text}'

@agent.tool 
To pass RunContext to a tool, use the tool[](https://ai.pydantic.dev/dependencies/<../api/agent/#pydantic_ai.agent.Agent.tool>) decorator.
[](https://ai.pydantic.dev/dependencies/<#__code_3_annotation_1>)
async def get_joke_material(ctx: RunContext[MyDeps], subject: str) -> str:
  response = await ctx.deps.http_client.get(
    'https://example.com#jokes',
    params={'subject': subject},
    headers={'Authorization': f'Bearer {ctx.deps.api_key}'},
  )
  response.raise_for_status()
  return response.text

@agent.result_validator 
RunContext may optionally be passed to a result_validator[](https://ai.pydantic.dev/dependencies/<../api/agent/#pydantic_ai.agent.Agent.result_validator>) function as the first argument.
[](https://ai.pydantic.dev/dependencies/<#__code_3_annotation_2>)
async def validate_result(ctx: RunContext[MyDeps], final_response: str) -> str:
  response = await ctx.deps.http_client.post(
    'https://example.com#validate',
    headers={'Authorization': f'Bearer {ctx.deps.api_key}'},
    params={'query': final_response},
  )
  if response.status_code == 400:
    raise ModelRetry(f'invalid response: {response.text}')
  response.raise_for_status()
  return final_response

async def main():
  async with httpx.AsyncClient() as client:
    deps = MyDeps('foobar', client)
    result = await agent.run('Tell me a joke.', deps=deps)
    print(result.data)
    #> Did you hear about the toothpaste scandal? They called it Colgate.

```

_(This example is complete, it can be run "as is" — you'll need to add`asyncio.run(main())` to run `main`)_
## Overriding Dependencies
When testing agents, it's useful to be able to customise dependencies.
While this can sometimes be done by calling the agent directly within unit tests, we can also override dependencies while calling application code which in turn calls the agent.
This is done via the `override`[](https://ai.pydantic.dev/dependencies/<../api/agent/#pydantic_ai.agent.Agent.override>) method on the agent.
joke_app.py```
from dataclasses import dataclass
import httpx
from pydantic_ai import Agent, RunContext

@dataclass
class MyDeps:
  api_key: str
  http_client: httpx.AsyncClient
  async def system_prompt_factory(self) -> str: 
Define a method on the dependency to make the system prompt easier to customise.
[](https://ai.pydantic.dev/dependencies/<#__code_4_annotation_1>)
    response = await self.http_client.get('https://example.com')
    response.raise_for_status()
    return f'Prompt: {response.text}'

joke_agent = Agent('openai:gpt-4o', deps_type=MyDeps)

@joke_agent.system_prompt
async def get_system_prompt(ctx: RunContext[MyDeps]) -> str:
  return await ctx.deps.system_prompt_factory() 
Call the system prompt factory from within the system prompt function.
[](https://ai.pydantic.dev/dependencies/<#__code_4_annotation_2>)

async def application_code(prompt: str) -> str: 
Application code that calls the agent, in a real application this might be an API endpoint.
[](https://ai.pydantic.dev/dependencies/<#__code_4_annotation_3>)
  ...
  ...
  # now deep within application code we call our agent
  async with httpx.AsyncClient() as client:
    app_deps = MyDeps('foobar', client)
    result = await joke_agent.run(prompt, deps=app_deps) 
Call the agent from within the application code, in a real application this call might be deep within a call stack. Note app_deps here will NOT be used when deps are overridden.
[](https://ai.pydantic.dev/dependencies/<#__code_4_annotation_4>)
  return result.data

```

_(This example is complete, it can be run "as is")_
test_joke_app.py```
from joke_app import MyDeps, application_code, joke_agent

class TestMyDeps(MyDeps): 
Define a subclass of MyDeps in tests to customise the system prompt factory.
[](https://ai.pydantic.dev/dependencies/<#__code_5_annotation_1>)
  async def system_prompt_factory(self) -> str:
    return 'test prompt'

async def test_application_code():
  test_deps = TestMyDeps('test_key', None) 
Create an instance of the test dependency, we don't need to pass an http_client here as it's not used.
[](https://ai.pydantic.dev/dependencies/<#__code_5_annotation_2>)
  with joke_agent.override(deps=test_deps): 
Override the dependencies of the agent for the duration of the with block, test_deps will be used when the agent is run.
[](https://ai.pydantic.dev/dependencies/<#__code_5_annotation_3>)
    joke = await application_code('Tell me a joke.') 
Now we can safely call our application code, the agent will use the overridden dependencies.
[](https://ai.pydantic.dev/dependencies/<#__code_5_annotation_4>)
  assert joke.startswith('Did you hear about the toothpaste scandal?')

```

## Examples
The following examples demonstrate how to use dependencies in PydanticAI:
  * [Weather Agent](https://ai.pydantic.dev/dependencies/<../examples/weather-agent/>)
  * [SQL Generation](https://ai.pydantic.dev/dependencies/<../examples/sql-gen/>)
  * [RAG](https://ai.pydantic.dev/dependencies/<../examples/rag/>)


© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/examples_bank-support.md
================
[ Skip to content ](https://ai.pydantic.dev/examples/bank-support/<#running-the-example>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/bank-support/<../..> "PydanticAI")
PydanticAI 
Bank support 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/bank-support/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/bank-support/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/bank-support/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/examples/bank-support/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/examples/bank-support/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/examples/bank-support/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/examples/bank-support/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/examples/bank-support/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/examples/bank-support/agents/>)
    * [ Models  ](https://ai.pydantic.dev/examples/bank-support/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/examples/bank-support/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/examples/bank-support/tools/>)
    * [ Results  ](https://ai.pydantic.dev/examples/bank-support/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/examples/bank-support/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/examples/bank-support/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/examples/bank-support/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/examples/bank-support/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/examples/bank-support/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/examples/bank-support/<../>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/examples/bank-support/<../pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/examples/bank-support/<../weather-agent/>)
    * Bank support  [ Bank support  ](https://ai.pydantic.dev/examples/bank-support/<./>) Table of contents 
      * [ Running the Example  ](https://ai.pydantic.dev/examples/bank-support/<#running-the-example>)
      * [ Example Code  ](https://ai.pydantic.dev/examples/bank-support/<#example-code>)
    * [ SQL Generation  ](https://ai.pydantic.dev/examples/bank-support/<../sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/examples/bank-support/<../flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/examples/bank-support/<../rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/examples/bank-support/<../stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/examples/bank-support/<../stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/examples/bank-support/<../chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/examples/bank-support/<../question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/examples/bank-support/api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/examples/bank-support/api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/examples/bank-support/api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/examples/bank-support/api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/examples/bank-support/api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/examples/bank-support/api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/examples/bank-support/api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/examples/bank-support/api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/examples/bank-support/api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/examples/bank-support/api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/examples/bank-support/api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/examples/bank-support/api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/examples/bank-support/api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/examples/bank-support/api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/examples/bank-support/api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/examples/bank-support/api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/examples/bank-support/api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/examples/bank-support/api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/examples/bank-support/api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/examples/bank-support/api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/examples/bank-support/api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/examples/bank-support/api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/examples/bank-support/api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Running the Example  ](https://ai.pydantic.dev/examples/bank-support/<#running-the-example>)
  * [ Example Code  ](https://ai.pydantic.dev/examples/bank-support/<#example-code>)


  1. [ Introduction  ](https://ai.pydantic.dev/examples/bank-support/<../..>)
  2. [ Examples  ](https://ai.pydantic.dev/examples/bank-support/<../>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/examples/bank-support/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/examples/bank-support/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Bank support
Small but complete example of using PydanticAI to build a support agent for a bank.
Demonstrates:
  * [dynamic system prompt](https://ai.pydantic.dev/examples/bank-support/agents/#system-prompts>)
  * [structured `result_type`](https://ai.pydantic.dev/examples/bank-support/results/#structured-result-validation>)
  * [tools](https://ai.pydantic.dev/examples/bank-support/tools/>)


## Running the Example
With [dependencies installed and environment variables set](https://ai.pydantic.dev/examples/bank-support/<../#usage>), run:
[pip](https://ai.pydantic.dev/examples/bank-support/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/examples/bank-support/<#__tabbed_1_2>)
```
python-mpydantic_ai_examples.bank_support

```

```
uvrun-mpydantic_ai_examples.bank_support

```

(or `PYDANTIC_AI_MODEL=gemini-1.5-flash ...`)
## Example Code
bank_support.py```
from dataclasses import dataclass
from pydantic import BaseModel, Field
from pydantic_ai import Agent, RunContext

class DatabaseConn:
"""This is a fake database for example purposes.
  In reality, you'd be connecting to an external database
  (e.g. PostgreSQL) to get information about customers.
  """
  @classmethod
  async def customer_name(cls, *, id: int) -> str | None:
    if id == 123:
      return 'John'
  @classmethod
  async def customer_balance(cls, *, id: int, include_pending: bool) -> float:
    if id == 123:
      return 123.45
    else:
      raise ValueError('Customer not found')

@dataclass
class SupportDependencies:
  customer_id: int
  db: DatabaseConn

class SupportResult(BaseModel):
  support_advice: str = Field(description='Advice returned to the customer')
  block_card: bool = Field(description='Whether to block their')
  risk: int = Field(description='Risk level of query', ge=0, le=10)

support_agent = Agent(
  'openai:gpt-4o',
  deps_type=SupportDependencies,
  result_type=SupportResult,
  system_prompt=(
    'You are a support agent in our bank, give the '
    'customer support and judge the risk level of their query. '
    "Reply using the customer's name."
  ),
)

@support_agent.system_prompt
async def add_customer_name(ctx: RunContext[SupportDependencies]) -> str:
  customer_name = await ctx.deps.db.customer_name(id=ctx.deps.customer_id)
  return f"The customer's name is {customer_name!r}"

@support_agent.tool
async def customer_balance(
  ctx: RunContext[SupportDependencies], include_pending: bool
) -> str:
"""Returns the customer's current account balance."""
  balance = await ctx.deps.db.customer_balance(
    id=ctx.deps.customer_id,
    include_pending=include_pending,
  )
  return f'${balance:.2f}'

if __name__ == '__main__':
  deps = SupportDependencies(customer_id=123, db=DatabaseConn())
  result = support_agent.run_sync('What is my balance?', deps=deps)
  print(result.data)
"""
  support_advice='Hello John, your current account balance, including pending transactions, is $123.45.' block_card=False risk=1
  """
  result = support_agent.run_sync('I just lost my card!', deps=deps)
  print(result.data)
"""
  support_advice="I'm sorry to hear that, John. We are temporarily blocking your card to prevent unauthorized transactions." block_card=True risk=8
  """

```

© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/examples_chat-app.md
================
[ Skip to content ](https://ai.pydantic.dev/examples/chat-app/<#chat-app-with-fastapi>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/chat-app/<../..> "PydanticAI")
PydanticAI 
Chat App with FastAPI 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/chat-app/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/chat-app/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/chat-app/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/examples/chat-app/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/examples/chat-app/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/examples/chat-app/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/examples/chat-app/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/examples/chat-app/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/examples/chat-app/agents/>)
    * [ Models  ](https://ai.pydantic.dev/examples/chat-app/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/examples/chat-app/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/examples/chat-app/tools/>)
    * [ Results  ](https://ai.pydantic.dev/examples/chat-app/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/examples/chat-app/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/examples/chat-app/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/examples/chat-app/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/examples/chat-app/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/examples/chat-app/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/examples/chat-app/<../>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/examples/chat-app/<../pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/examples/chat-app/<../weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/examples/chat-app/<../bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/examples/chat-app/<../sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/examples/chat-app/<../flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/examples/chat-app/<../rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/examples/chat-app/<../stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/examples/chat-app/<../stream-whales/>)
    * Chat App with FastAPI  [ Chat App with FastAPI  ](https://ai.pydantic.dev/examples/chat-app/<./>) Table of contents 
      * [ Running the Example  ](https://ai.pydantic.dev/examples/chat-app/<#running-the-example>)
      * [ Example Code  ](https://ai.pydantic.dev/examples/chat-app/<#example-code>)
    * [ Question Graph  ](https://ai.pydantic.dev/examples/chat-app/<../question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/examples/chat-app/api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/examples/chat-app/api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/examples/chat-app/api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/examples/chat-app/api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/examples/chat-app/api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/examples/chat-app/api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/examples/chat-app/api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/examples/chat-app/api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/examples/chat-app/api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/examples/chat-app/api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/examples/chat-app/api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/examples/chat-app/api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/examples/chat-app/api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/examples/chat-app/api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/examples/chat-app/api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/examples/chat-app/api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/examples/chat-app/api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/examples/chat-app/api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/examples/chat-app/api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/examples/chat-app/api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/examples/chat-app/api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/examples/chat-app/api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/examples/chat-app/api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Running the Example  ](https://ai.pydantic.dev/examples/chat-app/<#running-the-example>)
  * [ Example Code  ](https://ai.pydantic.dev/examples/chat-app/<#example-code>)


  1. [ Introduction  ](https://ai.pydantic.dev/examples/chat-app/<../..>)
  2. [ Examples  ](https://ai.pydantic.dev/examples/chat-app/<../>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/examples/chat-app/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/examples/chat-app/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Chat App with FastAPI
Simple chat app example build with FastAPI.
Demonstrates:
  * [reusing chat history](https://ai.pydantic.dev/examples/chat-app/message-history/>)
  * [serializing messages](https://ai.pydantic.dev/examples/chat-app/message-history/#accessing-messages-from-results>)
  * [streaming responses](https://ai.pydantic.dev/examples/chat-app/results/#streamed-results>)


This demonstrates storing chat history between requests and using it to give the model context for new responses.
Most of the complex logic here is between `chat_app.py` which streams the response to the browser, and `chat_app.ts` which renders messages in the browser.
## Running the Example
With [dependencies installed and environment variables set](https://ai.pydantic.dev/examples/chat-app/<../#usage>), run:
[pip](https://ai.pydantic.dev/examples/chat-app/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/examples/chat-app/<#__tabbed_1_2>)
```
python-mpydantic_ai_examples.chat_app

```

```
uvrun-mpydantic_ai_examples.chat_app

```

Then open the app at [localhost:8000](https://ai.pydantic.dev/examples/chat-app/<http:/localhost:8000>).
[![Example conversation](https://ai.pydantic.dev/img/chat-app-example.png)](https://ai.pydantic.dev/examples/chat-app/img/chat-app-example.png>)
## Example Code
Python code that runs the chat app:
chat_app.py```
from __future__ import annotations as _annotations
import asyncio
import json
import sqlite3
from collections.abc import AsyncIterator
from concurrent.futures.thread import ThreadPoolExecutor
from contextlib import asynccontextmanager
from dataclasses import dataclass
from datetime import datetime, timezone
from functools import partial
from pathlib import Path
from typing import Annotated, Any, Callable, Literal, TypeVar
import fastapi
import logfire
from fastapi import Depends, Request
from fastapi.responses import FileResponse, Response, StreamingResponse
from typing_extensions import LiteralString, ParamSpec, TypedDict
from pydantic_ai import Agent
from pydantic_ai.exceptions import UnexpectedModelBehavior
from pydantic_ai.messages import (
  ModelMessage,
  ModelMessagesTypeAdapter,
  ModelRequest,
  ModelResponse,
  TextPart,
  UserPromptPart,
)
# 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured
logfire.configure(send_to_logfire='if-token-present')
agent = Agent('openai:gpt-4o')
THIS_DIR = Path(__file__).parent

@asynccontextmanager
async def lifespan(_app: fastapi.FastAPI):
  async with Database.connect() as db:
    yield {'db': db}

app = fastapi.FastAPI(lifespan=lifespan)
logfire.instrument_fastapi(app)

@app.get('/')
async def index() -> FileResponse:
  return FileResponse((THIS_DIR / 'chat_app.html'), media_type='text/html')

@app.get('/chat_app.ts')
async def main_ts() -> FileResponse:
"""Get the raw typescript code, it's compiled in the browser, forgive me."""
  return FileResponse((THIS_DIR / 'chat_app.ts'), media_type='text/plain')

async def get_db(request: Request) -> Database:
  return request.state.db

@app.get('/chat/')
async def get_chat(database: Database = Depends(get_db)) -> Response:
  msgs = await database.get_messages()
  return Response(
    b'\n'.join(json.dumps(to_chat_message(m)).encode('utf-8') for m in msgs),
    media_type='text/plain',
  )

class ChatMessage(TypedDict):
"""Format of messages sent to the browser."""
  role: Literal['user', 'model']
  timestamp: str
  content: str

def to_chat_message(m: ModelMessage) -> ChatMessage:
  first_part = m.parts[0]
  if isinstance(m, ModelRequest):
    if isinstance(first_part, UserPromptPart):
      return {
        'role': 'user',
        'timestamp': first_part.timestamp.isoformat(),
        'content': first_part.content,
      }
  elif isinstance(m, ModelResponse):
    if isinstance(first_part, TextPart):
      return {
        'role': 'model',
        'timestamp': m.timestamp.isoformat(),
        'content': first_part.content,
      }
  raise UnexpectedModelBehavior(f'Unexpected message type for chat app: {m}')

@app.post('/chat/')
async def post_chat(
  prompt: Annotated[str, fastapi.Form()], database: Database = Depends(get_db)
) -> StreamingResponse:
  async def stream_messages():
"""Streams new line delimited JSON `Message`s to the client."""
    # stream the user prompt so that can be displayed straight away
    yield (
      json.dumps(
        {
          'role': 'user',
          'timestamp': datetime.now(tz=timezone.utc).isoformat(),
          'content': prompt,
        }
      ).encode('utf-8')
      + b'\n'
    )
    # get the chat history so far to pass as context to the agent
    messages = await database.get_messages()
    # run the agent with the user prompt and the chat history
    async with agent.run_stream(prompt, message_history=messages) as result:
      async for text in result.stream(debounce_by=0.01):
        # text here is a `str` and the frontend wants
        # JSON encoded ModelResponse, so we create one
        m = ModelResponse(parts=[TextPart(text)], timestamp=result.timestamp())
        yield json.dumps(to_chat_message(m)).encode('utf-8') + b'\n'
    # add new messages (e.g. the user prompt and the agent response in this case) to the database
    await database.add_messages(result.new_messages_json())
  return StreamingResponse(stream_messages(), media_type='text/plain')

P = ParamSpec('P')
R = TypeVar('R')

@dataclass
class Database:
"""Rudimentary database to store chat messages in SQLite.
  The SQLite standard library package is synchronous, so we
  use a thread pool executor to run queries asynchronously.
  """
  con: sqlite3.Connection
  _loop: asyncio.AbstractEventLoop
  _executor: ThreadPoolExecutor
  @classmethod
  @asynccontextmanager
  async def connect(
    cls, file: Path = THIS_DIR / '.chat_app_messages.sqlite'
  ) -> AsyncIterator[Database]:
    with logfire.span('connect to DB'):
      loop = asyncio.get_event_loop()
      executor = ThreadPoolExecutor(max_workers=1)
      con = await loop.run_in_executor(executor, cls._connect, file)
      slf = cls(con, loop, executor)
    try:
      yield slf
    finally:
      await slf._asyncify(con.close)
  @staticmethod
  def _connect(file: Path) -> sqlite3.Connection:
    con = sqlite3.connect(str(file))
    con = logfire.instrument_sqlite3(con)
    cur = con.cursor()
    cur.execute(
      'CREATE TABLE IF NOT EXISTS messages (id INT PRIMARY KEY, message_list TEXT);'
    )
    con.commit()
    return con
  async def add_messages(self, messages: bytes):
    await self._asyncify(
      self._execute,
      'INSERT INTO messages (message_list) VALUES (?);',
      messages,
      commit=True,
    )
    await self._asyncify(self.con.commit)
  async def get_messages(self) -> list[ModelMessage]:
    c = await self._asyncify(
      self._execute, 'SELECT message_list FROM messages order by id'
    )
    rows = await self._asyncify(c.fetchall)
    messages: list[ModelMessage] = []
    for row in rows:
      messages.extend(ModelMessagesTypeAdapter.validate_json(row[0]))
    return messages
  def _execute(
    self, sql: LiteralString, *args: Any, commit: bool = False
  ) -> sqlite3.Cursor:
    cur = self.con.cursor()
    cur.execute(sql, args)
    if commit:
      self.con.commit()
    return cur
  async def _asyncify(
    self, func: Callable[P, R], *args: P.args, **kwargs: P.kwargs
  ) -> R:
    return await self._loop.run_in_executor( # type: ignore
      self._executor,
      partial(func, **kwargs),
      *args, # type: ignore
    )

if __name__ == '__main__':
  import uvicorn
  uvicorn.run(
    'pydantic_ai_examples.chat_app:app', reload=True, reload_dirs=[str(THIS_DIR)]
  )

```

Simple HTML page to render the app:
chat_app.html```
<!DOCTYPE html>
<html lang="en">
<head>
 <meta charset="UTF-8">
 <meta name="viewport" content="width=device-width, initial-scale=1.0">
 <title>Chat App</title>
 <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
 <style>
main{
max-width:700px;
}
#conversation.user::before{
content:'You asked: ';
font-weight:bold;
display:block;
}
#conversation.model::before{
content:'AI Response: ';
font-weight:bold;
display:block;
}
#spinner{
opacity:0;
transition:opacity500msease-in;
width:30px;
height:30px;
border:3pxsolid#222;
border-bottom-color:transparent;
border-radius:50%;
animation:rotation1slinearinfinite;
}
@keyframesrotation{
0%{transform:rotate(0deg);}
100%{transform:rotate(360deg);}
}
#spinner.active{
opacity:1;
}
</style>
</head>
<body>
 <main class="border rounded mx-auto my-5 p-4">
  <h1>Chat App</h1>
  <p>Ask me anything...</p>
  <div id="conversation" class="px-2"></div>
  <div class="d-flex justify-content-center mb-3">
   <div id="spinner"></div>
  </div>
  <form method="post">
   <input id="prompt-input" name="prompt" class="form-control"/>
   <div class="d-flex justify-content-end">
    <button class="btn btn-primary mt-2">Send</button>
   </div>
  </form>
  <div id="error" class="d-none text-danger">
   Error occurred, check the browser developer console for more information.
  </div>
 </main>
</body>
</html>
<script src="https://cdnjs.cloudflare.com/ajax/libs/typescript/5.6.3/typescript.min.js" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script type="module">
// to let me write TypeScript, without adding the burden of npm we do a dirty, non-production-ready hack
// and transpile the TypeScript code in the browser
// this is (arguably) A neat demo trick, but not suitable for production!
asyncfunctionloadTs(){
constresponse=awaitfetch('/chat_app.ts');
consttsCode=awaitresponse.text();
constjsCode=window.ts.transpile(tsCode,{target:"es2015"});
letscript=document.createElement('script');
script.type='module';
script.text=jsCode;
document.body.appendChild(script);
}
loadTs().catch((e)=>{
console.error(e);
document.getElementById('error').classList.remove('d-none');
document.getElementById('spinner').classList.remove('active');
});
</script>

```

TypeScript to handle rendering the messages, to keep this simple (and at the risk of offending frontend developers) the typescript code is passed to the browser as plain text and transpiled in the browser.
chat_app.ts```
// BIG FAT WARNING: to avoid the complexity of npm, this typescript is compiled in the browser
// there's currently no static type checking
import{marked}from'https://cdnjs.cloudflare.com/ajax/libs/marked/15.0.0/lib/marked.esm.js'
constconvElement=document.getElementById('conversation')
constpromptInput=document.getElementById('prompt-input')asHTMLInputElement
constspinner=document.getElementById('spinner')
// stream the response and render messages as each chunk is received
// data is sent as newline-delimited JSON
asyncfunctiononFetchResponse(response:Response):Promise<void>{
lettext=''
letdecoder=newTextDecoder()
if(response.ok){
constreader=response.body.getReader()
while(true){
const{done,value}=awaitreader.read()
if(done){
break
}
text+=decoder.decode(value)
addMessages(text)
spinner.classList.remove('active')
}
addMessages(text)
promptInput.disabled=false
promptInput.focus()
}else{
consttext=awaitresponse.text()
console.error(`Unexpected response: ${response.status}`,{response,text})
thrownewError(`Unexpected response: ${response.status}`)
}
}
// The format of messages, this matches pydantic-ai both for brevity and understanding
// in production, you might not want to keep this format all the way to the frontend
interfaceMessage{
role:string
content:string
timestamp:string
}
// take raw response text and render messages into the `#conversation` element
// Message timestamp is assumed to be a unique identifier of a message, and is used to deduplicate
// hence you can send data about the same message multiple times, and it will be updated
// instead of creating a new message elements
functionaddMessages(responseText:string){
constlines=responseText.split('\n')
constmessages:Message[]=lines.filter(line=>line.length>1).map(j=>JSON.parse(j))
for(constmessageofmessages){
// we use the timestamp as a crude element id
const{timestamp,role,content}=message
constid=`msg-${timestamp}`
letmsgDiv=document.getElementById(id)
if(!msgDiv){
msgDiv=document.createElement('div')
msgDiv.id=id
msgDiv.title=`${role} at ${timestamp}`
msgDiv.classList.add('border-top','pt-2',role)
convElement.appendChild(msgDiv)
}
msgDiv.innerHTML=marked.parse(content)
}
window.scrollTo({top:document.body.scrollHeight,behavior:'smooth'})
}
functiononError(error:any){
console.error(error)
document.getElementById('error').classList.remove('d-none')
document.getElementById('spinner').classList.remove('active')
}
asyncfunctiononSubmit(e:SubmitEvent):Promise<void>{
e.preventDefault()
spinner.classList.add('active')
constbody=newFormData(e.targetasHTMLFormElement)
promptInput.value=''
promptInput.disabled=true
constresponse=awaitfetch('/chat/',{method:'POST',body})
awaitonFetchResponse(response)
}
// call onSubmit when the form is submitted (e.g. user clicks the send button or hits Enter)
document.querySelector('form').addEventListener('submit',(e)=>onSubmit(e).catch(onError))
// load messages on page load
fetch('/chat/').then(onFetchResponse).catch(onError)

```

© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/examples_flight-booking.md
================
[ Skip to content ](https://ai.pydantic.dev/examples/flight-booking/<#running-the-example>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/flight-booking/<../..> "PydanticAI")
PydanticAI 
Flight booking 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/flight-booking/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/flight-booking/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/flight-booking/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/examples/flight-booking/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/examples/flight-booking/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/examples/flight-booking/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/examples/flight-booking/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/examples/flight-booking/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/examples/flight-booking/agents/>)
    * [ Models  ](https://ai.pydantic.dev/examples/flight-booking/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/examples/flight-booking/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/examples/flight-booking/tools/>)
    * [ Results  ](https://ai.pydantic.dev/examples/flight-booking/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/examples/flight-booking/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/examples/flight-booking/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/examples/flight-booking/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/examples/flight-booking/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/examples/flight-booking/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/examples/flight-booking/<../>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/examples/flight-booking/<../pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/examples/flight-booking/<../weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/examples/flight-booking/<../bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/examples/flight-booking/<../sql-gen/>)
    * Flight booking  [ Flight booking  ](https://ai.pydantic.dev/examples/flight-booking/<./>) Table of contents 
      * [ Running the Example  ](https://ai.pydantic.dev/examples/flight-booking/<#running-the-example>)
      * [ Example Code  ](https://ai.pydantic.dev/examples/flight-booking/<#example-code>)
    * [ RAG  ](https://ai.pydantic.dev/examples/flight-booking/<../rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/examples/flight-booking/<../stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/examples/flight-booking/<../stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/examples/flight-booking/<../chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/examples/flight-booking/<../question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/examples/flight-booking/api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/examples/flight-booking/api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/examples/flight-booking/api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/examples/flight-booking/api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/examples/flight-booking/api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/examples/flight-booking/api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/examples/flight-booking/api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/examples/flight-booking/api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/examples/flight-booking/api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/examples/flight-booking/api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/examples/flight-booking/api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/examples/flight-booking/api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/examples/flight-booking/api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/examples/flight-booking/api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/examples/flight-booking/api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/examples/flight-booking/api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/examples/flight-booking/api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/examples/flight-booking/api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/examples/flight-booking/api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/examples/flight-booking/api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/examples/flight-booking/api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/examples/flight-booking/api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/examples/flight-booking/api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Running the Example  ](https://ai.pydantic.dev/examples/flight-booking/<#running-the-example>)
  * [ Example Code  ](https://ai.pydantic.dev/examples/flight-booking/<#example-code>)


  1. [ Introduction  ](https://ai.pydantic.dev/examples/flight-booking/<../..>)
  2. [ Examples  ](https://ai.pydantic.dev/examples/flight-booking/<../>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/examples/flight-booking/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/examples/flight-booking/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Flight booking
Example of a multi-agent flow where one agent delegates work to another, then hands off control to a third agent.
Demonstrates:
  * [agent delegation](https://ai.pydantic.dev/examples/flight-booking/multi-agent-applications/#agent-delegation>)
  * [programmatic agent hand-off](https://ai.pydantic.dev/examples/flight-booking/multi-agent-applications/#programmatic-agent-hand-off>)
  * [usage limits](https://ai.pydantic.dev/examples/flight-booking/agents/#usage-limits>)


In this scenario, a group of agents work together to find the best flight for a user.
The control flow for this example can be summarised as follows:
```
graph TD
 START --> search_agent("search agent")
 search_agent --> extraction_agent("extraction agent")
 extraction_agent --> search_agent
 search_agent --> human_confirm("human confirm")
 human_confirm --> search_agent
 search_agent --> FAILED
 human_confirm --> find_seat_function("find seat function")
 find_seat_function --> human_seat_choice("human seat choice")
 human_seat_choice --> find_seat_agent("find seat agent")
 find_seat_agent --> find_seat_function
 find_seat_function --> buy_flights("buy flights")
 buy_flights --> SUCCESS
```

## Running the Example
With [dependencies installed and environment variables set](https://ai.pydantic.dev/examples/flight-booking/<../#usage>), run:
[pip](https://ai.pydantic.dev/examples/flight-booking/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/examples/flight-booking/<#__tabbed_1_2>)
```
python-mpydantic_ai_examples.flight_booking

```

```
uvrun-mpydantic_ai_examples.flight_booking

```

## Example Code
flight_booking.py```
import datetime
from dataclasses import dataclass
from typing import Literal
import logfire
from pydantic import BaseModel, Field
from rich.prompt import Prompt
from pydantic_ai import Agent, ModelRetry, RunContext
from pydantic_ai.messages import ModelMessage
from pydantic_ai.usage import Usage, UsageLimits
# 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured
logfire.configure(send_to_logfire='if-token-present')

class FlightDetails(BaseModel):
"""Details of the most suitable flight."""
  flight_number: str
  price: int
  origin: str = Field(description='Three-letter airport code')
  destination: str = Field(description='Three-letter airport code')
  date: datetime.date

class NoFlightFound(BaseModel):
"""When no valid flight is found."""

@dataclass
class Deps:
  web_page_text: str
  req_origin: str
  req_destination: str
  req_date: datetime.date

# This agent is responsible for controlling the flow of the conversation.
search_agent = Agent[Deps, FlightDetails | NoFlightFound](
  'openai:gpt-4o',
  result_type=FlightDetails | NoFlightFound, # type: ignore
  retries=4,
  system_prompt=(
    'Your job is to find the cheapest flight for the user on the given date. '
  ),
)

# This agent is responsible for extracting flight details from web page text.
extraction_agent = Agent(
  'openai:gpt-4o',
  result_type=list[FlightDetails],
  system_prompt='Extract all the flight details from the given text.',
)

@search_agent.tool
async def extract_flights(ctx: RunContext[Deps]) -> list[FlightDetails]:
"""Get details of all flights."""
  # we pass the usage to the search agent so requests within this agent are counted
  result = await extraction_agent.run(ctx.deps.web_page_text, usage=ctx.usage)
  logfire.info('found {flight_count} flights', flight_count=len(result.data))
  return result.data

@search_agent.result_validator
async def validate_result(
  ctx: RunContext[Deps], result: FlightDetails | NoFlightFound
) -> FlightDetails | NoFlightFound:
"""Procedural validation that the flight meets the constraints."""
  if isinstance(result, NoFlightFound):
    return result
  errors: list[str] = []
  if result.origin != ctx.deps.req_origin:
    errors.append(
      f'Flight should have origin {ctx.deps.req_origin}, not {result.origin}'
    )
  if result.destination != ctx.deps.req_destination:
    errors.append(
      f'Flight should have destination {ctx.deps.req_destination}, not {result.destination}'
    )
  if result.date != ctx.deps.req_date:
    errors.append(f'Flight should be on {ctx.deps.req_date}, not {result.date}')
  if errors:
    raise ModelRetry('\n'.join(errors))
  else:
    return result

class SeatPreference(BaseModel):
  row: int = Field(ge=1, le=30)
  seat: Literal['A', 'B', 'C', 'D', 'E', 'F']

class Failed(BaseModel):
"""Unable to extract a seat selection."""

# This agent is responsible for extracting the user's seat selection
seat_preference_agent = Agent[
  None, SeatPreference | Failed
](
  'openai:gpt-4o',
  result_type=SeatPreference | Failed, # type: ignore
  system_prompt=(
    "Extract the user's seat preference. "
    'Seats A and F are window seats. '
    'Row 1 is the front row and has extra leg room. '
    'Rows 14, and 20 also have extra leg room. '
  ),
)

# in reality this would be downloaded from a booking site,
# potentially using another agent to navigate the site
flights_web_page = """
1. Flight SFO-AK123
- Price: $350
- Origin: San Francisco International Airport (SFO)
- Destination: Ted Stevens Anchorage International Airport (ANC)
- Date: January 10, 2025
2. Flight SFO-AK456
- Price: $370
- Origin: San Francisco International Airport (SFO)
- Destination: Fairbanks International Airport (FAI)
- Date: January 10, 2025
3. Flight SFO-AK789
- Price: $400
- Origin: San Francisco International Airport (SFO)
- Destination: Juneau International Airport (JNU)
- Date: January 20, 2025
4. Flight NYC-LA101
- Price: $250
- Origin: San Francisco International Airport (SFO)
- Destination: Ted Stevens Anchorage International Airport (ANC)
- Date: January 10, 2025
5. Flight CHI-MIA202
- Price: $200
- Origin: Chicago O'Hare International Airport (ORD)
- Destination: Miami International Airport (MIA)
- Date: January 12, 2025
6. Flight BOS-SEA303
- Price: $120
- Origin: Boston Logan International Airport (BOS)
- Destination: Ted Stevens Anchorage International Airport (ANC)
- Date: January 12, 2025
7. Flight DFW-DEN404
- Price: $150
- Origin: Dallas/Fort Worth International Airport (DFW)
- Destination: Denver International Airport (DEN)
- Date: January 10, 2025
8. Flight ATL-HOU505
- Price: $180
- Origin: Hartsfield-Jackson Atlanta International Airport (ATL)
- Destination: George Bush Intercontinental Airport (IAH)
- Date: January 10, 2025
"""
# restrict how many requests this app can make to the LLM
usage_limits = UsageLimits(request_limit=15)

async def main():
  deps = Deps(
    web_page_text=flights_web_page,
    req_origin='SFO',
    req_destination='ANC',
    req_date=datetime.date(2025, 1, 10),
  )
  message_history: list[ModelMessage] | None = None
  usage: Usage = Usage()
  # run the agent until a satisfactory flight is found
  while True:
    result = await search_agent.run(
      f'Find me a flight from {deps.req_origin} to {deps.req_destination} on {deps.req_date}',
      deps=deps,
      usage=usage,
      message_history=message_history,
      usage_limits=usage_limits,
    )
    if isinstance(result.data, NoFlightFound):
      print('No flight found')
      break
    else:
      flight = result.data
      print(f'Flight found: {flight}')
      answer = Prompt.ask(
        'Do you want to buy this flight, or keep searching? (buy/*search)',
        choices=['buy', 'search', ''],
        show_choices=False,
      )
      if answer == 'buy':
        seat = await find_seat(usage)
        await buy_tickets(flight, seat)
        break
      else:
        message_history = result.all_messages(
          result_tool_return_content='Please suggest another flight'
        )

async def find_seat(usage: Usage) -> SeatPreference:
  message_history: list[ModelMessage] | None = None
  while True:
    answer = Prompt.ask('What seat would you like?')
    result = await seat_preference_agent.run(
      answer,
      message_history=message_history,
      usage=usage,
      usage_limits=usage_limits,
    )
    if isinstance(result.data, SeatPreference):
      return result.data
    else:
      print('Could not understand seat preference. Please try again.')
      message_history = result.all_messages()

async def buy_tickets(flight_details: FlightDetails, seat: SeatPreference):
  print(f'Purchasing flight {flight_details=!r}{seat=!r}...')

if __name__ == '__main__':
  import asyncio
  asyncio.run(main())

```

© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/examples_pydantic-model.md
================
[ Skip to content ](https://ai.pydantic.dev/examples/pydantic-model/<#pydantic-model>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/pydantic-model/<../..> "PydanticAI")
PydanticAI 
Pydantic Model 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/pydantic-model/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/pydantic-model/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/pydantic-model/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/examples/pydantic-model/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/examples/pydantic-model/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/examples/pydantic-model/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/examples/pydantic-model/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/examples/pydantic-model/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/examples/pydantic-model/agents/>)
    * [ Models  ](https://ai.pydantic.dev/examples/pydantic-model/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/examples/pydantic-model/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/examples/pydantic-model/tools/>)
    * [ Results  ](https://ai.pydantic.dev/examples/pydantic-model/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/examples/pydantic-model/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/examples/pydantic-model/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/examples/pydantic-model/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/examples/pydantic-model/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/examples/pydantic-model/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/examples/pydantic-model/<../>)
Examples 
    * Pydantic Model  [ Pydantic Model  ](https://ai.pydantic.dev/examples/pydantic-model/<./>) Table of contents 
      * [ Running the Example  ](https://ai.pydantic.dev/examples/pydantic-model/<#running-the-example>)
      * [ Example Code  ](https://ai.pydantic.dev/examples/pydantic-model/<#example-code>)
    * [ Weather agent  ](https://ai.pydantic.dev/examples/pydantic-model/<../weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/examples/pydantic-model/<../bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/examples/pydantic-model/<../sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/examples/pydantic-model/<../flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/examples/pydantic-model/<../rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/examples/pydantic-model/<../stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/examples/pydantic-model/<../stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/examples/pydantic-model/<../chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/examples/pydantic-model/<../question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/examples/pydantic-model/api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/examples/pydantic-model/api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/examples/pydantic-model/api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/examples/pydantic-model/api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/examples/pydantic-model/api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/examples/pydantic-model/api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/examples/pydantic-model/api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/examples/pydantic-model/api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/examples/pydantic-model/api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/examples/pydantic-model/api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/examples/pydantic-model/api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/examples/pydantic-model/api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/examples/pydantic-model/api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/examples/pydantic-model/api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/examples/pydantic-model/api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/examples/pydantic-model/api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/examples/pydantic-model/api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/examples/pydantic-model/api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/examples/pydantic-model/api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/examples/pydantic-model/api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/examples/pydantic-model/api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/examples/pydantic-model/api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/examples/pydantic-model/api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Running the Example  ](https://ai.pydantic.dev/examples/pydantic-model/<#running-the-example>)
  * [ Example Code  ](https://ai.pydantic.dev/examples/pydantic-model/<#example-code>)


  1. [ Introduction  ](https://ai.pydantic.dev/examples/pydantic-model/<../..>)
  2. [ Examples  ](https://ai.pydantic.dev/examples/pydantic-model/<../>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/examples/pydantic-model/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/examples/pydantic-model/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Pydantic Model
Simple example of using PydanticAI to construct a Pydantic model from a text input.
Demonstrates:
  * [structured `result_type`](https://ai.pydantic.dev/examples/pydantic-model/results/#structured-result-validation>)


## Running the Example
With [dependencies installed and environment variables set](https://ai.pydantic.dev/examples/pydantic-model/<../#usage>), run:
[pip](https://ai.pydantic.dev/examples/pydantic-model/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/examples/pydantic-model/<#__tabbed_1_2>)
```
python-mpydantic_ai_examples.pydantic_model

```

```
uvrun-mpydantic_ai_examples.pydantic_model

```

This examples uses `openai:gpt-4o` by default, but it works well with other models, e.g. you can run it with Gemini using:
[pip](https://ai.pydantic.dev/examples/pydantic-model/<#__tabbed_2_1>)[uv](https://ai.pydantic.dev/examples/pydantic-model/<#__tabbed_2_2>)
```
PYDANTIC_AI_MODEL=gemini-1.5-propython-mpydantic_ai_examples.pydantic_model

```

```
PYDANTIC_AI_MODEL=gemini-1.5-prouvrun-mpydantic_ai_examples.pydantic_model

```

(or `PYDANTIC_AI_MODEL=gemini-1.5-flash ...`)
## Example Code
pydantic_model.py```
import os
from typing import cast
import logfire
from pydantic import BaseModel
from pydantic_ai import Agent
from pydantic_ai.models import KnownModelName
# 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured
logfire.configure(send_to_logfire='if-token-present')

class MyModel(BaseModel):
  city: str
  country: str

model = cast(KnownModelName, os.getenv('PYDANTIC_AI_MODEL', 'openai:gpt-4o'))
print(f'Using model: {model}')
agent = Agent(model, result_type=MyModel)
if __name__ == '__main__':
  result = agent.run_sync('The windy city in the US of A.')
  print(result.data)
  print(result.usage())

```

© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/examples_question-graph.md
================
[ Skip to content ](https://ai.pydantic.dev/examples/question-graph/<#question-graph>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/question-graph/<../..> "PydanticAI")
PydanticAI 
Question Graph 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/question-graph/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/question-graph/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/question-graph/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/examples/question-graph/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/examples/question-graph/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/examples/question-graph/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/examples/question-graph/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/examples/question-graph/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/examples/question-graph/agents/>)
    * [ Models  ](https://ai.pydantic.dev/examples/question-graph/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/examples/question-graph/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/examples/question-graph/tools/>)
    * [ Results  ](https://ai.pydantic.dev/examples/question-graph/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/examples/question-graph/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/examples/question-graph/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/examples/question-graph/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/examples/question-graph/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/examples/question-graph/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/examples/question-graph/<../>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/examples/question-graph/<../pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/examples/question-graph/<../weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/examples/question-graph/<../bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/examples/question-graph/<../sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/examples/question-graph/<../flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/examples/question-graph/<../rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/examples/question-graph/<../stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/examples/question-graph/<../stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/examples/question-graph/<../chat-app/>)
    * Question Graph  [ Question Graph  ](https://ai.pydantic.dev/examples/question-graph/<./>) Table of contents 
      * [ Running the Example  ](https://ai.pydantic.dev/examples/question-graph/<#running-the-example>)
      * [ Example Code  ](https://ai.pydantic.dev/examples/question-graph/<#example-code>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/examples/question-graph/api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/examples/question-graph/api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/examples/question-graph/api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/examples/question-graph/api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/examples/question-graph/api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/examples/question-graph/api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/examples/question-graph/api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/examples/question-graph/api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/examples/question-graph/api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/examples/question-graph/api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/examples/question-graph/api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/examples/question-graph/api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/examples/question-graph/api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/examples/question-graph/api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/examples/question-graph/api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/examples/question-graph/api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/examples/question-graph/api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/examples/question-graph/api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/examples/question-graph/api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/examples/question-graph/api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/examples/question-graph/api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/examples/question-graph/api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/examples/question-graph/api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Running the Example  ](https://ai.pydantic.dev/examples/question-graph/<#running-the-example>)
  * [ Example Code  ](https://ai.pydantic.dev/examples/question-graph/<#example-code>)


  1. [ Introduction  ](https://ai.pydantic.dev/examples/question-graph/<../..>)
  2. [ Examples  ](https://ai.pydantic.dev/examples/question-graph/<../>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/examples/question-graph/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/examples/question-graph/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Question Graph
Example of a graph for asking and evaluating questions.
Demonstrates:
  * `pydantic_graph`[](https://ai.pydantic.dev/examples/question-graph/graph/>)


## Running the Example
With [dependencies installed and environment variables set](https://ai.pydantic.dev/examples/question-graph/<../#usage>), run:
[pip](https://ai.pydantic.dev/examples/question-graph/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/examples/question-graph/<#__tabbed_1_2>)
```
python-mpydantic_ai_examples.question_graph

```

```
uvrun-mpydantic_ai_examples.question_graph

```

## Example Code
question_graph.py```
from __future__ import annotations as _annotations
from dataclasses import dataclass, field
from pathlib import Path
from typing import Annotated
import logfire
from devtools import debug
from pydantic_graph import BaseNode, Edge, End, Graph, GraphRunContext, HistoryStep
from pydantic_ai import Agent
from pydantic_ai.format_as_xml import format_as_xml
from pydantic_ai.messages import ModelMessage
# 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured
logfire.configure(send_to_logfire='if-token-present')
ask_agent = Agent('openai:gpt-4o', result_type=str)

@dataclass
class QuestionState:
  question: str | None = None
  ask_agent_messages: list[ModelMessage] = field(default_factory=list)
  evaluate_agent_messages: list[ModelMessage] = field(default_factory=list)

@dataclass
class Ask(BaseNode[QuestionState]):
  async def run(self, ctx: GraphRunContext[QuestionState]) -> Answer:
    result = await ask_agent.run(
      'Ask a simple question with a single correct answer.',
      message_history=ctx.state.ask_agent_messages,
    )
    ctx.state.ask_agent_messages += result.all_messages()
    ctx.state.question = result.data
    return Answer()

@dataclass
class Answer(BaseNode[QuestionState]):
  answer: str | None = None
  async def run(self, ctx: GraphRunContext[QuestionState]) -> Evaluate:
    assert self.answer is not None
    return Evaluate(self.answer)

@dataclass
class EvaluationResult:
  correct: bool
  comment: str

evaluate_agent = Agent(
  'openai:gpt-4o',
  result_type=EvaluationResult,
  system_prompt='Given a question and answer, evaluate if the answer is correct.',
)

@dataclass
class Evaluate(BaseNode[QuestionState]):
  answer: str
  async def run(
    self,
    ctx: GraphRunContext[QuestionState],
  ) -> Congratulate | Reprimand:
    assert ctx.state.question is not None
    result = await evaluate_agent.run(
      format_as_xml({'question': ctx.state.question, 'answer': self.answer}),
      message_history=ctx.state.evaluate_agent_messages,
    )
    ctx.state.evaluate_agent_messages += result.all_messages()
    if result.data.correct:
      return Congratulate(result.data.comment)
    else:
      return Reprimand(result.data.comment)

@dataclass
class Congratulate(BaseNode[QuestionState, None, None]):
  comment: str
  async def run(
    self, ctx: GraphRunContext[QuestionState]
  ) -> Annotated[End, Edge(label='success')]:
    print(f'Correct answer! {self.comment}')
    return End(None)

@dataclass
class Reprimand(BaseNode[QuestionState]):
  comment: str
  async def run(self, ctx: GraphRunContext[QuestionState]) -> Ask:
    print(f'Comment: {self.comment}')
    # > Comment: Vichy is no longer the capital of France.
    ctx.state.question = None
    return Ask()

question_graph = Graph(
  nodes=(Ask, Answer, Evaluate, Congratulate, Reprimand), state_type=QuestionState
)

async def run_as_continuous():
  state = QuestionState()
  node = Ask()
  history: list[HistoryStep[QuestionState, None]] = []
  with logfire.span('run questions graph'):
    while True:
      node = await question_graph.next(node, history, state=state)
      if isinstance(node, End):
        debug([e.data_snapshot() for e in history])
        break
      elif isinstance(node, Answer):
        assert state.question
        node.answer = input(f'{state.question} ')
      # otherwise just continue

async def run_as_cli(answer: str | None):
  history_file = Path('question_graph_history.json')
  history = (
    question_graph.load_history(history_file.read_bytes())
    if history_file.exists()
    else []
  )
  if history:
    last = history[-1]
    assert last.kind == 'node', 'expected last step to be a node'
    state = last.state
    assert answer is not None, 'answer is required to continue from history'
    node = Answer(answer)
  else:
    state = QuestionState()
    node = Ask()
  debug(state, node)
  with logfire.span('run questions graph'):
    while True:
      node = await question_graph.next(node, history, state=state)
      if isinstance(node, End):
        debug([e.data_snapshot() for e in history])
        print('Finished!')
        break
      elif isinstance(node, Answer):
        print(state.question)
        break
      # otherwise just continue
  history_file.write_bytes(question_graph.dump_history(history, indent=2))

if __name__ == '__main__':
  import asyncio
  import sys
  try:
    sub_command = sys.argv[1]
    assert sub_command in ('continuous', 'cli', 'mermaid')
  except (IndexError, AssertionError):
    print(
      'Usage:\n'
      ' uv run -m pydantic_ai_examples.question_graph mermaid\n'
      'or:\n'
      ' uv run -m pydantic_ai_examples.question_graph continuous\n'
      'or:\n'
      ' uv run -m pydantic_ai_examples.question_graph cli [answer]',
      file=sys.stderr,
    )
    sys.exit(1)
  if sub_command == 'mermaid':
    print(question_graph.mermaid_code(start_node=Ask))
  elif sub_command == 'continuous':
    asyncio.run(run_as_continuous())
  else:
    a = sys.argv[2] if len(sys.argv) > 2 else None
    asyncio.run(run_as_cli(a))

```

The mermaid diagram generated in this example looks like this:
```
---
title: question_graph
---
stateDiagram-v2
 [*] --> Ask
 Ask --> Answer: ask the question
 Answer --> Evaluate: answer the question
 Evaluate --> Congratulate
 Evaluate --> Castigate
 Congratulate --> [*]: success
 Castigate --> Ask: try again
```

© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/examples_rag.md
================
[ Skip to content ](https://ai.pydantic.dev/examples/rag/<#rag>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/rag/<../..> "PydanticAI")
PydanticAI 
RAG 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/rag/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/rag/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/rag/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/examples/rag/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/examples/rag/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/examples/rag/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/examples/rag/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/examples/rag/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/examples/rag/agents/>)
    * [ Models  ](https://ai.pydantic.dev/examples/rag/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/examples/rag/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/examples/rag/tools/>)
    * [ Results  ](https://ai.pydantic.dev/examples/rag/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/examples/rag/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/examples/rag/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/examples/rag/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/examples/rag/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/examples/rag/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/examples/rag/<../>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/examples/rag/<../pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/examples/rag/<../weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/examples/rag/<../bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/examples/rag/<../sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/examples/rag/<../flight-booking/>)
    * RAG  [ RAG  ](https://ai.pydantic.dev/examples/rag/<./>) Table of contents 
      * [ Example Code  ](https://ai.pydantic.dev/examples/rag/<#example-code>)
    * [ Stream markdown  ](https://ai.pydantic.dev/examples/rag/<../stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/examples/rag/<../stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/examples/rag/<../chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/examples/rag/<../question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/examples/rag/api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/examples/rag/api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/examples/rag/api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/examples/rag/api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/examples/rag/api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/examples/rag/api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/examples/rag/api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/examples/rag/api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/examples/rag/api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/examples/rag/api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/examples/rag/api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/examples/rag/api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/examples/rag/api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/examples/rag/api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/examples/rag/api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/examples/rag/api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/examples/rag/api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/examples/rag/api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/examples/rag/api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/examples/rag/api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/examples/rag/api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/examples/rag/api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/examples/rag/api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Example Code  ](https://ai.pydantic.dev/examples/rag/<#example-code>)


  1. [ Introduction  ](https://ai.pydantic.dev/examples/rag/<../..>)
  2. [ Examples  ](https://ai.pydantic.dev/examples/rag/<../>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/examples/rag/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/examples/rag/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# RAG
RAG search example. This demo allows you to ask question of the [logfire](https://ai.pydantic.dev/examples/rag/<https:/pydantic.dev/logfire>) documentation.
Demonstrates:
  * [tools](https://ai.pydantic.dev/examples/rag/tools/>)
  * [agent dependencies](https://ai.pydantic.dev/examples/rag/dependencies/>)
  * RAG search


This is done by creating a database containing each section of the markdown documentation, then registering the search tool with the PydanticAI agent.
Logic for extracting sections from markdown files and a JSON file with that data is available in [this gist](https://ai.pydantic.dev/examples/rag/<https:/gist.github.com/samuelcolvin/4b5bb9bb163b1122ff17e29e48c10992>).
[PostgreSQL with pgvector](https://ai.pydantic.dev/examples/rag/<https:/github.com/pgvector/pgvector>) is used as the search database, the easiest way to download and run pgvector is using Docker:
```
mkdirpostgres-data
dockerrun--rm\
-ePOSTGRES_PASSWORD=postgres\
-p54320:5432\
-v`pwd`/postgres-data:/var/lib/postgresql/data\
pgvector/pgvector:pg17

```

As with the [SQL gen](https://ai.pydantic.dev/examples/rag/<../sql-gen/>) example, we run postgres on port `54320` to avoid conflicts with any other postgres instances you may have running. We also mount the PostgreSQL `data` directory locally to persist the data if you need to stop and restart the container.
With that running and [dependencies installed and environment variables set](https://ai.pydantic.dev/examples/rag/<../#usage>), we can build the search database with (**WARNING** : this requires the `OPENAI_API_KEY` env variable and will calling the OpenAI embedding API around 300 times to generate embeddings for each section of the documentation):
[pip](https://ai.pydantic.dev/examples/rag/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/examples/rag/<#__tabbed_1_2>)
```
python-mpydantic_ai_examples.ragbuild

```

```
uvrun-mpydantic_ai_examples.ragbuild

```

(Note building the database doesn't use PydanticAI right now, instead it uses the OpenAI SDK directly.)
You can then ask the agent a question with:
[pip](https://ai.pydantic.dev/examples/rag/<#__tabbed_2_1>)[uv](https://ai.pydantic.dev/examples/rag/<#__tabbed_2_2>)
```
python-mpydantic_ai_examples.ragsearch"How do I configure logfire to work with FastAPI?"

```

```
uvrun-mpydantic_ai_examples.ragsearch"How do I configure logfire to work with FastAPI?"

```

## Example Code
rag.py```
from __future__ import annotations as _annotations
import asyncio
import re
import sys
import unicodedata
from contextlib import asynccontextmanager
from dataclasses import dataclass
import asyncpg
import httpx
import logfire
import pydantic_core
from openai import AsyncOpenAI
from pydantic import TypeAdapter
from typing_extensions import AsyncGenerator
from pydantic_ai import RunContext
from pydantic_ai.agent import Agent
# 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured
logfire.configure(send_to_logfire='if-token-present')
logfire.instrument_asyncpg()

@dataclass
class Deps:
  openai: AsyncOpenAI
  pool: asyncpg.Pool

agent = Agent('openai:gpt-4o', deps_type=Deps)

@agent.tool
async def retrieve(context: RunContext[Deps], search_query: str) -> str:
"""Retrieve documentation sections based on a search query.
  Args:
    context: The call context.
    search_query: The search query.
  """
  with logfire.span(
    'create embedding for {search_query=}', search_query=search_query
  ):
    embedding = await context.deps.openai.embeddings.create(
      input=search_query,
      model='text-embedding-3-small',
    )
  assert (
    len(embedding.data) == 1
  ), f'Expected 1 embedding, got {len(embedding.data)}, doc query: {search_query!r}'
  embedding = embedding.data[0].embedding
  embedding_json = pydantic_core.to_json(embedding).decode()
  rows = await context.deps.pool.fetch(
    'SELECT url, title, content FROM doc_sections ORDER BY embedding <-> $1 LIMIT 8',
    embedding_json,
  )
  return '\n\n'.join(
    f'# {row["title"]}\nDocumentation URL:{row["url"]}\n\n{row["content"]}\n'
    for row in rows
  )

async def run_agent(question: str):
"""Entry point to run the agent and perform RAG based question answering."""
  openai = AsyncOpenAI()
  logfire.instrument_openai(openai)
  logfire.info('Asking "{question}"', question=question)
  async with database_connect(False) as pool:
    deps = Deps(openai=openai, pool=pool)
    answer = await agent.run(question, deps=deps)
  print(answer.data)

#######################################################
# The rest of this file is dedicated to preparing the #
# search database, and some utilities.        #
#######################################################
# JSON document from
# https://gist.github.com/samuelcolvin/4b5bb9bb163b1122ff17e29e48c10992
DOCS_JSON = (
  'https://gist.githubusercontent.com/'
  'samuelcolvin/4b5bb9bb163b1122ff17e29e48c10992/raw/'
  '80c5925c42f1442c24963aaf5eb1a324d47afe95/logfire_docs.json'
)

async def build_search_db():
"""Build the search database."""
  async with httpx.AsyncClient() as client:
    response = await client.get(DOCS_JSON)
    response.raise_for_status()
  sections = sessions_ta.validate_json(response.content)
  openai = AsyncOpenAI()
  logfire.instrument_openai(openai)
  async with database_connect(True) as pool:
    with logfire.span('create schema'):
      async with pool.acquire() as conn:
        async with conn.transaction():
          await conn.execute(DB_SCHEMA)
    sem = asyncio.Semaphore(10)
    async with asyncio.TaskGroup() as tg:
      for section in sections:
        tg.create_task(insert_doc_section(sem, openai, pool, section))

async def insert_doc_section(
  sem: asyncio.Semaphore,
  openai: AsyncOpenAI,
  pool: asyncpg.Pool,
  section: DocsSection,
) -> None:
  async with sem:
    url = section.url()
    exists = await pool.fetchval('SELECT 1 FROM doc_sections WHERE url = $1', url)
    if exists:
      logfire.info('Skipping {url=}', url=url)
      return
    with logfire.span('create embedding for {url=}', url=url):
      embedding = await openai.embeddings.create(
        input=section.embedding_content(),
        model='text-embedding-3-small',
      )
    assert (
      len(embedding.data) == 1
    ), f'Expected 1 embedding, got {len(embedding.data)}, doc section: {section}'
    embedding = embedding.data[0].embedding
    embedding_json = pydantic_core.to_json(embedding).decode()
    await pool.execute(
      'INSERT INTO doc_sections (url, title, content, embedding) VALUES ($1, $2, $3, $4)',
      url,
      section.title,
      section.content,
      embedding_json,
    )

@dataclass
class DocsSection:
  id: int
  parent: int | None
  path: str
  level: int
  title: str
  content: str
  def url(self) -> str:
    url_path = re.sub(r'\.md$', '', self.path)
    return (
      f'https://logfire.pydantic.dev/docs/{url_path}/#{slugify(self.title,"-")}'
    )
  def embedding_content(self) -> str:
    return '\n\n'.join((f'path: {self.path}', f'title: {self.title}', self.content))

sessions_ta = TypeAdapter(list[DocsSection])

# pyright: reportUnknownMemberType=false
# pyright: reportUnknownVariableType=false
@asynccontextmanager
async def database_connect(
  create_db: bool = False,
) -> AsyncGenerator[asyncpg.Pool, None]:
  server_dsn, database = (
    'postgresql://postgres:postgres@localhost:54320',
    'pydantic_ai_rag',
  )
  if create_db:
    with logfire.span('check and create DB'):
      conn = await asyncpg.connect(server_dsn)
      try:
        db_exists = await conn.fetchval(
          'SELECT 1 FROM pg_database WHERE datname = $1', database
        )
        if not db_exists:
          await conn.execute(f'CREATE DATABASE {database}')
      finally:
        await conn.close()
  pool = await asyncpg.create_pool(f'{server_dsn}/{database}')
  try:
    yield pool
  finally:
    await pool.close()

DB_SCHEMA = """
CREATE EXTENSION IF NOT EXISTS vector;
CREATE TABLE IF NOT EXISTS doc_sections (
  id serial PRIMARY KEY,
  url text NOT NULL UNIQUE,
  title text NOT NULL,
  content text NOT NULL,
  -- text-embedding-3-small returns a vector of 1536 floats
  embedding vector(1536) NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_doc_sections_embedding ON doc_sections USING hnsw (embedding vector_l2_ops);
"""

def slugify(value: str, separator: str, unicode: bool = False) -> str:
"""Slugify a string, to make it URL friendly."""
  # Taken unchanged from https://github.com/Python-Markdown/markdown/blob/3.7/markdown/extensions/toc.py#L38
  if not unicode:
    # Replace Extended Latin characters with ASCII, i.e. `žlutý` => `zluty`
    value = unicodedata.normalize('NFKD', value)
    value = value.encode('ascii', 'ignore').decode('ascii')
  value = re.sub(r'[^\w\s-]', '', value).strip().lower()
  return re.sub(rf'[{separator}\s]+', separator, value)

if __name__ == '__main__':
  action = sys.argv[1] if len(sys.argv) > 1 else None
  if action == 'build':
    asyncio.run(build_search_db())
  elif action == 'search':
    if len(sys.argv) == 3:
      q = sys.argv[2]
    else:
      q = 'How do I configure logfire to work with FastAPI?'
    asyncio.run(run_agent(q))
  else:
    print(
      'uv run --extra examples -m pydantic_ai_examples.rag build|search',
      file=sys.stderr,
    )
    sys.exit(1)

```

© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/examples_sql-gen.md
================
[ Skip to content ](https://ai.pydantic.dev/examples/sql-gen/<#sql-generation>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/sql-gen/<../..> "PydanticAI")
PydanticAI 
SQL Generation 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/sql-gen/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/sql-gen/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/sql-gen/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/examples/sql-gen/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/examples/sql-gen/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/examples/sql-gen/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/examples/sql-gen/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/examples/sql-gen/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/examples/sql-gen/agents/>)
    * [ Models  ](https://ai.pydantic.dev/examples/sql-gen/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/examples/sql-gen/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/examples/sql-gen/tools/>)
    * [ Results  ](https://ai.pydantic.dev/examples/sql-gen/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/examples/sql-gen/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/examples/sql-gen/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/examples/sql-gen/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/examples/sql-gen/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/examples/sql-gen/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/examples/sql-gen/<../>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/examples/sql-gen/<../pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/examples/sql-gen/<../weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/examples/sql-gen/<../bank-support/>)
    * SQL Generation  [ SQL Generation  ](https://ai.pydantic.dev/examples/sql-gen/<./>) Table of contents 
      * [ Running the Example  ](https://ai.pydantic.dev/examples/sql-gen/<#running-the-example>)
      * [ Example Code  ](https://ai.pydantic.dev/examples/sql-gen/<#example-code>)
    * [ Flight booking  ](https://ai.pydantic.dev/examples/sql-gen/<../flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/examples/sql-gen/<../rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/examples/sql-gen/<../stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/examples/sql-gen/<../stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/examples/sql-gen/<../chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/examples/sql-gen/<../question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/examples/sql-gen/api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/examples/sql-gen/api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/examples/sql-gen/api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/examples/sql-gen/api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/examples/sql-gen/api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/examples/sql-gen/api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/examples/sql-gen/api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/examples/sql-gen/api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/examples/sql-gen/api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/examples/sql-gen/api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/examples/sql-gen/api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/examples/sql-gen/api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/examples/sql-gen/api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/examples/sql-gen/api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/examples/sql-gen/api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/examples/sql-gen/api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/examples/sql-gen/api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/examples/sql-gen/api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/examples/sql-gen/api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/examples/sql-gen/api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/examples/sql-gen/api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/examples/sql-gen/api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/examples/sql-gen/api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Running the Example  ](https://ai.pydantic.dev/examples/sql-gen/<#running-the-example>)
  * [ Example Code  ](https://ai.pydantic.dev/examples/sql-gen/<#example-code>)


  1. [ Introduction  ](https://ai.pydantic.dev/examples/sql-gen/<../..>)
  2. [ Examples  ](https://ai.pydantic.dev/examples/sql-gen/<../>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/examples/sql-gen/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/examples/sql-gen/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# SQL Generation
Example demonstrating how to use PydanticAI to generate SQL queries based on user input.
Demonstrates:
  * [dynamic system prompt](https://ai.pydantic.dev/examples/sql-gen/agents/#system-prompts>)
  * [structured `result_type`](https://ai.pydantic.dev/examples/sql-gen/results/#structured-result-validation>)
  * [result validation](https://ai.pydantic.dev/examples/sql-gen/results/#result-validators-functions>)
  * [agent dependencies](https://ai.pydantic.dev/examples/sql-gen/dependencies/>)


## Running the Example
The resulting SQL is validated by running it as an `EXPLAIN` query on PostgreSQL. To run the example, you first need to run PostgreSQL, e.g. via Docker:
```
dockerrun--rm-ePOSTGRES_PASSWORD=postgres-p54320:5432postgres

```

_(we run postgres on port`54320` to avoid conflicts with any other postgres instances you may have running)_
With [dependencies installed and environment variables set](https://ai.pydantic.dev/examples/sql-gen/<../#usage>), run:
[pip](https://ai.pydantic.dev/examples/sql-gen/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/examples/sql-gen/<#__tabbed_1_2>)
```
python-mpydantic_ai_examples.sql_gen

```

```
uvrun-mpydantic_ai_examples.sql_gen

```

or to use a custom prompt:
[pip](https://ai.pydantic.dev/examples/sql-gen/<#__tabbed_2_1>)[uv](https://ai.pydantic.dev/examples/sql-gen/<#__tabbed_2_2>)
```
python-mpydantic_ai_examples.sql_gen"find me errors"

```

```
uvrun-mpydantic_ai_examples.sql_gen"find me errors"

```

This model uses `gemini-1.5-flash` by default since Gemini is good at single shot queries of this kind.
## Example Code
sql_gen.py```
import asyncio
import sys
from collections.abc import AsyncGenerator
from contextlib import asynccontextmanager
from dataclasses import dataclass
from datetime import date
from typing import Annotated, Any, Union
import asyncpg
import logfire
from annotated_types import MinLen
from devtools import debug
from pydantic import BaseModel, Field
from typing_extensions import TypeAlias
from pydantic_ai import Agent, ModelRetry, RunContext
from pydantic_ai.format_as_xml import format_as_xml
# 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured
logfire.configure(send_to_logfire='if-token-present')
logfire.instrument_asyncpg()
DB_SCHEMA = """
CREATE TABLE records (
  created_at timestamptz,
  start_timestamp timestamptz,
  end_timestamp timestamptz,
  trace_id text,
  span_id text,
  parent_span_id text,
  level log_level,
  span_name text,
  message text,
  attributes_json_schema text,
  attributes jsonb,
  tags text[],
  is_exception boolean,
  otel_status_message text,
  service_name text
);
"""
SQL_EXAMPLES = [
  {
    'request': 'show me records where foobar is false',
    'response': "SELECT * FROM records WHERE attributes->>'foobar' = false",
  },
  {
    'request': 'show me records where attributes include the key "foobar"',
    'response': "SELECT * FROM records WHERE attributes ? 'foobar'",
  },
  {
    'request': 'show me records from yesterday',
    'response': "SELECT * FROM records WHERE start_timestamp::date > CURRENT_TIMESTAMP - INTERVAL '1 day'",
  },
  {
    'request': 'show me error records with the tag "foobar"',
    'response': "SELECT * FROM records WHERE level = 'error' and 'foobar' = ANY(tags)",
  },
]

@dataclass
class Deps:
  conn: asyncpg.Connection

class Success(BaseModel):
"""Response when SQL could be successfully generated."""
  sql_query: Annotated[str, MinLen(1)]
  explanation: str = Field(
    '', description='Explanation of the SQL query, as markdown'
  )

class InvalidRequest(BaseModel):
"""Response the user input didn't include enough information to generate SQL."""
  error_message: str

Response: TypeAlias = Union[Success, InvalidRequest]
agent: Agent[Deps, Response] = Agent(
  'google-gla:gemini-1.5-flash',
  # Type ignore while we wait for PEP-0747, nonetheless unions will work fine everywhere else
  result_type=Response, # type: ignore
  deps_type=Deps,
)

@agent.system_prompt
async def system_prompt() -> str:
  return f"""\
Given the following PostgreSQL table of records, your job is to
write a SQL query that suits the user's request.
Database schema:
{DB_SCHEMA}
today's date = {date.today()}
{format_as_xml(SQL_EXAMPLES)}
"""

@agent.result_validator
async def validate_result(ctx: RunContext[Deps], result: Response) -> Response:
  if isinstance(result, InvalidRequest):
    return result
  # gemini often adds extraneous backslashes to SQL
  result.sql_query = result.sql_query.replace('\\', '')
  if not result.sql_query.upper().startswith('SELECT'):
    raise ModelRetry('Please create a SELECT query')
  try:
    await ctx.deps.conn.execute(f'EXPLAIN {result.sql_query}')
  except asyncpg.exceptions.PostgresError as e:
    raise ModelRetry(f'Invalid query: {e}') from e
  else:
    return result

async def main():
  if len(sys.argv) == 1:
    prompt = 'show me logs from yesterday, with level "error"'
  else:
    prompt = sys.argv[1]
  async with database_connect(
    'postgresql://postgres:postgres@localhost:54320', 'pydantic_ai_sql_gen'
  ) as conn:
    deps = Deps(conn)
    result = await agent.run(prompt, deps=deps)
  debug(result.data)

# pyright: reportUnknownMemberType=false
# pyright: reportUnknownVariableType=false
@asynccontextmanager
async def database_connect(server_dsn: str, database: str) -> AsyncGenerator[Any, None]:
  with logfire.span('check and create DB'):
    conn = await asyncpg.connect(server_dsn)
    try:
      db_exists = await conn.fetchval(
        'SELECT 1 FROM pg_database WHERE datname = $1', database
      )
      if not db_exists:
        await conn.execute(f'CREATE DATABASE {database}')
    finally:
      await conn.close()
  conn = await asyncpg.connect(f'{server_dsn}/{database}')
  try:
    with logfire.span('create schema'):
      async with conn.transaction():
        if not db_exists:
          await conn.execute(
            "CREATE TYPE log_level AS ENUM ('debug', 'info', 'warning', 'error', 'critical')"
          )
        await conn.execute(DB_SCHEMA)
    yield conn
  finally:
    await conn.close()

if __name__ == '__main__':
  asyncio.run(main())

```

© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/examples_stream-markdown.md
================
[ Skip to content ](https://ai.pydantic.dev/examples/stream-markdown/<#running-the-example>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/stream-markdown/<../..> "PydanticAI")
PydanticAI 
Stream markdown 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/stream-markdown/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/stream-markdown/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/stream-markdown/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/examples/stream-markdown/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/examples/stream-markdown/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/examples/stream-markdown/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/examples/stream-markdown/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/examples/stream-markdown/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/examples/stream-markdown/agents/>)
    * [ Models  ](https://ai.pydantic.dev/examples/stream-markdown/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/examples/stream-markdown/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/examples/stream-markdown/tools/>)
    * [ Results  ](https://ai.pydantic.dev/examples/stream-markdown/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/examples/stream-markdown/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/examples/stream-markdown/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/examples/stream-markdown/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/examples/stream-markdown/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/examples/stream-markdown/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/examples/stream-markdown/<../>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/examples/stream-markdown/<../pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/examples/stream-markdown/<../weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/examples/stream-markdown/<../bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/examples/stream-markdown/<../sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/examples/stream-markdown/<../flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/examples/stream-markdown/<../rag/>)
    * Stream markdown  [ Stream markdown  ](https://ai.pydantic.dev/examples/stream-markdown/<./>) Table of contents 
      * [ Running the Example  ](https://ai.pydantic.dev/examples/stream-markdown/<#running-the-example>)
      * [ Example Code  ](https://ai.pydantic.dev/examples/stream-markdown/<#example-code>)
    * [ Stream whales  ](https://ai.pydantic.dev/examples/stream-markdown/<../stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/examples/stream-markdown/<../chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/examples/stream-markdown/<../question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/examples/stream-markdown/api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/examples/stream-markdown/api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/examples/stream-markdown/api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/examples/stream-markdown/api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/examples/stream-markdown/api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/examples/stream-markdown/api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/examples/stream-markdown/api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/examples/stream-markdown/api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/examples/stream-markdown/api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/examples/stream-markdown/api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/examples/stream-markdown/api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/examples/stream-markdown/api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/examples/stream-markdown/api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/examples/stream-markdown/api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/examples/stream-markdown/api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/examples/stream-markdown/api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/examples/stream-markdown/api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/examples/stream-markdown/api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/examples/stream-markdown/api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/examples/stream-markdown/api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/examples/stream-markdown/api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/examples/stream-markdown/api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/examples/stream-markdown/api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Running the Example  ](https://ai.pydantic.dev/examples/stream-markdown/<#running-the-example>)
  * [ Example Code  ](https://ai.pydantic.dev/examples/stream-markdown/<#example-code>)


  1. [ Introduction  ](https://ai.pydantic.dev/examples/stream-markdown/<../..>)
  2. [ Examples  ](https://ai.pydantic.dev/examples/stream-markdown/<../>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/examples/stream-markdown/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/examples/stream-markdown/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Stream markdown
This example shows how to stream markdown from an agent, using the `rich`[](https://ai.pydantic.dev/examples/stream-markdown/<https:/github.com/Textualize/rich>) library to highlight the output in the terminal.
It'll run the example with both OpenAI and Google Gemini models if the required environment variables are set.
Demonstrates:
  * [streaming text responses](https://ai.pydantic.dev/examples/stream-markdown/results/#streaming-text>)


## Running the Example
With [dependencies installed and environment variables set](https://ai.pydantic.dev/examples/stream-markdown/<../#usage>), run:
[pip](https://ai.pydantic.dev/examples/stream-markdown/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/examples/stream-markdown/<#__tabbed_1_2>)
```
python-mpydantic_ai_examples.stream_markdown

```

```
uvrun-mpydantic_ai_examples.stream_markdown

```

## Example Code
```
import asyncio
import os
import logfire
from rich.console import Console, ConsoleOptions, RenderResult
from rich.live import Live
from rich.markdown import CodeBlock, Markdown
from rich.syntax import Syntax
from rich.text import Text
from pydantic_ai import Agent
from pydantic_ai.models import KnownModelName
# 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured
logfire.configure(send_to_logfire='if-token-present')
agent = Agent()
# models to try, and the appropriate env var
models: list[tuple[KnownModelName, str]] = [
  ('google-gla:gemini-1.5-flash', 'GEMINI_API_KEY'),
  ('openai:gpt-4o-mini', 'OPENAI_API_KEY'),
  ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

async def main():
  prettier_code_blocks()
  console = Console()
  prompt = 'Show me a short example of using Pydantic.'
  console.log(f'Asking: {prompt}...', style='cyan')
  for model, env_var in models:
    if env_var in os.environ:
      console.log(f'Using model: {model}')
      with Live('', console=console, vertical_overflow='visible') as live:
        async with agent.run_stream(prompt, model=model) as result:
          async for message in result.stream():
            live.update(Markdown(message))
      console.log(result.usage())
    else:
      console.log(f'{model} requires {env_var} to be set.')

def prettier_code_blocks():
"""Make rich code blocks prettier and easier to copy.
  From https://github.com/samuelcolvin/aicli/blob/v0.8.0/samuelcolvin_aicli.py#L22
  """
  class SimpleCodeBlock(CodeBlock):
    def __rich_console__(
      self, console: Console, options: ConsoleOptions
    ) -> RenderResult:
      code = str(self.text).rstrip()
      yield Text(self.lexer_name, style='dim')
      yield Syntax(
        code,
        self.lexer_name,
        theme=self.theme,
        background_color='default',
        word_wrap=True,
      )
      yield Text(f'/{self.lexer_name}', style='dim')
  Markdown.elements['fence'] = SimpleCodeBlock

if __name__ == '__main__':
  asyncio.run(main())

```

© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/examples_stream-whales.md
================
[ Skip to content ](https://ai.pydantic.dev/examples/stream-whales/<#running-the-example>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/stream-whales/<../..> "PydanticAI")
PydanticAI 
Stream whales 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/stream-whales/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/stream-whales/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/stream-whales/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/examples/stream-whales/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/examples/stream-whales/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/examples/stream-whales/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/examples/stream-whales/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/examples/stream-whales/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/examples/stream-whales/agents/>)
    * [ Models  ](https://ai.pydantic.dev/examples/stream-whales/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/examples/stream-whales/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/examples/stream-whales/tools/>)
    * [ Results  ](https://ai.pydantic.dev/examples/stream-whales/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/examples/stream-whales/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/examples/stream-whales/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/examples/stream-whales/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/examples/stream-whales/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/examples/stream-whales/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/examples/stream-whales/<../>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/examples/stream-whales/<../pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/examples/stream-whales/<../weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/examples/stream-whales/<../bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/examples/stream-whales/<../sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/examples/stream-whales/<../flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/examples/stream-whales/<../rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/examples/stream-whales/<../stream-markdown/>)
    * Stream whales  [ Stream whales  ](https://ai.pydantic.dev/examples/stream-whales/<./>) Table of contents 
      * [ Running the Example  ](https://ai.pydantic.dev/examples/stream-whales/<#running-the-example>)
      * [ Example Code  ](https://ai.pydantic.dev/examples/stream-whales/<#example-code>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/examples/stream-whales/<../chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/examples/stream-whales/<../question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/examples/stream-whales/api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/examples/stream-whales/api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/examples/stream-whales/api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/examples/stream-whales/api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/examples/stream-whales/api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/examples/stream-whales/api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/examples/stream-whales/api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/examples/stream-whales/api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/examples/stream-whales/api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/examples/stream-whales/api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/examples/stream-whales/api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/examples/stream-whales/api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/examples/stream-whales/api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/examples/stream-whales/api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/examples/stream-whales/api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/examples/stream-whales/api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/examples/stream-whales/api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/examples/stream-whales/api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/examples/stream-whales/api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/examples/stream-whales/api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/examples/stream-whales/api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/examples/stream-whales/api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/examples/stream-whales/api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Running the Example  ](https://ai.pydantic.dev/examples/stream-whales/<#running-the-example>)
  * [ Example Code  ](https://ai.pydantic.dev/examples/stream-whales/<#example-code>)


  1. [ Introduction  ](https://ai.pydantic.dev/examples/stream-whales/<../..>)
  2. [ Examples  ](https://ai.pydantic.dev/examples/stream-whales/<../>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/examples/stream-whales/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/examples/stream-whales/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Stream whales
Information about whales — an example of streamed structured response validation.
Demonstrates:
  * [streaming structured responses](https://ai.pydantic.dev/examples/stream-whales/results/#streaming-structured-responses>)


This script streams structured responses from GPT-4 about whales, validates the data and displays it as a dynamic table using `rich`[](https://ai.pydantic.dev/examples/stream-whales/<https:/github.com/Textualize/rich>) as the data is received.
## Running the Example
With [dependencies installed and environment variables set](https://ai.pydantic.dev/examples/stream-whales/<../#usage>), run:
[pip](https://ai.pydantic.dev/examples/stream-whales/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/examples/stream-whales/<#__tabbed_1_2>)
```
python-mpydantic_ai_examples.stream_whales

```

```
uvrun-mpydantic_ai_examples.stream_whales

```

Should give an output like this:
## Example Code
stream_whales.py```
from typing import Annotated
import logfire
from pydantic import Field, ValidationError
from rich.console import Console
from rich.live import Live
from rich.table import Table
from typing_extensions import NotRequired, TypedDict
from pydantic_ai import Agent
# 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured
logfire.configure(send_to_logfire='if-token-present')

class Whale(TypedDict):
  name: str
  length: Annotated[
    float, Field(description='Average length of an adult whale in meters.')
  ]
  weight: NotRequired[
    Annotated[
      float,
      Field(description='Average weight of an adult whale in kilograms.', ge=50),
    ]
  ]
  ocean: NotRequired[str]
  description: NotRequired[Annotated[str, Field(description='Short Description')]]

agent = Agent('openai:gpt-4', result_type=list[Whale])

async def main():
  console = Console()
  with Live('\n' * 36, console=console) as live:
    console.print('Requesting data...', style='cyan')
    async with agent.run_stream(
      'Generate me details of 5 species of Whale.'
    ) as result:
      console.print('Response:', style='green')
      async for message, last in result.stream_structured(debounce_by=0.01):
        try:
          whales = await result.validate_structured_result(
            message, allow_partial=not last
          )
        except ValidationError as exc:
          if all(
            e['type'] == 'missing' and e['loc'] == ('response',)
            for e in exc.errors()
          ):
            continue
          else:
            raise
        table = Table(
          title='Species of Whale',
          caption='Streaming Structured responses from GPT-4',
          width=120,
        )
        table.add_column('ID', justify='right')
        table.add_column('Name')
        table.add_column('Avg. Length (m)', justify='right')
        table.add_column('Avg. Weight (kg)', justify='right')
        table.add_column('Ocean')
        table.add_column('Description', justify='right')
        for wid, whale in enumerate(whales, start=1):
          table.add_row(
            str(wid),
            whale['name'],
            f'{whale["length"]:0.0f}',
            f'{w:0.0f}' if (w := whale.get('weight')) else '…',
            whale.get('ocean') or '…',
            whale.get('description') or '…',
          )
        live.update(table)

if __name__ == '__main__':
  import asyncio
  asyncio.run(main())

```

© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/examples_weather-agent.md
================
[ Skip to content ](https://ai.pydantic.dev/examples/weather-agent/<#running-the-example>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/weather-agent/<../..> "PydanticAI")
PydanticAI 
Weather agent 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/weather-agent/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/weather-agent/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/weather-agent/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/examples/weather-agent/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/examples/weather-agent/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/examples/weather-agent/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/examples/weather-agent/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/examples/weather-agent/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/examples/weather-agent/agents/>)
    * [ Models  ](https://ai.pydantic.dev/examples/weather-agent/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/examples/weather-agent/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/examples/weather-agent/tools/>)
    * [ Results  ](https://ai.pydantic.dev/examples/weather-agent/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/examples/weather-agent/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/examples/weather-agent/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/examples/weather-agent/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/examples/weather-agent/multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/examples/weather-agent/graph/>)
  * [ Examples  ](https://ai.pydantic.dev/examples/weather-agent/<../>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/examples/weather-agent/<../pydantic-model/>)
    * Weather agent  [ Weather agent  ](https://ai.pydantic.dev/examples/weather-agent/<./>) Table of contents 
      * [ Running the Example  ](https://ai.pydantic.dev/examples/weather-agent/<#running-the-example>)
      * [ Example Code  ](https://ai.pydantic.dev/examples/weather-agent/<#example-code>)
      * [ Running the UI  ](https://ai.pydantic.dev/examples/weather-agent/<#running-the-ui>)
      * [ UI Code  ](https://ai.pydantic.dev/examples/weather-agent/<#ui-code>)
    * [ Bank support  ](https://ai.pydantic.dev/examples/weather-agent/<../bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/examples/weather-agent/<../sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/examples/weather-agent/<../flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/examples/weather-agent/<../rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/examples/weather-agent/<../stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/examples/weather-agent/<../stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/examples/weather-agent/<../chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/examples/weather-agent/<../question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/examples/weather-agent/api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/examples/weather-agent/api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/examples/weather-agent/api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/examples/weather-agent/api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/examples/weather-agent/api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/examples/weather-agent/api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/examples/weather-agent/api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/examples/weather-agent/api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/examples/weather-agent/api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/examples/weather-agent/api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/examples/weather-agent/api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/examples/weather-agent/api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/examples/weather-agent/api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/examples/weather-agent/api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/examples/weather-agent/api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/examples/weather-agent/api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/examples/weather-agent/api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/examples/weather-agent/api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/examples/weather-agent/api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/examples/weather-agent/api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/examples/weather-agent/api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/examples/weather-agent/api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/examples/weather-agent/api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Running the Example  ](https://ai.pydantic.dev/examples/weather-agent/<#running-the-example>)
  * [ Example Code  ](https://ai.pydantic.dev/examples/weather-agent/<#example-code>)
  * [ Running the UI  ](https://ai.pydantic.dev/examples/weather-agent/<#running-the-ui>)
  * [ UI Code  ](https://ai.pydantic.dev/examples/weather-agent/<#ui-code>)


  1. [ Introduction  ](https://ai.pydantic.dev/examples/weather-agent/<../..>)
  2. [ Examples  ](https://ai.pydantic.dev/examples/weather-agent/<../>)


# Weather agent
Example of PydanticAI with multiple tools which the LLM needs to call in turn to answer a question.
Demonstrates:
  * [tools](https://ai.pydantic.dev/examples/weather-agent/tools/>)
  * [agent dependencies](https://ai.pydantic.dev/examples/weather-agent/dependencies/>)
  * [streaming text responses](https://ai.pydantic.dev/examples/weather-agent/results/#streaming-text>)
  * Building a [Gradio](https://ai.pydantic.dev/examples/weather-agent/<https:/www.gradio.app/>) UI for the agent


In this case the idea is a "weather" agent — the user can ask for the weather in multiple locations, the agent will use the `get_lat_lng` tool to get the latitude and longitude of the locations, then use the `get_weather` tool to get the weather for those locations.
## Running the Example
To run this example properly, you might want to add two extra API keys **(Note if either key is missing, the code will fall back to dummy data, so they're not required)** :
  * A weather API key from [tomorrow.io](https://ai.pydantic.dev/examples/weather-agent/<https:/www.tomorrow.io/weather-api/>) set via `WEATHER_API_KEY`
  * A geocoding API key from [geocode.maps.co](https://ai.pydantic.dev/examples/weather-agent/<https:/geocode.maps.co/>) set via `GEO_API_KEY`


With [dependencies installed and environment variables set](https://ai.pydantic.dev/examples/weather-agent/<../#usage>), run:
[pip](https://ai.pydantic.dev/examples/weather-agent/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/examples/weather-agent/<#__tabbed_1_2>)
```
python-mpydantic_ai_examples.weather_agent

```

```
uvrun-mpydantic_ai_examples.weather_agent

```

## Example Code
pydantic_ai_examples/weather_agent.py```
from __future__ import annotations as _annotations
import asyncio
import os
from dataclasses import dataclass
from typing import Any
import logfire
from devtools import debug
from httpx import AsyncClient
from pydantic_ai import Agent, ModelRetry, RunContext
# 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured
logfire.configure(send_to_logfire='if-token-present')

@dataclass
class Deps:
  client: AsyncClient
  weather_api_key: str | None
  geo_api_key: str | None

weather_agent = Agent(
  'openai:gpt-4o',
  # 'Be concise, reply with one sentence.' is enough for some models (like openai) to use
  # the below tools appropriately, but others like anthropic and gemini require a bit more direction.
  system_prompt=(
    'Be concise, reply with one sentence.'
    'Use the `get_lat_lng` tool to get the latitude and longitude of the locations, '
    'then use the `get_weather` tool to get the weather.'
  ),
  deps_type=Deps,
  retries=2,
)

@weather_agent.tool
async def get_lat_lng(
  ctx: RunContext[Deps], location_description: str
) -> dict[str, float]:
"""Get the latitude and longitude of a location.
  Args:
    ctx: The context.
    location_description: A description of a location.
  """
  if ctx.deps.geo_api_key is None:
    # if no API key is provided, return a dummy response (London)
    return {'lat': 51.1, 'lng': -0.1}
  params = {
    'q': location_description,
    'api_key': ctx.deps.geo_api_key,
  }
  with logfire.span('calling geocode API', params=params) as span:
    r = await ctx.deps.client.get('https://geocode.maps.co/search', params=params)
    r.raise_for_status()
    data = r.json()
    span.set_attribute('response', data)
  if data:
    return {'lat': data[0]['lat'], 'lng': data[0]['lon']}
  else:
    raise ModelRetry('Could not find the location')

@weather_agent.tool
async def get_weather(ctx: RunContext[Deps], lat: float, lng: float) -> dict[str, Any]:
"""Get the weather at a location.
  Args:
    ctx: The context.
    lat: Latitude of the location.
    lng: Longitude of the location.
  """
  if ctx.deps.weather_api_key is None:
    # if no API key is provided, return a dummy response
    return {'temperature': '21 °C', 'description': 'Sunny'}
  params = {
    'apikey': ctx.deps.weather_api_key,
    'location': f'{lat},{lng}',
    'units': 'metric',
  }
  with logfire.span('calling weather API', params=params) as span:
    r = await ctx.deps.client.get(
      'https://api.tomorrow.io/v4/weather/realtime', params=params
    )
    r.raise_for_status()
    data = r.json()
    span.set_attribute('response', data)
  values = data['data']['values']
  # https://docs.tomorrow.io/reference/data-layers-weather-codes
  code_lookup = {
    1000: 'Clear, Sunny',
    1100: 'Mostly Clear',
    1101: 'Partly Cloudy',
    1102: 'Mostly Cloudy',
    1001: 'Cloudy',
    2000: 'Fog',
    2100: 'Light Fog',
    4000: 'Drizzle',
    4001: 'Rain',
    4200: 'Light Rain',
    4201: 'Heavy Rain',
    5000: 'Snow',
    5001: 'Flurries',
    5100: 'Light Snow',
    5101: 'Heavy Snow',
    6000: 'Freezing Drizzle',
    6001: 'Freezing Rain',
    6200: 'Light Freezing Rain',
    6201: 'Heavy Freezing Rain',
    7000: 'Ice Pellets',
    7101: 'Heavy Ice Pellets',
    7102: 'Light Ice Pellets',
    8000: 'Thunderstorm',
  }
  return {
    'temperature': f'{values["temperatureApparent"]:0.0f}°C',
    'description': code_lookup.get(values['weatherCode'], 'Unknown'),
  }

async def main():
  async with AsyncClient() as client:
    # create a free API key at https://www.tomorrow.io/weather-api/
    weather_api_key = os.getenv('WEATHER_API_KEY')
    # create a free API key at https://geocode.maps.co/
    geo_api_key = os.getenv('GEO_API_KEY')
    deps = Deps(
      client=client, weather_api_key=weather_api_key, geo_api_key=geo_api_key
    )
    result = await weather_agent.run(
      'What is the weather like in London and in Wiltshire?', deps=deps
    )
    debug(result)
    print('Response:', result.data)

if __name__ == '__main__':
  asyncio.run(main())

```

## Running the UI
You can build multi-turn chat applications for your agent with [Gradio](https://ai.pydantic.dev/examples/weather-agent/<https:/www.gradio.app/>), a framework for building AI web applications entirely in python. Gradio comes with built-in chat components and agent support so the entire UI will be implemented in a single python file!
Here's what the UI looks like for the weather agent:
Note, to run the UI, you'll need Python 3.10+.
```
pipinstallgradio>=5.9.0
python/uv-run-mpydantic_ai_examples.weather_agent_gradio

```

## UI Code
pydantic_ai_examples/weather_agent_gradio.py```
#! pydantic_ai_examples/weather_agent_gradio.py

```

© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/examples.md
================
[ Skip to content ](https://ai.pydantic.dev/examples/<#examples>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/<..> "PydanticAI")
PydanticAI 
Examples 
Type to start searching
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/examples/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/examples/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/examples/<..>)
  * [ Installation  ](https://ai.pydantic.dev/examples/<../install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/examples/<../help/>)
  * [ Contributing  ](https://ai.pydantic.dev/examples/<../contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/examples/<../troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/examples/<../agents/>)
    * [ Models  ](https://ai.pydantic.dev/examples/<../models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/examples/<../dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/examples/<../tools/>)
    * [ Results  ](https://ai.pydantic.dev/examples/<../results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/examples/<../message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/examples/<../testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/examples/<../logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/examples/<../multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/examples/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/examples/<./>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/examples/<pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/examples/<weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/examples/<bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/examples/<sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/examples/<flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/examples/<rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/examples/<stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/examples/<stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/examples/<chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/examples/<question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/examples/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/examples/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/examples/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/examples/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/examples/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/examples/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/examples/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/examples/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/examples/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/examples/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/examples/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/examples/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/examples/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/examples/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/examples/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/examples/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/examples/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/examples/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/examples/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/examples/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/examples/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/examples/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/examples/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Usage  ](https://ai.pydantic.dev/examples/<#usage>)
    * [ Installing required dependencies  ](https://ai.pydantic.dev/examples/<#installing-required-dependencies>)
    * [ Setting model environment variables  ](https://ai.pydantic.dev/examples/<#setting-model-environment-variables>)
    * [ Running Examples  ](https://ai.pydantic.dev/examples/<#running-examples>)


  1. [ Introduction  ](https://ai.pydantic.dev/examples/<..>)
  2. [ Examples  ](https://ai.pydantic.dev/examples/<./>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/examples/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/examples/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Examples
Examples of how to use PydanticAI and what it can do.
## Usage
These examples are distributed with `pydantic-ai` so you can run them either by cloning the [pydantic-ai repo](https://ai.pydantic.dev/examples/<https:/github.com/pydantic/pydantic-ai>) or by simply installing `pydantic-ai` from PyPI with `pip` or `uv`.
### Installing required dependencies
Either way you'll need to install extra dependencies to run some examples, you just need to install the `examples` optional dependency group.
If you've installed `pydantic-ai` via pip/uv, you can install the extra dependencies with:
[pip](https://ai.pydantic.dev/examples/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/examples/<#__tabbed_1_2>)
```
pipinstall'pydantic-ai[examples]'

```

```
uvadd'pydantic-ai[examples]'

```

If you clone the repo, you should instead use `uv sync --extra examples` to install extra dependencies.
### Setting model environment variables
These examples will need you to set up authentication with one or more of the LLMs, see the [model configuration](https://ai.pydantic.dev/examples/<../models/>) docs for details on how to do this.
TL;DR: in most cases you'll need to set one of the following environment variables:
[OpenAI](https://ai.pydantic.dev/examples/<#__tabbed_2_1>)[Google Gemini](https://ai.pydantic.dev/examples/<#__tabbed_2_2>)
```
exportOPENAI_API_KEY=your-api-key

```

```
exportGEMINI_API_KEY=your-api-key

```

### Running Examples
To run the examples (this will work whether you installed `pydantic_ai`, or cloned the repo), run:
[pip](https://ai.pydantic.dev/examples/<#__tabbed_3_1>)[uv](https://ai.pydantic.dev/examples/<#__tabbed_3_2>)
```
python-mpydantic_ai_examples.<example_module_name>

```

```
uvrun-mpydantic_ai_examples.<example_module_name>

```

For examples, to run the very simple `pydantic_model`[](https://ai.pydantic.dev/examples/<pydantic-model/>) example:
[pip](https://ai.pydantic.dev/examples/<#__tabbed_4_1>)[uv](https://ai.pydantic.dev/examples/<#__tabbed_4_2>)
```
python-mpydantic_ai_examples.pydantic_model

```

```
uvrun-mpydantic_ai_examples.pydantic_model

```

If you like one-liners and you're using uv, you can run a pydantic-ai example with zero setup:
```
OPENAI_API_KEY='your-api-key'\
uvrun--with'pydantic-ai[examples]'\
-mpydantic_ai_examples.pydantic_model

```

You'll probably want to edit examples in addition to just running them. You can copy the examples to a new directory with:
[pip](https://ai.pydantic.dev/examples/<#__tabbed_5_1>)[uv](https://ai.pydantic.dev/examples/<#__tabbed_5_2>)
```
python-mpydantic_ai_examples--copy-toexamples/

```

```
uvrun-mpydantic_ai_examples--copy-toexamples/

```

© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/graph.md
================
[ Skip to content ](https://ai.pydantic.dev/graph/<#graphs>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/graph/<..> "PydanticAI")
PydanticAI 
Graphs 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/graph/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/graph/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/graph/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/graph/<..>)
  * [ Installation  ](https://ai.pydantic.dev/graph/<../install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/graph/<../help/>)
  * [ Contributing  ](https://ai.pydantic.dev/graph/<../contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/graph/<../troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/graph/<../agents/>)
    * [ Models  ](https://ai.pydantic.dev/graph/<../models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/graph/<../dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/graph/<../tools/>)
    * [ Results  ](https://ai.pydantic.dev/graph/<../results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/graph/<../message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/graph/<../testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/graph/<../logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/graph/<../multi-agent-applications/>)
    * Graphs  [ Graphs  ](https://ai.pydantic.dev/graph/<./>) Table of contents 
      * [ Installation  ](https://ai.pydantic.dev/graph/<#installation>)
      * [ Graph Types  ](https://ai.pydantic.dev/graph/<#graph-types>)
        * [ GraphRunContext  ](https://ai.pydantic.dev/graph/<#graphruncontext>)
        * [ End  ](https://ai.pydantic.dev/graph/<#end>)
        * [ Nodes  ](https://ai.pydantic.dev/graph/<#nodes>)
        * [ Graph  ](https://ai.pydantic.dev/graph/<#graph>)
      * [ Stateful Graphs  ](https://ai.pydantic.dev/graph/<#stateful-graphs>)
      * [ GenAI Example  ](https://ai.pydantic.dev/graph/<#genai-example>)
      * [ Custom Control Flow  ](https://ai.pydantic.dev/graph/<#custom-control-flow>)
      * [ Dependency Injection  ](https://ai.pydantic.dev/graph/<#dependency-injection>)
      * [ Mermaid Diagrams  ](https://ai.pydantic.dev/graph/<#mermaid-diagrams>)
        * [ Setting Direction of the State Diagram  ](https://ai.pydantic.dev/graph/<#setting-direction-of-the-state-diagram>)
  * [ Examples  ](https://ai.pydantic.dev/graph/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/graph/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/graph/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/graph/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/graph/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/graph/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/graph/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/graph/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/graph/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/graph/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/graph/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/graph/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/graph/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/graph/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/graph/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/graph/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/graph/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/graph/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/graph/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/graph/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/graph/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/graph/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/graph/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/graph/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/graph/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/graph/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/graph/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/graph/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/graph/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/graph/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/graph/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/graph/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Installation  ](https://ai.pydantic.dev/graph/<#installation>)
  * [ Graph Types  ](https://ai.pydantic.dev/graph/<#graph-types>)
    * [ GraphRunContext  ](https://ai.pydantic.dev/graph/<#graphruncontext>)
    * [ End  ](https://ai.pydantic.dev/graph/<#end>)
    * [ Nodes  ](https://ai.pydantic.dev/graph/<#nodes>)
    * [ Graph  ](https://ai.pydantic.dev/graph/<#graph>)
  * [ Stateful Graphs  ](https://ai.pydantic.dev/graph/<#stateful-graphs>)
  * [ GenAI Example  ](https://ai.pydantic.dev/graph/<#genai-example>)
  * [ Custom Control Flow  ](https://ai.pydantic.dev/graph/<#custom-control-flow>)
  * [ Dependency Injection  ](https://ai.pydantic.dev/graph/<#dependency-injection>)
  * [ Mermaid Diagrams  ](https://ai.pydantic.dev/graph/<#mermaid-diagrams>)
    * [ Setting Direction of the State Diagram  ](https://ai.pydantic.dev/graph/<#setting-direction-of-the-state-diagram>)


  1. [ Introduction  ](https://ai.pydantic.dev/graph/<..>)
  2. [ Documentation  ](https://ai.pydantic.dev/graph/<../agents/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/graph/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/graph/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Graphs
Don't use a nail gun unless you need a nail gun
If PydanticAI [agents](https://ai.pydantic.dev/graph/<../agents/>) are a hammer, and [multi-agent workflows](https://ai.pydantic.dev/graph/<../multi-agent-applications/>) are a sledgehammer, then graphs are a nail gun:
  * sure, nail guns look cooler than hammers
  * but nail guns take a lot more setup than hammers
  * and nail guns don't make you a better builder, they make you a builder with a nail gun
  * Lastly, (and at the risk of torturing this metaphor), if you're a fan of medieval tools like mallets and untyped Python, you probably won't like nail guns or our approach to graphs. (But then again, if you're not a fan of type hints in Python, you've probably already bounced off PydanticAI to use one of the toy agent frameworks — good luck, and feel free to borrow my sledgehammer when you realize you need it)


In short, graphs are a powerful tool, but they're not the right tool for every job. Please consider other [multi-agent approaches](https://ai.pydantic.dev/graph/<../multi-agent-applications/>) before proceeding.
If you're not confident a graph-based approach is a good idea, it might be unnecessary.
Graphs and finite state machines (FSMs) are a powerful abstraction to model, execute, control and visualize complex workflows.
Alongside PydanticAI, we've developed `pydantic-graph` — an async graph and state machine library for Python where nodes and edges are defined using type hints.
While this library is developed as part of PydanticAI; it has no dependency on `pydantic-ai` and can be considered as a pure graph-based state machine library. You may find it useful whether or not you're using PydanticAI or even building with GenAI.
`pydantic-graph` is designed for advanced users and makes heavy use of Python generics and types hints. It is not designed to be as beginner-friendly as PydanticAI.
Very Early beta
Graph support was [introduced](https://ai.pydantic.dev/graph/<https:/github.com/pydantic/pydantic-ai/pull/528>) in v0.0.19 and is in very earlier beta. The API is subject to change. The documentation is incomplete. The implementation is incomplete.
## Installation
`pydantic-graph` is a required dependency of `pydantic-ai`, and an optional dependency of `pydantic-ai-slim`, see [installation instructions](https://ai.pydantic.dev/graph/<../install/#slim-install>) for more information. You can also install it directly:
[pip](https://ai.pydantic.dev/graph/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/graph/<#__tabbed_1_2>)
```
pipinstallpydantic-graph

```

```
uvaddpydantic-graph

```

## Graph Types
`pydantic-graph` made up of a few key components:
### GraphRunContext
`GraphRunContext`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.GraphRunContext>) — The context for the graph run, similar to PydanticAI's `RunContext`[](https://ai.pydantic.dev/graph/<../api/tools/#pydantic_ai.tools.RunContext>). This holds the state of the graph and dependencies and is passed to nodes when they're run.
`GraphRunContext` is generic in the state type of the graph it's used in, `StateT`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/state/#pydantic_graph.state.StateT>).
### End
`End`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.End>) — return value to indicate the graph run should end.
`End` is generic in the graph return type of the graph it's used in, `RunEndT`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.RunEndT>).
### Nodes
Subclasses of `BaseNode`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode>) define nodes for execution in the graph.
Nodes, which are generally `dataclass`[es](https://ai.pydantic.dev/graph/<https:/docs.python.org/3/library/dataclasses.html#dataclasses.dataclass>), generally consist of:
  * fields containing any parameters required/optional when calling the node
  * the business logic to execute the node, in the `run`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode.run>) method
  * return annotations of the `run`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode.run>) method, which are read by `pydantic-graph` to determine the outgoing edges of the node


Nodes are generic in:
  * **state** , which must have the same type as the state of graphs they're included in, `StateT`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/state/#pydantic_graph.state.StateT>) has a default of `None`, so if you're not using state you can omit this generic parameter, see [stateful graphs](https://ai.pydantic.dev/graph/<#stateful-graphs>) for more information
  * **deps** , which must have the same type as the deps of the graph they're included in, `DepsT`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.DepsT>) has a default of `None`, so if you're not using deps you can omit this generic parameter, see [dependency injection](https://ai.pydantic.dev/graph/<#dependency-injection>) for more information
  * **graph return type** — this only applies if the node returns `End`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.End>). `RunEndT`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.RunEndT>) has a default of [Never](https://ai.pydantic.dev/graph/<https:/docs.python.org/3/library/typing.html#typing.Never>) so this generic parameter can be omitted if the node doesn't return `End`, but must be included if it does.


Here's an example of a start or intermediate node in a graph — it can't end the run as it doesn't return `End`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.End>):
intermediate_node.py```
from dataclasses import dataclass
from pydantic_graph import BaseNode, GraphRunContext

@dataclass
class MyNode(BaseNode[MyState]): [](https://ai.pydantic.dev/graph/<#__code_2_annotation_1>)
  foo: int 
MyNode is a dataclass and has a single field foo, an int.
[](https://ai.pydantic.dev/graph/<#__code_2_annotation_2>)
  async def run(
    self,
    ctx: GraphRunContext[MyState], 
The run method takes a GraphRunContext parameter, again parameterized with state MyState.
[](https://ai.pydantic.dev/graph/<#__code_2_annotation_3>)
  ) -> AnotherNode: 
The return type of the run method is AnotherNode (not shown), this is used to determine the outgoing edges of the node.
[](https://ai.pydantic.dev/graph/<#__code_2_annotation_4>)
    ...
    return AnotherNode()

```

We could extend `MyNode` to optionally end the run if `foo` is divisible by 5:
intermediate_or_end_node.py```
from dataclasses import dataclass
from pydantic_graph import BaseNode, End, GraphRunContext

@dataclass
class MyNode(BaseNode[MyState, None, int]): 
We parameterize the node with the return type (int in this case) as well as state. Because generic parameters are positional-only, we have to include None as the second parameter representing deps.
[](https://ai.pydantic.dev/graph/<#__code_3_annotation_1>)
  foo: int
  async def run(
    self,
    ctx: GraphRunContext[MyState],
  ) -> AnotherNode | End[int]: 
The return type of the run method is now a union of AnotherNode and End[int], this allows the node to end the run if foo is divisible by 5.
[](https://ai.pydantic.dev/graph/<#__code_3_annotation_2>)
    if self.foo % 5 == 0:
      return End(self.foo)
    else:
      return AnotherNode()

```

### Graph
`Graph`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph>) — this is the execution graph itself, made up of a set of [node classes](https://ai.pydantic.dev/graph/<#nodes>) (i.e., `BaseNode` subclasses).
`Graph` is generic in:
  * **state** the state type of the graph, `StateT`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/state/#pydantic_graph.state.StateT>)
  * **deps** the deps type of the graph, `DepsT`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.DepsT>)
  * **graph return type** the return type of the graph run, `RunEndT`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.RunEndT>)


Here's an example of a simple graph:
graph_example.py```
from __future__ import annotations
from dataclasses import dataclass
from pydantic_graph import BaseNode, End, Graph, GraphRunContext

@dataclass
class DivisibleBy5(BaseNode[None, None, int]): 
The DivisibleBy5 node is parameterized with None for the state param and None for the deps param as this graph doesn't use state or deps, and int as it can end the run.
[](https://ai.pydantic.dev/graph/<#__code_4_annotation_1>)
  foo: int
  async def run(
    self,
    ctx: GraphRunContext,
  ) -> Increment | End[int]:
    if self.foo % 5 == 0:
      return End(self.foo)
    else:
      return Increment(self.foo)

@dataclass
class Increment(BaseNode): 
The Increment node doesn't return End, so the RunEndT generic parameter is omitted, state can also be omitted as the graph doesn't use state.
[](https://ai.pydantic.dev/graph/<#__code_4_annotation_2>)
  foo: int
  async def run(self, ctx: GraphRunContext) -> DivisibleBy5:
    return DivisibleBy5(self.foo + 1)

fives_graph = Graph(nodes=[DivisibleBy5, Increment]) 
The graph is created with a sequence of nodes.
[](https://ai.pydantic.dev/graph/<#__code_4_annotation_3>)
result, history = fives_graph.run_sync(DivisibleBy5(4)) 
The graph is run synchronously with run_sync[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph.run_sync>) the initial state None and the start node DivisibleBy5(4) are passed as arguments.
[](https://ai.pydantic.dev/graph/<#__code_4_annotation_4>)
print(result)
#> 5
# the full history is quite verbose (see below), so we'll just print the summary
print([item.data_snapshot() for item in history])
#> [DivisibleBy5(foo=4), Increment(foo=4), DivisibleBy5(foo=5), End(data=5)]

```

_(This example is complete, it can be run "as is" with Python 3.10+)_
A [mermaid diagram](https://ai.pydantic.dev/graph/<#mermaid-diagrams>) for this graph can be generated with the following code:
graph_example_diagram.py```
from graph_example import DivisibleBy5, fives_graph
fives_graph.mermaid_code(start_node=DivisibleBy5)

```

```
---
title: fives_graph
---
stateDiagram-v2
 [*] --> DivisibleBy5
 DivisibleBy5 --> Increment
 DivisibleBy5 --> [*]
 Increment --> DivisibleBy5
```

In order to visualize a graph within a `jupyter-notebook`, `IPython.display` needs to be used:
jupyter_display_mermaid.py```
from graph_example import DivisibleBy5, fives_graph
from IPython.display import Image, display
display(Image(fives_graph.mermaid_image(start_node=DivisibleBy5)))

```

## Stateful Graphs
The "state" concept in `pydantic-graph` provides an optional way to access and mutate an object (often a `dataclass` or Pydantic model) as nodes run in a graph. If you think of Graphs as a production line, then your state is the engine being passed along the line and built up by each node as the graph is run.
In the future, we intend to extend `pydantic-graph` to provide state persistence with the state recorded after each node is run, see [#695](https://ai.pydantic.dev/graph/<https:/github.com/pydantic/pydantic-ai/issues/695>).
Here's an example of a graph which represents a vending machine where the user may insert coins and select a product to purchase.
vending_machine.py```
from __future__ import annotations
from dataclasses import dataclass
from rich.prompt import Prompt
from pydantic_graph import BaseNode, End, Graph, GraphRunContext

@dataclass
class MachineState: 
The state of the vending machine is defined as a dataclass with the user's balance and the product they've selected, if any.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_1>)
  user_balance: float = 0.0
  product: str | None = None

@dataclass
class InsertCoin(BaseNode[MachineState]): 
The InsertCoin node, BaseNode[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode>) is parameterized with MachineState as that's the state used in this graph.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_3>)
  async def run(self, ctx: GraphRunContext[MachineState]) -> CoinsInserted: 
The return type of the node's run[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode.run>) method is important as it is used to determine the outgoing edges of the node. This information in turn is used to render mermaid diagrams[](https://ai.pydantic.dev/graph/<#mermaid-diagrams>) and is enforced at runtime to detect misbehavior as soon as possible.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_16>)
    return CoinsInserted(float(Prompt.ask('Insert coins'))) 
The InsertCoin node prompts the user to insert coins. We keep things simple by just entering a monetary amount as a float. Before you start thinking this is a toy too since it's using rich's Prompt.ask[](https://ai.pydantic.dev/graph/<https:/rich.readthedocs.io/en/stable/reference/prompt.html#rich.prompt.PromptBase.ask>) within nodes, see below[](https://ai.pydantic.dev/graph/<#custom-control-flow>) for how control flow can be managed when nodes require external input.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_4>)

@dataclass
class CoinsInserted(BaseNode[MachineState]):
  amount: float 
The CoinsInserted node; again this is a dataclass[](https://ai.pydantic.dev/graph/<https:/docs.python.org/3/library/dataclasses.html#dataclasses.dataclass>), in this case with one field amount, thus nodes calling CoinsInserted must provide an amount.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_5>)
  async def run(
    self, ctx: GraphRunContext[MachineState]
  ) -> SelectProduct | Purchase: 
The return type of CoinsInserted's run[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode.run>) method is a union, meaning multiple outgoing edges are possible.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_17>)
    ctx.state.user_balance += self.amount 
Update the user's balance with the amount inserted.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_6>)
    if ctx.state.product is not None: 
If the user has already selected a product, go to Purchase, otherwise go to SelectProduct.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_7>)
      return Purchase(ctx.state.product)
    else:
      return SelectProduct()

@dataclass
class SelectProduct(BaseNode[MachineState]):
  async def run(self, ctx: GraphRunContext[MachineState]) -> Purchase:
    return Purchase(Prompt.ask('Select product'))

PRODUCT_PRICES = { 
A dictionary of products mapped to prices.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_2>)
  'water': 1.25,
  'soda': 1.50,
  'crisps': 1.75,
  'chocolate': 2.00,
}

@dataclass
class Purchase(BaseNode[MachineState, None, None]): 
Unlike other nodes, Purchase can end the run, so the RunEndT[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.RunEndT>) generic parameter must be set. In this case it's None since the graph run return type is None.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_18>)
  product: str
  async def run(
    self, ctx: GraphRunContext[MachineState]
  ) -> End | InsertCoin | SelectProduct:
    if price := PRODUCT_PRICES.get(self.product): 
In the Purchase node, look up the price of the product if the user entered a valid product.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_8>)
      ctx.state.product = self.product 
If the user did enter a valid product, set the product in the state so we don't revisit SelectProduct.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_9>)
      if ctx.state.user_balance >= price: 
If the balance is enough to purchase the product, adjust the balance to reflect the purchase and return End[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.End>) to end the graph. We're not using the run return type, so we call End with None.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_10>)
        ctx.state.user_balance -= price
        return End(None)
      else:
        diff = price - ctx.state.user_balance
        print(f'Not enough money for {self.product}, need {diff:0.2f} more')
        #> Not enough money for crisps, need 0.75 more
        return InsertCoin() 
If the balance is insufficient, to go InsertCoin to prompt the user to insert more coins.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_11>)
    else:
      print(f'No such product: {self.product}, try again')
      return SelectProduct() 
If the product is invalid, go to SelectProduct to prompt the user to select a product again.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_12>)

vending_machine_graph = Graph( 
The graph is created by passing a list of nodes to Graph[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph>). Order of nodes is not important, but will alter how diagrams[](https://ai.pydantic.dev/graph/<#mermaid-diagrams>) are displayed.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_13>)
  nodes=[InsertCoin, CoinsInserted, SelectProduct, Purchase]
)

async def main():
  state = MachineState() 
Initialize the state. This will be passed to the graph run and mutated as the graph runs.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_14>)
  await vending_machine_graph.run(InsertCoin(), state=state) 
Run the graph with the initial state. Since the graph can be run from any node, we must pass the start node — in this case, InsertCoin. Graph.run[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph.run>) returns a tuple of the return value (None) in this case, and the history[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/state/#pydantic_graph.state.HistoryStep>) of the graph run.
[](https://ai.pydantic.dev/graph/<#__code_7_annotation_15>)
  print(f'purchase successful item={state.product} change={state.user_balance:0.2f}')
  #> purchase successful item=crisps change=0.25

```

_(This example is complete, it can be run "as is" with Python 3.10+ — you'll need to add`asyncio.run(main())` to run `main`)_
A [mermaid diagram](https://ai.pydantic.dev/graph/<#mermaid-diagrams>) for this graph can be generated with the following code:
vending_machine_diagram.py```
from vending_machine import InsertCoin, vending_machine_graph
vending_machine_graph.mermaid_code(start_node=InsertCoin)

```

The diagram generated by the above code is:
```
---
title: vending_machine_graph
---
stateDiagram-v2
 [*] --> InsertCoin
 InsertCoin --> CoinsInserted
 CoinsInserted --> SelectProduct
 CoinsInserted --> Purchase
 SelectProduct --> Purchase
 Purchase --> InsertCoin
 Purchase --> SelectProduct
 Purchase --> [*]
```

See [below](https://ai.pydantic.dev/graph/<#mermaid-diagrams>) for more information on generating diagrams.
## GenAI Example
So far we haven't shown an example of a Graph that actually uses PydanticAI or GenAI at all.
In this example, one agent generates a welcome email to a user and the other agent provides feedback on the email.
This graph has a very simple structure:
```
---
title: feedback_graph
---
stateDiagram-v2
 [*] --> WriteEmail
 WriteEmail --> Feedback
 Feedback --> WriteEmail
 Feedback --> [*]
```

genai_email_feedback.py```
from __future__ import annotations as _annotations
from dataclasses import dataclass, field
from pydantic import BaseModel, EmailStr
from pydantic_ai import Agent
from pydantic_ai.format_as_xml import format_as_xml
from pydantic_ai.messages import ModelMessage
from pydantic_graph import BaseNode, End, Graph, GraphRunContext

@dataclass
class User:
  name: str
  email: EmailStr
  interests: list[str]

@dataclass
class Email:
  subject: str
  body: str

@dataclass
class State:
  user: User
  write_agent_messages: list[ModelMessage] = field(default_factory=list)

email_writer_agent = Agent(
  'google-vertex:gemini-1.5-pro',
  result_type=Email,
  system_prompt='Write a welcome email to our tech blog.',
)

@dataclass
class WriteEmail(BaseNode[State]):
  email_feedback: str | None = None
  async def run(self, ctx: GraphRunContext[State]) -> Feedback:
    if self.email_feedback:
      prompt = (
        f'Rewrite the email for the user:\n'
        f'{format_as_xml(ctx.state.user)}\n'
        f'Feedback: {self.email_feedback}'
      )
    else:
      prompt = (
        f'Write a welcome email for the user:\n'
        f'{format_as_xml(ctx.state.user)}'
      )
    result = await email_writer_agent.run(
      prompt,
      message_history=ctx.state.write_agent_messages,
    )
    ctx.state.write_agent_messages += result.all_messages()
    return Feedback(result.data)

class EmailRequiresWrite(BaseModel):
  feedback: str

class EmailOk(BaseModel):
  pass

feedback_agent = Agent[None, EmailRequiresWrite | EmailOk](
  'openai:gpt-4o',
  result_type=EmailRequiresWrite | EmailOk, # type: ignore
  system_prompt=(
    'Review the email and provide feedback, email must reference the users specific interests.'
  ),
)

@dataclass
class Feedback(BaseNode[State, None, Email]):
  email: Email
  async def run(
    self,
    ctx: GraphRunContext[State],
  ) -> WriteEmail | End[Email]:
    prompt = format_as_xml({'user': ctx.state.user, 'email': self.email})
    result = await feedback_agent.run(prompt)
    if isinstance(result.data, EmailRequiresWrite):
      return WriteEmail(email_feedback=result.data.feedback)
    else:
      return End(self.email)

async def main():
  user = User(
    name='John Doe',
    email='john.joe@example.com',
    interests=['Haskel', 'Lisp', 'Fortran'],
  )
  state = State(user)
  feedback_graph = Graph(nodes=(WriteEmail, Feedback))
  email, _ = await feedback_graph.run(WriteEmail(), state=state)
  print(email)
"""
  Email(
    subject='Welcome to our tech blog!',
    body='Hello John, Welcome to our tech blog! ...',
  )
  """

```

_(This example is complete, it can be run "as is" with Python 3.10+ — you'll need to add`asyncio.run(main())` to run `main`)_
## Custom Control Flow
In many real-world applications, Graphs cannot run uninterrupted from start to finish — they might require external input, or run over an extended period of time such that a single process cannot execute the entire graph run from start to finish without interruption.
In these scenarios the `next`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph.next>) method can be used to run the graph one node at a time.
In this example, an AI asks the user a question, the user provides an answer, the AI evaluates the answer and ends if the user got it right or asks another question if they got it wrong.
`ai_q_and_a_graph.py` — `question_graph` definition
ai_q_and_a_graph.py```
from __future__ import annotations as _annotations
from dataclasses import dataclass, field
from pydantic_graph import BaseNode, End, Graph, GraphRunContext
from pydantic_ai import Agent
from pydantic_ai.format_as_xml import format_as_xml
from pydantic_ai.messages import ModelMessage
ask_agent = Agent('openai:gpt-4o', result_type=str)

@dataclass
class QuestionState:
  question: str | None = None
  ask_agent_messages: list[ModelMessage] = field(default_factory=list)
  evaluate_agent_messages: list[ModelMessage] = field(default_factory=list)

@dataclass
class Ask(BaseNode[QuestionState]):
  async def run(self, ctx: GraphRunContext[QuestionState]) -> Answer:
    result = await ask_agent.run(
      'Ask a simple question with a single correct answer.',
      message_history=ctx.state.ask_agent_messages,
    )
    ctx.state.ask_agent_messages += result.all_messages()
    ctx.state.question = result.data
    return Answer(result.data)

@dataclass
class Answer(BaseNode[QuestionState]):
  question: str
  answer: str | None = None
  async def run(self, ctx: GraphRunContext[QuestionState]) -> Evaluate:
    assert self.answer is not None
    return Evaluate(self.answer)

@dataclass
class EvaluationResult:
  correct: bool
  comment: str

evaluate_agent = Agent(
  'openai:gpt-4o',
  result_type=EvaluationResult,
  system_prompt='Given a question and answer, evaluate if the answer is correct.',
)

@dataclass
class Evaluate(BaseNode[QuestionState]):
  answer: str
  async def run(
    self,
    ctx: GraphRunContext[QuestionState],
  ) -> End[str] | Reprimand:
    assert ctx.state.question is not None
    result = await evaluate_agent.run(
      format_as_xml({'question': ctx.state.question, 'answer': self.answer}),
      message_history=ctx.state.evaluate_agent_messages,
    )
    ctx.state.evaluate_agent_messages += result.all_messages()
    if result.data.correct:
      return End(result.data.comment)
    else:
      return Reprimand(result.data.comment)

@dataclass
class Reprimand(BaseNode[QuestionState]):
  comment: str
  async def run(self, ctx: GraphRunContext[QuestionState]) -> Ask:
    print(f'Comment: {self.comment}')
    ctx.state.question = None
    return Ask()

question_graph = Graph(nodes=(Ask, Answer, Evaluate, Reprimand))

```

_(This example is complete, it can be run "as is" with Python 3.10+)_
ai_q_and_a_run.py```
from rich.prompt import Prompt
from pydantic_graph import End, HistoryStep
from ai_q_and_a_graph import Ask, question_graph, QuestionState, Answer

async def main():
  state = QuestionState() 
Create the state object which will be mutated by next[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph.next>).
[](https://ai.pydantic.dev/graph/<#__code_11_annotation_1>)
  node = Ask() 
The start node is Ask but will be updated by next[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph.next>) as the graph runs.
[](https://ai.pydantic.dev/graph/<#__code_11_annotation_2>)
  history: list[HistoryStep[QuestionState]] = [] 
The history of the graph run is stored in a list of HistoryStep[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/state/#pydantic_graph.state.HistoryStep>) objects. Again next[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph.next>) will update this list in place.
[](https://ai.pydantic.dev/graph/<#__code_11_annotation_3>)
  while True:
    node = await question_graph.next(node, history, state=state) 
Run[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph.next>) the graph one node at a time, updating the state, current node and history as the graph runs.
[](https://ai.pydantic.dev/graph/<#__code_11_annotation_4>)
    if isinstance(node, Answer):
      node.answer = Prompt.ask(node.question) 
If the current node is an Answer node, prompt the user for an answer.
[](https://ai.pydantic.dev/graph/<#__code_11_annotation_5>)
    elif isinstance(node, End): 
Since we're using next[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph.next>) we have to manually check for an End[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.End>) and exit the loop if we get one.
[](https://ai.pydantic.dev/graph/<#__code_11_annotation_6>)
      print(f'Correct answer! {node.data}')
      #> Correct answer! Well done, 1 + 1 = 2
      print([e.data_snapshot() for e in history])
"""
      [
        Ask(),
        Answer(question='What is the capital of France?', answer='Vichy'),
        Evaluate(answer='Vichy'),
        Reprimand(comment='Vichy is no longer the capital of France.'),
        Ask(),
        Answer(question='what is 1 + 1?', answer='2'),
        Evaluate(answer='2'),
      ]
      """
      return
    # otherwise just continue

```

_(This example is complete, it can be run "as is" with Python 3.10+ — you'll need to add`asyncio.run(main())` to run `main`)_
A [mermaid diagram](https://ai.pydantic.dev/graph/<#mermaid-diagrams>) for this graph can be generated with the following code:
ai_q_and_a_diagram.py```
from ai_q_and_a_graph import Ask, question_graph
question_graph.mermaid_code(start_node=Ask)

```

```
---
title: question_graph
---
stateDiagram-v2
 [*] --> Ask
 Ask --> Answer
 Answer --> Evaluate
 Evaluate --> Reprimand
 Evaluate --> [*]
 Reprimand --> Ask
```

You maybe have noticed that although this examples transfers control flow out of the graph run, we're still using [rich's `Prompt.ask`](https://ai.pydantic.dev/graph/<https:/rich.readthedocs.io/en/stable/reference/prompt.html#rich.prompt.PromptBase.ask>) to get user input, with the process hanging while we wait for the user to enter a response. For an example of genuine out-of-process control flow, see the [question graph example](https://ai.pydantic.dev/graph/<../examples/question-graph/>).
## Dependency Injection
As with PydanticAI, `pydantic-graph` supports dependency injection via a generic parameter on `Graph`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph>) and `BaseNode`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode>), and the `GraphRunContext.deps`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.GraphRunContext.deps>) fields.
As an example of dependency injection, let's modify the `DivisibleBy5` example [above](https://ai.pydantic.dev/graph/<#graph>) to use a `ProcessPoolExecutor`[](https://ai.pydantic.dev/graph/<https:/docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor>) to run the compute load in a separate process (this is a contrived example, `ProcessPoolExecutor` wouldn't actually improve performance in this example):
deps_example.py```
from __future__ import annotations
import asyncio
from concurrent.futures import ProcessPoolExecutor
from dataclasses import dataclass
from pydantic_graph import BaseNode, End, Graph, GraphRunContext

@dataclass
class GraphDeps:
  executor: ProcessPoolExecutor

@dataclass
class DivisibleBy5(BaseNode[None, None, int]):
  foo: int
  async def run(
    self,
    ctx: GraphRunContext,
  ) -> Increment | End[int]:
    if self.foo % 5 == 0:
      return End(self.foo)
    else:
      return Increment(self.foo)

@dataclass
class Increment(BaseNode):
  foo: int
  async def run(self, ctx: GraphRunContext) -> DivisibleBy5:
    loop = asyncio.get_running_loop()
    compute_result = await loop.run_in_executor(
      ctx.deps.executor,
      self.compute,
    )
    return DivisibleBy5(compute_result)
  def compute(self) -> int:
    return self.foo + 1

fives_graph = Graph(nodes=[DivisibleBy5, Increment])

async def main():
  with ProcessPoolExecutor() as executor:
    deps = GraphDeps(executor)
    result, history = await fives_graph.run(DivisibleBy5(3), deps=deps)
  print(result)
  #> 5
  # the full history is quite verbose (see below), so we'll just print the summary
  print([item.data_snapshot() for item in history])
"""
  [
    DivisibleBy5(foo=3),
    Increment(foo=3),
    DivisibleBy5(foo=4),
    Increment(foo=4),
    DivisibleBy5(foo=5),
    End(data=5),
  ]
  """

```

_(This example is complete, it can be run "as is" with Python 3.10+ — you'll need to add`asyncio.run(main())` to run `main`)_
## Mermaid Diagrams
Pydantic Graph can generate [mermaid](https://ai.pydantic.dev/graph/<https:/mermaid.js.org/>) `stateDiagram-v2`[](https://ai.pydantic.dev/graph/<https:/mermaid.js.org/syntax/stateDiagram.html>) diagrams for graphs, as shown above.
These diagrams can be generated with:
  * `Graph.mermaid_code`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph.mermaid_code>) to generate the mermaid code for a graph
  * `Graph.mermaid_image`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph.mermaid_image>) to generate an image of the graph using [mermaid.ink](https://ai.pydantic.dev/graph/<https:/mermaid.ink/>)
  * `Graph.mermaid_save`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph.mermaid_save>) to generate an image of the graph using [mermaid.ink](https://ai.pydantic.dev/graph/<https:/mermaid.ink/>) and save it to a file


Beyond the diagrams shown above, you can also customize mermaid diagrams with the following options:
  * `Edge`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.Edge>) allows you to apply a label to an edge
  * `BaseNode.docstring_notes`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode.docstring_notes>) and `BaseNode.get_note`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode.get_note>) allows you to add notes to nodes
  * The `highlighted_nodes`[](https://ai.pydantic.dev/graph/<../api/pydantic_graph/graph/#pydantic_graph.graph.Graph.mermaid_code>) parameter allows you to highlight specific node(s) in the diagram


Putting that together, we can edit the last `ai_q_and_a_graph.py`[](https://ai.pydantic.dev/graph/<#custom-control-flow>) example to:
  * add labels to some edges
  * add a note to the `Ask` node
  * highlight the `Answer` node
  * save the diagram as a `PNG` image to file


ai_q_and_a_graph_extra.py```
...
from typing import Annotated

from pydantic_graph import BaseNode, End, Graph, GraphRunContext, Edge

...
@dataclass
class Ask(BaseNode[QuestionState]):
"""Generate question using GPT-4o."""
  docstring_notes = True
  async def run(
    self, ctx: GraphRunContext[QuestionState]
  ) -> Annotated[Answer, Edge(label='Ask the question')]:
    ...
...
@dataclass
class Evaluate(BaseNode[QuestionState]):
  answer: str
  async def run(
      self,
      ctx: GraphRunContext[QuestionState],
  ) -> Annotated[End[str], Edge(label='success')] | Reprimand:
    ...
...
question_graph.mermaid_save('image.png', highlighted_nodes=[Answer])

```

_(This example is not complete and cannot be run directly)_
Would generate and image that looks like this:
```
---
title: question_graph
---
stateDiagram-v2
 Ask --> Answer: Ask the question
 note right of Ask
  Judge the answer.
  Decide on next step.
 end note
 Answer --> Evaluate
 Evaluate --> Reprimand
 Evaluate --> [*]: success
 Reprimand --> Ask
classDef highlighted fill:#fdff32
class Answer highlighted
```

### Setting Direction of the State Diagram
You can specify the direction of the state diagram using one of the following values:
  * `'TB'`: Top to bottom, the diagram flows vertically from top to bottom.
  * `'LR'`: Left to right, the diagram flows horizontally from left to right.
  * `'RL'`: Right to left, the diagram flows horizontally from right to left.
  * `'BT'`: Bottom to top, the diagram flows vertically from bottom to top.


Here is an example of how to do this using 'Left to Right' (LR) instead of the default 'Top to Bottom' (TB) 
vending_machine_diagram.py```
from vending_machine import InsertCoin, vending_machine_graph
vending_machine_graph.mermaid_code(start_node=InsertCoin, direction='LR')

```

```
---
title: vending_machine_graph
---
stateDiagram-v2
 direction LR
 [*] --> InsertCoin
 InsertCoin --> CoinsInserted
 CoinsInserted --> SelectProduct
 CoinsInserted --> Purchase
 SelectProduct --> Purchase
 Purchase --> InsertCoin
 Purchase --> SelectProduct
 Purchase --> [*]
```

© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/help.md
================
[ Skip to content ](https://ai.pydantic.dev/help/<#getting-help>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/help/<..> "PydanticAI")
PydanticAI 
Getting Help 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/help/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/help/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/help/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/help/<..>)
  * [ Installation  ](https://ai.pydantic.dev/help/<../install/>)
  * Getting Help  [ Getting Help  ](https://ai.pydantic.dev/help/<./>) Table of contents 
    * [ Slack  ](https://ai.pydantic.dev/help/<#slack>)
    * [ GitHub Issues  ](https://ai.pydantic.dev/help/<#github-issues>)
  * [ Contributing  ](https://ai.pydantic.dev/help/<../contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/help/<../troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/help/<../agents/>)
    * [ Models  ](https://ai.pydantic.dev/help/<../models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/help/<../dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/help/<../tools/>)
    * [ Results  ](https://ai.pydantic.dev/help/<../results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/help/<../message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/help/<../testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/help/<../logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/help/<../multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/help/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/help/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/help/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/help/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/help/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/help/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/help/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/help/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/help/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/help/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/help/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/help/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/help/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/help/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/help/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/help/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/help/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/help/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/help/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/help/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/help/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/help/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/help/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/help/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/help/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/help/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/help/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/help/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/help/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/help/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/help/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/help/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/help/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/help/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/help/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Slack  ](https://ai.pydantic.dev/help/<#slack>)
  * [ GitHub Issues  ](https://ai.pydantic.dev/help/<#github-issues>)


# Getting Help
If you need help getting started with PydanticAI or with advanced usage, the following sources may be useful.
##  Slack
Join the `#pydantic-ai` channel in the [Pydantic Slack](https://ai.pydantic.dev/help/<https:/join.slack.com/t/pydanticlogfire/shared_invite/zt-2war8jrjq-w_nWG6ZX7Zm~gnzY7cXSog>) to ask questions, get help, and chat about PydanticAI. There's also channels for Pydantic, Logfire, and FastUI.
If you're on a [Logfire](https://ai.pydantic.dev/help/<https:/pydantic.dev/logfire>) Pro plan, you can also get a dedicated private slack collab channel with us.
##  GitHub Issues
The [PydanticAI GitHub Issues](https://ai.pydantic.dev/help/<https:/github.com/pydantic/pydantic-ai/issues>) are a great place to ask questions and give us feedback.
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/index.md
================
[Crawl4AI Documentation (v0.4.3bx)](https://docs.crawl4ai.com/<https:/docs.crawl4ai.com/>)
  * [ Home ](https://docs.crawl4ai.com/<.>)
  * [ Quick Start ](https://docs.crawl4ai.com/<core/quickstart/>)
  * [ Search ](https://docs.crawl4ai.com/<#>)


  * Home
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/<core/installation/>)
    * [Docker Deployment](https://docs.crawl4ai.com/<core/docker-deploymeny/>)
  * [Quick Start](https://docs.crawl4ai.com/<core/quickstart/>)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/<blog/>)
    * [Changelog](https://docs.crawl4ai.com/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)
  * Core
    * [Simple Crawling](https://docs.crawl4ai.com/<core/simple-crawling/>)
    * [Crawler Result](https://docs.crawl4ai.com/<core/crawler-result/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/<core/browser-crawler-config/>)
    * [Markdown Generation](https://docs.crawl4ai.com/<core/markdown-generation/>)
    * [Fit Markdown](https://docs.crawl4ai.com/<core/fit-markdown/>)
    * [Page Interaction](https://docs.crawl4ai.com/<core/page-interaction/>)
    * [Content Selection](https://docs.crawl4ai.com/<core/content-selection/>)
    * [Cache Modes](https://docs.crawl4ai.com/<core/cache-modes/>)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/<core/local-files/>)
    * [Link & Media](https://docs.crawl4ai.com/<core/link-media/>)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/<advanced/advanced-features/>)
    * [File Downloading](https://docs.crawl4ai.com/<advanced/file-downloading/>)
    * [Lazy Loading](https://docs.crawl4ai.com/<advanced/lazy-loading/>)
    * [Hooks & Auth](https://docs.crawl4ai.com/<advanced/hooks-auth/>)
    * [Proxy & Security](https://docs.crawl4ai.com/<advanced/proxy-security/>)
    * [Session Management](https://docs.crawl4ai.com/<advanced/session-management/>)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/<advanced/multi-url-crawling/>)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/<advanced/crawl-dispatcher/>)
    * [Identity Based Crawling](https://docs.crawl4ai.com/<advanced/identity-based-crawling/>)
    * [SSL Certificate](https://docs.crawl4ai.com/<advanced/ssl-certificate/>)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/<extraction/no-llm-strategies/>)
    * [LLM Strategies](https://docs.crawl4ai.com/<extraction/llm-strategies/>)
    * [Clustering Strategies](https://docs.crawl4ai.com/<extraction/clustring-strategies/>)
    * [Chunking](https://docs.crawl4ai.com/<extraction/chunking/>)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/<api/async-webcrawler/>)
    * [arun()](https://docs.crawl4ai.com/<api/arun/>)
    * [arun_many()](https://docs.crawl4ai.com/<api/arun_many/>)
    * [Browser & Crawler Config](https://docs.crawl4ai.com/<api/parameters/>)
    * [CrawlResult](https://docs.crawl4ai.com/<api/crawl-result/>)
    * [Strategies](https://docs.crawl4ai.com/<api/strategies/>)


  * [🚀🤖 Crawl4AI: Open-Source LLM-Friendly Web Crawler & Scraper](https://docs.crawl4ai.com/<#crawl4ai-open-source-llm-friendly-web-crawler-scraper>)
  * [Quick Start](https://docs.crawl4ai.com/<#quick-start>)
  * [What Does Crawl4AI Do?](https://docs.crawl4ai.com/<#what-does-crawl4ai-do>)
  * [Documentation Structure](https://docs.crawl4ai.com/<#documentation-structure>)
  * [How You Can Support](https://docs.crawl4ai.com/<#how-you-can-support>)
  * [Quick Links](https://docs.crawl4ai.com/<#quick-links>)


# 🚀🤖 Crawl4AI: Open-Source LLM-Friendly Web Crawler & Scraper
[ ![unclecode%2Fcrawl4ai | Trendshift](https://trendshift.io/api/badge/repositories/11716) ](https://docs.crawl4ai.com/<https:/trendshift.io/repositories/11716>)
[ ![GitHub Stars](https://img.shields.io/github/stars/unclecode/crawl4ai?style=social) ](https://docs.crawl4ai.com/<https:/github.com/unclecode/crawl4ai/stargazers>) [ ![GitHub Forks](https://img.shields.io/github/forks/unclecode/crawl4ai?style=social) ](https://docs.crawl4ai.com/<https:/github.com/unclecode/crawl4ai/network/members>) [ ![PyPI version](https://badge.fury.io/py/crawl4ai.svg) ](https://docs.crawl4ai.com/<https:/badge.fury.io/py/crawl4ai>)
[ ![Python Version](https://img.shields.io/pypi/pyversions/crawl4ai) ](https://docs.crawl4ai.com/<https:/pypi.org/project/crawl4ai/>) [ ![Downloads](https://static.pepy.tech/badge/crawl4ai/month) ](https://docs.crawl4ai.com/<https:/pepy.tech/project/crawl4ai>) [ ![License](https://img.shields.io/github/license/unclecode/crawl4ai) ](https://docs.crawl4ai.com/<https:/github.com/unclecode/crawl4ai/blob/main/LICENSE>)
Crawl4AI is the #1 trending GitHub repository, actively maintained by a vibrant community. It delivers blazing-fast, AI-ready web crawling tailored for large language models, AI agents, and data pipelines. Fully open source, flexible, and built for real-time performance, **Crawl4AI** empowers developers with unmatched speed, precision, and deployment ease.
> **Note** : If you're looking for the old documentation, you can access it [here](https://docs.crawl4ai.com/<https:/old.docs.crawl4ai.com>).
## Quick Start
Here's a quick example to show you how easy it is to use Crawl4AI with its asynchronous capabilities:
```
import asyncio
from crawl4ai import AsyncWebCrawler
async def main():
  # Create an instance of AsyncWebCrawler
  async with AsyncWebCrawler() as crawler:
    # Run the crawler on a URL
    result = await crawler.arun(url="https://crawl4ai.com")
    # Print the extracted content
    print(result.markdown)
# Run the async main function
asyncio.run(main())

```

## What Does Crawl4AI Do?
Crawl4AI is a feature-rich crawler and scraper that aims to:
1. **Generate Clean Markdown** : Perfect for RAG pipelines or direct ingestion into LLMs. 2. **Structured Extraction** : Parse repeated patterns with CSS, XPath, or LLM-based extraction. 3. **Advanced Browser Control** : Hooks, proxies, stealth modes, session re-use—fine-grained control. 4. **High Performance** : Parallel crawling, chunk-based extraction, real-time use cases. 5. **Open Source** : No forced API keys, no paywalls—everyone can access their data. 
**Core Philosophies** : - **Democratize Data** : Free to use, transparent, and highly configurable. - **LLM Friendly** : Minimally processed, well-structured text, images, and metadata, so AI models can easily consume it.
## Documentation Structure
To help you get started, we’ve organized our docs into clear sections:
  * **Setup & Installation** Basic instructions to install Crawl4AI via pip or Docker. 
  * **Quick Start** A hands-on introduction showing how to do your first crawl, generate Markdown, and do a simple extraction. 
  * **Core** Deeper guides on single-page crawling, advanced browser/crawler parameters, content filtering, and caching. 
  * **Advanced** Explore link & media handling, lazy loading, hooking & authentication, proxies, session management, and more. 
  * **Extraction** Detailed references for no-LLM (CSS, XPath) vs. LLM-based strategies, chunking, and clustering approaches. 
  * **API Reference** Find the technical specifics of each class and method, including `AsyncWebCrawler`, `arun()`, and `CrawlResult`.


Throughout these sections, you’ll find code samples you can **copy-paste** into your environment. If something is missing or unclear, raise an issue or PR.
## How You Can Support
  * **Star & Fork**: If you find Crawl4AI helpful, star the repo on GitHub or fork it to add your own features. 
  * **File Issues** : Encounter a bug or missing feature? Let us know by filing an issue, so we can improve. 
  * **Pull Requests** : Whether it’s a small fix, a big feature, or better docs—contributions are always welcome. 
  * **Join Discord** : Come chat about web scraping, crawling tips, or AI workflows with the community. 
  * **Spread the Word** : Mention Crawl4AI in your blog posts, talks, or on social media. 


**Our mission** : to empower everyone—students, researchers, entrepreneurs, data scientists—to access, parse, and shape the world’s data with speed, cost-efficiency, and creative freedom.
## Quick Links
  * **[GitHub Repo](https://docs.crawl4ai.com/<https:/github.com/unclecode/crawl4ai>)**
  * **[Installation Guide](https://docs.crawl4ai.com/<core/installation/>)**
  * **[Quick Start](https://docs.crawl4ai.com/<core/quickstart/>)**
  * **[API Reference](https://docs.crawl4ai.com/<api/async-webcrawler/>)**
  * **[Changelog](https://docs.crawl4ai.com/<https:/github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md>)**


Thank you for joining me on this journey. Let’s keep building an **open, democratic** approach to data extraction and AI together.
Happy Crawling! — _Unclecode, Founder & Maintainer of Crawl4AI_
Site built with [MkDocs](https://docs.crawl4ai.com/<http:/www.mkdocs.org>) and [Terminal for MkDocs](https://docs.crawl4ai.com/<https:/github.com/ntno/mkdocs-terminal>). 
##### Search
xClose
Type to start searching

================
File: crawled_docs/install.md
================
[ Skip to content ](https://ai.pydantic.dev/install/<#installation>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/install/<..> "PydanticAI")
PydanticAI 
Installation 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/install/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/install/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/install/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/install/<..>)
  * Installation  [ Installation  ](https://ai.pydantic.dev/install/<./>) Table of contents 
    * [ Use with Pydantic Logfire  ](https://ai.pydantic.dev/install/<#use-with-pydantic-logfire>)
    * [ Running Examples  ](https://ai.pydantic.dev/install/<#running-examples>)
    * [ Slim Install  ](https://ai.pydantic.dev/install/<#slim-install>)
  * [ Getting Help  ](https://ai.pydantic.dev/install/<../help/>)
  * [ Contributing  ](https://ai.pydantic.dev/install/<../contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/install/<../troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/install/<../agents/>)
    * [ Models  ](https://ai.pydantic.dev/install/<../models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/install/<../dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/install/<../tools/>)
    * [ Results  ](https://ai.pydantic.dev/install/<../results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/install/<../message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/install/<../testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/install/<../logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/install/<../multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/install/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/install/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/install/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/install/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/install/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/install/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/install/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/install/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/install/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/install/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/install/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/install/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/install/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/install/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/install/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/install/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/install/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/install/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/install/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/install/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/install/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/install/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/install/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/install/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/install/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/install/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/install/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/install/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/install/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/install/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/install/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/install/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/install/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/install/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/install/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Use with Pydantic Logfire  ](https://ai.pydantic.dev/install/<#use-with-pydantic-logfire>)
  * [ Running Examples  ](https://ai.pydantic.dev/install/<#running-examples>)
  * [ Slim Install  ](https://ai.pydantic.dev/install/<#slim-install>)


# Installation
PydanticAI is available on PyPI as `pydantic-ai`[](https://ai.pydantic.dev/install/<https:/pypi.org/project/pydantic-ai/>) so installation is as simple as:
[pip](https://ai.pydantic.dev/install/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/install/<#__tabbed_1_2>)
```
pipinstallpydantic-ai

```

```
uvaddpydantic-ai

```

(Requires Python 3.9+)
This installs the `pydantic_ai` package, core dependencies, and libraries required to use all the models included in PydanticAI. If you want to use a specific model, you can install the ["slim"](https://ai.pydantic.dev/install/<#slim-install>) version of PydanticAI.
## Use with Pydantic Logfire
PydanticAI has an excellent (but completely optional) integration with [Pydantic Logfire](https://ai.pydantic.dev/install/<https:/pydantic.dev/logfire>) to help you view and understand agent runs.
To use Logfire with PydanticAI, install `pydantic-ai` or `pydantic-ai-slim` with the `logfire` optional group:
[pip](https://ai.pydantic.dev/install/<#__tabbed_2_1>)[uv](https://ai.pydantic.dev/install/<#__tabbed_2_2>)
```
pipinstall'pydantic-ai[logfire]'

```

```
uvadd'pydantic-ai[logfire]'

```

From there, follow the [Logfire setup docs](https://ai.pydantic.dev/install/<../logfire/#using-logfire>) to configure Logfire.
## Running Examples
We distribute the `pydantic_ai_examples`[](https://ai.pydantic.dev/install/<https:/github.com/pydantic/pydantic-ai/tree/main/pydantic_ai_examples>) directory as a separate PyPI package (`pydantic-ai-examples`[](https://ai.pydantic.dev/install/<https:/pypi.org/project/pydantic-ai-examples/>)) to make examples extremely easy to customize and run.
To install examples, use the `examples` optional group:
[pip](https://ai.pydantic.dev/install/<#__tabbed_3_1>)[uv](https://ai.pydantic.dev/install/<#__tabbed_3_2>)
```
pipinstall'pydantic-ai[examples]'

```

```
uvadd'pydantic-ai[examples]'

```

To run the examples, follow instructions in the [examples docs](https://ai.pydantic.dev/install/<../examples/>).
## Slim Install
If you know which model you're going to use and want to avoid installing superfluous packages, you can use the `pydantic-ai-slim`[](https://ai.pydantic.dev/install/<https:/pypi.org/project/pydantic-ai-slim/>) package. For example, if you're using just `OpenAIModel`[](https://ai.pydantic.dev/install/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel>), you would run:
[pip](https://ai.pydantic.dev/install/<#__tabbed_4_1>)[uv](https://ai.pydantic.dev/install/<#__tabbed_4_2>)
```
pipinstall'pydantic-ai-slim[openai]'

```

```
uvadd'pydantic-ai-slim[openai]'

```

`pydantic-ai-slim` has the following optional groups:
  * `logfire` — installs `logfire`[](https://ai.pydantic.dev/install/<../logfire/>) [PyPI ↗](https://ai.pydantic.dev/install/<https:/pypi.org/project/logfire>)
  * `graph` - installs `pydantic-graph`[](https://ai.pydantic.dev/install/<../graph/>) [PyPI ↗](https://ai.pydantic.dev/install/<https:/pypi.org/project/pydantic-graph>)
  * `openai` — installs `openai` [PyPI ↗](https://ai.pydantic.dev/install/<https:/pypi.org/project/openai>)
  * `vertexai` — installs `google-auth` [PyPI ↗](https://ai.pydantic.dev/install/<https:/pypi.org/project/google-auth>) and `requests` [PyPI ↗](https://ai.pydantic.dev/install/<https:/pypi.org/project/requests>)
  * `anthropic` — installs `anthropic` [PyPI ↗](https://ai.pydantic.dev/install/<https:/pypi.org/project/anthropic>)
  * `groq` — installs `groq` [PyPI ↗](https://ai.pydantic.dev/install/<https:/pypi.org/project/groq>)
  * `mistral` — installs `mistralai` [PyPI ↗](https://ai.pydantic.dev/install/<https:/pypi.org/project/mistralai>)
  * `cohere` - installs `cohere` [PyPI ↗](https://ai.pydantic.dev/install/<https:/pypi.org/project/cohere>)


See the [models](https://ai.pydantic.dev/install/<../models/>) documentation for information on which optional dependencies are required for each model.
You can also install dependencies for multiple models and use cases, for example:
[pip](https://ai.pydantic.dev/install/<#__tabbed_5_1>)[uv](https://ai.pydantic.dev/install/<#__tabbed_5_2>)
```
pipinstall'pydantic-ai-slim[openai,vertexai,logfire]'

```

```
uvadd'pydantic-ai-slim[openai,vertexai,logfire]'

```

© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/logfire.md
================
[ Skip to content ](https://ai.pydantic.dev/logfire/<#debugging-and-monitoring>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/logfire/<..> "PydanticAI")
PydanticAI 
Debugging and Monitoring 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/logfire/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/logfire/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/logfire/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/logfire/<..>)
  * [ Installation  ](https://ai.pydantic.dev/logfire/<../install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/logfire/<../help/>)
  * [ Contributing  ](https://ai.pydantic.dev/logfire/<../contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/logfire/<../troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/logfire/<../agents/>)
    * [ Models  ](https://ai.pydantic.dev/logfire/<../models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/logfire/<../dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/logfire/<../tools/>)
    * [ Results  ](https://ai.pydantic.dev/logfire/<../results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/logfire/<../message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/logfire/<../testing-evals/>)
    * Debugging and Monitoring  [ Debugging and Monitoring  ](https://ai.pydantic.dev/logfire/<./>) Table of contents 
      * [ Pydantic Logfire  ](https://ai.pydantic.dev/logfire/<#pydantic-logfire>)
      * [ Using Logfire  ](https://ai.pydantic.dev/logfire/<#using-logfire>)
        * [ Debugging  ](https://ai.pydantic.dev/logfire/<#debugging>)
        * [ Monitoring Performance  ](https://ai.pydantic.dev/logfire/<#monitoring-performance>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/logfire/<../multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/logfire/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/logfire/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/logfire/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/logfire/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/logfire/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/logfire/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/logfire/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/logfire/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/logfire/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/logfire/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/logfire/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/logfire/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/logfire/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/logfire/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/logfire/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/logfire/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/logfire/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/logfire/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/logfire/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/logfire/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/logfire/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/logfire/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/logfire/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/logfire/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/logfire/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/logfire/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/logfire/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/logfire/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/logfire/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/logfire/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/logfire/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/logfire/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/logfire/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/logfire/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/logfire/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Pydantic Logfire  ](https://ai.pydantic.dev/logfire/<#pydantic-logfire>)
  * [ Using Logfire  ](https://ai.pydantic.dev/logfire/<#using-logfire>)
    * [ Debugging  ](https://ai.pydantic.dev/logfire/<#debugging>)
    * [ Monitoring Performance  ](https://ai.pydantic.dev/logfire/<#monitoring-performance>)


  1. [ Introduction  ](https://ai.pydantic.dev/logfire/<..>)
  2. [ Documentation  ](https://ai.pydantic.dev/logfire/<../agents/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/logfire/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/logfire/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Debugging and Monitoring
Applications that use LLMs have some challenges that are well known and understood: LLMs are **slow** , **unreliable** and **expensive**.
These applications also have some challenges that most developers have encountered much less often: LLMs are **fickle** and **non-deterministic**. Subtle changes in a prompt can completely change a model's performance, and there's no `EXPLAIN` query you can run to understand why.
Warning
From a software engineers point of view, you can think of LLMs as the worst database you've ever heard of, but worse.
If LLMs weren't so bloody useful, we'd never touch them.
To build successful applications with LLMs, we need new tools to understand both model performance, and the behavior of applications that rely on them.
LLM Observability tools that just let you understand how your model is performing are useless: making API calls to an LLM is easy, it's building that into an application that's hard.
## Pydantic Logfire
[Pydantic Logfire](https://ai.pydantic.dev/logfire/<https:/pydantic.dev/logfire>) is an observability platform developed by the team who created and maintain Pydantic and PydanticAI. Logfire aims to let you understand your entire application: Gen AI, classic predictive AI, HTTP traffic, database queries and everything else a modern application needs.
Pydantic Logfire is a commercial product
Logfire is a commercially supported, hosted platform with an extremely generous and perpetual [free tier](https://ai.pydantic.dev/logfire/<https:/pydantic.dev/pricing/>). You can sign up and start using Logfire in a couple of minutes.
PydanticAI has built-in (but optional) support for Logfire via the `logfire-api`[](https://ai.pydantic.dev/logfire/<https:/github.com/pydantic/logfire/tree/main/logfire-api>) no-op package.
That means if the `logfire` package is installed and configured, detailed information about agent runs is sent to Logfire. But if the `logfire` package is not installed, there's virtually no overhead and nothing is sent.
Here's an example showing details of running the [Weather Agent](https://ai.pydantic.dev/logfire/<../examples/weather-agent/>) in Logfire:
[![Weather Agent Logfire](https://ai.pydantic.dev/img/logfire-weather-agent.png)](https://ai.pydantic.dev/logfire/<../img/logfire-weather-agent.png>)
## Using Logfire
To use logfire, you'll need a logfire [account](https://ai.pydantic.dev/logfire/<https:/logfire.pydantic.dev>), and logfire installed:
[pip](https://ai.pydantic.dev/logfire/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/logfire/<#__tabbed_1_2>)
```
pipinstall'pydantic-ai[logfire]'

```

```
uvadd'pydantic-ai[logfire]'

```

Then authenticate your local environment with logfire:
[pip](https://ai.pydantic.dev/logfire/<#__tabbed_2_1>)[uv](https://ai.pydantic.dev/logfire/<#__tabbed_2_2>)
```
logfireauth

```

```
uvrunlogfireauth

```

And configure a project to send data to:
[pip](https://ai.pydantic.dev/logfire/<#__tabbed_3_1>)[uv](https://ai.pydantic.dev/logfire/<#__tabbed_3_2>)
```
logfireprojectsnew

```

```
uvrunlogfireprojectsnew

```

(Or use an existing project with `logfire projects use`)
The last step is to add logfire to your code:
adding_logfire.py```
import logfire
logfire.configure()

```

The [logfire documentation](https://ai.pydantic.dev/logfire/<https:/logfire.pydantic.dev/docs/>) has more details on how to use logfire, including how to instrument other libraries like Pydantic, HTTPX and FastAPI.
Since Logfire is build on [OpenTelemetry](https://ai.pydantic.dev/logfire/<https:/opentelemetry.io/>), you can use the Logfire Python SDK to send data to any OpenTelemetry collector.
Once you have logfire set up, there are two primary ways it can help you understand your application:
  * **Debugging** — Using the live view to see what's happening in your application in real-time.
  * **Monitoring** — Using SQL and dashboards to observe the behavior of your application, Logfire is effectively a SQL database that stores information about how your application is running.


### Debugging
To demonstrate how Logfire can let you visualise the flow of a PydanticAI run, here's the view you get from Logfire while running the [chat app examples](https://ai.pydantic.dev/logfire/<../examples/chat-app/>):
### Monitoring Performance
We can also query data with SQL in Logfire to monitor the performance of an application. Here's a real world example of using Logfire to monitor PydanticAI runs inside Logfire itself:
[![Logfire monitoring PydanticAI](https://ai.pydantic.dev/img/logfire-monitoring-pydanticai.png)](https://ai.pydantic.dev/logfire/<../img/logfire-monitoring-pydanticai.png>)
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/message-history.md
================
[ Skip to content ](https://ai.pydantic.dev/message-history/<#messages-and-chat-history>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/message-history/<..> "PydanticAI")
PydanticAI 
Messages and chat history 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/message-history/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/message-history/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/message-history/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/message-history/<..>)
  * [ Installation  ](https://ai.pydantic.dev/message-history/<../install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/message-history/<../help/>)
  * [ Contributing  ](https://ai.pydantic.dev/message-history/<../contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/message-history/<../troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/message-history/<../agents/>)
    * [ Models  ](https://ai.pydantic.dev/message-history/<../models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/message-history/<../dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/message-history/<../tools/>)
    * [ Results  ](https://ai.pydantic.dev/message-history/<../results/>)
    * Messages and chat history  [ Messages and chat history  ](https://ai.pydantic.dev/message-history/<./>) Table of contents 
      * [ Accessing Messages from Results  ](https://ai.pydantic.dev/message-history/<#accessing-messages-from-results>)
      * [ Using Messages as Input for Further Agent Runs  ](https://ai.pydantic.dev/message-history/<#using-messages-as-input-for-further-agent-runs>)
      * [ Other ways of using messages  ](https://ai.pydantic.dev/message-history/<#other-ways-of-using-messages>)
      * [ Examples  ](https://ai.pydantic.dev/message-history/<#examples>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/message-history/<../testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/message-history/<../logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/message-history/<../multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/message-history/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/message-history/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/message-history/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/message-history/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/message-history/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/message-history/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/message-history/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/message-history/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/message-history/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/message-history/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/message-history/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/message-history/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/message-history/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/message-history/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/message-history/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/message-history/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/message-history/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/message-history/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/message-history/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/message-history/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/message-history/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/message-history/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/message-history/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/message-history/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/message-history/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/message-history/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/message-history/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/message-history/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/message-history/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/message-history/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/message-history/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/message-history/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/message-history/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/message-history/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/message-history/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Accessing Messages from Results  ](https://ai.pydantic.dev/message-history/<#accessing-messages-from-results>)
  * [ Using Messages as Input for Further Agent Runs  ](https://ai.pydantic.dev/message-history/<#using-messages-as-input-for-further-agent-runs>)
  * [ Other ways of using messages  ](https://ai.pydantic.dev/message-history/<#other-ways-of-using-messages>)
  * [ Examples  ](https://ai.pydantic.dev/message-history/<#examples>)


  1. [ Introduction  ](https://ai.pydantic.dev/message-history/<..>)
  2. [ Documentation  ](https://ai.pydantic.dev/message-history/<../agents/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/message-history/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/message-history/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Messages and chat history
PydanticAI provides access to messages exchanged during an agent run. These messages can be used both to continue a coherent conversation, and to understand how an agent performed.
### Accessing Messages from Results
After running an agent, you can access the messages exchanged during that run from the `result` object.
Both `RunResult`[](https://ai.pydantic.dev/message-history/<../api/result/#pydantic_ai.result.RunResult>) (returned by `Agent.run`[](https://ai.pydantic.dev/message-history/<../api/agent/#pydantic_ai.agent.Agent.run>), `Agent.run_sync`[](https://ai.pydantic.dev/message-history/<../api/agent/#pydantic_ai.agent.Agent.run_sync>)) and `StreamedRunResult`[](https://ai.pydantic.dev/message-history/<../api/result/#pydantic_ai.result.StreamedRunResult>) (returned by `Agent.run_stream`[](https://ai.pydantic.dev/message-history/<../api/agent/#pydantic_ai.agent.Agent.run_stream>)) have the following methods:
  * `all_messages()`[](https://ai.pydantic.dev/message-history/<../api/result/#pydantic_ai.result.RunResult.all_messages>): returns all messages, including messages from prior runs. There's also a variant that returns JSON bytes, `all_messages_json()`[](https://ai.pydantic.dev/message-history/<../api/result/#pydantic_ai.result.RunResult.all_messages_json>).
  * `new_messages()`[](https://ai.pydantic.dev/message-history/<../api/result/#pydantic_ai.result.RunResult.new_messages>): returns only the messages from the current run. There's also a variant that returns JSON bytes, `new_messages_json()`[](https://ai.pydantic.dev/message-history/<../api/result/#pydantic_ai.result.RunResult.new_messages_json>).


StreamedRunResult and complete messages
On `StreamedRunResult`[](https://ai.pydantic.dev/message-history/<../api/result/#pydantic_ai.result.StreamedRunResult>), the messages returned from these methods will only include the final result message once the stream has finished.
E.g. you've awaited one of the following coroutines:
  * `StreamedRunResult.stream()`[](https://ai.pydantic.dev/message-history/<../api/result/#pydantic_ai.result.StreamedRunResult.stream>)
  * `StreamedRunResult.stream_text()`[](https://ai.pydantic.dev/message-history/<../api/result/#pydantic_ai.result.StreamedRunResult.stream_text>)
  * `StreamedRunResult.stream_structured()`[](https://ai.pydantic.dev/message-history/<../api/result/#pydantic_ai.result.StreamedRunResult.stream_structured>)
  * `StreamedRunResult.get_data()`[](https://ai.pydantic.dev/message-history/<../api/result/#pydantic_ai.result.StreamedRunResult.get_data>)


**Note:** The final result message will NOT be added to result messages if you use `.stream_text(delta=True)`[](https://ai.pydantic.dev/message-history/<../api/result/#pydantic_ai.result.StreamedRunResult.stream_text>) since in this case the result content is never built as one string.
Example of accessing methods on a `RunResult`[](https://ai.pydantic.dev/message-history/<../api/result/#pydantic_ai.result.RunResult>) :
run_result_messages.py```
from pydantic_ai import Agent
agent = Agent('openai:gpt-4o', system_prompt='Be a helpful assistant.')
result = agent.run_sync('Tell me a joke.')
print(result.data)
#> Did you hear about the toothpaste scandal? They called it Colgate.
# all messages from the run
print(result.all_messages())
"""
[
  ModelRequest(
    parts=[
      SystemPromptPart(
        content='Be a helpful assistant.',
        dynamic_ref=None,
        part_kind='system-prompt',
      ),
      UserPromptPart(
        content='Tell me a joke.',
        timestamp=datetime.datetime(...),
        part_kind='user-prompt',
      ),
    ],
    kind='request',
  ),
  ModelResponse(
    parts=[
      TextPart(
        content='Did you hear about the toothpaste scandal? They called it Colgate.',
        part_kind='text',
      )
    ],
    model_name='function:model_logic',
    timestamp=datetime.datetime(...),
    kind='response',
  ),
]
"""

```

_(This example is complete, it can be run "as is")_
Example of accessing methods on a `StreamedRunResult`[](https://ai.pydantic.dev/message-history/<../api/result/#pydantic_ai.result.StreamedRunResult>) :
streamed_run_result_messages.py```
from pydantic_ai import Agent
agent = Agent('openai:gpt-4o', system_prompt='Be a helpful assistant.')

async def main():
  async with agent.run_stream('Tell me a joke.') as result:
    # incomplete messages before the stream finishes
    print(result.all_messages())
"""
    [
      ModelRequest(
        parts=[
          SystemPromptPart(
            content='Be a helpful assistant.',
            dynamic_ref=None,
            part_kind='system-prompt',
          ),
          UserPromptPart(
            content='Tell me a joke.',
            timestamp=datetime.datetime(...),
            part_kind='user-prompt',
          ),
        ],
        kind='request',
      )
    ]
    """
    async for text in result.stream_text():
      print(text)
      #> Did you hear
      #> Did you hear about the toothpaste
      #> Did you hear about the toothpaste scandal? They called
      #> Did you hear about the toothpaste scandal? They called it Colgate.
    # complete messages once the stream finishes
    print(result.all_messages())
"""
    [
      ModelRequest(
        parts=[
          SystemPromptPart(
            content='Be a helpful assistant.',
            dynamic_ref=None,
            part_kind='system-prompt',
          ),
          UserPromptPart(
            content='Tell me a joke.',
            timestamp=datetime.datetime(...),
            part_kind='user-prompt',
          ),
        ],
        kind='request',
      ),
      ModelResponse(
        parts=[
          TextPart(
            content='Did you hear about the toothpaste scandal? They called it Colgate.',
            part_kind='text',
          )
        ],
        model_name='function:stream_model_logic',
        timestamp=datetime.datetime(...),
        kind='response',
      ),
    ]
    """

```

_(This example is complete, it can be run "as is" — you'll need to add`asyncio.run(main())` to run `main`)_
### Using Messages as Input for Further Agent Runs
The primary use of message histories in PydanticAI is to maintain context across multiple agent runs.
To use existing messages in a run, pass them to the `message_history` parameter of `Agent.run`[](https://ai.pydantic.dev/message-history/<../api/agent/#pydantic_ai.agent.Agent.run>), `Agent.run_sync`[](https://ai.pydantic.dev/message-history/<../api/agent/#pydantic_ai.agent.Agent.run_sync>) or `Agent.run_stream`[](https://ai.pydantic.dev/message-history/<../api/agent/#pydantic_ai.agent.Agent.run_stream>).
If `message_history` is set and not empty, a new system prompt is not generated — we assume the existing message history includes a system prompt.
Reusing messages in a conversation```
from pydantic_ai import Agent
agent = Agent('openai:gpt-4o', system_prompt='Be a helpful assistant.')
result1 = agent.run_sync('Tell me a joke.')
print(result1.data)
#> Did you hear about the toothpaste scandal? They called it Colgate.
result2 = agent.run_sync('Explain?', message_history=result1.new_messages())
print(result2.data)
#> This is an excellent joke invent by Samuel Colvin, it needs no explanation.
print(result2.all_messages())
"""
[
  ModelRequest(
    parts=[
      SystemPromptPart(
        content='Be a helpful assistant.',
        dynamic_ref=None,
        part_kind='system-prompt',
      ),
      UserPromptPart(
        content='Tell me a joke.',
        timestamp=datetime.datetime(...),
        part_kind='user-prompt',
      ),
    ],
    kind='request',
  ),
  ModelResponse(
    parts=[
      TextPart(
        content='Did you hear about the toothpaste scandal? They called it Colgate.',
        part_kind='text',
      )
    ],
    model_name='function:model_logic',
    timestamp=datetime.datetime(...),
    kind='response',
  ),
  ModelRequest(
    parts=[
      UserPromptPart(
        content='Explain?',
        timestamp=datetime.datetime(...),
        part_kind='user-prompt',
      )
    ],
    kind='request',
  ),
  ModelResponse(
    parts=[
      TextPart(
        content='This is an excellent joke invent by Samuel Colvin, it needs no explanation.',
        part_kind='text',
      )
    ],
    model_name='function:model_logic',
    timestamp=datetime.datetime(...),
    kind='response',
  ),
]
"""

```

_(This example is complete, it can be run "as is")_
## Other ways of using messages
Since messages are defined by simple dataclasses, you can manually create and manipulate, e.g. for testing.
The message format is independent of the model used, so you can use messages in different agents, or the same agent with different models.
```
from pydantic_ai import Agent
agent = Agent('openai:gpt-4o', system_prompt='Be a helpful assistant.')
result1 = agent.run_sync('Tell me a joke.')
print(result1.data)
#> Did you hear about the toothpaste scandal? They called it Colgate.
result2 = agent.run_sync(
  'Explain?', model='gemini-1.5-pro', message_history=result1.new_messages()
)
print(result2.data)
#> This is an excellent joke invent by Samuel Colvin, it needs no explanation.
print(result2.all_messages())
"""
[
  ModelRequest(
    parts=[
      SystemPromptPart(
        content='Be a helpful assistant.',
        dynamic_ref=None,
        part_kind='system-prompt',
      ),
      UserPromptPart(
        content='Tell me a joke.',
        timestamp=datetime.datetime(...),
        part_kind='user-prompt',
      ),
    ],
    kind='request',
  ),
  ModelResponse(
    parts=[
      TextPart(
        content='Did you hear about the toothpaste scandal? They called it Colgate.',
        part_kind='text',
      )
    ],
    model_name='function:model_logic',
    timestamp=datetime.datetime(...),
    kind='response',
  ),
  ModelRequest(
    parts=[
      UserPromptPart(
        content='Explain?',
        timestamp=datetime.datetime(...),
        part_kind='user-prompt',
      )
    ],
    kind='request',
  ),
  ModelResponse(
    parts=[
      TextPart(
        content='This is an excellent joke invent by Samuel Colvin, it needs no explanation.',
        part_kind='text',
      )
    ],
    model_name='function:model_logic',
    timestamp=datetime.datetime(...),
    kind='response',
  ),
]
"""

```

## Examples
For a more complete example of using messages in conversations, see the [chat app](https://ai.pydantic.dev/message-history/<../examples/chat-app/>) example.
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/models.md
================
[ Skip to content ](https://ai.pydantic.dev/models/<#openai>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/models/<..> "PydanticAI")
PydanticAI 
Models 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/models/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/models/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/models/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/models/<..>)
  * [ Installation  ](https://ai.pydantic.dev/models/<../install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/models/<../help/>)
  * [ Contributing  ](https://ai.pydantic.dev/models/<../contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/models/<../troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/models/<../agents/>)
    * Models  [ Models  ](https://ai.pydantic.dev/models/<./>) Table of contents 
      * [ OpenAI  ](https://ai.pydantic.dev/models/<#openai>)
        * [ Install  ](https://ai.pydantic.dev/models/<#install>)
        * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration>)
        * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable>)
        * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument>)
        * [ Custom OpenAI Client  ](https://ai.pydantic.dev/models/<#custom-openai-client>)
      * [ Anthropic  ](https://ai.pydantic.dev/models/<#anthropic>)
        * [ Install  ](https://ai.pydantic.dev/models/<#install_1>)
        * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_1>)
        * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_1>)
        * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_1>)
      * [ Gemini  ](https://ai.pydantic.dev/models/<#gemini>)
        * [ Install  ](https://ai.pydantic.dev/models/<#install_2>)
        * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_2>)
        * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_2>)
        * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_2>)
      * [ Gemini via VertexAI  ](https://ai.pydantic.dev/models/<#gemini-via-vertexai>)
        * [ Install  ](https://ai.pydantic.dev/models/<#install_3>)
        * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_3>)
        * [ Application default credentials  ](https://ai.pydantic.dev/models/<#application-default-credentials>)
        * [ Service account  ](https://ai.pydantic.dev/models/<#service-account>)
        * [ Customising region  ](https://ai.pydantic.dev/models/<#customising-region>)
      * [ Groq  ](https://ai.pydantic.dev/models/<#groq>)
        * [ Install  ](https://ai.pydantic.dev/models/<#install_4>)
        * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_4>)
        * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_3>)
        * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_3>)
      * [ Mistral  ](https://ai.pydantic.dev/models/<#mistral>)
        * [ Install  ](https://ai.pydantic.dev/models/<#install_5>)
        * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_5>)
        * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_4>)
        * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_4>)
      * [ Cohere  ](https://ai.pydantic.dev/models/<#cohere>)
        * [ Install  ](https://ai.pydantic.dev/models/<#install_6>)
        * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_6>)
        * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_5>)
        * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_5>)
      * [ OpenAI-compatible Models  ](https://ai.pydantic.dev/models/<#openai-compatible-models>)
        * [ Ollama  ](https://ai.pydantic.dev/models/<#ollama>)
          * [ Example local usage  ](https://ai.pydantic.dev/models/<#example-local-usage>)
          * [ Example using a remote server  ](https://ai.pydantic.dev/models/<#example-using-a-remote-server>)
        * [ OpenRouter  ](https://ai.pydantic.dev/models/<#openrouter>)
        * [ Grok (xAI)  ](https://ai.pydantic.dev/models/<#grok-xai>)
        * [ DeepSeek  ](https://ai.pydantic.dev/models/<#deepseek>)
      * [ Implementing Custom Models  ](https://ai.pydantic.dev/models/<#implementing-custom-models>)
    * [ Dependencies  ](https://ai.pydantic.dev/models/<../dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/models/<../tools/>)
    * [ Results  ](https://ai.pydantic.dev/models/<../results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/models/<../message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/models/<../testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/models/<../logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/models/<../multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/models/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/models/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/models/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/models/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/models/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/models/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/models/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/models/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/models/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/models/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/models/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/models/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/models/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/models/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/models/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/models/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/models/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/models/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/models/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/models/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/models/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/models/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/models/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/models/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/models/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/models/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/models/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/models/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/models/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/models/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/models/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/models/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/models/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/models/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/models/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ OpenAI  ](https://ai.pydantic.dev/models/<#openai>)
    * [ Install  ](https://ai.pydantic.dev/models/<#install>)
    * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration>)
    * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable>)
    * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument>)
    * [ Custom OpenAI Client  ](https://ai.pydantic.dev/models/<#custom-openai-client>)
  * [ Anthropic  ](https://ai.pydantic.dev/models/<#anthropic>)
    * [ Install  ](https://ai.pydantic.dev/models/<#install_1>)
    * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_1>)
    * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_1>)
    * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_1>)
  * [ Gemini  ](https://ai.pydantic.dev/models/<#gemini>)
    * [ Install  ](https://ai.pydantic.dev/models/<#install_2>)
    * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_2>)
    * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_2>)
    * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_2>)
  * [ Gemini via VertexAI  ](https://ai.pydantic.dev/models/<#gemini-via-vertexai>)
    * [ Install  ](https://ai.pydantic.dev/models/<#install_3>)
    * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_3>)
    * [ Application default credentials  ](https://ai.pydantic.dev/models/<#application-default-credentials>)
    * [ Service account  ](https://ai.pydantic.dev/models/<#service-account>)
    * [ Customising region  ](https://ai.pydantic.dev/models/<#customising-region>)
  * [ Groq  ](https://ai.pydantic.dev/models/<#groq>)
    * [ Install  ](https://ai.pydantic.dev/models/<#install_4>)
    * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_4>)
    * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_3>)
    * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_3>)
  * [ Mistral  ](https://ai.pydantic.dev/models/<#mistral>)
    * [ Install  ](https://ai.pydantic.dev/models/<#install_5>)
    * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_5>)
    * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_4>)
    * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_4>)
  * [ Cohere  ](https://ai.pydantic.dev/models/<#cohere>)
    * [ Install  ](https://ai.pydantic.dev/models/<#install_6>)
    * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_6>)
    * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_5>)
    * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_5>)
  * [ OpenAI-compatible Models  ](https://ai.pydantic.dev/models/<#openai-compatible-models>)
    * [ Ollama  ](https://ai.pydantic.dev/models/<#ollama>)
      * [ Example local usage  ](https://ai.pydantic.dev/models/<#example-local-usage>)
      * [ Example using a remote server  ](https://ai.pydantic.dev/models/<#example-using-a-remote-server>)
    * [ OpenRouter  ](https://ai.pydantic.dev/models/<#openrouter>)
    * [ Grok (xAI)  ](https://ai.pydantic.dev/models/<#grok-xai>)
    * [ DeepSeek  ](https://ai.pydantic.dev/models/<#deepseek>)
  * [ Implementing Custom Models  ](https://ai.pydantic.dev/models/<#implementing-custom-models>)


  1. [ Introduction  ](https://ai.pydantic.dev/models/<..>)
  2. [ Documentation  ](https://ai.pydantic.dev/models/<../agents/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/models/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/models/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Models
PydanticAI is Model-agnostic and has built in support for the following model providers:
  * [OpenAI](https://ai.pydantic.dev/models/<#openai>)
  * [Anthropic](https://ai.pydantic.dev/models/<#anthropic>)
  * Gemini via two different APIs: [Generative Language API](https://ai.pydantic.dev/models/<#gemini>) and [VertexAI API](https://ai.pydantic.dev/models/<#gemini-via-vertexai>)
  * [Ollama](https://ai.pydantic.dev/models/<#ollama>)
  * [Deepseek](https://ai.pydantic.dev/models/<#deepseek>)
  * [Groq](https://ai.pydantic.dev/models/<#groq>)
  * [Mistral](https://ai.pydantic.dev/models/<#mistral>)
  * [Cohere](https://ai.pydantic.dev/models/<#cohere>)


See [OpenAI-compatible models](https://ai.pydantic.dev/models/<#openai-compatible-models>) for more examples on how to use models such as [OpenRouter](https://ai.pydantic.dev/models/<#openrouter>), and [Grok (xAI)](https://ai.pydantic.dev/models/<#grok-xai>) that support the OpenAI SDK.
You can also [add support for other models](https://ai.pydantic.dev/models/<#implementing-custom-models>).
PydanticAI also comes with `TestModel`[](https://ai.pydantic.dev/models/<../api/models/test/>) and `FunctionModel`[](https://ai.pydantic.dev/models/<../api/models/function/>) for testing and development.
To use each model provider, you need to configure your local environment and make sure you have the right packages installed.
## OpenAI
### Install
To use OpenAI models, you need to either install `pydantic-ai`[](https://ai.pydantic.dev/models/<../install/>), or install `pydantic-ai-slim`[](https://ai.pydantic.dev/models/<../install/#slim-install>) with the `openai` optional group:
[pip](https://ai.pydantic.dev/models/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/models/<#__tabbed_1_2>)
```
pipinstall'pydantic-ai-slim[openai]'

```

```
uvadd'pydantic-ai-slim[openai]'

```

### Configuration
To use `OpenAIModel`[](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel>) through their main API, go to [platform.openai.com](https://ai.pydantic.dev/models/<https:/platform.openai.com/>) and follow your nose until you find the place to generate an API key.
### Environment variable
Once you have the API key, you can set it as an environment variable:
```
exportOPENAI_API_KEY='your-api-key'

```

You can then use `OpenAIModel`[](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel>) by name:
openai_model_by_name.py```
from pydantic_ai import Agent
agent = Agent('openai:gpt-4o')
...

```

Or initialise the model directly with just the model name:
openai_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
model = OpenAIModel('gpt-4o')
agent = Agent(model)
...

```

### `api_key` argument
If you don't want to or can't set the environment variable, you can pass it at runtime via the `api_key`[ argument](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel.__init__>):
openai_model_api_key.py```
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
model = OpenAIModel('gpt-4o', api_key='your-api-key')
agent = Agent(model)
...

```

### Custom OpenAI Client
`OpenAIModel` also accepts a custom `AsyncOpenAI` client via the `openai_client`[ parameter](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel.__init__>), so you can customise the `organization`, `project`, `base_url` etc. as defined in the [OpenAI API docs](https://ai.pydantic.dev/models/<https:/platform.openai.com/docs/api-reference>).
You could also use the `AsyncAzureOpenAI`[](https://ai.pydantic.dev/models/<https:/learn.microsoft.com/en-us/azure/ai-services/openai/how-to/switching-endpoints>) client to use the Azure OpenAI API.
openai_azure.py```
from openai import AsyncAzureOpenAI
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
client = AsyncAzureOpenAI(
  azure_endpoint='...',
  api_version='2024-07-01-preview',
  api_key='your-api-key',
)
model = OpenAIModel('gpt-4o', openai_client=client)
agent = Agent(model)
...

```

## Anthropic
### Install
To use `AnthropicModel`[](https://ai.pydantic.dev/models/<../api/models/anthropic/#pydantic_ai.models.anthropic.AnthropicModel>) models, you need to either install `pydantic-ai`[](https://ai.pydantic.dev/models/<../install/>), or install `pydantic-ai-slim`[](https://ai.pydantic.dev/models/<../install/#slim-install>) with the `anthropic` optional group:
[pip](https://ai.pydantic.dev/models/<#__tabbed_2_1>)[uv](https://ai.pydantic.dev/models/<#__tabbed_2_2>)
```
pipinstall'pydantic-ai-slim[anthropic]'

```

```
uvadd'pydantic-ai-slim[anthropic]'

```

### Configuration
To use [Anthropic](https://ai.pydantic.dev/models/<https:/anthropic.com>) through their API, go to [console.anthropic.com/settings/keys](https://ai.pydantic.dev/models/<https:/console.anthropic.com/settings/keys>) to generate an API key.
`AnthropicModelName`[](https://ai.pydantic.dev/models/<../api/models/anthropic/#pydantic_ai.models.anthropic.AnthropicModelName>) contains a list of available Anthropic models.
### Environment variable
Once you have the API key, you can set it as an environment variable:
```
exportANTHROPIC_API_KEY='your-api-key'

```

You can then use `AnthropicModel`[](https://ai.pydantic.dev/models/<../api/models/anthropic/#pydantic_ai.models.anthropic.AnthropicModel>) by name:
anthropic_model_by_name.py```
from pydantic_ai import Agent
agent = Agent('anthropic:claude-3-5-sonnet-latest')
...

```

Or initialise the model directly with just the model name:
anthropic_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.anthropic import AnthropicModel
model = AnthropicModel('claude-3-5-sonnet-latest')
agent = Agent(model)
...

```

### `api_key` argument
If you don't want to or can't set the environment variable, you can pass it at runtime via the `api_key`[ argument](https://ai.pydantic.dev/models/<../api/models/anthropic/#pydantic_ai.models.anthropic.AnthropicModel.__init__>):
anthropic_model_api_key.py```
from pydantic_ai import Agent
from pydantic_ai.models.anthropic import AnthropicModel
model = AnthropicModel('claude-3-5-sonnet-latest', api_key='your-api-key')
agent = Agent(model)
...

```

## Gemini
For prototyping only
Google themselves refer to this API as the "hobby" API, I've received 503 responses from it a number of times. The API is easy to use and useful for prototyping and simple demos, but I would not rely on it in production.
If you want to run Gemini models in production, you should use the [VertexAI API](https://ai.pydantic.dev/models/<#gemini-via-vertexai>) described below.
### Install
To use `GeminiModel`[](https://ai.pydantic.dev/models/<../api/models/gemini/#pydantic_ai.models.gemini.GeminiModel>) models, you just need to install `pydantic-ai`[](https://ai.pydantic.dev/models/<../install/>) or `pydantic-ai-slim`[](https://ai.pydantic.dev/models/<../install/#slim-install>), no extra dependencies are required.
### Configuration
`GeminiModel`[](https://ai.pydantic.dev/models/<../api/models/gemini/#pydantic_ai.models.gemini.GeminiModel>) let's you use the Google's Gemini models through their [Generative Language API](https://ai.pydantic.dev/models/<https:/ai.google.dev/api/all-methods>), `generativelanguage.googleapis.com`.
`GeminiModelName`[](https://ai.pydantic.dev/models/<../api/models/gemini/#pydantic_ai.models.gemini.GeminiModelName>) contains a list of available Gemini models that can be used through this interface.
To use `GeminiModel`, go to [aistudio.google.com](https://ai.pydantic.dev/models/<https:/aistudio.google.com/>) and follow your nose until you find the place to generate an API key.
### Environment variable
Once you have the API key, you can set it as an environment variable:
```
exportGEMINI_API_KEY=your-api-key

```

You can then use `GeminiModel`[](https://ai.pydantic.dev/models/<../api/models/gemini/#pydantic_ai.models.gemini.GeminiModel>) by name:
gemini_model_by_name.py```
from pydantic_ai import Agent
agent = Agent('google-gla:gemini-1.5-flash')
...

```

Note
The `google-gla` provider prefix represents the [Google **G** enerative **L** anguage **A** PI](https://ai.pydantic.dev/models/<https:/ai.google.dev/api/all-methods>) for `GeminiModel`s. `google-vertex` is used with [Vertex AI](https://ai.pydantic.dev/models/<https:/cloud.google.com/vertex-ai/generative-ai/docs/learn/models>) for `VertexAIModel`s.
Or initialise the model directly with just the model name:
gemini_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.gemini import GeminiModel
model = GeminiModel('gemini-1.5-flash')
agent = Agent(model)
...

```

### `api_key` argument
If you don't want to or can't set the environment variable, you can pass it at runtime via the `api_key`[ argument](https://ai.pydantic.dev/models/<../api/models/gemini/#pydantic_ai.models.gemini.GeminiModel.__init__>):
gemini_model_api_key.py```
from pydantic_ai import Agent
from pydantic_ai.models.gemini import GeminiModel
model = GeminiModel('gemini-1.5-flash', api_key='your-api-key')
agent = Agent(model)
...

```

## Gemini via VertexAI
To run Google's Gemini models in production, you should use `VertexAIModel`[](https://ai.pydantic.dev/models/<../api/models/vertexai/#pydantic_ai.models.vertexai.VertexAIModel>) which uses the `*-aiplatform.googleapis.com` API.
`GeminiModelName`[](https://ai.pydantic.dev/models/<../api/models/gemini/#pydantic_ai.models.gemini.GeminiModelName>) contains a list of available Gemini models that can be used through this interface.
### Install
To use `VertexAIModel`[](https://ai.pydantic.dev/models/<../api/models/vertexai/#pydantic_ai.models.vertexai.VertexAIModel>), you need to either install `pydantic-ai`[](https://ai.pydantic.dev/models/<../install/>), or install `pydantic-ai-slim`[](https://ai.pydantic.dev/models/<../install/#slim-install>) with the `vertexai` optional group:
[pip](https://ai.pydantic.dev/models/<#__tabbed_3_1>)[uv](https://ai.pydantic.dev/models/<#__tabbed_3_2>)
```
pipinstall'pydantic-ai-slim[vertexai]'

```

```
uvadd'pydantic-ai-slim[vertexai]'

```

### Configuration
This interface has a number of advantages over `generativelanguage.googleapis.com` documented above:
  1. The VertexAI API is more reliably and marginally lower latency in our experience.
  2. You can [purchase provisioned throughput](https://ai.pydantic.dev/models/<https:/cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput#purchase-provisioned-throughput>) with VertexAI to guarantee capacity.
  3. If you're running PydanticAI inside GCP, you don't need to set up authentication, it should "just work".
  4. You can decide which region to use, which might be important from a regulatory perspective, and might improve latency.


The big disadvantage is that for local development you may need to create and configure a "service account", which I've found extremely painful to get right in the past.
Whichever way you authenticate, you'll need to have VertexAI enabled in your GCP account.
### Application default credentials
Luckily if you're running PydanticAI inside GCP, or you have the `gcloud`[ CLI](https://ai.pydantic.dev/models/<https:/cloud.google.com/sdk/gcloud>) installed and configured, you should be able to use `VertexAIModel` without any additional setup.
To use `VertexAIModel`, with [application default credentials](https://ai.pydantic.dev/models/<https:/cloud.google.com/docs/authentication/application-default-credentials>) configured (e.g. with `gcloud`), you can simply use:
vertexai_application_default_credentials.py```
from pydantic_ai import Agent
from pydantic_ai.models.vertexai import VertexAIModel
model = VertexAIModel('gemini-1.5-flash')
agent = Agent(model)
...

```

Internally this uses `google.auth.default()`[](https://ai.pydantic.dev/models/<https:/google-auth.readthedocs.io/en/master/reference/google.auth.html>) from the `google-auth` package to obtain credentials.
Won't fail until `agent.run()`
Because `google.auth.default()` requires network requests and can be slow, it's not run until you call `agent.run()`. Meaning any configuration or permissions error will only be raised when you try to use the model. To initialize the model for this check to be run, call `await model.ainit()`[](https://ai.pydantic.dev/models/<../api/models/vertexai/#pydantic_ai.models.vertexai.VertexAIModel.ainit>).
You may also need to pass the `project_id`[ argument to `VertexAIModel`](https://ai.pydantic.dev/models/<../api/models/vertexai/#pydantic_ai.models.vertexai.VertexAIModel.__init__>) if application default credentials don't set a project, if you pass `project_id` and it conflicts with the project set by application default credentials, an error is raised.
### Service account
If instead of application default credentials, you want to authenticate with a service account, you'll need to create a service account, add it to your GCP project (note: AFAIK this step is necessary even if you created the service account within the project), give that service account the "Vertex AI Service Agent" role, and download the service account JSON file.
Once you have the JSON file, you can use it thus:
vertexai_service_account.py```
from pydantic_ai import Agent
from pydantic_ai.models.vertexai import VertexAIModel
model = VertexAIModel(
  'gemini-1.5-flash',
  service_account_file='path/to/service-account.json',
)
agent = Agent(model)
...

```

### Customising region
Whichever way you authenticate, you can specify which region requests will be sent to via the `region`[ argument](https://ai.pydantic.dev/models/<../api/models/vertexai/#pydantic_ai.models.vertexai.VertexAIModel.__init__>).
Using a region close to your application can improve latency and might be important from a regulatory perspective.
vertexai_region.py```
from pydantic_ai import Agent
from pydantic_ai.models.vertexai import VertexAIModel
model = VertexAIModel('gemini-1.5-flash', region='asia-east1')
agent = Agent(model)
...

```

`VertexAiRegion`[](https://ai.pydantic.dev/models/<../api/models/vertexai/#pydantic_ai.models.vertexai.VertexAiRegion>) contains a list of available regions.
## Groq
### Install
To use `GroqModel`[](https://ai.pydantic.dev/models/<../api/models/groq/#pydantic_ai.models.groq.GroqModel>), you need to either install `pydantic-ai`[](https://ai.pydantic.dev/models/<../install/>), or install `pydantic-ai-slim`[](https://ai.pydantic.dev/models/<../install/#slim-install>) with the `groq` optional group:
[pip](https://ai.pydantic.dev/models/<#__tabbed_4_1>)[uv](https://ai.pydantic.dev/models/<#__tabbed_4_2>)
```
pipinstall'pydantic-ai-slim[groq]'

```

```
uvadd'pydantic-ai-slim[groq]'

```

### Configuration
To use [Groq](https://ai.pydantic.dev/models/<https:/groq.com/>) through their API, go to [console.groq.com/keys](https://ai.pydantic.dev/models/<https:/console.groq.com/keys>) and follow your nose until you find the place to generate an API key.
`GroqModelName`[](https://ai.pydantic.dev/models/<../api/models/groq/#pydantic_ai.models.groq.GroqModelName>) contains a list of available Groq models.
### Environment variable
Once you have the API key, you can set it as an environment variable:
```
exportGROQ_API_KEY='your-api-key'

```

You can then use `GroqModel`[](https://ai.pydantic.dev/models/<../api/models/groq/#pydantic_ai.models.groq.GroqModel>) by name:
groq_model_by_name.py```
from pydantic_ai import Agent
agent = Agent('groq:llama-3.3-70b-versatile')
...

```

Or initialise the model directly with just the model name:
groq_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.groq import GroqModel
model = GroqModel('llama-3.3-70b-versatile')
agent = Agent(model)
...

```

### `api_key` argument
If you don't want to or can't set the environment variable, you can pass it at runtime via the `api_key`[ argument](https://ai.pydantic.dev/models/<../api/models/groq/#pydantic_ai.models.groq.GroqModel.__init__>):
groq_model_api_key.py```
from pydantic_ai import Agent
from pydantic_ai.models.groq import GroqModel
model = GroqModel('llama-3.3-70b-versatile', api_key='your-api-key')
agent = Agent(model)
...

```

## Mistral
### Install
To use `MistralModel`[](https://ai.pydantic.dev/models/<../api/models/mistral/#pydantic_ai.models.mistral.MistralModel>), you need to either install `pydantic-ai`[](https://ai.pydantic.dev/models/<../install/>), or install `pydantic-ai-slim`[](https://ai.pydantic.dev/models/<../install/#slim-install>) with the `mistral` optional group:
[pip](https://ai.pydantic.dev/models/<#__tabbed_5_1>)[uv](https://ai.pydantic.dev/models/<#__tabbed_5_2>)
```
pipinstall'pydantic-ai-slim[mistral]'

```

```
uvadd'pydantic-ai-slim[mistral]'

```

### Configuration
To use [Mistral](https://ai.pydantic.dev/models/<https:/mistral.ai>) through their API, go to [console.mistral.ai/api-keys/](https://ai.pydantic.dev/models/<https:/console.mistral.ai/api-keys/>) and follow your nose until you find the place to generate an API key.
`NamedMistralModels`[](https://ai.pydantic.dev/models/<../api/models/mistral/#pydantic_ai.models.mistral.NamedMistralModels>) contains a list of the most popular Mistral models.
### Environment variable
Once you have the API key, you can set it as an environment variable:
```
exportMISTRAL_API_KEY='your-api-key'

```

You can then use `MistralModel`[](https://ai.pydantic.dev/models/<../api/models/mistral/#pydantic_ai.models.mistral.MistralModel>) by name:
mistral_model_by_name.py```
from pydantic_ai import Agent
agent = Agent('mistral:mistral-large-latest')
...

```

Or initialise the model directly with just the model name:
mistral_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.mistral import MistralModel
model = MistralModel('mistral-small-latest')
agent = Agent(model)
...

```

### `api_key` argument
If you don't want to or can't set the environment variable, you can pass it at runtime via the `api_key`[ argument](https://ai.pydantic.dev/models/<../api/models/mistral/#pydantic_ai.models.mistral.MistralModel.__init__>):
mistral_model_api_key.py```
from pydantic_ai import Agent
from pydantic_ai.models.mistral import MistralModel
model = MistralModel('mistral-small-latest', api_key='your-api-key')
agent = Agent(model)
...

```

## Cohere
### Install
To use `CohereModel`[](https://ai.pydantic.dev/models/<../api/models/cohere/#pydantic_ai.models.cohere.CohereModel>), you need to either install `pydantic-ai`[](https://ai.pydantic.dev/models/<../install/>), or install `pydantic-ai-slim`[](https://ai.pydantic.dev/models/<../install/#slim-install>) with the `cohere` optional group:
[pip](https://ai.pydantic.dev/models/<#__tabbed_6_1>)[uv](https://ai.pydantic.dev/models/<#__tabbed_6_2>)
```
pipinstall'pydantic-ai-slim[cohere]'

```

```
uvadd'pydantic-ai-slim[cohere]'

```

### Configuration
To use [Cohere](https://ai.pydantic.dev/models/<https:/cohere.com/>) through their API, go to [dashboard.cohere.com/api-keys](https://ai.pydantic.dev/models/<https:/dashboard.cohere.com/api-keys>) and follow your nose until you find the place to generate an API key.
`NamedCohereModels`[](https://ai.pydantic.dev/models/<../api/models/cohere/#pydantic_ai.models.cohere.NamedCohereModels>) contains a list of the most popular Cohere models.
### Environment variable
Once you have the API key, you can set it as an environment variable:
```
exportCO_API_KEY='your-api-key'

```

You can then use `CohereModel`[](https://ai.pydantic.dev/models/<../api/models/cohere/#pydantic_ai.models.cohere.CohereModel>) by name:
cohere_model_by_name.py```
from pydantic_ai import Agent
agent = Agent('cohere:command')
...

```

Or initialise the model directly with just the model name:
cohere_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.cohere import CohereModel
model = CohereModel('command', api_key='your-api-key')
agent = Agent(model)
...

```

### `api_key` argument
If you don't want to or can't set the environment variable, you can pass it at runtime via the `api_key`[ argument](https://ai.pydantic.dev/models/<../api/models/cohere/#pydantic_ai.models.cohere.CohereModel.__init__>):
cohere_model_api_key.py```
from pydantic_ai import Agent
from pydantic_ai.models.cohere import CohereModel
model = CohereModel('command', api_key='your-api-key')
agent = Agent(model)
...

```

## OpenAI-compatible Models
Many of the models are compatible with OpenAI API, and thus can be used with `OpenAIModel`[](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel>) in PydanticAI. Before getting started, check the [OpenAI](https://ai.pydantic.dev/models/<#openai>) section for installation and configuration instructions.
To use another OpenAI-compatible API, you can make use of the `base_url`[](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel.__init__>) and `api_key`[](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel.__init__>) arguments:
openai_model_base_url.py```
from pydantic_ai.models.openai import OpenAIModel
model = OpenAIModel(
  'model_name',
  base_url='https://<openai-compatible-api-endpoint>.com',
  api_key='your-api-key',
)
...

```

### Ollama
To use [Ollama](https://ai.pydantic.dev/models/<https:/ollama.com/>), you must first download the Ollama client, and then download a model using the [Ollama model library](https://ai.pydantic.dev/models/<https:/ollama.com/library>).
You must also ensure the Ollama server is running when trying to make requests to it. For more information, please see the [Ollama documentation](https://ai.pydantic.dev/models/<https:/github.com/ollama/ollama/tree/main/docs>).
#### Example local usage
With `ollama` installed, you can run the server with the model you want to use:
terminal-run-ollama```
ollamarunllama3.2

```

(this will pull the `llama3.2` model if you don't already have it downloaded) 
Then run your code, here's a minimal example:
ollama_example.py```
from pydantic import BaseModel
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel

class CityLocation(BaseModel):
  city: str
  country: str

ollama_model = OpenAIModel(model_name='llama3.2', base_url='http://localhost:11434/v1')
agent = Agent(ollama_model, result_type=CityLocation)
result = agent.run_sync('Where were the olympics held in 2012?')
print(result.data)
#> city='London' country='United Kingdom'
print(result.usage())
"""
Usage(requests=1, request_tokens=57, response_tokens=8, total_tokens=65, details=None)
"""

```

#### Example using a remote server
ollama_example_with_remote_server.py```
from pydantic import BaseModel
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
ollama_model = OpenAIModel(
  model_name='qwen2.5-coder:7b', 
The name of the model running on the remote server
[](https://ai.pydantic.dev/models/<#__code_43_annotation_1>)
  base_url='http://192.168.1.74:11434/v1', 
The url of the remote server
[](https://ai.pydantic.dev/models/<#__code_43_annotation_2>)
)

class CityLocation(BaseModel):
  city: str
  country: str

agent = Agent(model=ollama_model, result_type=CityLocation)
result = agent.run_sync('Where were the olympics held in 2012?')
print(result.data)
#> city='London' country='United Kingdom'
print(result.usage())
"""
Usage(requests=1, request_tokens=57, response_tokens=8, total_tokens=65, details=None)
"""

```

### OpenRouter
To use [OpenRouter](https://ai.pydantic.dev/models/<https:/openrouter.ai>), first create an API key at [openrouter.ai/keys](https://ai.pydantic.dev/models/<https:/openrouter.ai/keys>).
Once you have the API key, you can pass it to `OpenAIModel`[](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel>) as the `api_key` argument:
openrouter_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
model = OpenAIModel(
  'anthropic/claude-3.5-sonnet',
  base_url='https://openrouter.ai/api/v1',
  api_key='your-openrouter-api-key',
)
agent = Agent(model)
...

```

### Grok (xAI)
Go to [xAI API Console](https://ai.pydantic.dev/models/<https:/console.x.ai/>) and create an API key. Once you have the API key, follow the [xAI API Documentation](https://ai.pydantic.dev/models/<https:/docs.x.ai/docs/overview>), and set the `base_url` and `api_key` arguments appropriately:
grok_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
model = OpenAIModel(
  'grok-2-1212',
  base_url='https://api.x.ai/v1',
  api_key='your-xai-api-key',
)
agent = Agent(model)
...

```

### DeepSeek
Go to [DeepSeek API Platform](https://ai.pydantic.dev/models/<https:/platform.deepseek.com/api_keys>) and create an API key. Once you have the API key, follow the [DeepSeek API Documentation](https://ai.pydantic.dev/models/<https:/platform.deepseek.com/docs/api/overview>), and set the `base_url` and `api_key` arguments appropriately:
deepseek_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
model = OpenAIModel(
  'deepseek-chat',
  base_url='https://api.deepseek.com',
  api_key='your-deepseek-api-key',
)
agent = Agent(model)
...

```

## Implementing Custom Models
To implement support for models not already supported, you will need to subclass the `Model`[](https://ai.pydantic.dev/models/<../api/models/base/#pydantic_ai.models.Model>) abstract base class.
This in turn will require you to implement the following other abstract base classes:
  * `AgentModel`[](https://ai.pydantic.dev/models/<../api/models/base/#pydantic_ai.models.AgentModel>)
  * `StreamedResponse`[](https://ai.pydantic.dev/models/<../api/models/base/#pydantic_ai.models.StreamedResponse>)


The best place to start is to review the source code for existing implementations, e.g. `OpenAIModel`[](https://ai.pydantic.dev/models/<https:/github.com/pydantic/pydantic-ai/blob/main/pydantic_ai_slim/pydantic_ai/models/openai.py>).
For details on when we'll accept contributions adding new models to PydanticAI, see the [contributing guidelines](https://ai.pydantic.dev/models/<../contributing/#new-model-rules>).
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/multi-agent-applications.md
================
[ Skip to content ](https://ai.pydantic.dev/multi-agent-applications/<#multi-agent-applications>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/multi-agent-applications/<..> "PydanticAI")
PydanticAI 
Multi-agent Applications 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/multi-agent-applications/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/multi-agent-applications/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/multi-agent-applications/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/multi-agent-applications/<..>)
  * [ Installation  ](https://ai.pydantic.dev/multi-agent-applications/<../install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/multi-agent-applications/<../help/>)
  * [ Contributing  ](https://ai.pydantic.dev/multi-agent-applications/<../contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/multi-agent-applications/<../troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/multi-agent-applications/<../agents/>)
    * [ Models  ](https://ai.pydantic.dev/multi-agent-applications/<../models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/multi-agent-applications/<../dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/multi-agent-applications/<../tools/>)
    * [ Results  ](https://ai.pydantic.dev/multi-agent-applications/<../results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/multi-agent-applications/<../message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/multi-agent-applications/<../testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/multi-agent-applications/<../logfire/>)
    * Multi-agent Applications  [ Multi-agent Applications  ](https://ai.pydantic.dev/multi-agent-applications/<./>) Table of contents 
      * [ Agent delegation  ](https://ai.pydantic.dev/multi-agent-applications/<#agent-delegation>)
        * [ Agent delegation and dependencies  ](https://ai.pydantic.dev/multi-agent-applications/<#agent-delegation-and-dependencies>)
      * [ Programmatic agent hand-off  ](https://ai.pydantic.dev/multi-agent-applications/<#programmatic-agent-hand-off>)
      * [ Pydantic Graphs  ](https://ai.pydantic.dev/multi-agent-applications/<#pydantic-graphs>)
      * [ Examples  ](https://ai.pydantic.dev/multi-agent-applications/<#examples>)
    * [ Graphs  ](https://ai.pydantic.dev/multi-agent-applications/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/multi-agent-applications/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/multi-agent-applications/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/multi-agent-applications/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/multi-agent-applications/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/multi-agent-applications/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/multi-agent-applications/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/multi-agent-applications/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/multi-agent-applications/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/multi-agent-applications/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/multi-agent-applications/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/multi-agent-applications/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/multi-agent-applications/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/multi-agent-applications/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/multi-agent-applications/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/multi-agent-applications/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/multi-agent-applications/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/multi-agent-applications/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/multi-agent-applications/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/multi-agent-applications/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/multi-agent-applications/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/multi-agent-applications/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/multi-agent-applications/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/multi-agent-applications/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/multi-agent-applications/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/multi-agent-applications/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/multi-agent-applications/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/multi-agent-applications/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/multi-agent-applications/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/multi-agent-applications/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/multi-agent-applications/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/multi-agent-applications/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/multi-agent-applications/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/multi-agent-applications/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/multi-agent-applications/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Agent delegation  ](https://ai.pydantic.dev/multi-agent-applications/<#agent-delegation>)
    * [ Agent delegation and dependencies  ](https://ai.pydantic.dev/multi-agent-applications/<#agent-delegation-and-dependencies>)
  * [ Programmatic agent hand-off  ](https://ai.pydantic.dev/multi-agent-applications/<#programmatic-agent-hand-off>)
  * [ Pydantic Graphs  ](https://ai.pydantic.dev/multi-agent-applications/<#pydantic-graphs>)
  * [ Examples  ](https://ai.pydantic.dev/multi-agent-applications/<#examples>)


  1. [ Introduction  ](https://ai.pydantic.dev/multi-agent-applications/<..>)
  2. [ Documentation  ](https://ai.pydantic.dev/multi-agent-applications/<../agents/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/multi-agent-applications/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/multi-agent-applications/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Multi-agent Applications
There are roughly four levels of complexity when building applications with PydanticAI:
  1. Single agent workflows — what most of the `pydantic_ai` documentation covers
  2. [Agent delegation](https://ai.pydantic.dev/multi-agent-applications/<#agent-delegation>) — agents using another agent via tools
  3. [Programmatic agent hand-off](https://ai.pydantic.dev/multi-agent-applications/<#programmatic-agent-hand-off>) — one agent runs, then application code calls another agent
  4. [Graph based control flow](https://ai.pydantic.dev/multi-agent-applications/<../graph/>) — for the most complex cases, a graph-based state machine can be used to control the execution of multiple agents


Of course, you can combine multiple strategies in a single application.
## Agent delegation
"Agent delegation" refers to the scenario where an agent delegates work to another agent, then takes back control when the delegate agent (the agent called from within a tool) finishes.
Since agents are stateless and designed to be global, you do not need to include the agent itself in agent [dependencies](https://ai.pydantic.dev/multi-agent-applications/<../dependencies/>).
You'll generally want to pass `ctx.usage`[](https://ai.pydantic.dev/multi-agent-applications/<../api/tools/#pydantic_ai.tools.RunContext.usage>) to the `usage`[](https://ai.pydantic.dev/multi-agent-applications/<../api/agent/#pydantic_ai.agent.Agent.run>) keyword argument of the delegate agent run so usage within that run counts towards the total usage of the parent agent run.
Multiple models
Agent delegation doesn't need to use the same model for each agent. If you choose to use different models within a run, calculating the monetary cost from the final `result.usage()`[](https://ai.pydantic.dev/multi-agent-applications/<../api/result/#pydantic_ai.result.RunResult.usage>) of the run will not be possible, but you can still use `UsageLimits`[](https://ai.pydantic.dev/multi-agent-applications/<../api/usage/#pydantic_ai.usage.UsageLimits>) to avoid unexpected costs.
agent_delegation_simple.py```
from pydantic_ai import Agent, RunContext
from pydantic_ai.usage import UsageLimits
joke_selection_agent = Agent( 
The "parent" or controlling agent.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_0_annotation_1>)
  'openai:gpt-4o',
  system_prompt=(
    'Use the `joke_factory` to generate some jokes, then choose the best. '
    'You must return just a single joke.'
  ),
)
joke_generation_agent = Agent( 
The "delegate" agent, which is called from within a tool of the parent agent.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_0_annotation_2>)
  'google-gla:gemini-1.5-flash', result_type=list[str]
)

@joke_selection_agent.tool
async def joke_factory(ctx: RunContext[None], count: int) -> list[str]:
  r = await joke_generation_agent.run( 
Call the delegate agent from within a tool of the parent agent.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_0_annotation_3>)
    f'Please generate {count} jokes.',
    usage=ctx.usage, 
Pass the usage from the parent agent to the delegate agent so the final result.usage()[](https://ai.pydantic.dev/multi-agent-applications/<../api/result/#pydantic_ai.result.RunResult.usage>) includes the usage from both agents.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_0_annotation_4>)
  )
  return r.data 
Since the function returns list[str], and the result_type of joke_generation_agent is also list[str], we can simply return r.data from the tool.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_0_annotation_5>)

result = joke_selection_agent.run_sync(
  'Tell me a joke.',
  usage_limits=UsageLimits(request_limit=5, total_tokens_limit=300),
)
print(result.data)
#> Did you hear about the toothpaste scandal? They called it Colgate.
print(result.usage())
"""
Usage(
  requests=3, request_tokens=204, response_tokens=24, total_tokens=228, details=None
)
"""

```

_(This example is complete, it can be run "as is")_
The control flow for this example is pretty simple and can be summarised as follows:
```
graph TD
 START --> joke_selection_agent
 joke_selection_agent --> joke_factory["joke_factory (tool)"]
 joke_factory --> joke_generation_agent
 joke_generation_agent --> joke_factory
 joke_factory --> joke_selection_agent
 joke_selection_agent --> END
```

### Agent delegation and dependencies
Generally the delegate agent needs to either have the same [dependencies](https://ai.pydantic.dev/multi-agent-applications/<../dependencies/>) as the calling agent, or dependencies which are a subset of the calling agent's dependencies.
Initializing dependencies
We say "generally" above since there's nothing to stop you initializing dependencies within a tool call and therefore using interdependencies in a delegate agent that are not available on the parent, this should often be avoided since it can be significantly slower than reusing connections etc. from the parent agent.
agent_delegation_deps.py```
from dataclasses import dataclass
import httpx
from pydantic_ai import Agent, RunContext

@dataclass
class ClientAndKey: 
Define a dataclass to hold the client and API key dependencies.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_1_annotation_1>)
  http_client: httpx.AsyncClient
  api_key: str

joke_selection_agent = Agent(
  'openai:gpt-4o',
  deps_type=ClientAndKey, 
Set the deps_type of the calling agent — joke_selection_agent here.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_1_annotation_2>)
  system_prompt=(
    'Use the `joke_factory` tool to generate some jokes on the given subject, '
    'then choose the best. You must return just a single joke.'
  ),
)
joke_generation_agent = Agent(
  'gemini-1.5-flash',
  deps_type=ClientAndKey, 
Also set the deps_type of the delegate agent — joke_generation_agent here.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_1_annotation_4>)
  result_type=list[str],
  system_prompt=(
    'Use the "get_jokes" tool to get some jokes on the given subject, '
    'then extract each joke into a list.'
  ),
)

@joke_selection_agent.tool
async def joke_factory(ctx: RunContext[ClientAndKey], count: int) -> list[str]:
  r = await joke_generation_agent.run(
    f'Please generate {count} jokes.',
    deps=ctx.deps, 
Pass the dependencies to the delegate agent's run method within the tool call.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_1_annotation_3>)
    usage=ctx.usage,
  )
  return r.data

@joke_generation_agent.tool 
Define a tool on the delegate agent that uses the dependencies to make an HTTP request.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_1_annotation_5>)
async def get_jokes(ctx: RunContext[ClientAndKey], count: int) -> str:
  response = await ctx.deps.http_client.get(
    'https://example.com',
    params={'count': count},
    headers={'Authorization': f'Bearer {ctx.deps.api_key}'},
  )
  response.raise_for_status()
  return response.text

async def main():
  async with httpx.AsyncClient() as client:
    deps = ClientAndKey(client, 'foobar')
    result = await joke_selection_agent.run('Tell me a joke.', deps=deps)
    print(result.data)
    #> Did you hear about the toothpaste scandal? They called it Colgate.
    print(result.usage()) 
Usage now includes 4 requests — 2 from the calling agent and 2 from the delegate agent.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_1_annotation_6>)
"""
    Usage(
      requests=4,
      request_tokens=309,
      response_tokens=32,
      total_tokens=341,
      details=None,
    )
    """

```

_(This example is complete, it can be run "as is" — you'll need to add`asyncio.run(main())` to run `main`)_
This example shows how even a fairly simple agent delegation can lead to a complex control flow:
```
graph TD
 START --> joke_selection_agent
 joke_selection_agent --> joke_factory["joke_factory (tool)"]
 joke_factory --> joke_generation_agent
 joke_generation_agent --> get_jokes["get_jokes (tool)"]
 get_jokes --> http_request["HTTP request"]
 http_request --> get_jokes
 get_jokes --> joke_generation_agent
 joke_generation_agent --> joke_factory
 joke_factory --> joke_selection_agent
 joke_selection_agent --> END
```

## Programmatic agent hand-off
"Programmatic agent hand-off" refers to the scenario where multiple agents are called in succession, with application code and/or a human in the loop responsible for deciding which agent to call next.
Here agents don't need to use the same deps.
Here we show two agents used in succession, the first to find a flight and the second to extract the user's seat preference.
programmatic_handoff.py```
from typing import Literal, Union
from pydantic import BaseModel, Field
from rich.prompt import Prompt
from pydantic_ai import Agent, RunContext
from pydantic_ai.messages import ModelMessage
from pydantic_ai.usage import Usage, UsageLimits

class FlightDetails(BaseModel):
  flight_number: str

class Failed(BaseModel):
"""Unable to find a satisfactory choice."""

flight_search_agent = Agent[None, Union[FlightDetails, Failed]]( 
Define the first agent, which finds a flight. We use an explicit type annotation until PEP-747[](https://ai.pydantic.dev/multi-agent-applications/<https:/peps.python.org/pep-0747/>) lands, see structured results[](https://ai.pydantic.dev/multi-agent-applications/<../results/#structured-result-validation>). We use a union as the result type so the model can communicate if it's unable to find a satisfactory choice; internally, each member of the union will be registered as a separate tool.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_2_annotation_1>)
  'openai:gpt-4o',
  result_type=Union[FlightDetails, Failed], # type: ignore
  system_prompt=(
    'Use the "flight_search" tool to find a flight '
    'from the given origin to the given destination.'
  ),
)

@flight_search_agent.tool 
Define a tool on the agent to find a flight. In this simple case we could dispense with the tool and just define the agent to return structured data, then search for a flight, but in more complex scenarios the tool would be necessary.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_2_annotation_2>)
async def flight_search(
  ctx: RunContext[None], origin: str, destination: str
) -> Union[FlightDetails, None]:
  # in reality, this would call a flight search API or
  # use a browser to scrape a flight search website
  return FlightDetails(flight_number='AK456')

usage_limits = UsageLimits(request_limit=15) 
Define usage limits for the entire app.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_2_annotation_3>)

async def find_flight(usage: Usage) -> Union[FlightDetails, None]: 
Define a function to find a flight, which asks the user for their preferences and then calls the agent to find a flight.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_2_annotation_4>)
  message_history: Union[list[ModelMessage], None] = None
  for _ in range(3):
    prompt = Prompt.ask(
      'Where would you like to fly from and to?',
    )
    result = await flight_search_agent.run(
      prompt,
      message_history=message_history,
      usage=usage,
      usage_limits=usage_limits,
    )
    if isinstance(result.data, FlightDetails):
      return result.data
    else:
      message_history = result.all_messages(
        result_tool_return_content='Please try again.'
      )

class SeatPreference(BaseModel):
  row: int = Field(ge=1, le=30)
  seat: Literal['A', 'B', 'C', 'D', 'E', 'F']

# This agent is responsible for extracting the user's seat selection
seat_preference_agent = Agent[None, Union[SeatPreference, Failed]]( 
As with flight_search_agent above, we use an explicit type annotation to define the agent.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_2_annotation_5>)
  'openai:gpt-4o',
  result_type=Union[SeatPreference, Failed], # type: ignore
  system_prompt=(
    "Extract the user's seat preference. "
    'Seats A and F are window seats. '
    'Row 1 is the front row and has extra leg room. '
    'Rows 14, and 20 also have extra leg room. '
  ),
)

async def find_seat(usage: Usage) -> SeatPreference: 
Define a function to find the user's seat preference, which asks the user for their seat preference and then calls the agent to extract the seat preference.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_2_annotation_6>)
  message_history: Union[list[ModelMessage], None] = None
  while True:
    answer = Prompt.ask('What seat would you like?')
    result = await seat_preference_agent.run(
      answer,
      message_history=message_history,
      usage=usage,
      usage_limits=usage_limits,
    )
    if isinstance(result.data, SeatPreference):
      return result.data
    else:
      print('Could not understand seat preference. Please try again.')
      message_history = result.all_messages()

async def main(): 
Now that we've put our logic for running each agent into separate functions, our main app becomes very simple.
[](https://ai.pydantic.dev/multi-agent-applications/<#__code_2_annotation_7>)
  usage: Usage = Usage()
  opt_flight_details = await find_flight(usage)
  if opt_flight_details is not None:
    print(f'Flight found: {opt_flight_details.flight_number}')
    #> Flight found: AK456
    seat_preference = await find_seat(usage)
    print(f'Seat preference: {seat_preference}')
    #> Seat preference: row=1 seat='A'

```

_(This example is complete, it can be run "as is" — you'll need to add`asyncio.run(main())` to run `main`)_
The control flow for this example can be summarised as follows:
```
graph TB
 START --> ask_user_flight["ask user for flight"]
 subgraph find_flight
  flight_search_agent --> ask_user_flight
  ask_user_flight --> flight_search_agent
 end
 flight_search_agent --> ask_user_seat["ask user for seat"]
 flight_search_agent --> END
 subgraph find_seat
  seat_preference_agent --> ask_user_seat
  ask_user_seat --> seat_preference_agent
 end
 seat_preference_agent --> END
```

## Pydantic Graphs
See the [graph](https://ai.pydantic.dev/multi-agent-applications/<../graph/>) documentation on when and how to use graphs.
## Examples
The following examples demonstrate how to use dependencies in PydanticAI:
  * [Flight booking](https://ai.pydantic.dev/multi-agent-applications/<../examples/flight-booking/>)


© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/results.md
================
[ Skip to content ](https://ai.pydantic.dev/results/<#structured-result-validation>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/results/<..> "PydanticAI")
PydanticAI 
Results 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/results/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/results/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/results/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/results/<..>)
  * [ Installation  ](https://ai.pydantic.dev/results/<../install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/results/<../help/>)
  * [ Contributing  ](https://ai.pydantic.dev/results/<../contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/results/<../troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/results/<../agents/>)
    * [ Models  ](https://ai.pydantic.dev/results/<../models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/results/<../dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/results/<../tools/>)
    * Results  [ Results  ](https://ai.pydantic.dev/results/<./>) Table of contents 
      * [ Result data  ](https://ai.pydantic.dev/results/<#structured-result-validation>)
        * [ Result validators functions  ](https://ai.pydantic.dev/results/<#result-validators-functions>)
      * [ Streamed Results  ](https://ai.pydantic.dev/results/<#streamed-results>)
        * [ Streaming Text  ](https://ai.pydantic.dev/results/<#streaming-text>)
        * [ Streaming Structured Responses  ](https://ai.pydantic.dev/results/<#streaming-structured-responses>)
      * [ Examples  ](https://ai.pydantic.dev/results/<#examples>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/results/<../message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/results/<../testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/results/<../logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/results/<../multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/results/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/results/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/results/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/results/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/results/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/results/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/results/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/results/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/results/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/results/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/results/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/results/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/results/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/results/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/results/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/results/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/results/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/results/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/results/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/results/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/results/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/results/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/results/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/results/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/results/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/results/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/results/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/results/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/results/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/results/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/results/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/results/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/results/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/results/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/results/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Result data  ](https://ai.pydantic.dev/results/<#structured-result-validation>)
    * [ Result validators functions  ](https://ai.pydantic.dev/results/<#result-validators-functions>)
  * [ Streamed Results  ](https://ai.pydantic.dev/results/<#streamed-results>)
    * [ Streaming Text  ](https://ai.pydantic.dev/results/<#streaming-text>)
    * [ Streaming Structured Responses  ](https://ai.pydantic.dev/results/<#streaming-structured-responses>)
  * [ Examples  ](https://ai.pydantic.dev/results/<#examples>)


  1. [ Introduction  ](https://ai.pydantic.dev/results/<..>)
  2. [ Documentation  ](https://ai.pydantic.dev/results/<../agents/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/results/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/results/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Results
Results are the final values returned from [running an agent](https://ai.pydantic.dev/results/<../agents/#running-agents>). The result values are wrapped in `RunResult`[](https://ai.pydantic.dev/results/<../api/result/#pydantic_ai.result.RunResult>) and `StreamedRunResult`[](https://ai.pydantic.dev/results/<../api/result/#pydantic_ai.result.StreamedRunResult>) so you can access other data like [usage](https://ai.pydantic.dev/results/<../api/usage/#pydantic_ai.usage.Usage>) of the run and [message history](https://ai.pydantic.dev/results/<../message-history/#accessing-messages-from-results>)
Both `RunResult` and `StreamedRunResult` are generic in the data they wrap, so typing information about the data returned by the agent is preserved.
olympics.py```
from pydantic import BaseModel
from pydantic_ai import Agent

class CityLocation(BaseModel):
  city: str
  country: str

agent = Agent('google-gla:gemini-1.5-flash', result_type=CityLocation)
result = agent.run_sync('Where were the olympics held in 2012?')
print(result.data)
#> city='London' country='United Kingdom'
print(result.usage())
"""
Usage(requests=1, request_tokens=57, response_tokens=8, total_tokens=65, details=None)
"""

```

_(This example is complete, it can be run "as is")_
Runs end when either a plain text response is received or the model calls a tool associated with one of the structured result types. We will add limits to make sure a run doesn't go on indefinitely, see [#70](https://ai.pydantic.dev/results/<https:/github.com/pydantic/pydantic-ai/issues/70>).
## Result data
When the result type is `str`, or a union including `str`, plain text responses are enabled on the model, and the raw text response from the model is used as the response data.
If the result type is a union with multiple members (after remove `str` from the members), each member is registered as a separate tool with the model in order to reduce the complexity of the tool schemas and maximise the chances a model will respond correctly.
If the result type schema is not of type `"object"`, the result type is wrapped in a single element object, so the schema of all tools registered with the model are object schemas.
Structured results (like tools) use Pydantic to build the JSON schema used for the tool, and to validate the data returned by the model.
Bring on PEP-747
Until [PEP-747](https://ai.pydantic.dev/results/<https:/peps.python.org/pep-0747/>) "Annotating Type Forms" lands, unions are not valid as `type`s in Python.
When creating the agent we need to `# type: ignore` the `result_type` argument, and add a type hint to tell type checkers about the type of the agent.
Here's an example of returning either text or a structured value
box_or_error.py```
from typing import Union
from pydantic import BaseModel
from pydantic_ai import Agent

class Box(BaseModel):
  width: int
  height: int
  depth: int
  units: str

agent: Agent[None, Union[Box, str]] = Agent(
  'openai:gpt-4o-mini',
  result_type=Union[Box, str], # type: ignore
  system_prompt=(
    "Extract me the dimensions of a box, "
    "if you can't extract all data, ask the user to try again."
  ),
)
result = agent.run_sync('The box is 10x20x30')
print(result.data)
#> Please provide the units for the dimensions (e.g., cm, in, m).
result = agent.run_sync('The box is 10x20x30 cm')
print(result.data)
#> width=10 height=20 depth=30 units='cm'

```

_(This example is complete, it can be run "as is")_
Here's an example of using a union return type which registered multiple tools, and wraps non-object schemas in an object:
colors_or_sizes.py```
from typing import Union
from pydantic_ai import Agent
agent: Agent[None, Union[list[str], list[int]]] = Agent(
  'openai:gpt-4o-mini',
  result_type=Union[list[str], list[int]], # type: ignore
  system_prompt='Extract either colors or sizes from the shapes provided.',
)
result = agent.run_sync('red square, blue circle, green triangle')
print(result.data)
#> ['red', 'blue', 'green']
result = agent.run_sync('square size 10, circle size 20, triangle size 30')
print(result.data)
#> [10, 20, 30]

```

_(This example is complete, it can be run "as is")_
### Result validators functions
Some validation is inconvenient or impossible to do in Pydantic validators, in particular when the validation requires IO and is asynchronous. PydanticAI provides a way to add validation functions via the `agent.result_validator`[](https://ai.pydantic.dev/results/<../api/agent/#pydantic_ai.agent.Agent.result_validator>) decorator.
Here's a simplified variant of the [SQL Generation example](https://ai.pydantic.dev/results/<../examples/sql-gen/>):
sql_gen.py```
from typing import Union
from fake_database import DatabaseConn, QueryError
from pydantic import BaseModel
from pydantic_ai import Agent, RunContext, ModelRetry

class Success(BaseModel):
  sql_query: str

class InvalidRequest(BaseModel):
  error_message: str

Response = Union[Success, InvalidRequest]
agent: Agent[DatabaseConn, Response] = Agent(
  'google-gla:gemini-1.5-flash',
  result_type=Response, # type: ignore
  deps_type=DatabaseConn,
  system_prompt='Generate PostgreSQL flavored SQL queries based on user input.',
)

@agent.result_validator
async def validate_result(ctx: RunContext[DatabaseConn], result: Response) -> Response:
  if isinstance(result, InvalidRequest):
    return result
  try:
    await ctx.deps.execute(f'EXPLAIN {result.sql_query}')
  except QueryError as e:
    raise ModelRetry(f'Invalid query: {e}') from e
  else:
    return result

result = agent.run_sync(
  'get me users who were last active yesterday.', deps=DatabaseConn()
)
print(result.data)
#> sql_query='SELECT * FROM users WHERE last_active::date = today() - interval 1 day'

```

_(This example is complete, it can be run "as is")_
## Streamed Results
There two main challenges with streamed results:
  1. Validating structured responses before they're complete, this is achieved by "partial validation" which was recently added to Pydantic in [pydantic/pydantic#10748](https://ai.pydantic.dev/results/<https:/github.com/pydantic/pydantic/pull/10748>).
  2. When receiving a response, we don't know if it's the final response without starting to stream it and peeking at the content. PydanticAI streams just enough of the response to sniff out if it's a tool call or a result, then streams the whole thing and calls tools, or returns the stream as a `StreamedRunResult`[](https://ai.pydantic.dev/results/<../api/result/#pydantic_ai.result.StreamedRunResult>).


### Streaming Text
Example of streamed text result:
streamed_hello_world.py```
from pydantic_ai import Agent
agent = Agent('google-gla:gemini-1.5-flash') 
Streaming works with the standard Agent[](https://ai.pydantic.dev/results/<../api/agent/#pydantic_ai.agent.Agent>) class, and doesn't require any special setup, just a model that supports streaming (currently all models support streaming).
[](https://ai.pydantic.dev/results/<#__code_4_annotation_1>)

async def main():
  async with agent.run_stream('Where does "hello world" come from?') as result: 
The Agent.run_stream()[](https://ai.pydantic.dev/results/<../api/agent/#pydantic_ai.agent.Agent.run_stream>) method is used to start a streamed run, this method returns a context manager so the connection can be closed when the stream completes.
[](https://ai.pydantic.dev/results/<#__code_4_annotation_2>)
    async for message in result.stream_text(): 
Each item yield by StreamedRunResult.stream_text()[](https://ai.pydantic.dev/results/<../api/result/#pydantic_ai.result.StreamedRunResult.stream_text>) is the complete text response, extended as new data is received.
[](https://ai.pydantic.dev/results/<#__code_4_annotation_3>)
      print(message)
      #> The first known
      #> The first known use of "hello,
      #> The first known use of "hello, world" was in
      #> The first known use of "hello, world" was in a 1974 textbook
      #> The first known use of "hello, world" was in a 1974 textbook about the C
      #> The first known use of "hello, world" was in a 1974 textbook about the C programming language.

```

_(This example is complete, it can be run "as is" — you'll need to add`asyncio.run(main())` to run `main`)_
We can also stream text as deltas rather than the entire text in each item:
streamed_delta_hello_world.py```
from pydantic_ai import Agent
agent = Agent('google-gla:gemini-1.5-flash')

async def main():
  async with agent.run_stream('Where does "hello world" come from?') as result:
    async for message in result.stream_text(delta=True): 
stream_text[](https://ai.pydantic.dev/results/<../api/result/#pydantic_ai.result.StreamedRunResult.stream_text>) will error if the response is not text
[](https://ai.pydantic.dev/results/<#__code_5_annotation_1>)
      print(message)
      #> The first known
      #> use of "hello,
      #> world" was in
      #> a 1974 textbook
      #> about the C
      #> programming language.

```

_(This example is complete, it can be run "as is" — you'll need to add`asyncio.run(main())` to run `main`)_
Result message not included in `messages`
The final result message will **NOT** be added to result messages if you use `.stream_text(delta=True)`, see [Messages and chat history](https://ai.pydantic.dev/results/<../message-history/>) for more information.
### Streaming Structured Responses
Not all types are supported with partial validation in Pydantic, see [pydantic/pydantic#10748](https://ai.pydantic.dev/results/<https:/github.com/pydantic/pydantic/pull/10748>), generally for model-like structures it's currently best to use `TypeDict`.
Here's an example of streaming a use profile as it's built:
streamed_user_profile.py```
from datetime import date
from typing_extensions import TypedDict
from pydantic_ai import Agent

class UserProfile(TypedDict, total=False):
  name: str
  dob: date
  bio: str

agent = Agent(
  'openai:gpt-4o',
  result_type=UserProfile,
  system_prompt='Extract a user profile from the input',
)

async def main():
  user_input = 'My name is Ben, I was born on January 28th 1990, I like the chain the dog and the pyramid.'
  async with agent.run_stream(user_input) as result:
    async for profile in result.stream():
      print(profile)
      #> {'name': 'Ben'}
      #> {'name': 'Ben'}
      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes'}
      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the '}
      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyr'}
      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}
      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}

```

_(This example is complete, it can be run "as is" — you'll need to add`asyncio.run(main())` to run `main`)_
If you want fine-grained control of validation, particularly catching validation errors, you can use the following pattern:
streamed_user_profile.py```
from datetime import date
from pydantic import ValidationError
from typing_extensions import TypedDict
from pydantic_ai import Agent

class UserProfile(TypedDict, total=False):
  name: str
  dob: date
  bio: str

agent = Agent('openai:gpt-4o', result_type=UserProfile)

async def main():
  user_input = 'My name is Ben, I was born on January 28th 1990, I like the chain the dog and the pyramid.'
  async with agent.run_stream(user_input) as result:
    async for message, last in result.stream_structured(debounce_by=0.01): 
stream_structured[](https://ai.pydantic.dev/results/<../api/result/#pydantic_ai.result.StreamedRunResult.stream_structured>) streams the data as ModelResponse[](https://ai.pydantic.dev/results/<../api/messages/#pydantic_ai.messages.ModelResponse>) objects, thus iteration can't fail with a ValidationError.
[](https://ai.pydantic.dev/results/<#__code_7_annotation_1>)
      try:
        profile = await result.validate_structured_result( 
validate_structured_result[](https://ai.pydantic.dev/results/<../api/result/#pydantic_ai.result.StreamedRunResult.validate_structured_result>) validates the data, allow_partial=True enables pydantic's experimental_allow_partial flag on TypeAdapter[](https://ai.pydantic.dev/results/<https:/docs.pydantic.dev/latest/api/type_adapter/#pydantic.type_adapter.TypeAdapter.validate_json>).
[](https://ai.pydantic.dev/results/<#__code_7_annotation_2>)
          message,
          allow_partial=not last,
        )
      except ValidationError:
        continue
      print(profile)
      #> {'name': 'Ben'}
      #> {'name': 'Ben'}
      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes'}
      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the '}
      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyr'}
      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}
      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}

```

_(This example is complete, it can be run "as is" — you'll need to add`asyncio.run(main())` to run `main`)_
## Examples
The following examples demonstrate how to use streamed responses in PydanticAI:
  * [Stream markdown](https://ai.pydantic.dev/results/<../examples/stream-markdown/>)
  * [Stream Whales](https://ai.pydantic.dev/results/<../examples/stream-whales/>)


© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/testing-evals.md
================
[ Skip to content ](https://ai.pydantic.dev/testing-evals/<#testing-and-evals>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/testing-evals/<..> "PydanticAI")
PydanticAI 
Testing and Evals 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/testing-evals/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/testing-evals/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/testing-evals/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/testing-evals/<..>)
  * [ Installation  ](https://ai.pydantic.dev/testing-evals/<../install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/testing-evals/<../help/>)
  * [ Contributing  ](https://ai.pydantic.dev/testing-evals/<../contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/testing-evals/<../troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/testing-evals/<../agents/>)
    * [ Models  ](https://ai.pydantic.dev/testing-evals/<../models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/testing-evals/<../dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/testing-evals/<../tools/>)
    * [ Results  ](https://ai.pydantic.dev/testing-evals/<../results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/testing-evals/<../message-history/>)
    * Testing and Evals  [ Testing and Evals  ](https://ai.pydantic.dev/testing-evals/<./>) Table of contents 
      * [ Unit tests  ](https://ai.pydantic.dev/testing-evals/<#unit-tests>)
        * [ Unit testing with TestModel  ](https://ai.pydantic.dev/testing-evals/<#unit-testing-with-testmodel>)
        * [ Unit testing with FunctionModel  ](https://ai.pydantic.dev/testing-evals/<#unit-testing-with-functionmodel>)
        * [ Overriding model via pytest fixtures  ](https://ai.pydantic.dev/testing-evals/<#overriding-model-via-pytest-fixtures>)
      * [ Evals  ](https://ai.pydantic.dev/testing-evals/<#evals>)
        * [ Measuring performance  ](https://ai.pydantic.dev/testing-evals/<#measuring-performance>)
        * [ System prompt customization  ](https://ai.pydantic.dev/testing-evals/<#system-prompt-customization>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/testing-evals/<../logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/testing-evals/<../multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/testing-evals/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/testing-evals/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/testing-evals/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/testing-evals/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/testing-evals/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/testing-evals/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/testing-evals/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/testing-evals/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/testing-evals/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/testing-evals/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/testing-evals/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/testing-evals/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/testing-evals/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/testing-evals/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/testing-evals/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/testing-evals/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/testing-evals/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/testing-evals/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/testing-evals/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/testing-evals/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/testing-evals/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/testing-evals/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/testing-evals/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/testing-evals/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/testing-evals/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/testing-evals/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/testing-evals/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/testing-evals/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/testing-evals/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/testing-evals/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/testing-evals/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/testing-evals/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/testing-evals/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/testing-evals/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/testing-evals/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Unit tests  ](https://ai.pydantic.dev/testing-evals/<#unit-tests>)
    * [ Unit testing with TestModel  ](https://ai.pydantic.dev/testing-evals/<#unit-testing-with-testmodel>)
    * [ Unit testing with FunctionModel  ](https://ai.pydantic.dev/testing-evals/<#unit-testing-with-functionmodel>)
    * [ Overriding model via pytest fixtures  ](https://ai.pydantic.dev/testing-evals/<#overriding-model-via-pytest-fixtures>)
  * [ Evals  ](https://ai.pydantic.dev/testing-evals/<#evals>)
    * [ Measuring performance  ](https://ai.pydantic.dev/testing-evals/<#measuring-performance>)
    * [ System prompt customization  ](https://ai.pydantic.dev/testing-evals/<#system-prompt-customization>)


  1. [ Introduction  ](https://ai.pydantic.dev/testing-evals/<..>)
  2. [ Documentation  ](https://ai.pydantic.dev/testing-evals/<../agents/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/testing-evals/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/testing-evals/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Testing and Evals
With PydanticAI and LLM integrations in general, there are two distinct kinds of test:
  1. **Unit tests** — tests of your application code, and whether it's behaving correctly
  2. **Evals** — tests of the LLM, and how good or bad its responses are


For the most part, these two kinds of tests have pretty separate goals and considerations.
## Unit tests
Unit tests for PydanticAI code are just like unit tests for any other Python code.
Because for the most part they're nothing new, we have pretty well established tools and patterns for writing and running these kinds of tests.
Unless you're really sure you know better, you'll probably want to follow roughly this strategy:
  * Use `pytest`[](https://ai.pydantic.dev/testing-evals/<https:/docs.pytest.org/en/stable/>) as your test harness
  * If you find yourself typing out long assertions, use [inline-snapshot](https://ai.pydantic.dev/testing-evals/<https:/15r10nk.github.io/inline-snapshot/latest/>)
  * Similarly, [dirty-equals](https://ai.pydantic.dev/testing-evals/<https:/dirty-equals.helpmanual.io/latest/>) can be useful for comparing large data structures
  * Use `TestModel`[](https://ai.pydantic.dev/testing-evals/<../api/models/test/#pydantic_ai.models.test.TestModel>) or `FunctionModel`[](https://ai.pydantic.dev/testing-evals/<../api/models/function/#pydantic_ai.models.function.FunctionModel>) in place of your actual model to avoid the usage, latency and variability of real LLM calls
  * Use `Agent.override`[](https://ai.pydantic.dev/testing-evals/<../api/agent/#pydantic_ai.agent.Agent.override>) to replace your model inside your application logic
  * Set `ALLOW_MODEL_REQUESTS=False`[](https://ai.pydantic.dev/testing-evals/<../api/models/base/#pydantic_ai.models.ALLOW_MODEL_REQUESTS>) globally to block any requests from being made to non-test models accidentally


### Unit testing with `TestModel`
The simplest and fastest way to exercise most of your application code is using `TestModel`[](https://ai.pydantic.dev/testing-evals/<../api/models/test/#pydantic_ai.models.test.TestModel>), this will (by default) call all tools in the agent, then return either plain text or a structured response depending on the return type of the agent.
`TestModel` is not magic
The "clever" (but not too clever) part of `TestModel` is that it will attempt to generate valid structured data for [function tools](https://ai.pydantic.dev/testing-evals/<../tools/>) and [result types](https://ai.pydantic.dev/testing-evals/<../results/#structured-result-validation>) based on the schema of the registered tools.
There's no ML or AI in `TestModel`, it's just plain old procedural Python code that tries to generate data that satisfies the JSON schema of a tool.
The resulting data won't look pretty or relevant, but it should pass Pydantic's validation in most cases. If you want something more sophisticated, use `FunctionModel`[](https://ai.pydantic.dev/testing-evals/<../api/models/function/#pydantic_ai.models.function.FunctionModel>) and write your own data generation logic.
Let's write unit tests for the following application code:
weather_app.py```
import asyncio
from datetime import date
from pydantic_ai import Agent, RunContext
from fake_database import DatabaseConn 
DatabaseConn is a class that holds a database connection
[](https://ai.pydantic.dev/testing-evals/<#__code_0_annotation_1>)
from weather_service import WeatherService 
WeatherService has methods to get weather forecasts and historic data about the weather
[](https://ai.pydantic.dev/testing-evals/<#__code_0_annotation_2>)
weather_agent = Agent(
  'openai:gpt-4o',
  deps_type=WeatherService,
  system_prompt='Providing a weather forecast at the locations the user provides.',
)

@weather_agent.tool
def weather_forecast(
  ctx: RunContext[WeatherService], location: str, forecast_date: date
) -> str:
  if forecast_date < date.today(): 
We need to call a different endpoint depending on whether the date is in the past or the future, you'll see why this nuance is important below
[](https://ai.pydantic.dev/testing-evals/<#__code_0_annotation_3>)
    return ctx.deps.get_historic_weather(location, forecast_date)
  else:
    return ctx.deps.get_forecast(location, forecast_date)

async def run_weather_forecast( 
This function is the code we want to test, together with the agent it uses
[](https://ai.pydantic.dev/testing-evals/<#__code_0_annotation_4>)
  user_prompts: list[tuple[str, int]], conn: DatabaseConn
):
"""Run weather forecast for a list of user prompts and save."""
  async with WeatherService() as weather_service:
    async def run_forecast(prompt: str, user_id: int):
      result = await weather_agent.run(prompt, deps=weather_service)
      await conn.store_forecast(user_id, result.data)
    # run all prompts in parallel
    await asyncio.gather(
      *(run_forecast(prompt, user_id) for (prompt, user_id) in user_prompts)
    )

```

Here we have a function that takes a list of `(user_prompt, user_id)` tuples, gets a weather forecast for each prompt, and stores the result in the database.
**We want to test this code without having to mock certain objects or modify our code so we can pass test objects in.**
Here's how we would write tests using `TestModel`[](https://ai.pydantic.dev/testing-evals/<../api/models/test/#pydantic_ai.models.test.TestModel>):
test_weather_app.py```
from datetime import timezone
import pytest
from dirty_equals import IsNow
from pydantic_ai import models, capture_run_messages
from pydantic_ai.models.test import TestModel
from pydantic_ai.messages import (
  ModelResponse,
  SystemPromptPart,
  TextPart,
  ToolCallPart,
  ToolReturnPart,
  UserPromptPart,
  ModelRequest,
)
from fake_database import DatabaseConn
from weather_app import run_weather_forecast, weather_agent
pytestmark = pytest.mark.anyio 
We're using anyio[](https://ai.pydantic.dev/testing-evals/<https:/anyio.readthedocs.io/en/stable/>) to run async tests.
[](https://ai.pydantic.dev/testing-evals/<#__code_1_annotation_1>)
models.ALLOW_MODEL_REQUESTS = False 
This is a safety measure to make sure we don't accidentally make real requests to the LLM while testing, see ALLOW_MODEL_REQUESTS[](https://ai.pydantic.dev/testing-evals/<../api/models/base/#pydantic_ai.models.ALLOW_MODEL_REQUESTS>) for more details.
[](https://ai.pydantic.dev/testing-evals/<#__code_1_annotation_2>)

async def test_forecast():
  conn = DatabaseConn()
  user_id = 1
  with capture_run_messages() as messages:
    with weather_agent.override(model=TestModel()): 
We're using Agent.override[](https://ai.pydantic.dev/testing-evals/<../api/agent/#pydantic_ai.agent.Agent.override>) to replace the agent's model with TestModel[](https://ai.pydantic.dev/testing-evals/<../api/models/test/#pydantic_ai.models.test.TestModel>), the nice thing about override is that we can replace the model inside agent without needing access to the agent run* methods call site.
[](https://ai.pydantic.dev/testing-evals/<#__code_1_annotation_3>)
      prompt = 'What will the weather be like in London on 2024-11-28?'
      await run_weather_forecast([(prompt, user_id)], conn) 
Now we call the function we want to test inside the override context manager.
[](https://ai.pydantic.dev/testing-evals/<#__code_1_annotation_4>)
  forecast = await conn.get_forecast(user_id)
  assert forecast == '{"weather_forecast":"Sunny with a chance of rain"}' 
But default, TestModel will return a JSON string summarising the tools calls made, and what was returned. If you wanted to customise the response to something more closely aligned with the domain, you could add custom_result_text='Sunny'[](https://ai.pydantic.dev/testing-evals/<../api/models/test/#pydantic_ai.models.test.TestModel.custom_result_text>) when defining TestModel.
[](https://ai.pydantic.dev/testing-evals/<#__code_1_annotation_5>)
  assert messages == [ 
So far we don't actually know which tools were called and with which values, we can use capture_run_messages[](https://ai.pydantic.dev/testing-evals/<../api/agent/#pydantic_ai.agent.capture_run_messages>) to inspect messages from the most recent run and assert the exchange between the agent and the model occurred as expected.
[](https://ai.pydantic.dev/testing-evals/<#__code_1_annotation_6>)
    ModelRequest(
      parts=[
        SystemPromptPart(
          content='Providing a weather forecast at the locations the user provides.',
        ),
        UserPromptPart(
          content='What will the weather be like in London on 2024-11-28?',
          timestamp=IsNow(tz=timezone.utc), 
The IsNow[](https://ai.pydantic.dev/testing-evals/<https:/dirty-equals.helpmanual.io/latest/types/datetime/#dirty_equals.IsNow>) helper allows us to use declarative asserts even with data which will contain timestamps that change over time.
[](https://ai.pydantic.dev/testing-evals/<#__code_1_annotation_7>)
        ),
      ]
    ),
    ModelResponse(
      parts=[
        ToolCallPart(
          tool_name='weather_forecast',
          args={
            'location': 'a',
            'forecast_date': '2024-01-01', 
TestModel isn't doing anything clever to extract values from the prompt, so these values are hardcoded.
[](https://ai.pydantic.dev/testing-evals/<#__code_1_annotation_8>)
          },
          tool_call_id=None,
        )
      ],
      model_name='test',
      timestamp=IsNow(tz=timezone.utc),
    ),
    ModelRequest(
      parts=[
        ToolReturnPart(
          tool_name='weather_forecast',
          content='Sunny with a chance of rain',
          tool_call_id=None,
          timestamp=IsNow(tz=timezone.utc),
        ),
      ],
    ),
    ModelResponse(
      parts=[
        TextPart(
          content='{"weather_forecast":"Sunny with a chance of rain"}',
        )
      ],
      model_name='test',
      timestamp=IsNow(tz=timezone.utc),
    ),
  ]

```

### Unit testing with `FunctionModel`
The above tests are a great start, but careful readers will notice that the `WeatherService.get_forecast` is never called since `TestModel` calls `weather_forecast` with a date in the past.
To fully exercise `weather_forecast`, we need to use `FunctionModel`[](https://ai.pydantic.dev/testing-evals/<../api/models/function/#pydantic_ai.models.function.FunctionModel>) to customise how the tools is called.
Here's an example of using `FunctionModel` to test the `weather_forecast` tool with custom inputs
test_weather_app2.py```
import re
import pytest
from pydantic_ai import models
from pydantic_ai.messages import (
  ModelMessage,
  ModelResponse,
  TextPart,
  ToolCallPart,
)
from pydantic_ai.models.function import AgentInfo, FunctionModel
from fake_database import DatabaseConn
from weather_app import run_weather_forecast, weather_agent
pytestmark = pytest.mark.anyio
models.ALLOW_MODEL_REQUESTS = False

def call_weather_forecast( 
We define a function call_weather_forecast that will be called by FunctionModel in place of the LLM, this function has access to the list of ModelMessage[](https://ai.pydantic.dev/testing-evals/<../api/messages/#pydantic_ai.messages.ModelMessage>)s that make up the run, and AgentInfo[](https://ai.pydantic.dev/testing-evals/<../api/models/function/#pydantic_ai.models.function.AgentInfo>) which contains information about the agent and the function tools and return tools.
[](https://ai.pydantic.dev/testing-evals/<#__code_2_annotation_1>)
  messages: list[ModelMessage], info: AgentInfo
) -> ModelResponse:
  if len(messages) == 1:
    # first call, call the weather forecast tool
    user_prompt = messages[0].parts[-1]
    m = re.search(r'\d{4}-\d{2}-\d{2}', user_prompt.content)
    assert m is not None
    args = {'location': 'London', 'forecast_date': m.group()} 
Our function is slightly intelligent in that it tries to extract a date from the prompt, but just hard codes the location.
[](https://ai.pydantic.dev/testing-evals/<#__code_2_annotation_2>)
    return ModelResponse(parts=[ToolCallPart('weather_forecast', args)])
  else:
    # second call, return the forecast
    msg = messages[-1].parts[0]
    assert msg.part_kind == 'tool-return'
    return ModelResponse(parts=[TextPart(f'The forecast is: {msg.content}')])

async def test_forecast_future():
  conn = DatabaseConn()
  user_id = 1
  with weather_agent.override(model=FunctionModel(call_weather_forecast)): 
We use FunctionModel[](https://ai.pydantic.dev/testing-evals/<../api/models/function/#pydantic_ai.models.function.FunctionModel>) to replace the agent's model with our custom function.
[](https://ai.pydantic.dev/testing-evals/<#__code_2_annotation_3>)
    prompt = 'What will the weather be like in London on 2032-01-01?'
    await run_weather_forecast([(prompt, user_id)], conn)
  forecast = await conn.get_forecast(user_id)
  assert forecast == 'The forecast is: Rainy with a chance of sun'

```

### Overriding model via pytest fixtures
If you're writing lots of tests that all require model to be overridden, you can use [pytest fixtures](https://ai.pydantic.dev/testing-evals/<https:/docs.pytest.org/en/6.2.x/fixture.html>) to override the model with `TestModel`[](https://ai.pydantic.dev/testing-evals/<../api/models/test/#pydantic_ai.models.test.TestModel>) or `FunctionModel`[](https://ai.pydantic.dev/testing-evals/<../api/models/function/#pydantic_ai.models.function.FunctionModel>) in a reusable way.
Here's an example of a fixture that overrides the model with `TestModel`:
tests.py```
import pytest
from weather_app import weather_agent
from pydantic_ai.models.test import TestModel

@pytest.fixture
def override_weather_agent():
  with weather_agent.override(model=TestModel()):
    yield

async def test_forecast(override_weather_agent: None):
  ...
  # test code here

```

## Evals
"Evals" refers to evaluating a models performance for a specific application.
Warning
Unlike unit tests, evals are an emerging art/science; anyone who claims to know for sure exactly how your evals should be defined can safely be ignored.
Evals are generally more like benchmarks than unit tests, they never "pass" although they do "fail"; you care mostly about how they change over time.
Since evals need to be run against the real model, then can be slow and expensive to run, you generally won't want to run them in CI for every commit.
### Measuring performance
The hardest part of evals is measuring how well the model has performed.
In some cases (e.g. an agent to generate SQL) there are simple, easy to run tests that can be used to measure performance (e.g. is the SQL valid? Does it return the right results? Does it return just the right results?).
In other cases (e.g. an agent that gives advice on quitting smoking) it can be very hard or impossible to make quantitative measures of performance — in the smoking case you'd really need to run a double-blind trial over months, then wait 40 years and observe health outcomes to know if changes to your prompt were an improvement.
There are a few different strategies you can use to measure performance:
  * **End to end, self-contained tests** — like the SQL example, we can test the final result of the agent near-instantly
  * **Synthetic self-contained tests** — writing unit test style checks that the output is as expected, checks like `'chewing gum' in response`, while these checks might seem simplistic they can be helpful, one nice characteristic is that it's easy to tell what's wrong when they fail
  * **LLMs evaluating LLMs** — using another models, or even the same model with a different prompt to evaluate the performance of the agent (like when the class marks each other's homework because the teacher has a hangover), while the downsides and complexities of this approach are obvious, some think it can be a useful tool in the right circumstances
  * **Evals in prod** — measuring the end results of the agent in production, then creating a quantitative measure of performance, so you can easily measure changes over time as you change the prompt or model used, [logfire](https://ai.pydantic.dev/testing-evals/<../logfire/>) can be extremely useful in this case since you can write a custom query to measure the performance of your agent


### System prompt customization
The system prompt is the developer's primary tool in controlling an agent's behavior, so it's often useful to be able to customise the system prompt and see how performance changes. This is particularly relevant when the system prompt contains a list of examples and you want to understand how changing that list affects the model's performance.
Let's assume we have the following app for running SQL generated from a user prompt (this examples omits a lot of details for brevity, see the [SQL gen](https://ai.pydantic.dev/testing-evals/<../examples/sql-gen/>) example for a more complete code):
sql_app.py```
import json
from pathlib import Path
from typing import Union
from pydantic_ai import Agent, RunContext
from fake_database import DatabaseConn

class SqlSystemPrompt: 
The SqlSystemPrompt class is used to build the system prompt, it can be customised with a list of examples and a database type. We implement this as a separate class passed as a dep to the agent so we can override both the inputs and the logic during evals via dependency injection.
[](https://ai.pydantic.dev/testing-evals/<#__code_4_annotation_1>)
  def __init__(
    self, examples: Union[list[dict[str, str]], None] = None, db: str = 'PostgreSQL'
  ):
    if examples is None:
      # if examples aren't provided, load them from file, this is the default
      with Path('examples.json').open('rb') as f:
        self.examples = json.load(f)
    else:
      self.examples = examples
    self.db = db
  def build_prompt(self) -> str: 
The build_prompt method constructs the system prompt from the examples and the database type.
[](https://ai.pydantic.dev/testing-evals/<#__code_4_annotation_2>)
    return f"""\
Given the following {self.db} table of records, your job is to
write a SQL query that suits the user's request.
Database schema:
CREATE TABLE records (
 ...
);
{''.join(self.format_example(example)forexampleinself.examples)}
"""
  @staticmethod
  def format_example(example: dict[str, str]) -> str: 
Some people think that LLMs are more likely to generate good responses if examples are formatted as XML as it's to identify the end of a string, see #93[](https://ai.pydantic.dev/testing-evals/<https:/github.com/pydantic/pydantic-ai/issues/93>).
[](https://ai.pydantic.dev/testing-evals/<#__code_4_annotation_3>)
    return f"""\
<example>
 <request>{example['request']}</request>
 <sql>{example['sql']}</sql>
</example>
"""

sql_agent = Agent(
  'google-gla:gemini-1.5-flash',
  deps_type=SqlSystemPrompt,
)

@sql_agent.system_prompt
async def system_prompt(ctx: RunContext[SqlSystemPrompt]) -> str:
  return ctx.deps.build_prompt()

async def user_search(user_prompt: str) -> list[dict[str, str]]:
"""Search the database based on the user's prompts."""
  ... 
In reality, you would have more logic here, making it impractical to run the agent independently of the wider application.
[](https://ai.pydantic.dev/testing-evals/<#__code_4_annotation_4>)
  result = await sql_agent.run(user_prompt, deps=SqlSystemPrompt())
  conn = DatabaseConn()
  return await conn.execute(result.data)

```

`examples.json` looks something like this:
```
request: show me error records with the tag "foobar"
response: SELECT * FROM records WHERE level = 'error' and 'foobar' = ANY(tags)

```

examples.json```
{
"examples":[
{
"request":"Show me all records",
"sql":"SELECT * FROM records;"
},
{
"request":"Show me all records from 2021",
"sql":"SELECT * FROM records WHERE date_trunc('year', date) = '2021-01-01';"
},
{
"request":"show me error records with the tag 'foobar'",
"sql":"SELECT * FROM records WHERE level = 'error' and 'foobar' = ANY(tags);"
},
...
]
}

```

Now we want a way to quantify the success of the SQL generation so we can judge how changes to the agent affect its performance.
We can use `Agent.override`[](https://ai.pydantic.dev/testing-evals/<../api/agent/#pydantic_ai.agent.Agent.override>) to replace the system prompt with a custom one that uses a subset of examples, and then run the application code (in this case `user_search`). We also run the actual SQL from the examples and compare the "correct" result from the example SQL to the SQL generated by the agent. (We compare the results of running the SQL rather than the SQL itself since the SQL might be semantically equivalent but written in a different way).
To get a quantitative measure of performance, we assign points to each run as follows: * **-100** points if the generated SQL is invalid * **-1** point for each row returned by the agent (so returning lots of results is discouraged) * **+5** points for each row returned by the agent that matches the expected result
We use 5-fold cross-validation to judge the performance of the agent using our existing set of examples.
sql_app_evals.py```
import json
import statistics
from pathlib import Path
from itertools import chain
from fake_database import DatabaseConn, QueryError
from sql_app import sql_agent, SqlSystemPrompt, user_search

async def main():
  with Path('examples.json').open('rb') as f:
    examples = json.load(f)
  # split examples into 5 folds
  fold_size = len(examples) // 5
  folds = [examples[i : i + fold_size] for i in range(0, len(examples), fold_size)]
  conn = DatabaseConn()
  scores = []
  for i, fold in enumerate(folds, start=1):
    fold_score = 0
    # build all other folds into a list of examples
    other_folds = list(chain(*(f for j, f in enumerate(folds) if j != i)))
    # create a new system prompt with the other fold examples
    system_prompt = SqlSystemPrompt(examples=other_folds)
    # override the system prompt with the new one
    with sql_agent.override(deps=system_prompt):
      for case in fold:
        try:
          agent_results = await user_search(case['request'])
        except QueryError as e:
          print(f'Fold {i}{case}: {e}')
          fold_score -= 100
        else:
          # get the expected results using the SQL from this case
          expected_results = await conn.execute(case['sql'])
        agent_ids = [r['id'] for r in agent_results]
        # each returned value has a score of -1
        fold_score -= len(agent_ids)
        expected_ids = {r['id'] for r in expected_results}
        # each return value that matches the expected value has a score of 3
        fold_score += 5 * len(set(agent_ids) & expected_ids)
    scores.append(fold_score)
  overall_score = statistics.mean(scores)
  print(f'Overall score: {overall_score:0.2f}')
  #> Overall score: 12.00

```

We can then change the prompt, the model, or the examples and see how the score changes over time.
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/tools.md
================
[ Skip to content ](https://ai.pydantic.dev/tools/<#function-tools>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/tools/<..> "PydanticAI")
PydanticAI 
Function Tools 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/tools/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/tools/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/tools/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/tools/<..>)
  * [ Installation  ](https://ai.pydantic.dev/tools/<../install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/tools/<../help/>)
  * [ Contributing  ](https://ai.pydantic.dev/tools/<../contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/tools/<../troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/tools/<../agents/>)
    * [ Models  ](https://ai.pydantic.dev/tools/<../models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/tools/<../dependencies/>)
    * Function Tools  [ Function Tools  ](https://ai.pydantic.dev/tools/<./>) Table of contents 
      * [ Registering Function Tools via kwarg  ](https://ai.pydantic.dev/tools/<#registering-function-tools-via-kwarg>)
      * [ Function Tools vs. Structured Results  ](https://ai.pydantic.dev/tools/<#function-tools-vs-structured-results>)
      * [ Function tools and schema  ](https://ai.pydantic.dev/tools/<#function-tools-and-schema>)
      * [ Dynamic Function tools  ](https://ai.pydantic.dev/tools/<#tool-prepare>)
    * [ Results  ](https://ai.pydantic.dev/tools/<../results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/tools/<../message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/tools/<../testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/tools/<../logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/tools/<../multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/tools/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/tools/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/tools/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/tools/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/tools/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/tools/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/tools/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/tools/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/tools/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/tools/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/tools/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/tools/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/tools/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/tools/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/tools/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/tools/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/tools/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/tools/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/tools/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/tools/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/tools/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/tools/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/tools/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/tools/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/tools/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/tools/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/tools/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/tools/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/tools/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/tools/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/tools/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/tools/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/tools/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/tools/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/tools/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Registering Function Tools via kwarg  ](https://ai.pydantic.dev/tools/<#registering-function-tools-via-kwarg>)
  * [ Function Tools vs. Structured Results  ](https://ai.pydantic.dev/tools/<#function-tools-vs-structured-results>)
  * [ Function tools and schema  ](https://ai.pydantic.dev/tools/<#function-tools-and-schema>)
  * [ Dynamic Function tools  ](https://ai.pydantic.dev/tools/<#tool-prepare>)


  1. [ Introduction  ](https://ai.pydantic.dev/tools/<..>)
  2. [ Documentation  ](https://ai.pydantic.dev/tools/<../agents/>)


# Function Tools
Function tools provide a mechanism for models to retrieve extra information to help them generate a response.
They're useful when it is impractical or impossible to put all the context an agent might need into the system prompt, or when you want to make agents' behavior more deterministic or reliable by deferring some of the logic required to generate a response to another (not necessarily AI-powered) tool.
Function tools vs. RAG
Function tools are basically the "R" of RAG (Retrieval-Augmented Generation) — they augment what the model can do by letting it request extra information.
The main semantic difference between PydanticAI Tools and RAG is RAG is synonymous with vector search, while PydanticAI tools are more general-purpose. (Note: we may add support for vector search functionality in the future, particularly an API for generating embeddings. See [#58](https://ai.pydantic.dev/tools/<https:/github.com/pydantic/pydantic-ai/issues/58>))
There are a number of ways to register tools with an agent:
  * via the `@agent.tool`[](https://ai.pydantic.dev/tools/<../api/agent/#pydantic_ai.agent.Agent.tool>) decorator — for tools that need access to the agent [context](https://ai.pydantic.dev/tools/<../api/tools/#pydantic_ai.tools.RunContext>)
  * via the `@agent.tool_plain`[](https://ai.pydantic.dev/tools/<../api/agent/#pydantic_ai.agent.Agent.tool_plain>) decorator — for tools that do not need access to the agent [context](https://ai.pydantic.dev/tools/<../api/tools/#pydantic_ai.tools.RunContext>)
  * via the `tools`[](https://ai.pydantic.dev/tools/<../api/agent/#pydantic_ai.agent.Agent.__init__>) keyword argument to `Agent` which can take either plain functions, or instances of `Tool`[](https://ai.pydantic.dev/tools/<../api/tools/#pydantic_ai.tools.Tool>)


`@agent.tool` is considered the default decorator since in the majority of cases tools will need access to the agent context.
Here's an example using both:
dice_game.py```
import random
from pydantic_ai import Agent, RunContext
agent = Agent(
  'google-gla:gemini-1.5-flash', 
This is a pretty simple task, so we can use the fast and cheap Gemini flash model.
[](https://ai.pydantic.dev/tools/<#__code_0_annotation_1>)
  deps_type=str, 
We pass the user's name as the dependency, to keep things simple we use just the name as a string as the dependency.
[](https://ai.pydantic.dev/tools/<#__code_0_annotation_2>)
  system_prompt=(
    "You're a dice game, you should roll the die and see if the number "
    "you get back matches the user's guess. If so, tell them they're a winner. "
    "Use the player's name in the response."
  ),
)

@agent.tool_plain 
This tool doesn't need any context, it just returns a random number. You could probably use a dynamic system prompt in this case.
[](https://ai.pydantic.dev/tools/<#__code_0_annotation_3>)
def roll_die() -> str:
"""Roll a six-sided die and return the result."""
  return str(random.randint(1, 6))

@agent.tool 
This tool needs the player's name, so it uses RunContext to access dependencies which are just the player's name in this case.
[](https://ai.pydantic.dev/tools/<#__code_0_annotation_4>)
def get_player_name(ctx: RunContext[str]) -> str:
"""Get the player's name."""
  return ctx.deps

dice_result = agent.run_sync('My guess is 4', deps='Anne') 
Run the agent, passing the player's name as the dependency.
[](https://ai.pydantic.dev/tools/<#__code_0_annotation_5>)
print(dice_result.data)
#> Congratulations Anne, you guessed correctly! You're a winner!

```

_(This example is complete, it can be run "as is")_
Let's print the messages from that game to see what happened:
dice_game_messages.py```
from dice_game import dice_result
print(dice_result.all_messages())
"""
[
  ModelRequest(
    parts=[
      SystemPromptPart(
        content="You're a dice game, you should roll the die and see if the number you get back matches the user's guess. If so, tell them they're a winner. Use the player's name in the response.",
        dynamic_ref=None,
        part_kind='system-prompt',
      ),
      UserPromptPart(
        content='My guess is 4',
        timestamp=datetime.datetime(...),
        part_kind='user-prompt',
      ),
    ],
    kind='request',
  ),
  ModelResponse(
    parts=[
      ToolCallPart(
        tool_name='roll_die', args={}, tool_call_id=None, part_kind='tool-call'
      )
    ],
    model_name='function:model_logic',
    timestamp=datetime.datetime(...),
    kind='response',
  ),
  ModelRequest(
    parts=[
      ToolReturnPart(
        tool_name='roll_die',
        content='4',
        tool_call_id=None,
        timestamp=datetime.datetime(...),
        part_kind='tool-return',
      )
    ],
    kind='request',
  ),
  ModelResponse(
    parts=[
      ToolCallPart(
        tool_name='get_player_name',
        args={},
        tool_call_id=None,
        part_kind='tool-call',
      )
    ],
    model_name='function:model_logic',
    timestamp=datetime.datetime(...),
    kind='response',
  ),
  ModelRequest(
    parts=[
      ToolReturnPart(
        tool_name='get_player_name',
        content='Anne',
        tool_call_id=None,
        timestamp=datetime.datetime(...),
        part_kind='tool-return',
      )
    ],
    kind='request',
  ),
  ModelResponse(
    parts=[
      TextPart(
        content="Congratulations Anne, you guessed correctly! You're a winner!",
        part_kind='text',
      )
    ],
    model_name='function:model_logic',
    timestamp=datetime.datetime(...),
    kind='response',
  ),
]
"""

```

We can represent this with a diagram:
```
sequenceDiagram
  participant Agent
  participant LLM
  Note over Agent: Send prompts
  Agent ->> LLM: System: "You're a dice game..."<br>User: "My guess is 4"
  activate LLM
  Note over LLM: LLM decides to use<br>a tool
  LLM ->> Agent: Call tool<br>roll_die()
  deactivate LLM
  activate Agent
  Note over Agent: Rolls a six-sided die
  Agent -->> LLM: ToolReturn<br>"4"
  deactivate Agent
  activate LLM
  Note over LLM: LLM decides to use<br>another tool
  LLM ->> Agent: Call tool<br>get_player_name()
  deactivate LLM
  activate Agent
  Note over Agent: Retrieves player name
  Agent -->> LLM: ToolReturn<br>"Anne"
  deactivate Agent
  activate LLM
  Note over LLM: LLM constructs final response
  LLM ->> Agent: ModelResponse<br>"Congratulations Anne, ..."
  deactivate LLM
  Note over Agent: Game session complete
```

## Registering Function Tools via kwarg
As well as using the decorators, we can register tools via the `tools` argument to the `Agent`[ constructor](https://ai.pydantic.dev/tools/<../api/agent/#pydantic_ai.agent.Agent.__init__>). This is useful when you want to reuse tools, and can also give more fine-grained control over the tools.
dice_game_tool_kwarg.py```
import random
from pydantic_ai import Agent, RunContext, Tool

def roll_die() -> str:
"""Roll a six-sided die and return the result."""
  return str(random.randint(1, 6))

def get_player_name(ctx: RunContext[str]) -> str:
"""Get the player's name."""
  return ctx.deps

agent_a = Agent(
  'google-gla:gemini-1.5-flash',
  deps_type=str,
  tools=[roll_die, get_player_name], 
The simplest way to register tools via the Agent constructor is to pass a list of functions, the function signature is inspected to determine if the tool takes RunContext[](https://ai.pydantic.dev/tools/<../api/tools/#pydantic_ai.tools.RunContext>).
[](https://ai.pydantic.dev/tools/<#__code_2_annotation_1>)
)
agent_b = Agent(
  'google-gla:gemini-1.5-flash',
  deps_type=str,
  tools=[ 
agent_a and agent_b are identical — but we can use Tool[](https://ai.pydantic.dev/tools/<../api/tools/#pydantic_ai.tools.Tool>) to reuse tool definitions and give more fine-grained control over how tools are defined, e.g. setting their name or description, or using a custom prepare[](https://ai.pydantic.dev/tools/<#tool-prepare>) method.
[](https://ai.pydantic.dev/tools/<#__code_2_annotation_2>)
    Tool(roll_die, takes_ctx=False),
    Tool(get_player_name, takes_ctx=True),
  ],
)
dice_result = agent_b.run_sync('My guess is 4', deps='Anne')
print(dice_result.data)
#> Congratulations Anne, you guessed correctly! You're a winner!

```

_(This example is complete, it can be run "as is")_
## Function Tools vs. Structured Results
As the name suggests, function tools use the model's "tools" or "functions" API to let the model know what is available to call. Tools or functions are also used to define the schema(s) for structured responses, thus a model might have access to many tools, some of which call function tools while others end the run and return a result.
## Function tools and schema
Function parameters are extracted from the function signature, and all parameters except `RunContext` are used to build the schema for that tool call.
Even better, PydanticAI extracts the docstring from functions and (thanks to [griffe](https://ai.pydantic.dev/tools/<https:/mkdocstrings.github.io/griffe/>)) extracts parameter descriptions from the docstring and adds them to the schema.
[Griffe supports](https://ai.pydantic.dev/tools/<https:/mkdocstrings.github.io/griffe/reference/docstrings/#docstrings>) extracting parameter descriptions from `google`, `numpy`, and `sphinx` style docstrings. PydanticAI will infer the format to use based on the docstring, but you can explicitly set it using `docstring_format`[](https://ai.pydantic.dev/tools/<../api/tools/#pydantic_ai.tools.DocstringFormat>). You can also enforce parameter requirements by setting `require_parameter_descriptions=True`. This will raise a `UserError`[](https://ai.pydantic.dev/tools/<../api/exceptions/#pydantic_ai.exceptions.UserError>) if a parameter description is missing.
To demonstrate a tool's schema, here we use `FunctionModel`[](https://ai.pydantic.dev/tools/<../api/models/function/#pydantic_ai.models.function.FunctionModel>) to print the schema a model would receive:
tool_schema.py```
from pydantic_ai import Agent
from pydantic_ai.messages import ModelMessage, ModelResponse, TextPart
from pydantic_ai.models.function import AgentInfo, FunctionModel
agent = Agent()

@agent.tool_plain(docstring_format='google', require_parameter_descriptions=True)
def foobar(a: int, b: str, c: dict[str, list[float]]) -> str:
"""Get me foobar.
  Args:
    a: apple pie
    b: banana cake
    c: carrot smoothie
  """
  return f'{a}{b}{c}'

def print_schema(messages: list[ModelMessage], info: AgentInfo) -> ModelResponse:
  tool = info.function_tools[0]
  print(tool.description)
  #> Get me foobar.
  print(tool.parameters_json_schema)
"""
  {
    'properties': {
      'a': {'description': 'apple pie', 'title': 'A', 'type': 'integer'},
      'b': {'description': 'banana cake', 'title': 'B', 'type': 'string'},
      'c': {
        'additionalProperties': {'items': {'type': 'number'}, 'type': 'array'},
        'description': 'carrot smoothie',
        'title': 'C',
        'type': 'object',
      },
    },
    'required': ['a', 'b', 'c'],
    'type': 'object',
    'additionalProperties': False,
  }
  """
  return ModelResponse(parts=[TextPart('foobar')])

agent.run_sync('hello', model=FunctionModel(print_schema))

```

_(This example is complete, it can be run "as is")_
The return type of tool can be anything which Pydantic can serialize to JSON as some models (e.g. Gemini) support semi-structured return values, some expect text (OpenAI) but seem to be just as good at extracting meaning from the data. If a Python object is returned and the model expects a string, the value will be serialized to JSON.
If a tool has a single parameter that can be represented as an object in JSON schema (e.g. dataclass, TypedDict, pydantic model), the schema for the tool is simplified to be just that object.
Here's an example, we use `TestModel.agent_model_function_tools`[](https://ai.pydantic.dev/tools/<../api/models/test/#pydantic_ai.models.test.TestModel.agent_model_function_tools>) to inspect the tool schema that would be passed to the model.
single_parameter_tool.py```
from pydantic import BaseModel
from pydantic_ai import Agent
from pydantic_ai.models.test import TestModel
agent = Agent()

class Foobar(BaseModel):
"""This is a Foobar"""
  x: int
  y: str
  z: float = 3.14

@agent.tool_plain
def foobar(f: Foobar) -> str:
  return str(f)

test_model = TestModel()
result = agent.run_sync('hello', model=test_model)
print(result.data)
#> {"foobar":"x=0 y='a' z=3.14"}
print(test_model.agent_model_function_tools)
"""
[
  ToolDefinition(
    name='foobar',
    description='This is a Foobar',
    parameters_json_schema={
      'properties': {
        'x': {'title': 'X', 'type': 'integer'},
        'y': {'title': 'Y', 'type': 'string'},
        'z': {'default': 3.14, 'title': 'Z', 'type': 'number'},
      },
      'required': ['x', 'y'],
      'title': 'Foobar',
      'type': 'object',
    },
    outer_typed_dict_key=None,
  )
]
"""

```

_(This example is complete, it can be run "as is")_
## Dynamic Function tools
Tools can optionally be defined with another function: `prepare`, which is called at each step of a run to customize the definition of the tool passed to the model, or omit the tool completely from that step.
A `prepare` method can be registered via the `prepare` kwarg to any of the tool registration mechanisms:
  * `@agent.tool`[](https://ai.pydantic.dev/tools/<../api/agent/#pydantic_ai.agent.Agent.tool>) decorator
  * `@agent.tool_plain`[](https://ai.pydantic.dev/tools/<../api/agent/#pydantic_ai.agent.Agent.tool_plain>) decorator
  * `Tool`[](https://ai.pydantic.dev/tools/<../api/tools/#pydantic_ai.tools.Tool>) dataclass


The `prepare` method, should be of type `ToolPrepareFunc`[](https://ai.pydantic.dev/tools/<../api/tools/#pydantic_ai.tools.ToolPrepareFunc>), a function which takes `RunContext`[](https://ai.pydantic.dev/tools/<../api/tools/#pydantic_ai.tools.RunContext>) and a pre-built `ToolDefinition`[](https://ai.pydantic.dev/tools/<../api/tools/#pydantic_ai.tools.ToolDefinition>), and should either return that `ToolDefinition` with or without modifying it, return a new `ToolDefinition`, or return `None` to indicate this tools should not be registered for that step.
Here's a simple `prepare` method that only includes the tool if the value of the dependency is `42`.
As with the previous example, we use `TestModel`[](https://ai.pydantic.dev/tools/<../api/models/test/#pydantic_ai.models.test.TestModel>) to demonstrate the behavior without calling a real model.
tool_only_if_42.py```
from typing import Union
from pydantic_ai import Agent, RunContext
from pydantic_ai.tools import ToolDefinition
agent = Agent('test')

async def only_if_42(
  ctx: RunContext[int], tool_def: ToolDefinition
) -> Union[ToolDefinition, None]:
  if ctx.deps == 42:
    return tool_def

@agent.tool(prepare=only_if_42)
def hitchhiker(ctx: RunContext[int], answer: str) -> str:
  return f'{ctx.deps}{answer}'

result = agent.run_sync('testing...', deps=41)
print(result.data)
#> success (no tool calls)
result = agent.run_sync('testing...', deps=42)
print(result.data)
#> {"hitchhiker":"42 a"}

```

_(This example is complete, it can be run "as is")_
Here's a more complex example where we change the description of the `name` parameter to based on the value of `deps`
For the sake of variation, we create this tool using the `Tool`[](https://ai.pydantic.dev/tools/<../api/tools/#pydantic_ai.tools.Tool>) dataclass.
customize_name.py```
from __future__ import annotations
from typing import Literal
from pydantic_ai import Agent, RunContext
from pydantic_ai.models.test import TestModel
from pydantic_ai.tools import Tool, ToolDefinition

def greet(name: str) -> str:
  return f'hello {name}'

async def prepare_greet(
  ctx: RunContext[Literal['human', 'machine']], tool_def: ToolDefinition
) -> ToolDefinition | None:
  d = f'Name of the {ctx.deps} to greet.'
  tool_def.parameters_json_schema['properties']['name']['description'] = d
  return tool_def

greet_tool = Tool(greet, prepare=prepare_greet)
test_model = TestModel()
agent = Agent(test_model, tools=[greet_tool], deps_type=Literal['human', 'machine'])
result = agent.run_sync('testing...', deps='human')
print(result.data)
#> {"greet":"hello a"}
print(test_model.agent_model_function_tools)
"""
[
  ToolDefinition(
    name='greet',
    description='',
    parameters_json_schema={
      'properties': {
        'name': {
          'title': 'Name',
          'type': 'string',
          'description': 'Name of the human to greet.',
        }
      },
      'required': ['name'],
      'type': 'object',
      'additionalProperties': False,
    },
    outer_typed_dict_key=None,
  )
]
"""

```

_(This example is complete, it can be run "as is")_
© Pydantic Services Inc. 2024 to present

================
File: crawled_docs/troubleshooting.md
================
[ Skip to content ](https://ai.pydantic.dev/troubleshooting/<#troubleshooting>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/troubleshooting/<..> "PydanticAI")
PydanticAI 
Troubleshooting 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/troubleshooting/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/troubleshooting/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/troubleshooting/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/troubleshooting/<..>)
  * [ Installation  ](https://ai.pydantic.dev/troubleshooting/<../install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/troubleshooting/<../help/>)
  * [ Contributing  ](https://ai.pydantic.dev/troubleshooting/<../contributing/>)
  * Troubleshooting  [ Troubleshooting  ](https://ai.pydantic.dev/troubleshooting/<./>) Table of contents 
    * [ Jupyter Notebook Errors  ](https://ai.pydantic.dev/troubleshooting/<#jupyter-notebook-errors>)
      * [ RuntimeError: This event loop is already running  ](https://ai.pydantic.dev/troubleshooting/<#runtimeerror-this-event-loop-is-already-running>)
    * [ API Key Configuration  ](https://ai.pydantic.dev/troubleshooting/<#api-key-configuration>)
      * [ UserError: API key must be provided or set in the [MODEL]_API_KEY environment variable  ](https://ai.pydantic.dev/troubleshooting/<#usererror-api-key-must-be-provided-or-set-in-the-model_api_key-environment-variable>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/troubleshooting/<../agents/>)
    * [ Models  ](https://ai.pydantic.dev/troubleshooting/<../models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/troubleshooting/<../dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/troubleshooting/<../tools/>)
    * [ Results  ](https://ai.pydantic.dev/troubleshooting/<../results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/troubleshooting/<../message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/troubleshooting/<../testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/troubleshooting/<../logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/troubleshooting/<../multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/troubleshooting/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/troubleshooting/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/troubleshooting/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/troubleshooting/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/troubleshooting/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/troubleshooting/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/troubleshooting/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/troubleshooting/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/troubleshooting/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/troubleshooting/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/troubleshooting/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/troubleshooting/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/troubleshooting/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/troubleshooting/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/troubleshooting/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/troubleshooting/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/troubleshooting/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/troubleshooting/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/troubleshooting/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/troubleshooting/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/troubleshooting/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/troubleshooting/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/troubleshooting/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/troubleshooting/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/troubleshooting/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/troubleshooting/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/troubleshooting/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/troubleshooting/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/troubleshooting/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/troubleshooting/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/troubleshooting/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/troubleshooting/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/troubleshooting/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/troubleshooting/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/troubleshooting/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ Jupyter Notebook Errors  ](https://ai.pydantic.dev/troubleshooting/<#jupyter-notebook-errors>)
    * [ RuntimeError: This event loop is already running  ](https://ai.pydantic.dev/troubleshooting/<#runtimeerror-this-event-loop-is-already-running>)
  * [ API Key Configuration  ](https://ai.pydantic.dev/troubleshooting/<#api-key-configuration>)
    * [ UserError: API key must be provided or set in the [MODEL]_API_KEY environment variable  ](https://ai.pydantic.dev/troubleshooting/<#usererror-api-key-must-be-provided-or-set-in-the-model_api_key-environment-variable>)


# Troubleshooting
Below are suggestions on how to fix some common errors you might encounter while using PydanticAI. If the issue you're experiencing is not listed below or addressed in the documentation, please feel free to ask in the [Pydantic Slack](https://ai.pydantic.dev/troubleshooting/<../help/>) or create an issue on [GitHub](https://ai.pydantic.dev/troubleshooting/<https:/github.com/pydantic/pydantic-ai/issues>).
## Jupyter Notebook Errors
### `RuntimeError: This event loop is already running`
This error is caused by conflicts between the event loops in Jupyter notebook and PydanticAI's. One way to manage these conflicts is by using `nest-asyncio`[](https://ai.pydantic.dev/troubleshooting/<https:/pypi.org/project/nest-asyncio/>). Namely, before you execute any agent runs, do the following: 
```
import nest_asyncio
nest_asyncio.apply()

```

Note: This fix also applies to Google Colab. 
## API Key Configuration
### `UserError: API key must be provided or set in the [MODEL]_API_KEY environment variable`
If you're running into issues with setting the API key for your model, visit the [Models](https://ai.pydantic.dev/troubleshooting/<../models/>) page to learn more about how to set an environment variable and/or pass in an `api_key` argument.
© Pydantic Services Inc. 2024 to present

================
File: full_sites/www_bbc_com/innovation_artificial-intelligence_20250130_232010.md
================
[Skip to content](https://www.bbc.com/innovation/<#main-content>)
[British Broadcasting Corporation](https://www.bbc.com/innovation/</>)
[Register](https://www.bbc.com/innovation/<https:/session.bbc.com/session?action=register&userOrigin=BBCS_BBC&ptrt=https%3A%2F%2Fwww.bbc.com%2Finnovation%2Fartificial-intelligence>)
[Sign In](https://www.bbc.com/innovation/<https:/session.bbc.com/session?userOrigin=BBCS_BBC&ptrt=https%3A%2F%2Fwww.bbc.com%2Finnovation%2Fartificial-intelligence>)
  * [Home](https://www.bbc.com/innovation/</>)
  * [News](https://www.bbc.com/innovation/</news>)
  * [Sport](https://www.bbc.com/innovation/</sport>)
  * [Business](https://www.bbc.com/innovation/</business>)
  * [Innovation](https://www.bbc.com/innovation/</innovation>)
  * [Culture](https://www.bbc.com/innovation/</culture>)
  * [Arts](https://www.bbc.com/innovation/</arts>)
  * [Travel](https://www.bbc.com/innovation/</travel>)
  * [Earth](https://www.bbc.com/innovation/</future-planet>)
  * [Video](https://www.bbc.com/innovation/</video>)
  * [Live](https://www.bbc.com/innovation/</live>)


  * [Technology](https://www.bbc.com/innovation/</innovation/technology>)
  * [Science & Health](https://www.bbc.com/innovation/</innovation/science>)
  * [Artificial Intelligence](https://www.bbc.com/innovation/</innovation/artificial-intelligence>)
  * [AI v the Mind](https://www.bbc.com/innovation/</innovation/ai-v-the-mind>)


[Register](https://www.bbc.com/innovation/<https:/session.bbc.com/session?action=register&userOrigin=BBCS_BBC>)
[Sign In](https://www.bbc.com/innovation/<https:/session.bbc.com/session?userOrigin=BBCS_BBC>)
[Home](https://www.bbc.com/innovation/</>)
News
[Sport](https://www.bbc.com/innovation/</sport>)
Business
Innovation
Culture
Arts
Travel
Earth
[Video](https://www.bbc.com/innovation/</video>)
Live
[Audio](https://www.bbc.com/innovation/<https:/www.bbc.co.uk/sounds>)
[Weather](https://www.bbc.com/innovation/<https:/www.bbc.com/weather>)
[Newsletters](https://www.bbc.com/innovation/<https:/www.bbc.com/newsletters>)
# Artificial Intelligence
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![Illustration of DeepSeek logo in front of a Chinese flag](https://ichef.bbci.co.uk/news/480/cpsprodpb/fda2/live/ecd7bca0-de31-11ef-957d-39377e0b990a.jpg.webp)OpenAI says Chinese rivals using its work for their AI appsChatGPT maker says it will need extra protection from US government, following emergence of Chinese rival, DeepSeek.See more](https://www.bbc.com/innovation/</news/articles/c9vm1m8wpr9o>)
## Latest headlines
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![DeepSeek on the app store, showing it is ranked #1 overall.](https://ichef.bbci.co.uk/news/480/cpsprodpb/f1fb/live/f3437f10-dd6f-11ef-badc-3b0da2437492.jpg.webp)Be careful with DeepSeek, Australia says - so is it safe to use?Ed Husic is the first member of a Western government to raise privacy concerns about the Chinese chatbot.1 day agoTechnology](https://www.bbc.com/innovation/</news/articles/cx2k7r5nrvpo>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![Still of David TC Davies during a BBC studio interview ](https://ichef.bbci.co.uk/news/480/cpsprodpb/cc02/live/efa7c6a0-ddaf-11ef-a69b-6ddb4eb9391c.jpg.webp)Biased AI rejected my job applications, says ex-MPFormer Welsh Secretary David TC Davies says CV scanners rejected him over lack of a university degree. 2 days ago](https://www.bbc.com/innovation/</news/articles/c0m14m3kg7no>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![File picture showing workers in red tops and wearing face masks preparing laptops ahead of the Beijing 2022 Winter Olympics](https://ichef.bbci.co.uk/news/480/cpsprodpb/9498/live/5afdfae0-dd93-11ef-8e57-3d806936ced3.jpg.webp)UK will not be able to resist China's tech dominanceChina's AI success has come from policy and Chancellor Rachel Reeves's recent visit to China highlights the importance of a close relationship.2 days agoBusiness](https://www.bbc.com/innovation/</news/articles/c0rq0vyd549o>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![A trade on the New York Stock Exchange anxiously looks at screen with share prices](https://ichef.bbci.co.uk/news/480/cpsprodpb/d54c/live/27f31550-dda1-11ef-926a-cbf3c346618d.jpg.webp)US tech stocks steady after DeepSeek AI app shockDeepSeek's claim that its model was made at a fraction of the cost of its rivals has rocked the AI industry.2 days agoBusiness](https://www.bbc.com/innovation/</news/articles/c4gpq01rvd4o>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![A photo of the DeepSeek app, with the Chinese flag in the background](https://ichef.bbci.co.uk/news/480/cpsprodpb/3cb2/live/61ec64f0-dd4c-11ef-b20c-cf1b3bd7a488.jpg.webp)The Chinese AI app that has the world talkingA Chinese startup has built a low-cost AI model using less technologically advanced chips.2 days agoTechnology](https://www.bbc.com/innovation/</news/articles/c5yv5976z9po>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![This photo illustration shows the DeepSeek app on a mobile phone](https://ichef.bbci.co.uk/news/480/cpsprodpb/c10c/live/74752520-dd93-11ef-8e57-3d806936ced3.jpg.webp)DeepSeek shows AI's centre of power could shift away from USThe app's strong debut has shaken beliefs that the US would remain the unchallenged global AI superpower, writes the BBC's Marc Cieslak.2 days agoWorld](https://www.bbc.com/innovation/</news/articles/c9w5d9new0yo>)
## [ AI v the Mind](https://www.bbc.com/innovation/<https:/www.bbc.com/innovation/ai-v-the-mind>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![Illustration of a robotic hand holding a flower \(Credit: Estudio Santa Rita\)](https://ichef.bbci.co.uk/images/ic/480x270/p0kl2yn8.jpg.webp)Can a robot ever compete with the human hand?Our hands perform thousands of complex tasks every day – can artificial intelligence help robots match these extraordinary human appendages?21 Jan 2025Future](https://www.bbc.com/innovation/</future/article/20250121-why-hands-are-one-of-the-biggest-challenges-in-robotics>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![World's first recipient of an AI-powered bionic arm](https://ichef.bbci.co.uk/images/ic/480x270/p0kk9yff.jpg.webp)Meet the world's first recipient of an AI-powered bionic armSarah De Lagarde lost an arm and a leg after being hit by two trains in London. Now, she has an AI-powered arm.17 Jan 2025AI v the Mind](https://www.bbc.com/innovation/</reel/video/p0kk9s45/meet-the-world-s-first-recipient-of-an-ai-powered-bionic-arm>)
## Watch
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![Meet the world's first artist robot](https://ichef.bbci.co.uk/images/ic/480x270/p0jylsn7.jpg.webp)Meet the world's first artist robotWe find out how AI blurs the line between creation and automation, raising questions about the essence of art.18 Oct 2024Innovation](https://www.bbc.com/innovation/</reel/video/p0jylq65/ai-v-the-mind-meet-the-world-s-first-artist-robot>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![A tech firm stole our voices](https://ichef.bbci.co.uk/images/ic/480x270/p0jpr3nf.jpg.webp)'A tech firm stole our voices - then cloned and sold them'Two voice-over artists were listening to a podcast when they heard their own stolen AI-generated voices.19 Sep 2024Innovation](https://www.bbc.com/innovation/</reel/video/p0jpq13m/-a-tech-firm-stole-our-voices-then-cloned-and-sold-them->)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![Would you eat a meal dreamed up by a computer?](https://ichef.bbci.co.uk/images/ic/480x270/p0jl39yf.jpg.webp)Would you eat a meal dreamed up by a computer?AI v The Mind: We explore the world of food and ask if human expertise is the only way to deliver great flavour.23 Aug 2024Innovation](https://www.bbc.com/innovation/</reel/video/p0jl2lj0/would-you-eat-a-meal-dreamed-up-by-a-computer->)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![Century-old Olympics footage brought back to life](https://ichef.bbci.co.uk/images/ic/480x270/p0jhbwpw.jpg.webp)Century-old Olympics footage brought back to lifeA look through footage from the Paris 1924 Olympics gives viewers a chance to reflect on how much has changed.9 Aug 2024Sport](https://www.bbc.com/innovation/</reel/video/p0jh9gjs/century-old-olympics-footage-brought-back-to-life>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![How AI scouts sporting heroes of future at the Olympics](https://ichef.bbci.co.uk/images/ic/480x270/p0jh3rxr.jpg.webp)How AI scouts sporting heroes of future at the OlympicsA project using AI and sports science identifies potential future athletes from the crowds of Olympic fans.8 Aug 2024Sport](https://www.bbc.com/innovation/</reel/video/p0jh0d2y/how-ai-scouts-sporting-heroes-of-future-at-the-olympics>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![Can AI tell better jokes than a human?](https://ichef.bbci.co.uk/images/ic/480x270/p0jdl9hb.jpg.webp)Can AI tell funnier jokes than a human?In a clash of wit and technology, we bring together two unlikely adversaries: a comedian and an AI chatbot.26 Jul 2024Artificial Intelligence](https://www.bbc.com/innovation/</reel/video/p0jdknk8/ai-v-the-mind-can-ai-tell-better-jokes-than-a-human->)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![Watch the movie that rewrites itself](https://ichef.bbci.co.uk/images/ic/480x270/p0hzhyj9.jpg.webp)Watch the movie that rewrites itselfFilmmaker Gary Hustwit has created a documentary which can rewrite itself before every screening.7 Jun 2024Artificial Intelligence](https://www.bbc.com/innovation/</reel/video/p0hzhqr1/watch-the-movie-that-rewrites-itself>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![AI v The Mind](https://ichef.bbci.co.uk/images/ic/480x270/p0hv961m.jpg.webp)AI v The Mind: Who has the edge?In a new series, we will test the limits of the latest AI technology by pitting it against human experts.1 May 2024Artificial Intelligence](https://www.bbc.com/innovation/</reel/video/p0hv591s/ai-v-the-mind-who-has-the-edge->)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![How AI and deepfakes are changing politics](https://ichef.bbci.co.uk/images/ic/480x270/p0hkg4km.jpg.webp)How AI and deepfakes are changing politicsSome politicians have found themselves victims of deepfakes. Can the public trust politicians in the age of AI?12 Apr 2024Artificial Intelligence](https://www.bbc.com/innovation/</reel/video/p0hkflt4/how-ai-and-deepfakes-are-changing-politics>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![Motion capture](https://ichef.bbci.co.uk/images/ic/480x270/p078j70f.jpg.webp)Could this suit revolutionise motion capture?A company’s motion capture system offers access to advance animation capacities at an affordable price.14 Nov 2023Artificial Intelligence](https://www.bbc.com/innovation/</reel/video/p078j6pb/could-this-suit-revolutionise-motion-capture->)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![The chatbot redesigning death](https://ichef.bbci.co.uk/images/ic/480x270/p07n0jl4.jpg.webp)What happens to our digital lives when we die?Can technology help us keep a connection with lost loved ones?14 Nov 2023Artificial Intelligence](https://www.bbc.com/innovation/</reel/video/p07n0fz6/what-happens-to-our-digital-lives-when-we-die->)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![Fashion: Can AI predict future trends?](https://ichef.bbci.co.uk/images/ic/480x270/p06r449r.jpg.webp)Can artificial intelligence predict the future of fashion?Using AI to spot future fashion trends could also help reduce clothing waste. 14 Nov 2023Artificial Intelligence](https://www.bbc.com/innovation/</reel/video/p06qyg6f/can-artificial-intelligence-predict-the-future-of-fashion->)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![The tech keeping planes in the sky](https://ichef.bbci.co.uk/images/ic/480x270/p079xfxc.jpg.webp)The tech keeping planes in the skyThe team developing advanced flight safety aids in a small South African suburb.9 Nov 2023Artificial Intelligence](https://www.bbc.com/innovation/</reel/video/p079x98n/the-tech-keeping-planes-in-the-sky>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![When AI has an overactive imagination](https://ichef.bbci.co.uk/images/ic/480x270/p097d54b.jpg.webp)What happens when AI has an overactive imagination?Google DeepDream explores how artificial intelligence can produce dream-like art. 9 Nov 2023Artificial Intelligence](https://www.bbc.com/innovation/</reel/video/p093h7hr/what-happens-when-ai-has-an-overactive-imagination->)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![Half robot half woman](https://ichef.bbci.co.uk/images/ic/480x270/p0gdlldn.jpg.webp)ChatGPT: Why we're still smarter than machinesChatGPT has been hailed as a game-changer, but how smart are AI chatbots really? 9 Nov 2023Artificial Intelligence](https://www.bbc.com/innovation/</reel/video/p0fc9tlx/chatgpt-why-we-re-still-smarter-than-machines>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![God and robots: Will AI transform religion?](https://ichef.bbci.co.uk/images/ic/480x270/p09z7zzv.jpg.webp)God and robots: Will AI transform religion?AI is changing how we interact with everything – from food to healthcare, travel and also religion.9 Nov 2023Artificial Intelligence](https://www.bbc.com/innovation/</reel/video/p09z6fnd/god-and-robots-will-ai-transform-religion->)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![Using AI to decode animal languages](https://ichef.bbci.co.uk/images/ic/480x270/p0fw39m3.jpg.webp)How artificial intelligence is helping us talk to animalsScientists are exploring the possibilities of using AI in communicating with other species.9 Nov 2023Artificial Intelligence](https://www.bbc.com/innovation/</reel/video/p0fw36yv/how-artificial-intelligence-is-helping-us-talk-to-animals>)
[![](https://www.bbc.com/bbcx/grey-placeholder.png)![Getty Images 1404749040](https://ichef.bbci.co.uk/images/ic/480x270/p0f7nqp3.jpg.webp)Can artificial intelligence ever be sentient?Is it possible for artificial intelligence to develop consciousness and dream up emotions?9 Nov 2023Artificial Intelligence](https://www.bbc.com/innovation/</reel/video/p0f73vlw/can-artificial-intelligence-ever-be-sentient->)
## More artificial intelligence
[2 days ago![](https://www.bbc.com/bbcx/grey-placeholder.png)![A Chinese woman checks her phone, with a sign in the background reads "I heart Beijing"](https://ichef.bbci.co.uk/news/480/cpsprodpb/a483/live/4646bcc0-dd5e-11ef-8e2a-672c89b13e12.jpg.webp)How China's 'AI heroes' overcame US curbs to stun Silicon ValleyHow did a little-known Chinese start-up build a powerful new AI model despite restrictions? 2 days agoAsia](https://www.bbc.com/innovation/</news/articles/czepw096wy4o>)
[2 days ago![](https://www.bbc.com/bbcx/grey-placeholder.png)![Zoe Kleinman holding a mobile phone, stood in front of a screen with the DeepSeek logo on \(a purple whale\)](https://ichef.bbci.co.uk/news/480/cpsprodpb/112e/live/80305120-dd5a-11ef-bc01-8f2c83dad217.png.webp)Watch DeepSeek AI bot respond to question about China The BBC tests out the tool to see what type of answers it can and will give.2 days agoTechnology](https://www.bbc.com/innovation/</news/videos/c77rd5ddxn8o>)
[2 days ago![](https://www.bbc.com/bbcx/grey-placeholder.png)![BBC's Mark Cieslak](https://ichef.bbci.co.uk/news/480/cpsprodpb/d19b/live/d8a27ed0-dd43-11ef-a37f-eba91255dc3d.jpg.webp)BBC's AI correspondent explains why DeepSeek has caused shockwavesThe Chinese-based large language model is disrupting the AI industry and the stock market. 2 days agoTechnology](https://www.bbc.com/innovation/</news/videos/cly9lpx8xdko>)
[3 days ago![](https://www.bbc.com/bbcx/grey-placeholder.png)![Deepseek and ChatGPT app icons are seen in this illustration](https://ichef.bbci.co.uk/news/480/cpsprodpb/d9ff/live/3937d420-dd35-11ef-a37f-eba91255dc3d.jpg.webp)China's DeepSeek AI shakes industry and dents America's swaggerThe app spooked the markets as well as the bullish sense of American superiority in AI development.3 days agoTechnology](https://www.bbc.com/innovation/</news/articles/cd643wx888qo>)
[3 days ago![](https://www.bbc.com/bbcx/grey-placeholder.png)![A close up of Jensen Huang, chief executive of Nvidia](https://ichef.bbci.co.uk/news/480/cpsprodpb/da3d/live/808e7750-dd05-11ef-bdbb-4dd18d390726.jpg.webp)Nvidia shares sink as Chinese AI app spooks marketsShare prices in US and European firms fall as the Chinese technology threatens to disrupt the AI industry.3 days agoTechnology](https://www.bbc.com/innovation/</news/articles/c0qw7z2v1pgo>)
[3 days ago![](https://www.bbc.com/bbcx/grey-placeholder.png)![A phone screen with the DeepSeek logo, a cartoon purple whale.](https://ichef.bbci.co.uk/news/480/cpsprodpb/f331/live/2b4d01b0-dcd0-11ef-a37f-eba91255dc3d.jpg.webp)Is China's AI tool DeepSeek as good as it seems?The artificial intelligence (AI) tool has shocked US markets after bursting onto the scene.3 days agoTechnology](https://www.bbc.com/innovation/</news/articles/cx2jxvn0r51o>)
[5 days ago![](https://www.bbc.com/bbcx/grey-placeholder.png)![Sir Paul performs during his Got Back tour in London in December 2024 - he's in a blue suit and shirt playing the guitar on stage ](https://ichef.bbci.co.uk/news/480/cpsprodpb/0fae/live/d2c48ab0-da66-11ef-8711-bbcda1499774.jpg.webp)Paul McCartney: Don't let AI rip off artistsThe Beatle calls on the UK government to reconsider proposed changes to copyright law.5 days agoCulture](https://www.bbc.com/innovation/</news/articles/c8xqv9g8442o>)
[5 days ago![](https://www.bbc.com/bbcx/grey-placeholder.png)![Mannequin heads with hands holding phones coming out of them with a blue background \(Credit: Serenity Strull/BBC/Getty Images\)](https://ichef.bbci.co.uk/images/ic/480x270/p0klpkzk.jpg.webp)'Grief apps' are turning death into dataPeople are turning to 'grief apps' to cope with the loss of family and friends. But the new world of death data raises troubling questions.5 days agoFuture](https://www.bbc.com/innovation/</future/article/20250123-the-apps-turning-grief-into-data-points>)
[5 days ago![](https://www.bbc.com/bbcx/grey-placeholder.png)![Two white plugs and black mould on a bedroom wall.](https://ichef.bbci.co.uk/news/480/cpsprodpb/b71d/live/89aec580-d99d-11ef-941c-57ca5bda0a5e.jpg.webp)Team develops AI tool to find potential for mouldThe technology, partly developed by researchers in Leeds, also suggests ways to prevent the problem.5 days agoWest Yorkshire](https://www.bbc.com/innovation/</news/articles/cvgl7ge39y3o>)
12345...11
[British Broadcasting Corporation](https://www.bbc.com/innovation/</>)
  * [Home](https://www.bbc.com/innovation/<https:/www.bbc.com/>)
  * [News](https://www.bbc.com/innovation/</news>)
  * [Sport](https://www.bbc.com/innovation/</sport>)
  * [Business](https://www.bbc.com/innovation/</business>)
  * [Innovation](https://www.bbc.com/innovation/</innovation>)
  * [Culture](https://www.bbc.com/innovation/</culture>)
  * [Arts](https://www.bbc.com/innovation/</arts>)
  * [Travel](https://www.bbc.com/innovation/</travel>)
  * [Earth](https://www.bbc.com/innovation/</future-planet>)
  * [Video](https://www.bbc.com/innovation/</video>)
  * [Live](https://www.bbc.com/innovation/</live>)
  * [Audio](https://www.bbc.com/innovation/<https:/www.bbc.co.uk/sounds>)
  * [Weather](https://www.bbc.com/innovation/<https:/www.bbc.com/weather>)
  * [BBC Shop](https://www.bbc.com/innovation/<https:/shop.bbc.com/>)


BBC in other languages
## Follow BBC on:
  * [Terms of Use](https://www.bbc.com/innovation/<https:/www.bbc.co.uk/usingthebbc/terms>)
  * [About the BBC](https://www.bbc.com/innovation/<https:/www.bbc.co.uk/aboutthebbc>)
  * [Privacy Policy](https://www.bbc.com/innovation/<https:/www.bbc.com/usingthebbc/privacy/>)
  * [Cookies](https://www.bbc.com/innovation/<https:/www.bbc.com/usingthebbc/cookies/>)
  * [Accessibility Help](https://www.bbc.com/innovation/<https:/www.bbc.co.uk/accessibility/>)
  * [Contact the BBC](https://www.bbc.com/innovation/<https:/www.bbc.co.uk/contact>)
  * [Advertise with us](https://www.bbc.com/innovation/<https:/www.bbc.com/advertisingcontact>)
  * [Do not share or sell my info](https://www.bbc.com/innovation/<https:/www.bbc.com/usingthebbc/cookies/how-can-i-change-my-bbc-cookie-settings/>)
  * [Contact technical support](https://www.bbc.com/innovation/<https:/www.bbc.com/contact-bbc-com-help>)


Copyright 2025 BBC. All rights reserved. The _BBC_ is _not responsible for the content of external sites._ [**Read about our approach to external linking.**](https://www.bbc.com/innovation/<https:/www.bbc.co.uk/editorialguidelines/guidance/feeds-and-links>)

================
File: full_sites/www_bbc_com/news_20250130_231942.md
================
[Skip to content](https://www.bbc.com/<#main-content>)
[British Broadcasting Corporation](https://www.bbc.com/</>)
[Register](https://www.bbc.com/<https:/session.bbc.com/session?action=register&userOrigin=BBCS_BBC&ptrt=https%3A%2F%2Fwww.bbc.com%2Fnews>)
[Sign In](https://www.bbc.com/<https:/session.bbc.com/session?userOrigin=BBCS_BBC&ptrt=https%3A%2F%2Fwww.bbc.com%2Fnews>)
  * [Home](https://www.bbc.com/</>)
  * [News](https://www.bbc.com/</news>)
  * [Sport](https://www.bbc.com/</sport>)
  * [Business](https://www.bbc.com/</business>)
  * [Innovation](https://www.bbc.com/</innovation>)
  * [Culture](https://www.bbc.com/</culture>)
  * [Arts](https://www.bbc.com/</arts>)
  * [Travel](https://www.bbc.com/</travel>)
  * [Earth](https://www.bbc.com/</future-planet>)
  * [Video](https://www.bbc.com/</video>)
  * [Live](https://www.bbc.com/</live>)


  * [Israel-Gaza War](https://www.bbc.com/</news/topics/c2vdnvdg6xxt>)
  * [War in Ukraine](https://www.bbc.com/</news/war-in-ukraine>)
  * [US & Canada](https://www.bbc.com/</news/us-canada>)
  * [UK](https://www.bbc.com/</news/uk>)
  * [Africa](https://www.bbc.com/</news/world/africa>)
  * [Asia](https://www.bbc.com/</news/world/asia>)
  * [Australia](https://www.bbc.com/</news/world/australia>)
  * [Europe](https://www.bbc.com/</news/world/europe>)
  * [Latin America](https://www.bbc.com/</news/world/latin_america>)
  * [Middle East](https://www.bbc.com/</news/world/middle_east>)
  * [In Pictures](https://www.bbc.com/</news/in_pictures>)
  * [BBC InDepth](https://www.bbc.com/</news/bbcindepth>)
  * [BBC Verify](https://www.bbc.com/</news/bbcverify>)


[Register](https://www.bbc.com/<https:/session.bbc.com/session?action=register&userOrigin=BBCS_BBC>)
[Sign In](https://www.bbc.com/<https:/session.bbc.com/session?userOrigin=BBCS_BBC>)
[Home](https://www.bbc.com/</>)
News
[Sport](https://www.bbc.com/</sport>)
Business
Innovation
Culture
Arts
Travel
Earth
[Video](https://www.bbc.com/</video>)
Live
[Audio](https://www.bbc.com/<https:/www.bbc.co.uk/sounds>)
[Weather](https://www.bbc.com/<https:/www.bbc.com/weather>)
[Newsletters](https://www.bbc.com/<https:/www.bbc.com/newsletters>)
# 
News
News
[![Donald Trump standing at the podium in the White House](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/1071/live/5b241800-df29-11ef-a319-fb4e7360c4ec.jpg.webp)LIVETrump says cause of Washington DC air crash that left 67 dead is unknownThe president also suggested, without evidence, that diversity hiring policies in air traffic control could have been a factor](https://www.bbc.com/<https:/www.bbc.com/news/live/cy7kxx74yxlt>)
[![A boat approaches a wrecked helicopter in a river in front of houses](https://ichef.bbci.co.uk/news/480/cpsprodpb/92ce/live/3a77dd60-df26-11ef-a819-277e390a7a08.jpg.webp)BBC Verify analyses moments before crashBBC Verify's Nick Eardley has taken a closer look at what we know so far about the collision.1 hr agoUS & Canada](https://www.bbc.com/</news/videos/c4g95z8jqr4o>)
[![Tulsi Gabbard](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/1c49/live/9a07e8f0-df1d-11ef-bd1b-d536627785f2.jpg.webp)LIVETrump's intelligence pick Tulsi Gabbard says she is 'no puppet' in grilling on Syria trip and Edward SnowdenIf approved by the Senate, Gabbard will oversee US intelligence agencies like the CIA, FBI and the National Security Agency (NSA).](https://www.bbc.com/<https:/www.bbc.com/news/live/c1kmw8193ldt>)
## [US teen shot dead by father in Pakistan over TikTok videosPolice are looking at all aspects of the case, including the possibility of an honour killing.6 hrs agoAsia](https://www.bbc.com/</news/articles/cy8pvw3xxxeo>)
## [Mexico asks Google Maps not to rename Gulf of MexicoUS President Donald Trump has ordered that the body of water be renamed the Gulf of America.1 hr agoLatin America](https://www.bbc.com/</news/articles/clyn1rgngn8o>)
[![A boat approaches a wrecked helicopter in a river in front of houses](https://ichef.bbci.co.uk/news/480/cpsprodpb/92ce/live/3a77dd60-df26-11ef-a819-277e390a7a08.jpg.webp)BBC Verify analyses moments before crashBBC Verify's Nick Eardley has taken a closer look at what we know so far about the collision.1 hr agoUS & Canada](https://www.bbc.com/</news/videos/c4g95z8jqr4o>)
[![Yevgenia Shishkova and Vadim Naumov](https://ichef.bbci.co.uk/news/480/cpsprodpb/f01e/live/f6a9f1c0-df13-11ef-a75f-9dd268073925.jpg.webp)US and Russian figure skaters were on board flightThey include two teenagers, their mothers and two former Russian stars, according to their club in Boston.2 hrs agoUS & Canada](https://www.bbc.com/</news/articles/cn9370dny5xo>)
[![Two Thais taken hostage by Hamas are freed in Khan Yunis on January 30, 2025 - grab from video by BBC Gaza freelancer. Two men wearing white hoodies are surrounded by masked guards and people trying to take their pictures with their mobile phones](https://ichef.bbci.co.uk/news/480/cpsprodpb/db12/live/b3cdd8d0-df04-11ef-a030-9fe842194d0f.png.webp)Tears of joy as five Thai hostages held in Gaza are freed The five were working on farms in Israel when they were abducted during attacks on 7 October 2023.4 hrs ago](https://www.bbc.com/</news/articles/cj48qxd7jq5o>)
[![A large crowd gathers in the city of Ramallah](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/3789/live/1acc1410-df29-11ef-bd1b-d536627785f2.jpg.webp)LIVEHamas says 110 Palestinian prisoners freed after chaotic hostage releaseThree Israelis and five Thai hostages were freed earlier in what PM Benjamin Netanyahu called "shocking scenes".](https://www.bbc.com/<https:/www.bbc.com/news/live/cr53e7e7yg3t>)
[![Tulsi Gabbard](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/1c49/live/9a07e8f0-df1d-11ef-bd1b-d536627785f2.jpg.webp)LIVETrump's intelligence pick Tulsi Gabbard says she is 'no puppet' in grilling on Syria trip and Edward SnowdenIf approved by the Senate, Gabbard will oversee US intelligence agencies like the CIA, FBI and the National Security Agency (NSA).](https://www.bbc.com/<https:/www.bbc.com/news/live/c1kmw8193ldt>)
## [Rescuers race to pull out truck driver stuck in Japan sinkhole for days14 hrs agoAsia](https://www.bbc.com/</news/articles/cx24pvgxn0no>)
## [Five skiers killed in French Alps avalanches 8 hrs agoEurope](https://www.bbc.com/</news/articles/czep67j3w8do>)
## [Fans fill stadium for Virat Kohli's first domestic match in 12 years10 hrs agoAsia](https://www.bbc.com/</news/articles/cn8xvmjz8vxo>)
## [Man who burned Quran 'shot dead in Sweden'4 hrs agoEurope](https://www.bbc.com/</news/articles/cpdx2wqpg7zo>)
## [Merkel criticises her party leader after far-right vote3 hrs agoEurope](https://www.bbc.com/</news/articles/c3w89w5dxgvo>)
## More to explore
[![A$AP Rocky and Rihanna walking outside in Los Angeles ](https://ichef.bbci.co.uk/news/480/cpsprodpb/9b50/live/c8f89450-deac-11ef-b9c7-2941593f8747.jpg.webp)Rihanna appears at A$AP Rocky's trial - here's what to know about the case Jurors had been questioned about whether Rihanna's connection to the case could sway the verdict9 hrs agoUS & Canada](https://www.bbc.com/</news/articles/cqld9725r2go>)
[![A man stands in front of produce in Pakistan](https://ichef.bbci.co.uk/news/480/cpsprodpb/a0c2/live/83e57720-de9d-11ef-a675-95bda166cb56.jpg.webp)How a US freeze upended global aid in a matter of days The State Department says the freeze was the only way to evaluate aid programs and defended the pause.18 hrs agoWorld](https://www.bbc.com/</news/articles/c3604r84zjyo>)
[![Doron Steinbrecher walks through a crowd of Hamas fighters, with their faces covered and wearing green bandanas, and Emily Damari gets out of a vehicle as both women are handed over to the Red Cross](https://ichef.bbci.co.uk/news/480/cpsprodpb/5b64/live/4919ed30-de5f-11ef-acbf-c3b897b96092.jpg.webp)Inside the operation to bring Israel's hostages home from GazaIf anything goes wrong, it risks the hostages remaining in captivity, and reigniting the war.24 hrs ago](https://www.bbc.com/</news/articles/cy5kqqv56g1o>)
## [Russia withdraws military equipment from Syrian port, images showMoscow had moved columns of military vehicles to the port after the fall of Bashar al-Assad.8 hrs agoWorld](https://www.bbc.com/</news/articles/cly5zmm186no>)
## [FireAid concert: Who's performing and how to watch Stars including Billie Eilish and Olivia Rodrigo are set to help raise funds to rebuild the LA area.9 hrs agoUS & Canada](https://www.bbc.com/</news/articles/cqld9vqezqeo>)
[![A man stands in front of produce in Pakistan](https://ichef.bbci.co.uk/news/480/cpsprodpb/a0c2/live/83e57720-de9d-11ef-a675-95bda166cb56.jpg.webp)How a US freeze upended global aid in a matter of days The State Department says the freeze was the only way to evaluate aid programs and defended the pause.18 hrs agoWorld](https://www.bbc.com/</news/articles/c3604r84zjyo>)
[![Renee Zellweger attends the UK premiere of the film Bridget Jones: Mad About the Boy at Leicester Square in London on 29 January 2025.](https://ichef.bbci.co.uk/news/480/cpsprodpb/a6d3/live/2e8a2230-debb-11ef-a819-277e390a7a08.jpg.webp)Renée Zellweger: 'Fingers crossed' this is not the end of Bridget Jones Bridget Jones: Mad About the Boy has been billed as the final film in the series - but speaking at the London premiere its star says she is hoping that is not the case. 15 hrs agoCulture](https://www.bbc.com/</news/articles/cdxerg03xrqo>)
[![A sled dog with bright blue eyes peers out from its kennel ](https://ichef.bbci.co.uk/news/480/cpsprodpb/6a5e/live/a2dc3f60-de39-11ef-a69b-6ddb4eb9391c.jpg.webp)How sled dogs and pets respond when the clocks change The breeds show different reaction to clocks going back and forward, a study suggests.17 hrs agoScience & Environment](https://www.bbc.com/</news/articles/c4gwplknwz3o>)
[![Doron Steinbrecher walks through a crowd of Hamas fighters, with their faces covered and wearing green bandanas, and Emily Damari gets out of a vehicle as both women are handed over to the Red Cross](https://ichef.bbci.co.uk/news/480/cpsprodpb/5b64/live/4919ed30-de5f-11ef-acbf-c3b897b96092.jpg.webp)Inside the operation to bring Israel's hostages home from GazaIf anything goes wrong, it risks the hostages remaining in captivity, and reigniting the war.24 hrs ago](https://www.bbc.com/</news/articles/cy5kqqv56g1o>)
## Most watched
[1BBC Verify analyses moments before Washington DC plane crash](https://www.bbc.com/</news/videos/c4g95z8jqr4o>)
[2Traffic control radar shows moment of Washington DC crash](https://www.bbc.com/</news/videos/ce3nwy5v9g4o>)
[3Listen: Air traffic controllers appear to try to stop collision](https://www.bbc.com/</news/videos/ckg7kw9jnn0o>)
[4Watch: Rescue efforts as passenger jet and helicopter collide in DC](https://www.bbc.com/</news/videos/cwyek92v29lo>)
[5Witness describes seeing 'white flare' at moment of plane collision](https://www.bbc.com/</news/videos/cx2jnzpd4gno>)
## Most read
[1US and Russian figure skaters were on board crashed plane](https://www.bbc.com/</news/articles/cn9370dny5xo>)
[2Man who burned Quran 'shot dead in Sweden'](https://www.bbc.com/</news/articles/cpdx2wqpg7zo>)
[3What we know so far about Washington DC plane crash](https://www.bbc.com/</news/articles/c4g9kdgzj91o>)
[4US teen shot dead by father in Pakistan over TikTok videos](https://www.bbc.com/</news/articles/cy8pvw3xxxeo>)
[5In world's 'most controlled airspace', how could crash happen?](https://www.bbc.com/</news/articles/cpdx6le5l27o>)
[6Ex-US Senator Bob Menendez jailed for 11 years for bribery ](https://www.bbc.com/</news/articles/clyekv226l2o>)
[7Pentagon strips Gen Mark Milley of US security detail and clearance](https://www.bbc.com/</news/articles/cp3jd798kpzo>)
[8Traffic control radar shows moment of Washington DC crash](https://www.bbc.com/</news/videos/ce3nwy5v9g4o>)
[9Mexico asks Google Maps not to rename Gulf of Mexico](https://www.bbc.com/</news/articles/clyn1rgngn8o>)
[10Far-right vote on asylum rocks German parliament](https://www.bbc.com/</news/articles/ceq901dxjnzo>)
## Also in news
[![A South African soldier bows her head at a funeral in Pretoria of a colleague killed during a mortar incident in DR Congo - March 2024](https://ichef.bbci.co.uk/news/480/cpsprodpb/e584/live/788dfe10-df1a-11ef-a819-277e390a7a08.jpg.webp)South Africa and Rwanda go head-to-head over DR Congo warRwanda says South Africa is in “no position to take on the role of a peacemaker or mediator” in DR Congo.1 hr agoAfrica](https://www.bbc.com/</news/articles/c78w1ze7v25o>)
[![Image shows Trump](https://ichef.bbci.co.uk/news/480/cpsprodpb/a7b4/live/c6bf8250-deae-11ef-a819-277e390a7a08.jpg.webp)Trump says US will send some migrants to Guantanamo BayThe president orders the construction of a detention facility at the US Navy base, prompting an angry backlash from Cuba.16 hrs agoWorld](https://www.bbc.com/</news/articles/c5yelgxk3rlo>)
[![A close-up image of Duduzile Zuma-Sambudla](https://ichef.bbci.co.uk/news/480/cpsprodpb/0e86/live/bf1c8f00-de29-11ef-bf7d-c305fe575a19.jpg.webp)Zuma's daughter faces terrorism charges over South Africa riotsDuduzile Zuma-Sambudla is accused of inciting violence in 2021 following the jailing of her father.5 hrs agoAfrica](https://www.bbc.com/</news/articles/cwyekqn1k1ko>)
## [Bishop of Liverpool resigns after assault claimsThe Right Reverend Dr John Perumbalath denies the allegations from two women.3 hrs agoLiverpool](https://www.bbc.com/</news/articles/cq6gze93mpno>)
## [Ex-dancer settles with Royal Ballet School over 'body-shaming'Ellen Elphick said teachers at the school had left her with lifelong psychological damage.12 hrs agoLondon](https://www.bbc.com/</news/articles/cly418jw5yyo>)
[![Image shows Trump](https://ichef.bbci.co.uk/news/480/cpsprodpb/a7b4/live/c6bf8250-deae-11ef-a819-277e390a7a08.jpg.webp)Trump says US will send some migrants to Guantanamo BayThe president orders the construction of a detention facility at the US Navy base, prompting an angry backlash from Cuba.16 hrs agoWorld](https://www.bbc.com/</news/articles/c5yelgxk3rlo>)
[![Russell Brand](https://ichef.bbci.co.uk/news/480/cpsprodpb/3f81/live/89a7fd60-def0-11ef-a916-cf13bb39c9a1.jpg.webp)BBC apologises for culture of silence over Russell BrandStaff felt they could not speak up with concerns about the star's behaviour, an internal review finds.3 hrs agoCulture](https://www.bbc.com/</news/articles/c8r5076y05ko>)
[![A file photo of the town of Tamoun in the occupied West Bank taken on 7 January, 2025. The image shows rubble and people walking in the distance along a narrow street.](https://ichef.bbci.co.uk/news/480/cpsprodpb/4b06/live/6e044e70-dea9-11ef-8a93-0b3a45faead5.png.webp)Israeli strike kills 10 Palestinians in West Bank, health ministry saysThe Israeli military says it targeted what it describes as "armed terrorists" in the town of Tamoun.8 hrs ago](https://www.bbc.com/</news/articles/c20gpym140jo>)
[![A close-up image of Duduzile Zuma-Sambudla](https://ichef.bbci.co.uk/news/480/cpsprodpb/0e86/live/bf1c8f00-de29-11ef-bf7d-c305fe575a19.jpg.webp)Zuma's daughter faces terrorism charges over South Africa riotsDuduzile Zuma-Sambudla is accused of inciting violence in 2021 following the jailing of her father.5 hrs agoAfrica](https://www.bbc.com/</news/articles/cwyekqn1k1ko>)
## Sport
[![Yevgenia Shishkova and Vadim Naumov](https://ichef.bbci.co.uk/news/480/cpsprodpb/f01e/live/f6a9f1c0-df13-11ef-a75f-9dd268073925.jpg.webp)US and Russian figure skaters were on board crashed planeA number of figure skaters were among the passengers on board an aeroplane that hit a helicopter above Washington DC on Wednesday.2 hrs agoUS & Canada](https://www.bbc.com/</news/articles/cn9370dny5xo>)
[![Split image showing Manchester United head coach Ruben Amorim, Tottenham manager Ange Postecoglou and Rangers boss Philippe Clemente](https://ichef.bbci.co.uk/news/480/cpsprodpb/b160/live/f5a78e40-de55-11ef-badc-e32fa511f116.png.webp)Europa League final day - who is through and what's at stake?Manchester United, Tottenham and Rangers all have something at stake on what promises to be a thrilling final day of the Europa League league phase.8 hrs ago](https://www.bbc.com/</sport/football/articles/c5yellwg3r4o>)
[![Dave Cherry at Scotland training](https://ichef.bbci.co.uk/news/480/cpsprodpb/757d/live/7a8ffeb0-df11-11ef-a682-7ff171e0b93a.jpg.webp)Cherry, Gray & McDowall start for Scotland against ItalyDave Cherry and Jonny Gray earn first caps in two years as Stafford McDowall replaces injured captain Sione Tuipulotu at inside centre for Scotland's opening Six Nations match against Italy on Saturday.3 hrs agoScottish Rugby](https://www.bbc.com/</sport/rugby-union/articles/c0rq9wyq9gno>)
## [Man Utd make offer to Man City for England's KellyManchester United make an offer to sign England forward Chloe Kelly from rivals Manchester City.2 hrs agoWomen's Football](https://www.bbc.com/</sport/football/articles/c0lz9p8g6eeo>)
## [Arsenal charged over players' reaction to red cardArsenal are charged by the Football Association after players surrounded referee Michael Oliver during their 1-0 win against Wolves at Molineux Stadium last weekend. 2 hrs agoArsenal](https://www.bbc.com/</sport/football/articles/cvger7p8z3lo>)
[![Split image showing Manchester United head coach Ruben Amorim, Tottenham manager Ange Postecoglou and Rangers boss Philippe Clemente](https://ichef.bbci.co.uk/news/480/cpsprodpb/b160/live/f5a78e40-de55-11ef-badc-e32fa511f116.png.webp)Europa League final day - who is through and what's at stake?Manchester United, Tottenham and Rangers all have something at stake on what promises to be a thrilling final day of the Europa League league phase.8 hrs ago](https://www.bbc.com/</sport/football/articles/c5yellwg3r4o>)
[![Steven Gerrard sits in the dugout ](https://ichef.bbci.co.uk/news/480/cpsprodpb/b614/live/02228f90-de64-11ef-9863-c1cbabfba6e7.jpg.webp)Gerrard leaves Al-Ettifaq after 18 months in chargeSteven Gerrard leaves his role as manager of Saudi Pro League side Al-Ettifaq after 18 months in charge.6 hrs agoFootball](https://www.bbc.com/</sport/football/articles/cx2pyer4d14o>)
[![Sam Prendergast runs with the ball during Ireland's win over Australia in November](https://ichef.bbci.co.uk/news/480/cpsprodpb/95ce/live/cdc27f30-defe-11ef-ba00-65100a906e68.jpg.webp)Ireland pick Prendergast at fly-half for England gameIreland interim head coach Simon Easterby retains Sam Prendergast at fly-half for Ireland's opening Six Nations match against England on Saturday.6 hrs agoIreland](https://www.bbc.com/</sport/rugby-union/articles/c334p3z1mneo>)
[![Dave Cherry at Scotland training](https://ichef.bbci.co.uk/news/480/cpsprodpb/757d/live/7a8ffeb0-df11-11ef-a682-7ff171e0b93a.jpg.webp)Cherry, Gray & McDowall start for Scotland against ItalyDave Cherry and Jonny Gray earn first caps in two years as Stafford McDowall replaces injured captain Sione Tuipulotu at inside centre for Scotland's opening Six Nations match against Italy on Saturday.3 hrs agoScottish Rugby](https://www.bbc.com/</sport/rugby-union/articles/c0rq9wyq9gno>)
[British Broadcasting Corporation](https://www.bbc.com/</>)
  * [Home](https://www.bbc.com/<https:/www.bbc.com/>)
  * [News](https://www.bbc.com/</news>)
  * [Sport](https://www.bbc.com/</sport>)
  * [Business](https://www.bbc.com/</business>)
  * [Innovation](https://www.bbc.com/</innovation>)
  * [Culture](https://www.bbc.com/</culture>)
  * [Arts](https://www.bbc.com/</arts>)
  * [Travel](https://www.bbc.com/</travel>)
  * [Earth](https://www.bbc.com/</future-planet>)
  * [Video](https://www.bbc.com/</video>)
  * [Live](https://www.bbc.com/</live>)
  * [Audio](https://www.bbc.com/<https:/www.bbc.co.uk/sounds>)
  * [Weather](https://www.bbc.com/<https:/www.bbc.com/weather>)
  * [BBC Shop](https://www.bbc.com/<https:/shop.bbc.com/>)


BBC in other languages
## Follow BBC on:
  * [Terms of Use](https://www.bbc.com/<https:/www.bbc.co.uk/usingthebbc/terms>)
  * [About the BBC](https://www.bbc.com/<https:/www.bbc.co.uk/aboutthebbc>)
  * [Privacy Policy](https://www.bbc.com/<https:/www.bbc.com/usingthebbc/privacy/>)
  * [Cookies](https://www.bbc.com/<https:/www.bbc.com/usingthebbc/cookies/>)
  * [Accessibility Help](https://www.bbc.com/<https:/www.bbc.co.uk/accessibility/>)
  * [Contact the BBC](https://www.bbc.com/<https:/www.bbc.co.uk/contact>)
  * [Advertise with us](https://www.bbc.com/<https:/www.bbc.com/advertisingcontact>)
  * [Do not share or sell my info](https://www.bbc.com/<https:/www.bbc.com/usingthebbc/cookies/how-can-i-change-my-bbc-cookie-settings/>)
  * [Contact technical support](https://www.bbc.com/<https:/www.bbc.com/contact-bbc-com-help>)


Copyright 2025 BBC. All rights reserved. The _BBC_ is _not responsible for the content of external sites._ [**Read about our approach to external linking.**](https://www.bbc.com/<https:/www.bbc.co.uk/editorialguidelines/guidance/feeds-and-links>)

================
File: full_sites/www_bbc_com/news_20250130_233402.md
================
[Skip to content](https://www.bbc.com/<#main-content>)
[British Broadcasting Corporation](https://www.bbc.com/</>)
[Register](https://www.bbc.com/<https:/session.bbc.com/session?action=register&userOrigin=BBCS_BBC&ptrt=https%3A%2F%2Fwww.bbc.com%2Fnews>)
[Sign In](https://www.bbc.com/<https:/session.bbc.com/session?userOrigin=BBCS_BBC&ptrt=https%3A%2F%2Fwww.bbc.com%2Fnews>)
  * [Home](https://www.bbc.com/</>)
  * [News](https://www.bbc.com/</news>)
  * [Sport](https://www.bbc.com/</sport>)
  * [Business](https://www.bbc.com/</business>)
  * [Innovation](https://www.bbc.com/</innovation>)
  * [Culture](https://www.bbc.com/</culture>)
  * [Arts](https://www.bbc.com/</arts>)
  * [Travel](https://www.bbc.com/</travel>)
  * [Earth](https://www.bbc.com/</future-planet>)
  * [Video](https://www.bbc.com/</video>)
  * [Live](https://www.bbc.com/</live>)


  * [Israel-Gaza War](https://www.bbc.com/</news/topics/c2vdnvdg6xxt>)
  * [War in Ukraine](https://www.bbc.com/</news/war-in-ukraine>)
  * [US & Canada](https://www.bbc.com/</news/us-canada>)
  * [UK](https://www.bbc.com/</news/uk>)
  * [Africa](https://www.bbc.com/</news/world/africa>)
  * [Asia](https://www.bbc.com/</news/world/asia>)
  * [Australia](https://www.bbc.com/</news/world/australia>)
  * [Europe](https://www.bbc.com/</news/world/europe>)
  * [Latin America](https://www.bbc.com/</news/world/latin_america>)
  * [Middle East](https://www.bbc.com/</news/world/middle_east>)
  * [In Pictures](https://www.bbc.com/</news/in_pictures>)
  * [BBC InDepth](https://www.bbc.com/</news/bbcindepth>)
  * [BBC Verify](https://www.bbc.com/</news/bbcverify>)


[Register](https://www.bbc.com/<https:/session.bbc.com/session?action=register&userOrigin=BBCS_BBC>)
[Sign In](https://www.bbc.com/<https:/session.bbc.com/session?userOrigin=BBCS_BBC>)
[Home](https://www.bbc.com/</>)
News
[Sport](https://www.bbc.com/</sport>)
Business
Innovation
Culture
Arts
Travel
Earth
[Video](https://www.bbc.com/</video>)
Live
[Audio](https://www.bbc.com/<https:/www.bbc.co.uk/sounds>)
[Weather](https://www.bbc.com/<https:/www.bbc.com/weather>)
[Newsletters](https://www.bbc.com/<https:/www.bbc.com/newsletters>)
# 
News
News
[![Donald Trump standing at the podium in the White House](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/1071/live/5b241800-df29-11ef-a319-fb4e7360c4ec.jpg.webp)LIVETrump says cause of Washington DC air crash that left 67 dead is unknownThe president also suggested, without evidence, that diversity hiring policies in air traffic control could have been a factor](https://www.bbc.com/<https:/www.bbc.com/news/live/cy7kxx74yxlt>)
[![A boat approaches a wrecked helicopter in a river in front of houses](https://ichef.bbci.co.uk/news/480/cpsprodpb/92ce/live/3a77dd60-df26-11ef-a819-277e390a7a08.jpg.webp)BBC Verify analyses moments before crashBBC Verify's Nick Eardley has taken a closer look at what we know so far about the collision.1 hr agoUS & Canada](https://www.bbc.com/</news/videos/c4g95z8jqr4o>)
[![Tulsi Gabbard](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/1c49/live/9a07e8f0-df1d-11ef-bd1b-d536627785f2.jpg.webp)LIVETrump's intelligence pick Tulsi Gabbard says she is 'no puppet' in grilling on Syria trip and Edward SnowdenIf approved by the Senate, Gabbard will oversee US intelligence agencies like the CIA, FBI and the National Security Agency (NSA).](https://www.bbc.com/<https:/www.bbc.com/news/live/c1kmw8193ldt>)
## [US teen shot dead by father in Pakistan over TikTok videosPolice are looking at all aspects of the case, including the possibility of an honour killing.6 hrs agoAsia](https://www.bbc.com/</news/articles/cy8pvw3xxxeo>)
## [Mexico asks Google Maps not to rename Gulf of MexicoUS President Donald Trump has ordered that the body of water be renamed the Gulf of America.1 hr agoLatin America](https://www.bbc.com/</news/articles/clyn1rgngn8o>)
[![A boat approaches a wrecked helicopter in a river in front of houses](https://ichef.bbci.co.uk/news/480/cpsprodpb/92ce/live/3a77dd60-df26-11ef-a819-277e390a7a08.jpg.webp)BBC Verify analyses moments before crashBBC Verify's Nick Eardley has taken a closer look at what we know so far about the collision.1 hr agoUS & Canada](https://www.bbc.com/</news/videos/c4g95z8jqr4o>)
[![Yevgenia Shishkova and Vadim Naumov](https://ichef.bbci.co.uk/news/480/cpsprodpb/f01e/live/f6a9f1c0-df13-11ef-a75f-9dd268073925.jpg.webp)US and Russian figure skaters were on board flightThey include two teenagers, their mothers and two former Russian stars, according to their club in Boston.2 hrs agoUS & Canada](https://www.bbc.com/</news/articles/cn9370dny5xo>)
[![Two Thais taken hostage by Hamas are freed in Khan Yunis on January 30, 2025 - grab from video by BBC Gaza freelancer. Two men wearing white hoodies are surrounded by masked guards and people trying to take their pictures with their mobile phones](https://ichef.bbci.co.uk/news/480/cpsprodpb/db12/live/b3cdd8d0-df04-11ef-a030-9fe842194d0f.png.webp)Tears of joy as five Thai hostages held in Gaza are freed The five were working on farms in Israel when they were abducted during attacks on 7 October 2023.4 hrs ago](https://www.bbc.com/</news/articles/cj48qxd7jq5o>)
[![A large crowd gathers in the city of Ramallah](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/3789/live/1acc1410-df29-11ef-bd1b-d536627785f2.jpg.webp)LIVEHamas says 110 Palestinian prisoners freed after chaotic hostage releaseThree Israelis and five Thai hostages were freed earlier in what PM Benjamin Netanyahu called "shocking scenes".](https://www.bbc.com/<https:/www.bbc.com/news/live/cr53e7e7yg3t>)
[![Tulsi Gabbard](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/1c49/live/9a07e8f0-df1d-11ef-bd1b-d536627785f2.jpg.webp)LIVETrump's intelligence pick Tulsi Gabbard says she is 'no puppet' in grilling on Syria trip and Edward SnowdenIf approved by the Senate, Gabbard will oversee US intelligence agencies like the CIA, FBI and the National Security Agency (NSA).](https://www.bbc.com/<https:/www.bbc.com/news/live/c1kmw8193ldt>)
## [Rescuers race to pull out truck driver stuck in Japan sinkhole for days14 hrs agoAsia](https://www.bbc.com/</news/articles/cx24pvgxn0no>)
## [Five skiers killed in French Alps avalanches 8 hrs agoEurope](https://www.bbc.com/</news/articles/czep67j3w8do>)
## [Fans fill stadium for Virat Kohli's first domestic match in 12 years10 hrs agoAsia](https://www.bbc.com/</news/articles/cn8xvmjz8vxo>)
## [Man who burned Quran 'shot dead in Sweden'4 hrs agoEurope](https://www.bbc.com/</news/articles/cpdx2wqpg7zo>)
## [Merkel criticises her party leader after far-right vote3 hrs agoEurope](https://www.bbc.com/</news/articles/c3w89w5dxgvo>)
## More to explore
[![A$AP Rocky and Rihanna walking outside in Los Angeles ](https://ichef.bbci.co.uk/news/480/cpsprodpb/9b50/live/c8f89450-deac-11ef-b9c7-2941593f8747.jpg.webp)Rihanna appears at A$AP Rocky's trial - here's what to know about the case Jurors had been questioned about whether Rihanna's connection to the case could sway the verdict9 hrs agoUS & Canada](https://www.bbc.com/</news/articles/cqld9725r2go>)
[![A man stands in front of produce in Pakistan](https://ichef.bbci.co.uk/news/480/cpsprodpb/a0c2/live/83e57720-de9d-11ef-a675-95bda166cb56.jpg.webp)How a US freeze upended global aid in a matter of days The State Department says the freeze was the only way to evaluate aid programs and defended the pause.18 hrs agoWorld](https://www.bbc.com/</news/articles/c3604r84zjyo>)
[![Doron Steinbrecher walks through a crowd of Hamas fighters, with their faces covered and wearing green bandanas, and Emily Damari gets out of a vehicle as both women are handed over to the Red Cross](https://ichef.bbci.co.uk/news/480/cpsprodpb/5b64/live/4919ed30-de5f-11ef-acbf-c3b897b96092.jpg.webp)Inside the operation to bring Israel's hostages home from GazaIf anything goes wrong, it risks the hostages remaining in captivity, and reigniting the war.24 hrs ago](https://www.bbc.com/</news/articles/cy5kqqv56g1o>)
## [Russia withdraws military equipment from Syrian port, images showMoscow had moved columns of military vehicles to the port after the fall of Bashar al-Assad.8 hrs agoWorld](https://www.bbc.com/</news/articles/cly5zmm186no>)
## [FireAid concert: Who's performing and how to watch Stars including Billie Eilish and Olivia Rodrigo are set to help raise funds to rebuild the LA area.9 hrs agoUS & Canada](https://www.bbc.com/</news/articles/cqld9vqezqeo>)
[![A man stands in front of produce in Pakistan](https://ichef.bbci.co.uk/news/480/cpsprodpb/a0c2/live/83e57720-de9d-11ef-a675-95bda166cb56.jpg.webp)How a US freeze upended global aid in a matter of days The State Department says the freeze was the only way to evaluate aid programs and defended the pause.18 hrs agoWorld](https://www.bbc.com/</news/articles/c3604r84zjyo>)
[![Renee Zellweger attends the UK premiere of the film Bridget Jones: Mad About the Boy at Leicester Square in London on 29 January 2025.](https://ichef.bbci.co.uk/news/480/cpsprodpb/a6d3/live/2e8a2230-debb-11ef-a819-277e390a7a08.jpg.webp)Renée Zellweger: 'Fingers crossed' this is not the end of Bridget Jones Bridget Jones: Mad About the Boy has been billed as the final film in the series - but speaking at the London premiere its star says she is hoping that is not the case. 15 hrs agoCulture](https://www.bbc.com/</news/articles/cdxerg03xrqo>)
[![A sled dog with bright blue eyes peers out from its kennel ](https://ichef.bbci.co.uk/news/480/cpsprodpb/6a5e/live/a2dc3f60-de39-11ef-a69b-6ddb4eb9391c.jpg.webp)How sled dogs and pets respond when the clocks change The breeds show different reaction to clocks going back and forward, a study suggests.17 hrs agoScience & Environment](https://www.bbc.com/</news/articles/c4gwplknwz3o>)
[![Doron Steinbrecher walks through a crowd of Hamas fighters, with their faces covered and wearing green bandanas, and Emily Damari gets out of a vehicle as both women are handed over to the Red Cross](https://ichef.bbci.co.uk/news/480/cpsprodpb/5b64/live/4919ed30-de5f-11ef-acbf-c3b897b96092.jpg.webp)Inside the operation to bring Israel's hostages home from GazaIf anything goes wrong, it risks the hostages remaining in captivity, and reigniting the war.24 hrs ago](https://www.bbc.com/</news/articles/cy5kqqv56g1o>)
## Most watched
[1BBC Verify analyses moments before Washington DC plane crash](https://www.bbc.com/</news/videos/c4g95z8jqr4o>)
[2Traffic control radar shows moment of Washington DC crash](https://www.bbc.com/</news/videos/ce3nwy5v9g4o>)
[3Listen: Air traffic controllers appear to try to stop collision](https://www.bbc.com/</news/videos/ckg7kw9jnn0o>)
[4Watch: Rescue efforts as passenger jet and helicopter collide in DC](https://www.bbc.com/</news/videos/cwyek92v29lo>)
[5Witness describes seeing 'white flare' at moment of plane collision](https://www.bbc.com/</news/videos/cx2jnzpd4gno>)
## Most read
[1US and Russian figure skaters were on board crashed plane](https://www.bbc.com/</news/articles/cn9370dny5xo>)
[2Man who burned Quran 'shot dead in Sweden'](https://www.bbc.com/</news/articles/cpdx2wqpg7zo>)
[3What we know so far about Washington DC plane crash](https://www.bbc.com/</news/articles/c4g9kdgzj91o>)
[4US teen shot dead by father in Pakistan over TikTok videos](https://www.bbc.com/</news/articles/cy8pvw3xxxeo>)
[5In world's 'most controlled airspace', how could crash happen?](https://www.bbc.com/</news/articles/cpdx6le5l27o>)
[6Ex-US Senator Bob Menendez jailed for 11 years for bribery ](https://www.bbc.com/</news/articles/clyekv226l2o>)
[7Pentagon strips Gen Mark Milley of US security detail and clearance](https://www.bbc.com/</news/articles/cp3jd798kpzo>)
[8Traffic control radar shows moment of Washington DC crash](https://www.bbc.com/</news/videos/ce3nwy5v9g4o>)
[9Mexico asks Google Maps not to rename Gulf of Mexico](https://www.bbc.com/</news/articles/clyn1rgngn8o>)
[10Far-right vote on asylum rocks German parliament](https://www.bbc.com/</news/articles/ceq901dxjnzo>)
## Also in news
[![A South African soldier bows her head at a funeral in Pretoria of a colleague killed during a mortar incident in DR Congo - March 2024](https://ichef.bbci.co.uk/news/480/cpsprodpb/e584/live/788dfe10-df1a-11ef-a819-277e390a7a08.jpg.webp)South Africa and Rwanda go head-to-head over DR Congo warRwanda says South Africa is in “no position to take on the role of a peacemaker or mediator” in DR Congo.1 hr agoAfrica](https://www.bbc.com/</news/articles/c78w1ze7v25o>)
[![Image shows Trump](https://ichef.bbci.co.uk/news/480/cpsprodpb/a7b4/live/c6bf8250-deae-11ef-a819-277e390a7a08.jpg.webp)Trump says US will send some migrants to Guantanamo BayThe president orders the construction of a detention facility at the US Navy base, prompting an angry backlash from Cuba.16 hrs agoWorld](https://www.bbc.com/</news/articles/c5yelgxk3rlo>)
[![A close-up image of Duduzile Zuma-Sambudla](https://ichef.bbci.co.uk/news/480/cpsprodpb/0e86/live/bf1c8f00-de29-11ef-bf7d-c305fe575a19.jpg.webp)Zuma's daughter faces terrorism charges over South Africa riotsDuduzile Zuma-Sambudla is accused of inciting violence in 2021 following the jailing of her father.5 hrs agoAfrica](https://www.bbc.com/</news/articles/cwyekqn1k1ko>)
## [Bishop of Liverpool resigns after assault claimsThe Right Reverend Dr John Perumbalath denies the allegations from two women.3 hrs agoLiverpool](https://www.bbc.com/</news/articles/cq6gze93mpno>)
## [Ex-dancer settles with Royal Ballet School over 'body-shaming'Ellen Elphick said teachers at the school had left her with lifelong psychological damage.12 hrs agoLondon](https://www.bbc.com/</news/articles/cly418jw5yyo>)
[![Image shows Trump](https://ichef.bbci.co.uk/news/480/cpsprodpb/a7b4/live/c6bf8250-deae-11ef-a819-277e390a7a08.jpg.webp)Trump says US will send some migrants to Guantanamo BayThe president orders the construction of a detention facility at the US Navy base, prompting an angry backlash from Cuba.16 hrs agoWorld](https://www.bbc.com/</news/articles/c5yelgxk3rlo>)
[![Russell Brand](https://ichef.bbci.co.uk/news/480/cpsprodpb/3f81/live/89a7fd60-def0-11ef-a916-cf13bb39c9a1.jpg.webp)BBC apologises for culture of silence over Russell BrandStaff felt they could not speak up with concerns about the star's behaviour, an internal review finds.3 hrs agoCulture](https://www.bbc.com/</news/articles/c8r5076y05ko>)
[![A file photo of the town of Tamoun in the occupied West Bank taken on 7 January, 2025. The image shows rubble and people walking in the distance along a narrow street.](https://ichef.bbci.co.uk/news/480/cpsprodpb/4b06/live/6e044e70-dea9-11ef-8a93-0b3a45faead5.png.webp)Israeli strike kills 10 Palestinians in West Bank, health ministry saysThe Israeli military says it targeted what it describes as "armed terrorists" in the town of Tamoun.8 hrs ago](https://www.bbc.com/</news/articles/c20gpym140jo>)
[![A close-up image of Duduzile Zuma-Sambudla](https://ichef.bbci.co.uk/news/480/cpsprodpb/0e86/live/bf1c8f00-de29-11ef-bf7d-c305fe575a19.jpg.webp)Zuma's daughter faces terrorism charges over South Africa riotsDuduzile Zuma-Sambudla is accused of inciting violence in 2021 following the jailing of her father.5 hrs agoAfrica](https://www.bbc.com/</news/articles/cwyekqn1k1ko>)
## Sport
[![Yevgenia Shishkova and Vadim Naumov](https://ichef.bbci.co.uk/news/480/cpsprodpb/f01e/live/f6a9f1c0-df13-11ef-a75f-9dd268073925.jpg.webp)US and Russian figure skaters were on board crashed planeA number of figure skaters were among the passengers on board an aeroplane that hit a helicopter above Washington DC on Wednesday.2 hrs agoUS & Canada](https://www.bbc.com/</news/articles/cn9370dny5xo>)
[![Split image showing Manchester United head coach Ruben Amorim, Tottenham manager Ange Postecoglou and Rangers boss Philippe Clemente](https://ichef.bbci.co.uk/news/480/cpsprodpb/b160/live/f5a78e40-de55-11ef-badc-e32fa511f116.png.webp)Europa League final day - who is through and what's at stake?Manchester United, Tottenham and Rangers all have something at stake on what promises to be a thrilling final day of the Europa League league phase.8 hrs ago](https://www.bbc.com/</sport/football/articles/c5yellwg3r4o>)
[![Dave Cherry at Scotland training](https://ichef.bbci.co.uk/news/480/cpsprodpb/757d/live/7a8ffeb0-df11-11ef-a682-7ff171e0b93a.jpg.webp)Cherry, Gray & McDowall start for Scotland against ItalyDave Cherry and Jonny Gray earn first caps in two years as Stafford McDowall replaces injured captain Sione Tuipulotu at inside centre for Scotland's opening Six Nations match against Italy on Saturday.3 hrs agoScottish Rugby](https://www.bbc.com/</sport/rugby-union/articles/c0rq9wyq9gno>)
## [Man Utd make offer to Man City for England's KellyManchester United make an offer to sign England forward Chloe Kelly from rivals Manchester City.2 hrs agoWomen's Football](https://www.bbc.com/</sport/football/articles/c0lz9p8g6eeo>)
## [Arsenal charged over players' reaction to red cardArsenal are charged by the Football Association after players surrounded referee Michael Oliver during their 1-0 win against Wolves at Molineux Stadium last weekend. 2 hrs agoArsenal](https://www.bbc.com/</sport/football/articles/cvger7p8z3lo>)
[![Split image showing Manchester United head coach Ruben Amorim, Tottenham manager Ange Postecoglou and Rangers boss Philippe Clemente](https://ichef.bbci.co.uk/news/480/cpsprodpb/b160/live/f5a78e40-de55-11ef-badc-e32fa511f116.png.webp)Europa League final day - who is through and what's at stake?Manchester United, Tottenham and Rangers all have something at stake on what promises to be a thrilling final day of the Europa League league phase.8 hrs ago](https://www.bbc.com/</sport/football/articles/c5yellwg3r4o>)
[![Steven Gerrard sits in the dugout ](https://ichef.bbci.co.uk/news/480/cpsprodpb/b614/live/02228f90-de64-11ef-9863-c1cbabfba6e7.jpg.webp)Gerrard leaves Al-Ettifaq after 18 months in chargeSteven Gerrard leaves his role as manager of Saudi Pro League side Al-Ettifaq after 18 months in charge.6 hrs agoFootball](https://www.bbc.com/</sport/football/articles/cx2pyer4d14o>)
[![Sam Prendergast runs with the ball during Ireland's win over Australia in November](https://ichef.bbci.co.uk/news/480/cpsprodpb/95ce/live/cdc27f30-defe-11ef-ba00-65100a906e68.jpg.webp)Ireland pick Prendergast at fly-half for England gameIreland interim head coach Simon Easterby retains Sam Prendergast at fly-half for Ireland's opening Six Nations match against England on Saturday.6 hrs agoIreland](https://www.bbc.com/</sport/rugby-union/articles/c334p3z1mneo>)
[![Dave Cherry at Scotland training](https://ichef.bbci.co.uk/news/480/cpsprodpb/757d/live/7a8ffeb0-df11-11ef-a682-7ff171e0b93a.jpg.webp)Cherry, Gray & McDowall start for Scotland against ItalyDave Cherry and Jonny Gray earn first caps in two years as Stafford McDowall replaces injured captain Sione Tuipulotu at inside centre for Scotland's opening Six Nations match against Italy on Saturday.3 hrs agoScottish Rugby](https://www.bbc.com/</sport/rugby-union/articles/c0rq9wyq9gno>)
[British Broadcasting Corporation](https://www.bbc.com/</>)
  * [Home](https://www.bbc.com/<https:/www.bbc.com/>)
  * [News](https://www.bbc.com/</news>)
  * [Sport](https://www.bbc.com/</sport>)
  * [Business](https://www.bbc.com/</business>)
  * [Innovation](https://www.bbc.com/</innovation>)
  * [Culture](https://www.bbc.com/</culture>)
  * [Arts](https://www.bbc.com/</arts>)
  * [Travel](https://www.bbc.com/</travel>)
  * [Earth](https://www.bbc.com/</future-planet>)
  * [Video](https://www.bbc.com/</video>)
  * [Live](https://www.bbc.com/</live>)
  * [Audio](https://www.bbc.com/<https:/www.bbc.co.uk/sounds>)
  * [Weather](https://www.bbc.com/<https:/www.bbc.com/weather>)
  * [BBC Shop](https://www.bbc.com/<https:/shop.bbc.com/>)


BBC in other languages
## Follow BBC on:
  * [Terms of Use](https://www.bbc.com/<https:/www.bbc.co.uk/usingthebbc/terms>)
  * [About the BBC](https://www.bbc.com/<https:/www.bbc.co.uk/aboutthebbc>)
  * [Privacy Policy](https://www.bbc.com/<https:/www.bbc.com/usingthebbc/privacy/>)
  * [Cookies](https://www.bbc.com/<https:/www.bbc.com/usingthebbc/cookies/>)
  * [Accessibility Help](https://www.bbc.com/<https:/www.bbc.co.uk/accessibility/>)
  * [Contact the BBC](https://www.bbc.com/<https:/www.bbc.co.uk/contact>)
  * [Advertise with us](https://www.bbc.com/<https:/www.bbc.com/advertisingcontact>)
  * [Do not share or sell my info](https://www.bbc.com/<https:/www.bbc.com/usingthebbc/cookies/how-can-i-change-my-bbc-cookie-settings/>)
  * [Contact technical support](https://www.bbc.com/<https:/www.bbc.com/contact-bbc-com-help>)


Copyright 2025 BBC. All rights reserved. The _BBC_ is _not responsible for the content of external sites._ [**Read about our approach to external linking.**](https://www.bbc.com/<https:/www.bbc.co.uk/editorialguidelines/guidance/feeds-and-links>)

================
File: full_sites/www_bbc_com/news_articles_c4g9kdgzj91o_20250130_231948.md
================
[Skip to content](https://www.bbc.com/news/articles/<#main-content>)
[British Broadcasting Corporation](https://www.bbc.com/news/articles/</>)
[Register](https://www.bbc.com/news/articles/<https:/session.bbc.com/session?action=register&userOrigin=BBCS_BBC&ptrt=https%3A%2F%2Fwww.bbc.com%2Fnews%2Farticles%2Fc4g9kdgzj91o>)
[Sign In](https://www.bbc.com/news/articles/<https:/session.bbc.com/session?userOrigin=BBCS_BBC&ptrt=https%3A%2F%2Fwww.bbc.com%2Fnews%2Farticles%2Fc4g9kdgzj91o>)
  * [Home](https://www.bbc.com/news/articles/</>)
  * [News](https://www.bbc.com/news/articles/</news>)
  * [Sport](https://www.bbc.com/news/articles/</sport>)
  * [Business](https://www.bbc.com/news/articles/</business>)
  * [Innovation](https://www.bbc.com/news/articles/</innovation>)
  * [Culture](https://www.bbc.com/news/articles/</culture>)
  * [Arts](https://www.bbc.com/news/articles/</arts>)
  * [Travel](https://www.bbc.com/news/articles/</travel>)
  * [Earth](https://www.bbc.com/news/articles/</future-planet>)
  * [Video](https://www.bbc.com/news/articles/</video>)
  * [Live](https://www.bbc.com/news/articles/</live>)


[Register](https://www.bbc.com/news/articles/<https:/session.bbc.com/session?action=register&userOrigin=BBCS_BBC>)
[Sign In](https://www.bbc.com/news/articles/<https:/session.bbc.com/session?userOrigin=BBCS_BBC>)
[Home](https://www.bbc.com/news/articles/</>)
News
[Sport](https://www.bbc.com/news/articles/</sport>)
Business
Innovation
Culture
Arts
Travel
Earth
[Video](https://www.bbc.com/news/articles/</video>)
Live
[Audio](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/sounds>)
[Weather](https://www.bbc.com/news/articles/<https:/www.bbc.com/weather>)
[Newsletters](https://www.bbc.com/news/articles/<https:/www.bbc.com/newsletters>)
# What we know so far about Washington DC plane crash
54 minutes ago
Share
Save
Joel Guinto and James FitzGerald
BBC News
Share
Save
Watch: Rescue efforts as passenger jet and helicopter collide in DC
No survivors are expected after a passenger plane collided in mid air with a helicopter near Washington DC on Wednesday evening, officials in the US say.
The plane was carrying 64 passengers and crew when it landed in the Potomac River after the collision. The helicopter had three people on board, who were labelled a "fairly experienced crew" by Defence Secretary Pete Hegseth. 
Figure skaters from the US and Russia were among those who were on board the aeroplane, according to officials from US Figure Skating and a club in Boston. 
Authorities searching the freezing waters say they have switched to a recovery operation.
  * [Live: Follow the latest updates on the crash](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/news/live/cy7kxx74yxlt>)
  * [Watch: The scene in DC after moment of impact](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/news/videos/cwyek92v29lo>)
  * [Watch: First responders rush to the scene](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/news/videos/c93qx53pzn3o>)
  * Did you witness the incident? [Get in touch](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/send/u197191252>)


## What happened?
At about 21:00 local time (02:00 GMT) on Wednesday, a PSA Airlines jet operating as American Airlines 5342 collided with a US Army helicopter as it approached Ronald Reagan Washington National Airport, according to the Federal Aviation Administration (FAA).
The passenger plane broke into multiple pieces and sunk several feet into the river, while the helicopter ended up upside down on the water, reports said.
The plane, a Bombardier CRJ700, departed from Wichita, Kansas and was carrying 60 passengers and four crew, American Airlines said.
According to updates from officials, the helicopter was a Sikorsky H-60 that took off from Fort Belvoir in Virginia with three soldiers on board, and belonged to B Company, 12th Aviation Battalion.
Hegseth said the aircraft was on an annual proficiency flight, performing a night evaluation with standard goggles. He said names and ranks were being withheld until their next-of-kin had been informed.
A clip published online by LiveATC.net, which streams air traffic, purports to capture the air traffic control conversation in the moments before the crash. A controller can reportedly be heard warning the helicopter about the plane, but receiving no reply. The audio has not been verified by the BBC. 
The FAA said it would investigate the incident, together with the National Transportation Safety Board (NTSB). Hegseth said he expected this to quickly establish whether the helicopter was flying in the right corridor and altitude.
![An annotated satellite image shows the approximate crash site above the Potomac River. Highlighted nearby are Ronald Reagan International Airport, and the flight paths of both the plane and the helicopter](https://ichef.bbci.co.uk/news/480/cpsprodpb/0383/live/d7064420-df29-11ef-bd1b-d536627785f2.png.webp)
## How many victims are there?
DC Fire and EMS Chief John Donnelly said in a Thursday morning update that officials "don't believe there are any survivors from this accident".
He said teams had recovered 27 bodies from the plane, and one from the helicopter.
A law enforcement source familiar with the investigation earlier told CBS that a higher number of at least 30 bodies had already been found.
US Figure Skating said "several members of our skating community were sadly aboard" the flight. It said this group comprised athletes, coaches and family members who were returning home from a development camp in Kansas.
Russian citizens were also on board, the Kremlin confirmed - after local media reported that ice skating coaches and former world champions Yevgenia Shishkova and Vadim Naumov were on the plane.
About 300 responders on rubber boats were earlier deployed to search for survivors, Donnelly said in an earlier update. "The challenge is access, there is wind, pieces of ice (on the water). It is dangerous and hard to work in," he said.
Watch: First responders at scene of plane crash in Washington DC
## What are eyewitnesses saying?
Ari Schulman told NBC Washington that he saw the plane crash while driving on the George Washington Parkway, which runs along the airport.
He said the plane's approach looked normal, until he saw the aircraft bank hard to the right, with "streams of sparks" running underneath, illuminating its belly.
At that point, he said he knew that it looked "very, very wrong". Having seen plane landings there in the past, he said a plane's underside should not have been visible in the dark.
The sparks, he said, resembled a "giant roman candle" and went from the plane's nose to its tail.
Jimmy Mazeo said he saw the crash while having dinner with his girlfriend at a park near the airport.
He recalled seeing what looked like a "white flare" in the sky. He said planes flying into Ronald Reagan Airport appeared to have been flying in "irregular patterns".
Mr Mazeo said he did not think much of what he saw until emergency services started arriving at the scene.
Watch: Witness describes seeing ‘white flare’ at moment of plane collision
## What are US officials saying?
In a press conference on Thursday, President Donald Trump said the country was "in mourning", also taking the opportunity to take a swipe at his political foes, who he accused of hiring "mediocre" staff for air traffic control jobs.
He said he and his team had "strong opinions and ideas" about what had happened, but acknowledged that the investigation was at an early stage.
Speaking at the same press conference, Transport Secretary Sean Duffy and Hegseth vowed to get to the bottom of the incident.
American Airlines CEO Robert Isom expressed his "deep sorrow" about the collision in a video which has been posted to the airline's website.
That was echoed by Roger Marshall, a US senator representing Kansas, where the plane had travelled from. He described a "heartbreak beyond measure".
## What's the US's air safety record?
Major incidents of this kind are relatively rare in the US. The most recent comparable crash was in 2009, according to a list compiled by Reuters. 
That year, an aircraft crashed on approach to landing in Buffalo, New York, killing all 49 people on board and one person on the ground.
The airspace above Washington DC is both busy and highly controlled. It is used by domestic and international traffic using two airports, and there are extra factors of presidential flights, heavy military traffic and flights around the Pentagon.
Passenger airliners must follow fixed flight plans, said the BBC's transport correspondent Sean Dilley. In uncontrolled airspace, military pilots operate under strict instruction of air traffic controllers but unlike their civilian counterparts, they have freedom to deviate and a duty to "see and avoid" other aircraft.
![Composite image showing the two aircraft involved in the Washington DC crash: a Bombardier CRJ-700, which was carrying 60 passengers and four crew and was 106.1ft \(32.3m\) in length; and a UH-60 Black Hawk helicopter that was carrying three US soldiers and was 50.1ft \(15.27m\) in length](https://ichef.bbci.co.uk/news/480/cpsprodpb/007a/live/56fb46f0-df0a-11ef-bd1b-d536627785f2.png.webp)
[Aviation accidents and incidents](https://www.bbc.com/news/articles/</news/topics/c2n5vpdv320t>)
[US & Canada](https://www.bbc.com/news/articles/</news/world/us_and_canada>)
[United States](https://www.bbc.com/news/articles/</news/topics/cx1m7zg01xyt>)
Related
## [Iraq Hercules crash victims remembered 20 years on49 mins agoEngland](https://www.bbc.com/news/articles/</news/articles/ce8ynvn81gro>)
## [In world's 'most controlled airspace', how could crash happen?56 mins agoUS & Canada](https://www.bbc.com/news/articles/</news/articles/cpdx6le5l27o>)
## [BBC Verify analyses moments before Washington DC plane crash1 hr agoUS & Canada](https://www.bbc.com/news/articles/</news/videos/c4g95z8jqr4o>)
More
[2 hrs ago![Yevgenia Shishkova and Vadim Naumov](https://ichef.bbci.co.uk/news/480/cpsprodpb/f01e/live/f6a9f1c0-df13-11ef-a75f-9dd268073925.jpg.webp)US and Russian figure skaters were on board crashed planeThey include two teenagers, their mothers and two former Russian stars, according to their club in Boston.2 hrs agoUS & Canada](https://www.bbc.com/news/articles/</news/articles/cn9370dny5xo>)
[3 hrs ago![Police divers and boats are searching the water for survivors, while US authorities are investigating](https://ichef.bbci.co.uk/news/480/cpsprodpb/f3f5/live/ffa16be0-dec4-11ef-a819-277e390a7a08.png.webp)US officials switch to recovery effort after air crash near Washington DCNo survivors are expected after a plane with 64 people on board hit a helicopter carrying three soldiers.3 hrs agoUS & Canada](https://www.bbc.com/news/articles/</news/articles/c79d7y0l03po>)
[5 hrs ago![Audio wave over Ronal Reagan Airport in DC](https://ichef.bbci.co.uk/news/480/cpsprodpb/42c1/live/d0535f40-df2a-11ef-a819-277e390a7a08.jpg.webp)Listen: Air traffic controllers appear to try to stop collisionAudio from moments before collision captures controllers asking the military helicopter if it has seen the passenger jet. 5 hrs agoUS & Canada](https://www.bbc.com/news/articles/</news/videos/ckg7kw9jnn0o>)
[6 hrs ago![Man holds his left hand up while speaking to someone](https://ichef.bbci.co.uk/news/480/cpsprodpb/77ec/live/86e27c60-de4e-11ef-a7fb-0179c76258ac.jpg.webp)Who is Kash Patel, Trump's pick to shake up the FBI?The US president's loyal supporter hopes to be confirmed to run an agency that he has criticised.6 hrs ago](https://www.bbc.com/news/articles/</news/articles/c0rqpp52j5vo>)
[9 hrs ago![Olivia Rodrigo sings into a microphone with her hand pressed to her chest and her eyes closed](https://ichef.bbci.co.uk/news/480/cpsprodpb/7677/live/cb4c1c40-dee3-11ef-95b8-53b8dd8c4ede.jpg.webp)FireAid concert: Who's performing and how to watch Stars including Billie Eilish and Olivia Rodrigo are set to help raise funds to rebuild the LA area.9 hrs agoUS & Canada](https://www.bbc.com/news/articles/</news/articles/cqld9vqezqeo>)
[British Broadcasting Corporation](https://www.bbc.com/news/articles/</>)
  * [Home](https://www.bbc.com/news/articles/<https:/www.bbc.com/>)
  * [News](https://www.bbc.com/news/articles/</news>)
  * [Sport](https://www.bbc.com/news/articles/</sport>)
  * [Business](https://www.bbc.com/news/articles/</business>)
  * [Innovation](https://www.bbc.com/news/articles/</innovation>)
  * [Culture](https://www.bbc.com/news/articles/</culture>)
  * [Arts](https://www.bbc.com/news/articles/</arts>)
  * [Travel](https://www.bbc.com/news/articles/</travel>)
  * [Earth](https://www.bbc.com/news/articles/</future-planet>)
  * [Video](https://www.bbc.com/news/articles/</video>)
  * [Live](https://www.bbc.com/news/articles/</live>)
  * [Audio](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/sounds>)
  * [Weather](https://www.bbc.com/news/articles/<https:/www.bbc.com/weather>)
  * [BBC Shop](https://www.bbc.com/news/articles/<https:/shop.bbc.com/>)


BBC in other languages
## Follow BBC on:
  * [Terms of Use](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/usingthebbc/terms>)
  * [About the BBC](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/aboutthebbc>)
  * [Privacy Policy](https://www.bbc.com/news/articles/<https:/www.bbc.com/usingthebbc/privacy/>)
  * [Cookies](https://www.bbc.com/news/articles/<https:/www.bbc.com/usingthebbc/cookies/>)
  * [Accessibility Help](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/accessibility/>)
  * [Contact the BBC](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/contact>)
  * [Advertise with us](https://www.bbc.com/news/articles/<https:/www.bbc.com/advertisingcontact>)
  * [Do not share or sell my info](https://www.bbc.com/news/articles/<https:/www.bbc.com/usingthebbc/cookies/how-can-i-change-my-bbc-cookie-settings/>)
  * [Contact technical support](https://www.bbc.com/news/articles/<https:/www.bbc.com/contact-bbc-com-help>)


Copyright 2025 BBC. All rights reserved. The _BBC_ is _not responsible for the content of external sites._ [**Read about our approach to external linking.**](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/editorialguidelines/guidance/feeds-and-links>)

================
File: full_sites/www_bbc_com/news_articles_c79d7y0l03po_20250130_232001.md
================
[Skip to content](https://www.bbc.com/news/articles/<#main-content>)
[British Broadcasting Corporation](https://www.bbc.com/news/articles/</>)
[Register](https://www.bbc.com/news/articles/<https:/session.bbc.com/session?action=register&userOrigin=BBCS_BBC&ptrt=https%3A%2F%2Fwww.bbc.com%2Fnews%2Farticles%2Fc79d7y0l03po>)
[Sign In](https://www.bbc.com/news/articles/<https:/session.bbc.com/session?userOrigin=BBCS_BBC&ptrt=https%3A%2F%2Fwww.bbc.com%2Fnews%2Farticles%2Fc79d7y0l03po>)
  * [Home](https://www.bbc.com/news/articles/</>)
  * [News](https://www.bbc.com/news/articles/</news>)
  * [Sport](https://www.bbc.com/news/articles/</sport>)
  * [Business](https://www.bbc.com/news/articles/</business>)
  * [Innovation](https://www.bbc.com/news/articles/</innovation>)
  * [Culture](https://www.bbc.com/news/articles/</culture>)
  * [Arts](https://www.bbc.com/news/articles/</arts>)
  * [Travel](https://www.bbc.com/news/articles/</travel>)
  * [Earth](https://www.bbc.com/news/articles/</future-planet>)
  * [Video](https://www.bbc.com/news/articles/</video>)
  * [Live](https://www.bbc.com/news/articles/</live>)


[Register](https://www.bbc.com/news/articles/<https:/session.bbc.com/session?action=register&userOrigin=BBCS_BBC>)
[Sign In](https://www.bbc.com/news/articles/<https:/session.bbc.com/session?userOrigin=BBCS_BBC>)
[Home](https://www.bbc.com/news/articles/</>)
News
[Sport](https://www.bbc.com/news/articles/</sport>)
Business
Innovation
Culture
Arts
Travel
Earth
[Video](https://www.bbc.com/news/articles/</video>)
Live
[Audio](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/sounds>)
[Weather](https://www.bbc.com/news/articles/<https:/www.bbc.com/weather>)
[Newsletters](https://www.bbc.com/news/articles/<https:/www.bbc.com/newsletters>)
# US officials switch to recovery effort after air crash near Washington DC
3 hours ago
Share
Save
Rachel Looker, Kelly Ng, Madeline Halpert & Alex Loftus
BBC News, at Reagan National Airport, in Singapore and in New York
Share
Save
Watch: Rescue efforts as passenger jet and helicopter collide in DC
US officials say they do not expect to find any survivors after a mid-air collision near Washington DC, and have switched to a recovery operation as they continue their search of the Potomac River.
A passenger plane carrying 64 people crashed in the river after hitting a US Army helicopter near the American capital on Wednesday evening. 
Meanwhile, three US army soldiers were on board the Black Hawk helicopter. 
An official said teams had recovered 27 bodies from the plane, and one from the helicopter. A law enforcement source speaking to the BBC's US partner CBS had earlier given a higher number of 30 bodies.
The American Airlines flight from Wichita, Kansas, was approaching Ronald Reagan National Airport at around 21:00 local time (02:00 GMT) on Wednesday when the two aircraft collided. 
Figure skaters from the US were among those who were on board the aeroplane. Russia has confirmed that some of its citizens were also on board.
Several "athletes, coaches and family members" were returning from a development camp, US Figure Skating, the sport's American governing body, said in a statement. 
Russian media said the citizens on the plane were the former world champions Vadim Naumov, 55, and Evgenia Shishkova, 52, who are also married.
The Pentagon said the helicopter, a Sikorsky H-60, took off from Fort Belvoir in Virginia.
An official said it was on a training flight and belonged to B Company, 12th Aviation Battalion from Fort Belvoir in Virginia.
Multiple federal and local agencies are involved in the search effort. 
At the scene, the BBC observed debris believed to be from the aircraft floating in the Potomac River. US media says the aircraft split in half when it crashed into the water. 
BBC Verify confirmed both the plane and the helicopter were transmitting information about their flight paths and altitude ahead of the crash. 
They would have used an on board Traffic Collision Avoidance System (TCAS) to detect nearby flights, but Doug Rice, a retired American Airlines pilot, told broadcaster NBC these systems are not effective below 700ft (213m). 
The Federal Aviation Administration (FAA) said it would investigate the incident, together with the National Transportation Safety Board (NTSB).
![](https://www.bbc.com/bbcx/grey-placeholder.png)![Street map of the Washington DC area, showing a label with the last recorded plane position \(at 20:48 EST, 01:48 GMT\), in the Potomac River near the Ronald Reagan National Airport, both also highlighted. For reference, the White House has also been labelled up.](https://ichef.bbci.co.uk/news/480/cpsprodpb/518b/live/24be5830-def6-11ef-a819-277e390a7a08.png.webp)
Eyewitnesses told local media they saw sparks and flashes when the mid-air collision happened.
Ari Schulman told NBC Washington what unfolded before him quickly changed from "completely normal" to "very, very wrong".
He said there was "a stream of sparks" underneath the jet. 
BBC Transport correspondent Sean Dilley described DC's airspace as "intensely busy". 
With two major airports, heavy military traffic around the Pentagon and a Presidential airspace it is "one of the most tightly controlled airspace in the world", he said. 
  * [Live: Follow the latest updates on the crash](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/news/live/cy7kxx74yxlt>)
  * [What we know so far about the Washington DC plane crash](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/news/articles/c4g9kdgzj91o>)
  * [Watch: The scene in DC after moment of impact](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/news/videos/cwyek92v29lo>)
  * [Watch: First responders rush to the scene](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/news/videos/c93qx53pzn3o>)
  * Were you a witness to the incident? [Get in touch](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/send/u197191252>)


The city's emergency chief John Donnelly said 300 responders on rubber boats were deployed to search for survivors.
"There is wind, there are pieces of ice in the water...and because there is not a lot of light, you are out there searching every square inch of space," he said.
"These are very tough conditions for [rescuers] to dive in." 
![](https://www.bbc.com/bbcx/grey-placeholder.png)![Getty Images Emergency units respond after a passenger aircraft collided with a helicopter in the Potomac River near Ronald Reagan Washington Airport on January 30, 2025 ](https://ichef.bbci.co.uk/news/480/cpsprodpb/652c/live/38f395b0-ded6-11ef-8b60-0db4662a41ef.jpg.webp)Getty Images
The city's emergency chief said rescuers are battling cold, winds and darkness in the water
US President Donald Trump said he had been "fully briefed on the terrible accident". 
"Thank you for the incredible work being done by our first responders. I am monitoring the situation and will provide more details as they arise," he said in a statement. 
He also questioned how the incident could have happened, writing on TruthSocial that it "should have been prevented. NOT GOOD!!!"
Takeoffs and landings have been halted at Washington National as emergency personnel respond to the incident, the airport wrote in a post on X. 
Transportation Secretary Sean Duffy, whose appointment was only recently confirmed said "there will be a review of what happened here tonight". 
He said the government will take "appropriate action if necessary" to alter flight paths near Ronald Reagan airport. Flights have been diverted to Dulles International Airport, about 28 miles (45km) away.
Federal aviation authorities and the US Congress have launched investigations into the incident. 
American Airlines CEO Robert Isom expressed his "deep sorrow" and said the airline had sent a team to Washington DC, and he will be travelling there too. 
[Washington DC](https://www.bbc.com/news/articles/</news/topics/c1038wnxem1t>)
[Aviation accidents and incidents](https://www.bbc.com/news/articles/</news/topics/c2n5vpdv320t>)
[United States](https://www.bbc.com/news/articles/</news/topics/cx1m7zg01xyt>)
Related
## [In world's 'most controlled airspace', how could crash happen?56 mins agoUS & Canada](https://www.bbc.com/news/articles/</news/articles/cpdx6le5l27o>)
## [BBC Verify analyses moments before Washington DC plane crash1 hr agoUS & Canada](https://www.bbc.com/news/articles/</news/videos/c4g95z8jqr4o>)
## [US and Russian figure skaters were on board crashed plane2 hrs agoUS & Canada](https://www.bbc.com/news/articles/</news/articles/cn9370dny5xo>)
More
[49 mins ago![](https://www.bbc.com/bbcx/grey-placeholder.png)![ the 10 British servicemen who were killed when their Hercules plane crashed 30/1/2005 in Iraq. Top, from left: Squadron Leader Patrick Marshall, 39, Flight Lieutenant David Stead, 35, Flight Lieutenant Andrew Smith, 25, Flight Lieutenant Paul Pardoel, 35, Master Engineer Gary Nicholson, 42; bottom, from left: Chief Technician Richard Brown, 40, Flight Sergeant Mark Gibson, 34, Sergeant Robert O'Connor, 38, Corporal David Williams, 37, Acting Lance Corporal Steven Jones, 25.](https://ichef.bbci.co.uk/news/480/cpsprodpb/848d/live/c81f4480-df1e-11ef-a819-277e390a7a08.png.webp)Iraq Hercules crash victims remembered 20 years onTen servicemen were killed when their plane was shot down in Iraq on 30 January 2005.49 mins agoEngland](https://www.bbc.com/news/articles/</news/articles/ce8ynvn81gro>)
[54 mins ago![](https://www.bbc.com/bbcx/grey-placeholder.png)![Employees embrace at the American Airlines counter at Ronald Reagan National Airport after a nearby air crash](https://ichef.bbci.co.uk/news/480/cpsprodpb/961c/live/586a7310-df25-11ef-a819-277e390a7a08.jpg.webp)What we know so far about Washington DC plane crashThe aircraft collided with a military helicopter that was on a training flight as it approached the runway.54 mins agoUS & Canada](https://www.bbc.com/news/articles/</news/articles/c4g9kdgzj91o>)
[5 hrs ago![](https://www.bbc.com/bbcx/grey-placeholder.png)![John Donnelly wearing smart uniform speaking into microphone with crowd standing behind him](https://ichef.bbci.co.uk/news/480/cpsprodpb/5848/live/e6fcaa00-df0a-11ef-a319-fb4e7360c4ec.jpg.webp)'We don't believe there are any survivors' - DC fire chiefA plane and helicopter crashed in mid-air over Washington DC's Potomac River on Wednesday night.5 hrs ago](https://www.bbc.com/news/articles/</news/videos/c3vp1x2xq42o>)
[5 hrs ago![](https://www.bbc.com/bbcx/grey-placeholder.png)![Audio wave over Ronal Reagan Airport in DC](https://ichef.bbci.co.uk/news/480/cpsprodpb/42c1/live/d0535f40-df2a-11ef-a819-277e390a7a08.jpg.webp)Listen: Air traffic controllers appear to try to stop collisionAudio from moments before collision captures controllers asking the military helicopter if it has seen the passenger jet. 5 hrs agoUS & Canada](https://www.bbc.com/news/articles/</news/videos/ckg7kw9jnn0o>)
[6 hrs ago![](https://www.bbc.com/bbcx/grey-placeholder.png)![Man holds his left hand up while speaking to someone](https://ichef.bbci.co.uk/news/480/cpsprodpb/77ec/live/86e27c60-de4e-11ef-a7fb-0179c76258ac.jpg.webp)Who is Kash Patel, Trump's pick to shake up the FBI?The US president's loyal supporter hopes to be confirmed to run an agency that he has criticised.6 hrs ago](https://www.bbc.com/news/articles/</news/articles/c0rqpp52j5vo>)
[British Broadcasting Corporation](https://www.bbc.com/news/articles/</>)
  * [Home](https://www.bbc.com/news/articles/<https:/www.bbc.com/>)
  * [News](https://www.bbc.com/news/articles/</news>)
  * [Sport](https://www.bbc.com/news/articles/</sport>)
  * [Business](https://www.bbc.com/news/articles/</business>)
  * [Innovation](https://www.bbc.com/news/articles/</innovation>)
  * [Culture](https://www.bbc.com/news/articles/</culture>)
  * [Arts](https://www.bbc.com/news/articles/</arts>)
  * [Travel](https://www.bbc.com/news/articles/</travel>)
  * [Earth](https://www.bbc.com/news/articles/</future-planet>)
  * [Video](https://www.bbc.com/news/articles/</video>)
  * [Live](https://www.bbc.com/news/articles/</live>)
  * [Audio](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/sounds>)
  * [Weather](https://www.bbc.com/news/articles/<https:/www.bbc.com/weather>)
  * [BBC Shop](https://www.bbc.com/news/articles/<https:/shop.bbc.com/>)


BBC in other languages
## Follow BBC on:
  * [Terms of Use](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/usingthebbc/terms>)
  * [About the BBC](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/aboutthebbc>)
  * [Privacy Policy](https://www.bbc.com/news/articles/<https:/www.bbc.com/usingthebbc/privacy/>)
  * [Cookies](https://www.bbc.com/news/articles/<https:/www.bbc.com/usingthebbc/cookies/>)
  * [Accessibility Help](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/accessibility/>)
  * [Contact the BBC](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/contact>)
  * [Advertise with us](https://www.bbc.com/news/articles/<https:/www.bbc.com/advertisingcontact>)
  * [Do not share or sell my info](https://www.bbc.com/news/articles/<https:/www.bbc.com/usingthebbc/cookies/how-can-i-change-my-bbc-cookie-settings/>)
  * [Contact technical support](https://www.bbc.com/news/articles/<https:/www.bbc.com/contact-bbc-com-help>)


Copyright 2025 BBC. All rights reserved. The _BBC_ is _not responsible for the content of external sites._ [**Read about our approach to external linking.**](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/editorialguidelines/guidance/feeds-and-links>)

================
File: full_sites/www_bbc_com/news_articles_cy8pvw3xxxeo_20250130_233406.md
================
[Skip to content](https://www.bbc.com/news/articles/<#main-content>)
[British Broadcasting Corporation](https://www.bbc.com/news/articles/</>)
[Register](https://www.bbc.com/news/articles/<https:/session.bbc.com/session?action=register&userOrigin=BBCS_BBC&ptrt=https%3A%2F%2Fwww.bbc.com%2Fnews%2Farticles%2Fcy8pvw3xxxeo>)
[Sign In](https://www.bbc.com/news/articles/<https:/session.bbc.com/session?userOrigin=BBCS_BBC&ptrt=https%3A%2F%2Fwww.bbc.com%2Fnews%2Farticles%2Fcy8pvw3xxxeo>)
  * [Home](https://www.bbc.com/news/articles/</>)
  * [News](https://www.bbc.com/news/articles/</news>)
  * [Sport](https://www.bbc.com/news/articles/</sport>)
  * [Business](https://www.bbc.com/news/articles/</business>)
  * [Innovation](https://www.bbc.com/news/articles/</innovation>)
  * [Culture](https://www.bbc.com/news/articles/</culture>)
  * [Arts](https://www.bbc.com/news/articles/</arts>)
  * [Travel](https://www.bbc.com/news/articles/</travel>)
  * [Earth](https://www.bbc.com/news/articles/</future-planet>)
  * [Video](https://www.bbc.com/news/articles/</video>)
  * [Live](https://www.bbc.com/news/articles/</live>)


[Register](https://www.bbc.com/news/articles/<https:/session.bbc.com/session?action=register&userOrigin=BBCS_BBC>)
[Sign In](https://www.bbc.com/news/articles/<https:/session.bbc.com/session?userOrigin=BBCS_BBC>)
[Home](https://www.bbc.com/news/articles/</>)
News
[Sport](https://www.bbc.com/news/articles/</sport>)
Business
Innovation
Culture
Arts
Travel
Earth
[Video](https://www.bbc.com/news/articles/</video>)
Live
[Audio](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/sounds>)
[Weather](https://www.bbc.com/news/articles/<https:/www.bbc.com/weather>)
[Newsletters](https://www.bbc.com/news/articles/<https:/www.bbc.com/newsletters>)
# US teen shot dead by father in Pakistan over TikTok videos
6 hours ago
Share
Save
Kelly Ng
BBC News
Share
Save
![Getty Images TikTok on smartphone](https://ichef.bbci.co.uk/news/480/cpsprodpb/a07e/live/3fd34200-def8-11ef-98f2-fb6004d12416.jpg.webp)Getty Images
The victim's father said he found his daughter's TikTok posts "objectionable"
A man who recently moved his family back to Pakistan from the US has confessed to killing his teenage daughter because he disapproved of her TikTok videos, police have told the BBC.
Anwar ul-Haq was charged with murder after he admitted to shooting his daughter Hira in the south-western city of Quetta on Tuesday. He initially told investigators that unidentified men were behind the shooting.
The father, who has US citizenship, said he found his daughter's posts "objectionable".
Police said they were looking at all angles, including the possibility of an honour killing, which is not uncommon in the country.
Hundreds of people - most of them women - die in so-called honour killings in Pakistan each year, according to human rights groups. These killings are usually carried out by relatives who say they are acting in defence of their family's honour.
In the case of Hira Anwar, who was between 13 and 14 years old, a police spokesman said her family "had an objection to her dressing, lifestyle and social gathering".
The family lived in the US for 25 years and Hira started posting content on TikTok even before her family moved back to Pakistan.
Investigators said they were in possession on her phone, which is locked.
Her father's brother-in-law was also arrested in connection with the killing, police said.
If it is found to be an honour killing and they are found guilty, the men will face a mandatory life sentence - [a change made to the law by Pakistan's government in 2016](https://www.bbc.com/news/articles/<https:/www.bbc.com/news/world-asia-37578111>). Previously, they could avoid a jail term if pardoned by the victim's family.
In 2023, an Italian court handed a Pakistani couple [life sentences](https://www.bbc.com/news/articles/<https:/www.bbc.com/news/world-europe-67769159>) for killing their 18-year-old daughter because [she refused an arranged marriage](https://www.bbc.com/news/articles/<https:/www.bbc.com/news/world-europe-57425961>).
The year before, the brother of Pakistani social media star Qandeel Baloch was acquitted of murdering her on appeal. He had earlier been sentenced to life in prison after confessing to the 2016 killing, saying it was because the star had brought shame on the family.
## [Pakistan 'honour killing' sparked by doctored photo](https://www.bbc.com/news/articles/<https:/www.bbc.com/news/world-asia-67551554>)
## [A murder that reflects a divided nation](https://www.bbc.com/news/articles/<https:/www.bbc.com/news/world-asia-36815808>)
[Pakistan](https://www.bbc.com/news/articles/</news/topics/c008ql15vpyt>)
[Asia](https://www.bbc.com/news/articles/</news/topics/c5rznn0nvvyt>)
Related
## [West Indies in Pakistan 20253 days agoCricket](https://www.bbc.com/news/articles/</sport/cricket/articles/c4ng0d1x17yo>)
## [Windies seal first Test win in Pakistan for 34 years3 days agoCricket](https://www.bbc.com/news/articles/</sport/cricket/articles/cy48jg9jqw0o>)
## [Pakistan Youtuber ordered to make welfare videos for owning lion6 days agoAsia](https://www.bbc.com/news/articles/</news/articles/c897e1jgypdo>)
More
[11 hrs ago![Virat Kohli of India bats during day two of the Fifth Men's Test Match in the series between Australia and India at Sydney Cricket Ground on January 04, 2025 in Sydney, Australia. ](https://ichef.bbci.co.uk/news/480/cpsprodpb/e87e/live/909d3e10-ded1-11ef-8b60-0db4662a41ef.jpg.webp)Fans fill stadium for Virat Kohli's first domestic match in 12 yearsThe star batter has been facing a lean patch and has struggled for consistency in recent years. 11 hrs agoAsia](https://www.bbc.com/news/articles/</news/articles/cn8xvmjz8vxo>)
[14 hrs ago![Aerial view of a sinkhole, surrounded by fire trucks and rescuers](https://ichef.bbci.co.uk/news/480/cpsprodpb/860f/live/efec6250-dec3-11ef-bc61-5d0c625d7721.jpg.webp)Rescuers race to pull out truck driver stuck in Japan sinkhole for daysThe sinkhole in Yashio city has now grown to the size of a swimming pool, following road collapses.14 hrs agoAsia](https://www.bbc.com/news/articles/</news/articles/cx24pvgxn0no>)
[1 day ago![Hindu pilgrims stand inside a lost and found centre after they lost their relatives in crowds during the Maha Kumbh Mela festival in Prayagraj, India on January 28, 2025.](https://ichef.bbci.co.uk/news/480/cpsprodpb/0aa4/live/6306e880-de03-11ef-93a3-c3537ac3e868.jpg.webp)Thirty killed in crowd crush at India's Kumbh Mela festivalPilgrims rushing to take part in ritual bathing trampled over people on the banks of the Ganges.1 day agoAsia](https://www.bbc.com/news/articles/</news/articles/c3rwjnr12lwo>)
[1 day ago![Dragon dancers perform for the crowd in Manila](https://ichef.bbci.co.uk/news/480/cpsprodpb/107c/live/8567e6f0-de25-11ef-a37f-eba91255dc3d.jpg.webp)In pictures: Welcoming the Lunar New YearFireworks, music, lanterns, and dragon dancing filled streets across Asia to celebrate the Year of the Snake.1 day agoAsia](https://www.bbc.com/news/articles/</news/articles/cy9lp0z3edqo>)
[2 days ago![The traffic from Malaysia to Singapore on the JohorSingapore Causeway seen from Singapore](https://ichef.bbci.co.uk/news/480/cpsprodpb/8668/live/8d3bac50-ddfc-11ef-b9c7-b17eb95b0516.jpg.webp)Singapore influencer fined over false abduction claimShe alleged she was almost kidnapped at a mall on the Malaysian side of the border between the countries.2 days agoAsia](https://www.bbc.com/news/articles/</news/articles/c5y6l2pvvpxo>)
[British Broadcasting Corporation](https://www.bbc.com/news/articles/</>)
  * [Home](https://www.bbc.com/news/articles/<https:/www.bbc.com/>)
  * [News](https://www.bbc.com/news/articles/</news>)
  * [Sport](https://www.bbc.com/news/articles/</sport>)
  * [Business](https://www.bbc.com/news/articles/</business>)
  * [Innovation](https://www.bbc.com/news/articles/</innovation>)
  * [Culture](https://www.bbc.com/news/articles/</culture>)
  * [Arts](https://www.bbc.com/news/articles/</arts>)
  * [Travel](https://www.bbc.com/news/articles/</travel>)
  * [Earth](https://www.bbc.com/news/articles/</future-planet>)
  * [Video](https://www.bbc.com/news/articles/</video>)
  * [Live](https://www.bbc.com/news/articles/</live>)
  * [Audio](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/sounds>)
  * [Weather](https://www.bbc.com/news/articles/<https:/www.bbc.com/weather>)
  * [BBC Shop](https://www.bbc.com/news/articles/<https:/shop.bbc.com/>)


BBC in other languages
## Follow BBC on:
  * [Terms of Use](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/usingthebbc/terms>)
  * [About the BBC](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/aboutthebbc>)
  * [Privacy Policy](https://www.bbc.com/news/articles/<https:/www.bbc.com/usingthebbc/privacy/>)
  * [Cookies](https://www.bbc.com/news/articles/<https:/www.bbc.com/usingthebbc/cookies/>)
  * [Accessibility Help](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/accessibility/>)
  * [Contact the BBC](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/contact>)
  * [Advertise with us](https://www.bbc.com/news/articles/<https:/www.bbc.com/advertisingcontact>)
  * [Do not share or sell my info](https://www.bbc.com/news/articles/<https:/www.bbc.com/usingthebbc/cookies/how-can-i-change-my-bbc-cookie-settings/>)
  * [Contact technical support](https://www.bbc.com/news/articles/<https:/www.bbc.com/contact-bbc-com-help>)


Copyright 2025 BBC. All rights reserved. The _BBC_ is _not responsible for the content of external sites._ [**Read about our approach to external linking.**](https://www.bbc.com/news/articles/<https:/www.bbc.co.uk/editorialguidelines/guidance/feeds-and-links>)

================
File: full_sites/www_bbc_com/sport_football_articles_cx2pyer4d14o_20250130_231945.md
================
[BBC Homepage](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com>)
  * [Skip to content](https://www.bbc.com/sport/football/articles/<#main-heading>)
  * [Accessibility Help](https://www.bbc.com/sport/football/articles/<https:/www.bbc.co.uk/accessibility/>)


  * [Your account](https://www.bbc.com/sport/football/articles/<https:/account.bbc.com/account?lang=en-GB&ptrt=https%3A%2F%2Fwww.bbc.com%2Fsport%2Ffootball%2Farticles%2Fcx2pyer4d14o&userOrigin=SPORT_GNL>)


  * [Home](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com>)
  * [News](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/news>)
  * [Sport](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/sport>)
  * [Business](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/business>)
  * [Innovation](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/innovation>)
  * [Culture](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/culture>)
  * [Travel](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/travel>)
  * [Earth](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/future-planet>)
  * [Video](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/video>)
  * [Live](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/live>)
  * [More menu](https://www.bbc.com/sport/football/articles/<#global-navigation-more-menu>)


[More menu](https://www.bbc.com/sport/football/articles/<#global-navigation-more-menu>)
[Search BBC](https://www.bbc.com/sport/football/articles/<https:/www.bbc.co.uk/search?d=SPORT_GNL>)
  * [Home](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com>)
  * [News](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/news>)
  * [Sport](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/sport>)
  * [Business](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/business>)
  * [Innovation](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/innovation>)
  * [Culture](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/culture>)
  * [Travel](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/travel>)
  * [Earth](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/future-planet>)
  * [Video](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/video>)
  * [Live](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/live>)


[Close menu](https://www.bbc.com/sport/football/articles/<#more-menu-button>)
[BBC Sport](https://www.bbc.com/sport/football/articles/</sport>)
[Menu](https://www.bbc.com/sport/football/articles/</sport/all-sports>)
  * [Home](https://www.bbc.com/sport/football/articles/</sport>)
  * [Football](https://www.bbc.com/sport/football/articles/</sport/football>)
  * [Cricket](https://www.bbc.com/sport/football/articles/</sport/cricket>)
  * [Formula 1](https://www.bbc.com/sport/football/articles/</sport/formula1>)
  * [Rugby U](https://www.bbc.com/sport/football/articles/</sport/rugby-union>)
  * [Tennis](https://www.bbc.com/sport/football/articles/</sport/tennis>)
  * [Golf](https://www.bbc.com/sport/football/articles/</sport/golf>)
  * [Athletics](https://www.bbc.com/sport/football/articles/</sport/athletics>)
  * [Cycling](https://www.bbc.com/sport/football/articles/</sport/cycling>)


[More](https://www.bbc.com/sport/football/articles/</sport/all-sports>)
**A-Z Sports**
  * [ American Football](https://www.bbc.com/sport/football/articles/</sport/american-football>)
  * [Athletics](https://www.bbc.com/sport/football/articles/</sport/athletics>)
  * [Basketball](https://www.bbc.com/sport/football/articles/</sport/basketball>)
  * [Boxing](https://www.bbc.com/sport/football/articles/</sport/boxing>)
  * [Cricket](https://www.bbc.com/sport/football/articles/</sport/cricket>)
  * [Cycling](https://www.bbc.com/sport/football/articles/</sport/cycling>)
  * [Darts](https://www.bbc.com/sport/football/articles/</sport/darts>)
  * [Disability Sport](https://www.bbc.com/sport/football/articles/</sport/disability-sport>)
  * [Football](https://www.bbc.com/sport/football/articles/</sport/football>)
  * [Formula 1](https://www.bbc.com/sport/football/articles/</sport/formula1>)
  * [Gaelic Games](https://www.bbc.com/sport/football/articles/</sport/northern-ireland/gaelic-games>)
  * [Golf](https://www.bbc.com/sport/football/articles/</sport/golf>)
  * [Gymnastics](https://www.bbc.com/sport/football/articles/</sport/gymnastics>)
  * [Horse Racing](https://www.bbc.com/sport/football/articles/</sport/horse-racing>)
  * [Mixed Martial Arts](https://www.bbc.com/sport/football/articles/</sport/mixed-martial-arts>)
  * [Motorsport](https://www.bbc.com/sport/football/articles/</sport/motorsport>)
  * [Netball](https://www.bbc.com/sport/football/articles/</sport/netball>)
  * [Olympic Sports](https://www.bbc.com/sport/football/articles/</sport/olympics>)
  * [Rugby League](https://www.bbc.com/sport/football/articles/</sport/rugby-league>)
  * [Rugby Union](https://www.bbc.com/sport/football/articles/</sport/rugby-union>)
  * [Snooker](https://www.bbc.com/sport/football/articles/</sport/snooker>)
  * [Swimming](https://www.bbc.com/sport/football/articles/</sport/swimming>)
  * [Tennis](https://www.bbc.com/sport/football/articles/</sport/tennis>)
  * [Winter Sports](https://www.bbc.com/sport/football/articles/</sport/winter-sports>)
  * [Full Sports A-Z](https://www.bbc.com/sport/football/articles/</sport/all-sports>)


**More from Sport**
  * [ England](https://www.bbc.com/sport/football/articles/</sport/england>)
  * [Scotland](https://www.bbc.com/sport/football/articles/</sport/scotland>)
  * [Wales](https://www.bbc.com/sport/football/articles/</sport/wales>)
  * [Northern Ireland](https://www.bbc.com/sport/football/articles/</sport/northern-ireland>)
  * [News Feeds](https://www.bbc.com/sport/football/articles/</sport/15890345>)
  * [Help & FAQs](https://www.bbc.com/sport/football/articles/</sport/15561348>)


  * [Football](https://www.bbc.com/sport/football/articles/</sport/football>)
  * [Scores & Fixtures](https://www.bbc.com/sport/football/articles/</sport/football/scores-fixtures>)
  * [Tables](https://www.bbc.com/sport/football/articles/</sport/football/tables>)
  * [Gossip](https://www.bbc.com/sport/football/articles/</sport/football/gossip>)
  * [Transfers](https://www.bbc.com/sport/football/articles/</sport/football/transfers>)
  * [Top Scorers](https://www.bbc.com/sport/football/articles/</sport/football/premier-league/top-scorers>)
  * [Women](https://www.bbc.com/sport/football/articles/</sport/football/womens>)
  * [European](https://www.bbc.com/sport/football/articles/</sport/football/european>)
  * [All Teams](https://www.bbc.com/sport/football/articles/</sport/football/teams>)
  * [Leagues & Cups](https://www.bbc.com/sport/football/articles/</sport/football/leagues-cups>)
  * [Quizzes](https://www.bbc.com/sport/football/articles/</sport/football-quizzes>)


# Gerrard leaves Al-Ettifaq after 18 months in charge
![Steven Gerrard sits in the dugout ](https://ichef.bbci.co.uk/ace/standard/807/cpsprodpb/b614/live/02228f90-de64-11ef-9863-c1cbabfba6e7.jpg)Image source, Getty Images
Image caption, 
Steven Gerrard managed Rangers and Aston Villa before joining Al-Ettifaq in the summer of 2023
  * Published
5 hours ago


**Steven Gerrard has left his role as manager of Al-Ettifaq by mutual consent after 18 months in charge.**
The former Aston Villa and Rangers boss joined the Saudi Arabian club in July 2023.
Ex-England and Liverpool midfielder Gerrard [signed a two-year extension](https://www.bbc.com/sport/football/articles/</sport/football/68019672>) to his initial deal in January 2024, contracting him to the club until 2027.
But Al-Ettifaq have won just five of their 17 league matches this season, leaving them five points above the relegation zone.
"Football is unpredictable and sometimes things don't go the way we want," said Gerrard.
"However, I leave with great respect for the club and the country. I have no doubt that the work being done will bring success in the future and I wish the team the very best for the rest of the season.
"From the first day I was warmly welcomed and I have enjoyed the chance to work in a new country with a different culture.
"Overall I have learnt a lot and it's been a positive experience personally and for my family as well."
Al-Ettifaq club president Samer Al Misehal said Gerrard transformed the club.
"Sometimes things don't go as planned, but the firm foundations he helped build will guarantee a bright future in the long term," the president said.
"He changed the club for the better and that will never be forgotten. This decision, made with mutual respect and in agreement is in the best interest of both Steven and the club as we move forward."
After a stellar playing career with Liverpool and England, 44-year-old Gerrard began his managerial career with Rangers in 2018 and led the club to their first Scottish Premiership title in 10 years in 2020-21.
He succeeded Dean Smith as Villa manager in November 2021, but was sacked 11 months later after only 13 wins in 40 games.
Gerrard guided Al-Ettifaq to a sixth-place finish during his first season.
But he leaves with them 12th in a 16-team league, having won 23 of his 59 matches overall.
Gerrard was reportedly one of the best-paid managers in world football during his time in Saudi Arabia, on a salary of about £15m per year.
## Related topics
  * [Football](https://www.bbc.com/sport/football/articles/</sport/football>)


## More on this story
  * [Listen to the latest Football Daily podcast](https://www.bbc.com/sport/football/articles/</sounds/series/p02nrsln>)
  * [Get football news sent straight to your phone](https://www.bbc.com/sport/football/articles/</sport/articles/cl5q9dk9jl3o>)
    * Published
6 June 2024
![BBC Sport microphone and phone](https://ichef.bbci.co.uk/ace/standard/815/cpsprodpb/b2c7/live/922d6170-544c-11ef-aebc-6de4d31bf5cd.jpg)


## Top stories
  * [US and Russian figure skaters were on board crashed plane](https://www.bbc.com/sport/football/articles/</news/articles/cn9370dny5xo>)
    * Published
1 hour ago
  * [Europa League final day - who is through and what's at stake?](https://www.bbc.com/sport/football/articles/</sport/football/articles/c5yellwg3r4o>)
    * Published
7 hours ago
  * [Gerrard leaves Al-Ettifaq after 18 months in charge](https://www.bbc.com/sport/football/articles/</sport/football/articles/cx2pyer4d14o>)
    * Published
5 hours ago


## Elsewhere on the BBC
  * [Watch the UEFA Champions League highlights on iPlayer](https://www.bbc.com/sport/football/articles/</iplayer/episodes/m0021zjc?at_mid=VUevvd6Qma&at_campaign=UEFA_Champions_League_Highlights_2_Oct_2024&at_medium=display_ad&at_campaign_type=owned&at_audience_id=SS&at_product=iplayer&at_brand=m0021zjc&at_ptr_name=bbc&at_ptr_type=media&at_format=image&at_objective=consumption&at_link_title=UEFA_Champions_League_Highlights_2_Oct_2024&at_bbc_team=BBC>)
All the goals and unmissable moments from Europe's greatest football club competition
![UEFA Champions League](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/5d42/live/ccab6670-71bc-11ef-b282-4535eb84fe4b.jpg)
  * [Alison's camper van-style adventure](https://www.bbc.com/sport/football/articles/</iplayer/episode/m00272h2?at_mid=ceP0NRfW5G&at_campaign=Alison_Hammonds_Florida_Unpacked_S1_E1&at_medium=display_ad&at_campaign_type=owned&at_audience_id=SS&at_product=iplayer&at_brand=m00272gy&at_ptr_name=bbc&at_ptr_type=media&at_format=image&at_objective=consumption&at_link_title=Alison_Hammonds_Florida_Unpacked_S1_E1&at_bbc_team=BBC>)
Alison Hammond and her son, Aidan, tour America’s most colourful state in a jam-packed journey
![Alison Hammond's Florida Unpacked ](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/c00a/live/79c5d610-dc8e-11ef-bc01-8f2c83dad217.jpg)
  * [Why do we gossip?](https://www.bbc.com/sport/football/articles/</sounds/play/m0027520?at_mid=AvvodNu5G9&at_campaign=Why_Do_We_Do_That_Gossip&at_medium=display_ad&at_campaign_type=owned&at_audience_id=SS&at_product=sounds&at_brand=m001dgrp&at_ptr_name=bbc&at_ptr_type=media&at_format=image&at_objective=consumption&at_link_title=Why_Do_We_Do_That_Gossip&at_bbc_team=BBC>)
Anthropologist Ella Al-Shamahi uncovers the truth about an age-old human habit
![Why Do We Do That?](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/c655/live/c221b3b0-d97e-11ef-bc01-8f2c83dad217.jpg)
  * [Steven Knight's hit war drama has returned](https://www.bbc.com/sport/football/articles/</iplayer/episode/m0025ydc?at_mid=9qRiW1kH79&at_campaign=SAS_Rogue_Heroes_S2&at_medium=display_ad&at_campaign_type=owned&at_audience_id=SS&at_product=iplayer&at_brand=p0d5z0xy&at_ptr_name=bbc&at_ptr_type=media&at_format=image&at_objective=consumption&at_link_title=SAS_Rogue_Heroes_S2&at_bbc_team=BBC>)
Watch all episodes of the adrenaline-fuelled new series on BBC iPlayer now
![SAS Rogue Heroes](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/78f2/live/882543e0-bf05-11ef-a0f2-fd81ae5962f4.jpg)


## Elsewhere in Sport
  * ['Warne-esque' Alana shines at the King's HQ](https://www.bbc.com/sport/football/articles/</sport/cricket/articles/cjderkm2m7eo>)
![Australia leg-spinner Alana King celebrates a wicket with Georgia Voll](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/c0c4/live/98874c20-df0c-11ef-a319-fb4e7360c4ec.jpg)
  * [Beckham, Aguero, Formula E and celebrity influence on sport](https://www.bbc.com/sport/football/articles/</sport/motorsport/articles/cgj2gn98e20o>)
![Brooklyn Beckham behind the wheel of a Formula E car at the Mexico E-Prix in 2020](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/d80b/live/bd940440-dcaa-11ef-8ed5-8b292d335eb0.jpg)
  * [Scotland's Russell on Netflix, near misses & family](https://www.bbc.com/sport/football/articles/</sport/rugby-union/articles/c30dvjz8vz8o>)
![Finn Russell with his family](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/ef8c/live/27853310-de77-11ef-870c-5da91328a8f3.jpg)
  * [Five ways a new format has transformed the Champions League](https://www.bbc.com/sport/football/articles/</sport/football/articles/c2d30gl3dl3o>)
![Champions League logo at Real Madrid](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/6fd3/live/47eacb20-d9c1-11ef-a37f-eba91255dc3d.png)
  * [How does the Six Nations scoring work? VideoHow does the Six Nations scoring work?](https://www.bbc.com/sport/football/articles/</sport/rugby-union/videos/c75zv66w293o>)
![Ireland team, France team](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/47cd/live/02b5b120-df0f-11ef-a819-277e390a7a08.jpg)
  * [Who is through in Champions League and what's next?](https://www.bbc.com/sport/football/articles/</sport/football/articles/c2d3n579rkjo>)
![Arsenal celebrate](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/7692/live/d02ffe60-de9e-11ef-89c4-9fc5608573ce.jpg)
  * [Six players to watch out for in the Six Nations](https://www.bbc.com/sport/football/articles/</sport/rugby-union/articles/cn4zw81dydgo>)
![Sam Prendergast, Tom Willis, Dan Edwards and Tom Jordan](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/5de1/live/c0a53340-dd57-11ef-8e2a-672c89b13e12.png)
  * [How Mbappe & Bellingham sparked Real Madrid's resurgence](https://www.bbc.com/sport/football/articles/</sport/football/articles/cdjdzxj1vlyo>)
![Kylian Mbappe, Vinicius Junior, Rodrygo and Jude Bellingham](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/6070/live/9710f790-dd92-11ef-bc01-8f2c83dad217.png)
  * [How Van Dijk surprised Liverpool manager Slot](https://www.bbc.com/sport/football/articles/</sport/football/articles/c70k1dn1dgxo>)
![Virgil van Dijk and Arne Slot](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/09d9/live/4addb0c0-ddb0-11ef-a69b-6ddb4eb9391c.jpg)
  * [Why are Australia so much better than England?](https://www.bbc.com/sport/football/articles/</sport/cricket/articles/c04nepk34pdo>)
![Graphic showing dejected England and happy Australia](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/4a61/live/4b8c8d10-dcad-11ef-902e-cf9b84dc1357.jpg)
  * [McIlroy 'three goals' from career satisfaction](https://www.bbc.com/sport/football/articles/</sport/golf/articles/cvg8rnn28qwo>)
![Rory McIlroy celebrates winning a point for Europe against the US at the 2023 Ryder Cup in Rome](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/9158/live/921f5750-dcba-11ef-b089-1d31170cd28b.jpg)
  * [In Pictures: Sporting photos of the week](https://www.bbc.com/sport/football/articles/</sport/articles/c1dgq1gg6y4o>)
![Chelsea player Cole Palmer speaking with Manchester City manager Pep Guardiola](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/1eb6/live/8a580f70-dd6f-11ef-a37f-eba91255dc3d.jpg)
  * [Will Ireland author a first Six Nations three-peat?](https://www.bbc.com/sport/football/articles/</sport/rugby-union/articles/c8ed4g484p3o>)
![Ireland players celebrate their 2024 Six Nations success](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/6515/live/a3a497f0-da95-11ef-9d49-337410df6aa3.jpg)
  * ['A sheep to the slaughter' - Odemwingie's famous drive to QPR. Video'A sheep to the slaughter' - Odemwingie's famous drive to QPR](https://www.bbc.com/sport/football/articles/</sport/football/videos/cgrn5qdypl5o>)
![Deadline Day Dramas: Peter Odemwingie](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/60a4/live/54b03fa0-d8e2-11ef-a37f-eba91255dc3d.jpg)
  * [What is carbon monoxide rebreathing and why is cycling trying to ban it?](https://www.bbc.com/sport/football/articles/</sport/cycling/articles/cevezewr8zpo>)
![Jonas Vingegaard and Tadej Pogacar](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/c37b/live/fa32fd00-dc98-11ef-bc01-8f2c83dad217.jpg)
  * [Are we in a golden age of the Six Nations?](https://www.bbc.com/sport/football/articles/</sport/extra/8ah6oemcah/Six-Nation-The-Golden-Age>)
![Six Nations rugby union players ](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/4f36/live/5ef9e7e0-dca7-11ef-a37f-eba91255dc3d.jpg)
  * [Cole Palmer - made in the Caribbean](https://www.bbc.com/sport/football/articles/</sport/extra/en7wd155d9/cole-palmer-made-in-the-caribbean>)
![Cole Palmer](https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/b297/live/5a6e0410-d589-11ef-87df-d575b9a434a4.jpg)


  * [Home](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com>)
  * [News](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/news>)
  * [Sport](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/sport>)
  * [Business](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/business>)
  * [Innovation](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/innovation>)
  * [Culture](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/culture>)
  * [Travel](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/travel>)
  * [Earth](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/future-planet>)
  * [Video](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/video>)
  * [Live](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/live>)


  * [Terms of Use](https://www.bbc.com/sport/football/articles/<https:/www.bbc.co.uk/usingthebbc/terms>)
  * [About the BBC](https://www.bbc.com/sport/football/articles/<https:/www.bbc.co.uk/aboutthebbc>)
  * [Privacy Policy](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/usingthebbc/privacy>)
  * [Cookies](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/usingthebbc/cookies>)
  * [Accessibility Help](https://www.bbc.com/sport/football/articles/<https:/www.bbc.co.uk/accessibility>)
  * [Parental Guidance](https://www.bbc.com/sport/football/articles/<https:/www.bbc.co.uk/iplayer/guidance>)
  * [Contact the BBC](https://www.bbc.com/sport/football/articles/<https:/www.bbc.co.uk/contact>)
  * [BBC emails for you](https://www.bbc.com/sport/football/articles/<https:/www.bbc.co.uk/bbcnewsletter>)
  * [Advertise with us](https://www.bbc.com/sport/football/articles/<https:/www.bbc.com/advertisingcontact/>)


Copyright © 2025 BBC. The BBC is not responsible for the content of external sites. [Read about our approach to external linking.](https://www.bbc.com/sport/football/articles/<https:/www.bbc.co.uk/editorialguidelines/guidance/feeds-and-links>)

================
File: full_sites/www_bbc_com/travel_specialist_20250130_231952.md
================
[Skip to content](https://www.bbc.com/travel/<#main-content>)
[British Broadcasting Corporation](https://www.bbc.com/travel/</>)
[Register](https://www.bbc.com/travel/<https:/session.bbc.com/session?action=register&userOrigin=BBCS_BBC&ptrt=https%3A%2F%2Fwww.bbc.com%2Ftravel%2Fspecialist>)
[Sign In](https://www.bbc.com/travel/<https:/session.bbc.com/session?userOrigin=BBCS_BBC&ptrt=https%3A%2F%2Fwww.bbc.com%2Ftravel%2Fspecialist>)
  * [Home](https://www.bbc.com/travel/</>)
  * [News](https://www.bbc.com/travel/</news>)
  * [Sport](https://www.bbc.com/travel/</sport>)
  * [Business](https://www.bbc.com/travel/</business>)
  * [Innovation](https://www.bbc.com/travel/</innovation>)
  * [Culture](https://www.bbc.com/travel/</culture>)
  * [Arts](https://www.bbc.com/travel/</arts>)
  * [Travel](https://www.bbc.com/travel/</travel>)
  * [Earth](https://www.bbc.com/travel/</future-planet>)
  * [Video](https://www.bbc.com/travel/</video>)
  * [Live](https://www.bbc.com/travel/</live>)


  * [Destinations](https://www.bbc.com/travel/</travel/destinations>)
  * [World’s Table](https://www.bbc.com/travel/</travel/worlds-table>)
  * [Culture & Experiences](https://www.bbc.com/travel/</travel/cultural-experiences>)
  * [Adventures](https://www.bbc.com/travel/</travel/adventures>)
  * [The SpeciaList](https://www.bbc.com/travel/</travel/specialist>)


[Register](https://www.bbc.com/travel/<https:/session.bbc.com/session?action=register&userOrigin=BBCS_BBC>)
[Sign In](https://www.bbc.com/travel/<https:/session.bbc.com/session?userOrigin=BBCS_BBC>)
[Home](https://www.bbc.com/travel/</>)
News
[Sport](https://www.bbc.com/travel/</sport>)
Business
Innovation
Culture
Arts
Travel
Earth
[Video](https://www.bbc.com/travel/</video>)
Live
[Audio](https://www.bbc.com/travel/<https:/www.bbc.co.uk/sounds>)
[Weather](https://www.bbc.com/travel/<https:/www.bbc.com/weather>)
[Newsletters](https://www.bbc.com/travel/<https:/www.bbc.com/newsletters>)
# The SpeciaList
[![Tia Carrere \(Credit: Tia Carrere\)](https://ichef.bbci.co.uk/images/ic/raw/p0klyjxd.jpg.webp)Six ways to experience family-friendly HawaiiActress and singer Tia Carrere has deep Hawaiian roots and loves sharing her culture via music, films and moments spent with family. Here are her favourite ways to find "ohana" in Hawaii.5 days agoTravel](https://www.bbc.com/travel/</travel/article/20250124-tia-carreres-family-guide-to-visiting-hawaii>)
[![Huda Kattan \(Credit: Courtesy of Huda Kattan\)](https://ichef.bbci.co.uk/images/ic/480x270/p0kkgd1r.jpg.webp)A beauty mogul's guide to luxury self-care in DubaiDubai is synonymous with luxury and pampering, and Huda Beauty founder Huda Kattan knows where to find it. Here are her Dubai picks, from heavenly massages to crystal shopping.22 Jan 2025Travel](https://www.bbc.com/travel/</travel/article/20250121-huda-kattans-guide-to-self-care-in-dubai>)
[![Tia Carrere \(Credit: Tia Carrere\)](https://ichef.bbci.co.uk/images/ic/raw/p0klyjxd.jpg.webp)Six ways to experience family-friendly HawaiiActress and singer Tia Carrere has deep Hawaiian roots and loves sharing her culture via music, films and moments spent with family. Here are her favourite ways to find "ohana" in Hawaii.5 days agoTravel](https://www.bbc.com/travel/</travel/article/20250124-tia-carreres-family-guide-to-visiting-hawaii>)
[![Huda Kattan \(Credit: Courtesy of Huda Kattan\)](https://ichef.bbci.co.uk/images/ic/480x270/p0kkgd1r.jpg.webp)A beauty mogul's guide to luxury self-care in DubaiDubai is synonymous with luxury and pampering, and Huda Beauty founder Huda Kattan knows where to find it. Here are her Dubai picks, from heavenly massages to crystal shopping.22 Jan 2025Travel](https://www.bbc.com/travel/</travel/article/20250121-huda-kattans-guide-to-self-care-in-dubai>)
[![The northern lights in Greenland \(Credit: Getty Images\)](https://ichef.bbci.co.uk/images/ic/480x270/p0kh6d2j.jpg.webp)Six ways to experience GreenlandGreenlandic politician and Inuit educator Aleqa Hammond shares her top ways to experience the country, from sampling Greenlandic cuisine to viewing the Northern Lights in Ilulissat.18 Jan 2025Travel](https://www.bbc.com/travel/</travel/article/20250107-a-tour-of-greenland-with-the-countrys-first-female-prime-minister>)
[![A bowl of New England clam chowder \(Credit: Alamy\)](https://ichef.bbci.co.uk/images/ic/480x270/p0khxsvn.jpg.webp)Where to find Boston's best clam chowderChef Jeremy Sewall has cooked around the world, but home in Boston, he's known for his clam chowder. Here are his top local picks, from Neptune Oyster to Yankee Lobster.11 Jan 2025Travel](https://www.bbc.com/travel/</travel/article/20250110-a-chefs-guide-to-bostons-best-clam-chowder>)
[![Angelababy in Hong Kong \(Credit: Courtesy of Angelababy\)](https://ichef.bbci.co.uk/images/ic/480x270/p0kmgb2x.jpg.webp)A Chinese fashion influencer's guide to Hong KongAngelababy has called Hong Kong home since she was a young girl. Here are her local insider picks, from shopping on Hollywood Road to hiking Dragon's Back.](https://www.bbc.com/travel/</travel/article/20250127-angelababys-guide-to-hong-kong>)
[![The northern lights in Greenland \(Credit: Getty Images\)](https://ichef.bbci.co.uk/images/ic/480x270/p0kh6d2j.jpg.webp)Six ways to experience GreenlandGreenlandic politician and Inuit educator Aleqa Hammond shares her top ways to experience the country, from sampling Greenlandic cuisine to viewing the Northern Lights in Ilulissat.18 Jan 2025Travel](https://www.bbc.com/travel/</travel/article/20250107-a-tour-of-greenland-with-the-countrys-first-female-prime-minister>)
[![A bowl of New England clam chowder \(Credit: Alamy\)](https://ichef.bbci.co.uk/images/ic/480x270/p0khxsvn.jpg.webp)Where to find Boston's best clam chowderChef Jeremy Sewall has cooked around the world, but home in Boston, he's known for his clam chowder. Here are his top local picks, from Neptune Oyster to Yankee Lobster.11 Jan 2025Travel](https://www.bbc.com/travel/</travel/article/20250110-a-chefs-guide-to-bostons-best-clam-chowder>)
[![Ice swimmer Elina Mäkinen in an ice hole in Finland \(Credit: Taneli Kantanen\)](https://ichef.bbci.co.uk/images/ic/480x270/p0kgzd5z.jpg.webp)An ironwoman's guide to Finland's best icy plungesElina Mäkinen was the first Finnish woman to complete the Ice Mile. Here are her top ice bathing experiences, from plunges under the Northern Lights to paying homage to Arctic gods.8 Jan 2025Travel](https://www.bbc.com/travel/</travel/article/20250106-a-finnish-ironwomans-guide-to-finlands-best-outdoor-icy-plunges>)
[![Melanie Zanetti in a helicopter overlooking the city of Brisbane, Australia \(Credit: Nic Morely\)](https://ichef.bbci.co.uk/images/ic/480x270/p0kftlrv.jpg.webp)Bluey's mum's family-friendly guide to BrisbaneAustralian actress Melanie Zanetti, the voice behind Chilli Heeler, knows exactly what makes Brisbane so special. Here are her top picks for families in Queensland's capital.5 Jan 2025Travel](https://www.bbc.com/travel/</travel/article/20241230-a-family-friendly-guide-to-brisbane-australia-with-blueys-mum>)
[![Man skiing down steep terrain in Tuckerman Ravine, New Hampshire \(Credit: Alamy\)](https://ichef.bbci.co.uk/images/ic/480x270/p0kd221n.jpg.webp)Seven of New England's best ski experiencesChris Davenport is a born New Englander who learned his craft on the region's best slopes. Here are his favourite places to ski in the north-east, from Jay Peak to Stowe.21 Dec 2024Travel](https://www.bbc.com/travel/</travel/article/20241219-an-extreme-skiing-champions-guide-to-the-best-slopes-in-new-england>)
[![The snowy slopes of Whistler, Canada \(Credit: Kevin Fogolin\)](https://ichef.bbci.co.uk/images/ic/480x270/p0kcm6rx.jpg.webp)A freeski champion's guide to WhistlerCanada's Mike Douglas stands at the vanguard of his hometown's ski culture. Here are his local favourites, from schussing down Peak to Creek to ahi poke at Sushi Village.18 Dec 2024Travel](https://www.bbc.com/travel/</travel/article/20241217-a-guide-to-whistler-canada-from-the-godfather-of-freeskiing-mike-douglas>)
[![Rifugio Scoiattoli in Cortina d'Ampezzo, Dolomites, Italy \(Credit: Alamy\)](https://ichef.bbci.co.uk/images/ic/480x270/p0kbn41s.jpg.webp)How to spend a ski break in Cortina d'AmpezzoAs the world turns its gaze to Italy's Cortina d'Ampezzo - one of the hosts of the 2026 Winter Olympics - ski champion Kristian Ghedina shares his hometown picks.14 Dec 2024Travel](https://www.bbc.com/travel/</travel/article/20241212-a-downhill-ski-champions-guide-to-cortina-dampezzo-italy>)
[![](https://ichef.bbci.co.uk/images/ic/480x270/p0gtwr8t.jpg.webp)A stylist's guide to New York shoppingJust in time for the holidays, stylist to the stars Erin Walsh shares her insider recommendations for getting to the heart of New York City's vast shopping scene.11 Dec 2024Travel](https://www.bbc.com/travel/</travel/article/20231120-a-fashion-experts-insider-guide-to-shopping-in-new-york-city>)
## Watch
[![The Finnish secret to happiness: Avanto and Lu00f6yly](https://ichef.bbci.co.uk/images/ic/480x270/p0kl1w07.jpg.webp)The Finnish secret to happinessNordic etiquette: Learn how to sauna and ice plunge like a Finn and feel great afterwards.20 Jan 2025The SpeciaList](https://www.bbc.com/travel/</reel/video/p0kk3csg/the-finnish-secret-to-happiness-avanto-and-l-yly>)
[![The Turkish mountain of eternal fire](https://ichef.bbci.co.uk/images/ic/480x270/p0k6brff.jpg.webp)The mysterious origins of Chimaera's 2,500-year-old flamesOn Mount Chimaera, fire has been spitting out from rocks for over 2,500 years. Our local SpeciaList explains why.25 Nov 2024The SpeciaList](https://www.bbc.com/travel/</reel/video/p0k6bbzm/a-journey-to-the-turkish-mountain-of-eternal-flames>)
[![The island of 400 ancient shipwrecks](https://ichef.bbci.co.uk/images/ic/480x270/p0k4whj9.jpg.webp)Turkey's island of 400 ancient shipwrecksA dive into 3,500 years of underwater archeology, sunken cities and Lycian tombs with Prof Hakan Öniz.18 Nov 2024The SpeciaList](https://www.bbc.com/travel/</reel/video/p0k4vx2c/turkey-s-island-of-400-ancient-shipwrecks>)
[![Sardinia](https://ichef.bbci.co.uk/images/ic/480x270/p08brydr.jpg.webp)The Italian valley that holds the recipe for living over 100Can blue zones tell us the secret to a long and healthy life?9 Nov 2023The SpeciaList](https://www.bbc.com/travel/</reel/video/p08b8r8d/the-italian-valley-that-holds-the-recipe-for-living-over-100>)
[![The castle that may have inspired ‘Frankenstein’](https://ichef.bbci.co.uk/images/ic/480x270/p0cmkfd0.jpg.webp)The castle that may have inspired 'Frankenstein'The 13th Century 'Castle Frankenstein' that may have inspired a monster book.9 Nov 2023The SpeciaList](https://www.bbc.com/travel/</reel/video/p0cmjmzf/the-castle-that-may-have-inspired-frankenstein->)
[![Is this the secret to Swedish happiness?](https://ichef.bbci.co.uk/images/ic/480x270/p0bn000x.jpg.webp)The Swedish tradition that can make you happier at workHow the Swedish approach to coffee breaks can enhance productivity and happiness.9 Nov 2023The SpeciaList](https://www.bbc.com/travel/</reel/video/p0bmzygz/the-swedish-tradition-that-can-make-you-happier-at-work>)
[![Getty Images 1068722442](https://ichef.bbci.co.uk/images/ic/480x270/p08llwlh.jpg.webp)Why the secret to Icelandic happiness lies in their poolsHow did bathing become such an intrinsic part of Icelandic cultural identity?9 Nov 2023The SpeciaList](https://www.bbc.com/travel/</reel/video/p08ljdqv/why-the-secret-to-icelandic-happiness-lies-in-their-pools>)
## More from The SpeciaList
[7 Dec 2024![La Plagne, Savoie, France \(Credit: Getty Images\)](https://ichef.bbci.co.uk/images/ic/480x270/p0k9dpwq.jpg.webp)A ski champion's guide to La Plagne, FranceTess Ledeux grew up on the slopes of La Plagne and now she's a world-class freestyle champion. Here are her picks for her home slopes, from après-ski to otherworldly Alpine views.7 Dec 2024Travel](https://www.bbc.com/travel/</travel/article/20241206-a-ski-champions-guide-to-la-plagne-france>)
[4 Dec 2024![Landscape of the city of Antalya, Turkey \(Credit: Getty Images\)](https://ichef.bbci.co.uk/images/ic/480x270/p0k8nsl5.jpg.webp)A Turkish film star's guide to AntalyaActor Ekin Koç called seaside Antalya home before conquering the world of Turkish film. Here are his picks, from hiking the Lycian Road to catching a concert at the Aspendos Theatre.4 Dec 2024Travel](https://www.bbc.com/travel/</travel/article/20241203-a-turkish-film-and-tv-stars-guide-to-antalya-turkey>)
[23 Nov 2024![Kingston, Jamaica \(Credit: Getty Images\)](https://ichef.bbci.co.uk/images/ic/1024xn/p0k6hwq5.jpg.webp)A dancehall superstar's guide to JamaicaFrom hiking Dunn's River Falls to having bun and cheese, here are international pop artist Shenseea's picks for how to experience the best of her home nation.23 Nov 2024Travel](https://www.bbc.com/travel/</travel/article/20241120-shenseeas-guide-to-jamaica>)
[16 Nov 2024![Poutine \(Credit: Getty Images\)](https://ichef.bbci.co.uk/images/ic/480x270/p0k419ny.jpg.webp)Five of Montreal's best poutine spots - according to a local chefMontreal-born chef Michele Forgione makes one of the best poutines in the city.16 Nov 2024Travel](https://www.bbc.com/travel/</travel/article/20241112-montreals-best-poutine-according-to-a-local-chef>)
[13 Nov 2024![Chef Fatih Tutak in the city of Istanbul \(Credit: Ertuğrul Taban\)](https://ichef.bbci.co.uk/images/ic/480x270/p0k43yrg.jpg.webp)A chef's guide to the best food in IstanbulIstanbul-born chef Fatih Tutak shares his favourite culinary experiences in his hometown, from Turkish barbecue at Ahmet Ustam Ocakbaşı to micro-seasonal menus at Nazende.13 Nov 2024Travel](https://www.bbc.com/travel/</travel/article/20241112-a-two-michelin-star-chefs-guide-to-the-best-dining-spots-in-istanbul>)
[9 Nov 2024![A flamenco dancer on stage surrounded by musicians](https://ichef.bbci.co.uk/images/ic/raw/p0k3278p.jpg.webp)Five of Seville's best flamenco spotsManuela Barrios has performed flamenco around the world. Here are her favourite spots in Seville to see the spectacle.9 Nov 2024Travel](https://www.bbc.com/travel/</travel/article/20241107-a-flamenco-dancers-guide-to-seville>)
[2 Nov 2024![Chef Alejandro Ruiz in Oaxaca \(Credit: Alberto Lopez\)](https://ichef.bbci.co.uk/images/ic/480x270/p0k28045.jpg.webp)Where to get the best street food in Oaxaca CityChef Alejandro Ruiz thinks Oaxaca's street foods are a key to understanding its gastronomy. Here are his top street foods in the city, from memelas at Doña Vale to Tacos del Carmen.2 Nov 2024Travel](https://www.bbc.com/travel/</travel/article/20241101-a-oaxacan-chefs-guide-to-the-best-of-oaxaca-citys-street-food>)
[30 Oct 2024![Charlie MacLean \(Credit: The Charlie MacLean Foundation\)](https://ichef.bbci.co.uk/images/ic/480x270/p0k0rvq8.jpg.webp)A Scotch whisky lover's guide to EdinburghAuthor Charlie MacLean has made a life out of rating Scotch whisky. Here are his favourite ways to enjoy a dram, from cosy city pubs in Edinburgh to Victorian hotels in the Highlands.30 Oct 2024Travel](https://www.bbc.com/travel/</travel/article/20241029-a-scotch-whisky-lovers-guide-to-edinburgh>)
[26 Oct 2024![](https://ichef.bbci.co.uk/images/ic/480x270/p0jzpc3t.jpg.webp)An F1 driver's guide to Mexico CitySergio Pérez talks us through the must-see places in the capital ahead of the Mexican Grand Prix.26 Oct 2024Travel](https://www.bbc.com/travel/</travel/article/20241023-f1-driver-sergio-prezs-guide-to-a-weekend-in-mexico-city>)
12345...10
[British Broadcasting Corporation](https://www.bbc.com/travel/</>)
  * [Home](https://www.bbc.com/travel/<https:/www.bbc.com/>)
  * [News](https://www.bbc.com/travel/</news>)
  * [Sport](https://www.bbc.com/travel/</sport>)
  * [Business](https://www.bbc.com/travel/</business>)
  * [Innovation](https://www.bbc.com/travel/</innovation>)
  * [Culture](https://www.bbc.com/travel/</culture>)
  * [Arts](https://www.bbc.com/travel/</arts>)
  * [Travel](https://www.bbc.com/travel/</travel>)
  * [Earth](https://www.bbc.com/travel/</future-planet>)
  * [Video](https://www.bbc.com/travel/</video>)
  * [Live](https://www.bbc.com/travel/</live>)
  * [Audio](https://www.bbc.com/travel/<https:/www.bbc.co.uk/sounds>)
  * [Weather](https://www.bbc.com/travel/<https:/www.bbc.com/weather>)
  * [BBC Shop](https://www.bbc.com/travel/<https:/shop.bbc.com/>)


BBC in other languages
## Follow BBC on:
  * [Terms of Use](https://www.bbc.com/travel/<https:/www.bbc.co.uk/usingthebbc/terms>)
  * [About the BBC](https://www.bbc.com/travel/<https:/www.bbc.co.uk/aboutthebbc>)
  * [Privacy Policy](https://www.bbc.com/travel/<https:/www.bbc.com/usingthebbc/privacy/>)
  * [Cookies](https://www.bbc.com/travel/<https:/www.bbc.com/usingthebbc/cookies/>)
  * [Accessibility Help](https://www.bbc.com/travel/<https:/www.bbc.co.uk/accessibility/>)
  * [Contact the BBC](https://www.bbc.com/travel/<https:/www.bbc.co.uk/contact>)
  * [Advertise with us](https://www.bbc.com/travel/<https:/www.bbc.com/advertisingcontact>)
  * [Do not share or sell my info](https://www.bbc.com/travel/<https:/www.bbc.com/usingthebbc/cookies/how-can-i-change-my-bbc-cookie-settings/>)
  * [Contact technical support](https://www.bbc.com/travel/<https:/www.bbc.com/contact-bbc-com-help>)


Copyright 2025 BBC. All rights reserved. The _BBC_ is _not responsible for the content of external sites._ [**Read about our approach to external linking.**](https://www.bbc.com/travel/<https:/www.bbc.co.uk/editorialguidelines/guidance/feeds-and-links>)

================
File: multiple_pages.py
================
import asyncio
import os
from typing import List, Set
from datetime import datetime
from urllib.parse import urlparse, urljoin
import aiohttp
from bs4 import BeautifulSoup
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig
from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator

class FullSiteCrawler:
    def __init__(self, output_dir: str = "crawled_sites"):
        self.output_dir = output_dir
        self.browser_config = BrowserConfig(
            headless=True,
            extra_args=["--disable-gpu", "--disable-dev-shm-usage", "--no-sandbox"],
        )
        self.crawl_config = CrawlerRunConfig(
            markdown_generator=DefaultMarkdownGenerator()
        )
        
    def is_valid_url(self, url: str, base_domain: str) -> bool:
        """
        Checks if a URL is valid and belongs to the same domain.
        
        Args:
            url: URL to check
            base_domain: Domain to compare against
            
        Returns:
            bool: True if URL is valid and belongs to base domain
        """
        try:
            parsed = urlparse(url)
            return (
                bool(parsed.netloc) and
                parsed.netloc == base_domain and
                parsed.scheme in ['http', 'https'] and
                not any(ext in url.lower() for ext in ['.jpg', '.jpeg', '.png', '.gif', '.pdf', '.zip'])
            )
        except:
            return False

    async def discover_links(self, url: str, base_domain: str) -> Set[str]:
        """
        Discovers all links on a page belonging to the same domain.
        
        Args:
            url: URL to scan for links
            base_domain: Domain to filter links
            
        Returns:
            Set of discovered URLs
        """
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url) as response:
                    if response.status == 200:
                        html = await response.text()
                        soup = BeautifulSoup(html, 'html.parser')
                        
                        links = set()
                        for anchor in soup.find_all('a', href=True):
                            href = anchor['href']
                            full_url = urljoin(url, href)
                            
                            if self.is_valid_url(full_url, base_domain):
                                links.add(full_url)
                        
                        return links
                    return set()
        except Exception as e:
            print(f"Error discovering links on {url}: {str(e)}")
            return set()

    async def crawl_website(self, base_url: str, max_pages: int = 100):
        """
        Crawls an entire website up to max_pages.
        
        Args:
            base_url: Starting URL for the crawl
            max_pages: Maximum number of pages to crawl
        """
        print(f"\n=== Starting full crawl of {base_url} ===")
        
        # Create website-specific output directory
        base_domain = urlparse(base_url).netloc
        site_folder = base_domain.replace('.', '_')
        site_output_dir = os.path.join(self.output_dir, site_folder)
        os.makedirs(site_output_dir, exist_ok=True)
        
        # Initialize crawler
        crawler = AsyncWebCrawler(config=self.browser_config)
        await crawler.start()
        
        try:
            # Track URLs
            crawled_urls = set()
            to_crawl = {base_url}
            
            session_id = f"session_{site_folder}"
            
            while to_crawl and len(crawled_urls) < max_pages:
                current_url = to_crawl.pop()
                
                if current_url in crawled_urls:
                    continue
                
                # Crawl the page
                result = await crawler.arun(
                    url=current_url,
                    config=self.crawl_config,
                    session_id=session_id
                )
                
                if result.success:
                    # Save the content
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    parsed_url = urlparse(current_url)
                    path_part = parsed_url.path.strip('/').replace('/', '_')
                    if not path_part:
                        path_part = 'index'
                    filename = f"{path_part}_{timestamp}.md"
                    
                    filepath = os.path.join(site_output_dir, filename)
                    with open(filepath, 'w', encoding='utf-8') as f:
                        f.write(result.markdown_v2.raw_markdown)
                    
                    print(f"Crawled ({len(crawled_urls) + 1}/{max_pages}): {current_url}")
                    
                    # Discover new links
                    new_links = await self.discover_links(current_url, base_domain)
                    to_crawl.update(new_links - crawled_urls)
                    
                    # Mark as crawled
                    crawled_urls.add(current_url)
                    
                    # Add a small delay to be nice to the server
                    await asyncio.sleep(1)
                else:
                    print(f"Failed to crawl {current_url}: {result.error_message}")
            
            print(f"\nCrawl complete for {base_url}")
            print(f"Total pages crawled: {len(crawled_urls)}")
            print(f"Content saved in: {os.path.abspath(site_output_dir)}")
                    
        finally:
            await crawler.close()

async def main():
    # List of websites to crawl
    websites = [
        "https://www.bbc.com/news",  # Replace with actual website URL
        "https://edition.cnn.com/"  # Replace with actual website URL
    ]
    
    crawler = FullSiteCrawler(output_dir="full_sites")
    
    # Crawl each website
    for website in websites:
        await crawler.crawl_website(website, max_pages=100)  # Adjust max_pages as needed

if __name__ == "__main__":
    asyncio.run(main())

================
File: mutlple_page.py
================
import asyncio
import os
from uuid import uuid4
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig
from crawl4ai import MemoryAdaptiveDispatcher, SemaphoreDispatcher  # Correct import path
from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator

async def save_markdown_results(urls):
    # Configure markdown generation
    markdown_generator = DefaultMarkdownGenerator(
        options={"citations": True, "body_width": 80}
    )

    # Set up crawler configuration
    run_config = CrawlerRunConfig(
        cache_mode="bypass",
        markdown_generator=markdown_generator,
        extraction_strategy="auto"
    )

    # Configure dispatcher with correct parameters
    dispatcher = MemoryAdaptiveDispatcher(
        memory_threshold_percent=80.0,
        max_session_permit=10,
        check_interval=1.0,
        rate_limiter=None,
        monitor=None
    )

    async with AsyncWebCrawler() as crawler:
        results = await crawler.arun_many(
            urls=urls,
            config=run_config,
            dispatcher=dispatcher
        )

        # Process and save results
        for result in results:
            if result.success and result.markdown_v2:
                filename = f"{uuid4().hex}.md"
                with open(filename, "w", encoding="utf-8") as f:
                    f.write(result.markdown_v2.markdown_with_citations)
                print(f"Saved: {filename}")
            else:
                print(f"Failed: {result.url} - {result.error_message}")

async def main():
    urls = [
        "https://example.com",
        "https://www.wikipedia.org",
        "https://github.com"
    ]
    
    os.makedirs("markdown_results", exist_ok=True)
    os.chdir("markdown_results")
    
    await save_markdown_results(urls)

if __name__ == "__main__":
    asyncio.run(main())

================
File: requirements.txt
================
aiofiles==24.1.0
aiohappyeyeballs==2.4.4
aiohttp==3.11.11
aiosignal==1.3.2
aiosqlite==0.20.0
altair==5.5.0
annotated-types==0.7.0
anthropic==0.42.0
anyio==4.8.0
attrs==24.3.0
beautifulsoup4==4.12.3
blinker==1.9.0
cachetools==5.5.0
certifi==2024.12.14
cffi==1.17.1
charset-normalizer==3.4.1
click==8.1.8
colorama==0.4.6
Crawl4AI==0.4.247
cryptography==44.0.0
Deprecated==1.2.15
deprecation==2.1.0
distro==1.9.0
eval_type_backport==0.2.2
executing==2.1.0
fake-http-header==0.3.5
filelock==3.16.1
frozenlist==1.5.0
fsspec==2024.12.0
gitdb==4.0.12
GitPython==3.1.44
google-auth==2.37.0
googleapis-common-protos==1.66.0
gotrue==2.11.1
greenlet==3.1.1
griffe==1.5.4
groq==0.15.0
h11==0.14.0
h2==4.1.0
hpack==4.0.0
httpcore==1.0.7
httpx==0.27.2
huggingface-hub==0.27.1
hyperframe==6.0.1
idna==3.10
importlib_metadata==8.5.0
iniconfig==2.0.0
Jinja2==3.1.5
jiter==0.8.2
joblib==1.4.2
jsonpath-python==1.0.6
jsonschema==4.23.0
jsonschema-specifications==2024.10.1
litellm==1.57.8
logfire==3.1.0
logfire-api==3.1.0
lxml==5.3.0
markdown-it-py==3.0.0
MarkupSafe==3.0.2
mdurl==0.1.2
mistralai==1.2.6
mockito==1.5.3
multidict==6.1.0
mypy-extensions==1.0.0
narwhals==1.21.1
nltk==3.9.1
numpy==2.2.1
openai==1.59.6
opentelemetry-api==1.29.0
opentelemetry-exporter-otlp-proto-common==1.29.0
opentelemetry-exporter-otlp-proto-http==1.29.0
opentelemetry-instrumentation==0.50b0
opentelemetry-proto==1.29.0
opentelemetry-sdk==1.29.0
opentelemetry-semantic-conventions==0.50b0
packaging==24.2
pandas==2.2.3
pillow==10.4.0
playwright==1.49.1
pluggy==1.5.0
postgrest==0.19.1
propcache==0.2.1
protobuf==5.29.3
psutil==6.1.1
pyarrow==18.1.0
pyasn1==0.6.1
pyasn1_modules==0.4.1
pycparser==2.22
pydantic==2.10.5
pydantic-ai==0.0.18
pydantic-ai-slim==0.0.18
pydantic_core==2.27.2
pydeck==0.9.1
pyee==12.0.0
Pygments==2.19.1
pyOpenSSL==24.3.0
pytest==8.3.4
pytest-mockito==0.0.4
python-dateutil==2.9.0.post0
python-dotenv==1.0.1
pytz==2024.2
PyYAML==6.0.2
rank-bm25==0.2.2
realtime==2.1.0
referencing==0.35.1
regex==2024.11.6
requests==2.32.3
rich==13.9.4
rpds-py==0.22.3
rsa==4.9
six==1.17.0
smmap==5.0.2
sniffio==1.3.1
snowballstemmer==2.2.0
soupsieve==2.6
storage3==0.11.0
streamlit==1.41.1
StrEnum==0.4.15
supabase==2.11.0
supafunc==0.9.0
tenacity==9.0.0
tf-playwright-stealth==1.1.0
tiktoken==0.8.0
tokenizers==0.21.0
toml==0.10.2
tornado==6.4.2
tqdm==4.67.1
typing-inspect==0.9.0
typing_extensions==4.12.2
tzdata==2024.2
urllib3==2.3.0
watchdog==6.0.0
websockets==13.1
wrapt==1.17.1
xxhash==3.5.0
yarl==1.18.3
zipp==3.21.0

================
File: single_page.py
================
import asyncio
from crawl4ai import *

async def main():
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url="https://claude.ai/chat/b965fd82-24bf-4628-85e8-4bb37bff24a2",
        )
        print(result.markdown)

if __name__ == "__main__":
    asyncio.run(main())
