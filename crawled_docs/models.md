[ Skip to content ](https://ai.pydantic.dev/models/<#openai>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/models/<..> "PydanticAI")
PydanticAI 
Models 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/models/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/models/<..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/models/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/models/<..>)
  * [ Installation  ](https://ai.pydantic.dev/models/<../install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/models/<../help/>)
  * [ Contributing  ](https://ai.pydantic.dev/models/<../contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/models/<../troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/models/<../agents/>)
    * Models  [ Models  ](https://ai.pydantic.dev/models/<./>) Table of contents 
      * [ OpenAI  ](https://ai.pydantic.dev/models/<#openai>)
        * [ Install  ](https://ai.pydantic.dev/models/<#install>)
        * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration>)
        * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable>)
        * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument>)
        * [ Custom OpenAI Client  ](https://ai.pydantic.dev/models/<#custom-openai-client>)
      * [ Anthropic  ](https://ai.pydantic.dev/models/<#anthropic>)
        * [ Install  ](https://ai.pydantic.dev/models/<#install_1>)
        * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_1>)
        * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_1>)
        * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_1>)
      * [ Gemini  ](https://ai.pydantic.dev/models/<#gemini>)
        * [ Install  ](https://ai.pydantic.dev/models/<#install_2>)
        * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_2>)
        * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_2>)
        * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_2>)
      * [ Gemini via VertexAI  ](https://ai.pydantic.dev/models/<#gemini-via-vertexai>)
        * [ Install  ](https://ai.pydantic.dev/models/<#install_3>)
        * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_3>)
        * [ Application default credentials  ](https://ai.pydantic.dev/models/<#application-default-credentials>)
        * [ Service account  ](https://ai.pydantic.dev/models/<#service-account>)
        * [ Customising region  ](https://ai.pydantic.dev/models/<#customising-region>)
      * [ Groq  ](https://ai.pydantic.dev/models/<#groq>)
        * [ Install  ](https://ai.pydantic.dev/models/<#install_4>)
        * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_4>)
        * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_3>)
        * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_3>)
      * [ Mistral  ](https://ai.pydantic.dev/models/<#mistral>)
        * [ Install  ](https://ai.pydantic.dev/models/<#install_5>)
        * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_5>)
        * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_4>)
        * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_4>)
      * [ Cohere  ](https://ai.pydantic.dev/models/<#cohere>)
        * [ Install  ](https://ai.pydantic.dev/models/<#install_6>)
        * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_6>)
        * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_5>)
        * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_5>)
      * [ OpenAI-compatible Models  ](https://ai.pydantic.dev/models/<#openai-compatible-models>)
        * [ Ollama  ](https://ai.pydantic.dev/models/<#ollama>)
          * [ Example local usage  ](https://ai.pydantic.dev/models/<#example-local-usage>)
          * [ Example using a remote server  ](https://ai.pydantic.dev/models/<#example-using-a-remote-server>)
        * [ OpenRouter  ](https://ai.pydantic.dev/models/<#openrouter>)
        * [ Grok (xAI)  ](https://ai.pydantic.dev/models/<#grok-xai>)
        * [ DeepSeek  ](https://ai.pydantic.dev/models/<#deepseek>)
      * [ Implementing Custom Models  ](https://ai.pydantic.dev/models/<#implementing-custom-models>)
    * [ Dependencies  ](https://ai.pydantic.dev/models/<../dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/models/<../tools/>)
    * [ Results  ](https://ai.pydantic.dev/models/<../results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/models/<../message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/models/<../testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/models/<../logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/models/<../multi-agent-applications/>)
    * [ Graphs  ](https://ai.pydantic.dev/models/<../graph/>)
  * [ Examples  ](https://ai.pydantic.dev/models/<../examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/models/<../examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/models/<../examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/models/<../examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/models/<../examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/models/<../examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/models/<../examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/models/<../examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/models/<../examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/models/<../examples/chat-app/>)
    * [ Question Graph  ](https://ai.pydantic.dev/models/<../examples/question-graph/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/models/<../api/agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/models/<../api/tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/models/<../api/result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/models/<../api/messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/models/<../api/exceptions/>)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/models/<../api/settings/>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/models/<../api/usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/models/<../api/format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/models/<../api/models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/models/<../api/models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/models/<../api/models/anthropic/>)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/models/<../api/models/cohere/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/models/<../api/models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/models/<../api/models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/models/<../api/models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/models/<../api/models/mistral/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/models/<../api/models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/models/<../api/models/function/>)
    * [ pydantic_graph  ](https://ai.pydantic.dev/models/<../api/pydantic_graph/graph/>)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/models/<../api/pydantic_graph/nodes/>)
    * [ pydantic_graph.state  ](https://ai.pydantic.dev/models/<../api/pydantic_graph/state/>)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/models/<../api/pydantic_graph/mermaid/>)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/models/<../api/pydantic_graph/exceptions/>)


Table of contents 
  * [ OpenAI  ](https://ai.pydantic.dev/models/<#openai>)
    * [ Install  ](https://ai.pydantic.dev/models/<#install>)
    * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration>)
    * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable>)
    * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument>)
    * [ Custom OpenAI Client  ](https://ai.pydantic.dev/models/<#custom-openai-client>)
  * [ Anthropic  ](https://ai.pydantic.dev/models/<#anthropic>)
    * [ Install  ](https://ai.pydantic.dev/models/<#install_1>)
    * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_1>)
    * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_1>)
    * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_1>)
  * [ Gemini  ](https://ai.pydantic.dev/models/<#gemini>)
    * [ Install  ](https://ai.pydantic.dev/models/<#install_2>)
    * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_2>)
    * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_2>)
    * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_2>)
  * [ Gemini via VertexAI  ](https://ai.pydantic.dev/models/<#gemini-via-vertexai>)
    * [ Install  ](https://ai.pydantic.dev/models/<#install_3>)
    * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_3>)
    * [ Application default credentials  ](https://ai.pydantic.dev/models/<#application-default-credentials>)
    * [ Service account  ](https://ai.pydantic.dev/models/<#service-account>)
    * [ Customising region  ](https://ai.pydantic.dev/models/<#customising-region>)
  * [ Groq  ](https://ai.pydantic.dev/models/<#groq>)
    * [ Install  ](https://ai.pydantic.dev/models/<#install_4>)
    * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_4>)
    * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_3>)
    * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_3>)
  * [ Mistral  ](https://ai.pydantic.dev/models/<#mistral>)
    * [ Install  ](https://ai.pydantic.dev/models/<#install_5>)
    * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_5>)
    * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_4>)
    * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_4>)
  * [ Cohere  ](https://ai.pydantic.dev/models/<#cohere>)
    * [ Install  ](https://ai.pydantic.dev/models/<#install_6>)
    * [ Configuration  ](https://ai.pydantic.dev/models/<#configuration_6>)
    * [ Environment variable  ](https://ai.pydantic.dev/models/<#environment-variable_5>)
    * [ api_key argument  ](https://ai.pydantic.dev/models/<#api_key-argument_5>)
  * [ OpenAI-compatible Models  ](https://ai.pydantic.dev/models/<#openai-compatible-models>)
    * [ Ollama  ](https://ai.pydantic.dev/models/<#ollama>)
      * [ Example local usage  ](https://ai.pydantic.dev/models/<#example-local-usage>)
      * [ Example using a remote server  ](https://ai.pydantic.dev/models/<#example-using-a-remote-server>)
    * [ OpenRouter  ](https://ai.pydantic.dev/models/<#openrouter>)
    * [ Grok (xAI)  ](https://ai.pydantic.dev/models/<#grok-xai>)
    * [ DeepSeek  ](https://ai.pydantic.dev/models/<#deepseek>)
  * [ Implementing Custom Models  ](https://ai.pydantic.dev/models/<#implementing-custom-models>)


  1. [ Introduction  ](https://ai.pydantic.dev/models/<..>)
  2. [ Documentation  ](https://ai.pydantic.dev/models/<../agents/>)


Version Notice
This documentation is ahead of the last release by [1 commit](https://ai.pydantic.dev/models/<https:/github.com/pydantic/pydantic-ai/compare/v0.0.21...main>). You may see documentation for features not yet supported in the latest release [v0.0.21 2025-01-30](https://ai.pydantic.dev/models/<https:/github.com/pydantic/pydantic-ai/releases/tag/v0.0.21>). 
# Models
PydanticAI is Model-agnostic and has built in support for the following model providers:
  * [OpenAI](https://ai.pydantic.dev/models/<#openai>)
  * [Anthropic](https://ai.pydantic.dev/models/<#anthropic>)
  * Gemini via two different APIs: [Generative Language API](https://ai.pydantic.dev/models/<#gemini>) and [VertexAI API](https://ai.pydantic.dev/models/<#gemini-via-vertexai>)
  * [Ollama](https://ai.pydantic.dev/models/<#ollama>)
  * [Deepseek](https://ai.pydantic.dev/models/<#deepseek>)
  * [Groq](https://ai.pydantic.dev/models/<#groq>)
  * [Mistral](https://ai.pydantic.dev/models/<#mistral>)
  * [Cohere](https://ai.pydantic.dev/models/<#cohere>)


See [OpenAI-compatible models](https://ai.pydantic.dev/models/<#openai-compatible-models>) for more examples on how to use models such as [OpenRouter](https://ai.pydantic.dev/models/<#openrouter>), and [Grok (xAI)](https://ai.pydantic.dev/models/<#grok-xai>) that support the OpenAI SDK.
You can also [add support for other models](https://ai.pydantic.dev/models/<#implementing-custom-models>).
PydanticAI also comes with `TestModel`[](https://ai.pydantic.dev/models/<../api/models/test/>) and `FunctionModel`[](https://ai.pydantic.dev/models/<../api/models/function/>) for testing and development.
To use each model provider, you need to configure your local environment and make sure you have the right packages installed.
## OpenAI
### Install
To use OpenAI models, you need to either install `pydantic-ai`[](https://ai.pydantic.dev/models/<../install/>), or install `pydantic-ai-slim`[](https://ai.pydantic.dev/models/<../install/#slim-install>) with the `openai` optional group:
[pip](https://ai.pydantic.dev/models/<#__tabbed_1_1>)[uv](https://ai.pydantic.dev/models/<#__tabbed_1_2>)
```
pipinstall'pydantic-ai-slim[openai]'

```

```
uvadd'pydantic-ai-slim[openai]'

```

### Configuration
To use `OpenAIModel`[](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel>) through their main API, go to [platform.openai.com](https://ai.pydantic.dev/models/<https:/platform.openai.com/>) and follow your nose until you find the place to generate an API key.
### Environment variable
Once you have the API key, you can set it as an environment variable:
```
exportOPENAI_API_KEY='your-api-key'

```

You can then use `OpenAIModel`[](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel>) by name:
openai_model_by_name.py```
from pydantic_ai import Agent
agent = Agent('openai:gpt-4o')
...

```

Or initialise the model directly with just the model name:
openai_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
model = OpenAIModel('gpt-4o')
agent = Agent(model)
...

```

### `api_key` argument
If you don't want to or can't set the environment variable, you can pass it at runtime via the `api_key`[ argument](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel.__init__>):
openai_model_api_key.py```
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
model = OpenAIModel('gpt-4o', api_key='your-api-key')
agent = Agent(model)
...

```

### Custom OpenAI Client
`OpenAIModel` also accepts a custom `AsyncOpenAI` client via the `openai_client`[ parameter](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel.__init__>), so you can customise the `organization`, `project`, `base_url` etc. as defined in the [OpenAI API docs](https://ai.pydantic.dev/models/<https:/platform.openai.com/docs/api-reference>).
You could also use the `AsyncAzureOpenAI`[](https://ai.pydantic.dev/models/<https:/learn.microsoft.com/en-us/azure/ai-services/openai/how-to/switching-endpoints>) client to use the Azure OpenAI API.
openai_azure.py```
from openai import AsyncAzureOpenAI
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
client = AsyncAzureOpenAI(
  azure_endpoint='...',
  api_version='2024-07-01-preview',
  api_key='your-api-key',
)
model = OpenAIModel('gpt-4o', openai_client=client)
agent = Agent(model)
...

```

## Anthropic
### Install
To use `AnthropicModel`[](https://ai.pydantic.dev/models/<../api/models/anthropic/#pydantic_ai.models.anthropic.AnthropicModel>) models, you need to either install `pydantic-ai`[](https://ai.pydantic.dev/models/<../install/>), or install `pydantic-ai-slim`[](https://ai.pydantic.dev/models/<../install/#slim-install>) with the `anthropic` optional group:
[pip](https://ai.pydantic.dev/models/<#__tabbed_2_1>)[uv](https://ai.pydantic.dev/models/<#__tabbed_2_2>)
```
pipinstall'pydantic-ai-slim[anthropic]'

```

```
uvadd'pydantic-ai-slim[anthropic]'

```

### Configuration
To use [Anthropic](https://ai.pydantic.dev/models/<https:/anthropic.com>) through their API, go to [console.anthropic.com/settings/keys](https://ai.pydantic.dev/models/<https:/console.anthropic.com/settings/keys>) to generate an API key.
`AnthropicModelName`[](https://ai.pydantic.dev/models/<../api/models/anthropic/#pydantic_ai.models.anthropic.AnthropicModelName>) contains a list of available Anthropic models.
### Environment variable
Once you have the API key, you can set it as an environment variable:
```
exportANTHROPIC_API_KEY='your-api-key'

```

You can then use `AnthropicModel`[](https://ai.pydantic.dev/models/<../api/models/anthropic/#pydantic_ai.models.anthropic.AnthropicModel>) by name:
anthropic_model_by_name.py```
from pydantic_ai import Agent
agent = Agent('anthropic:claude-3-5-sonnet-latest')
...

```

Or initialise the model directly with just the model name:
anthropic_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.anthropic import AnthropicModel
model = AnthropicModel('claude-3-5-sonnet-latest')
agent = Agent(model)
...

```

### `api_key` argument
If you don't want to or can't set the environment variable, you can pass it at runtime via the `api_key`[ argument](https://ai.pydantic.dev/models/<../api/models/anthropic/#pydantic_ai.models.anthropic.AnthropicModel.__init__>):
anthropic_model_api_key.py```
from pydantic_ai import Agent
from pydantic_ai.models.anthropic import AnthropicModel
model = AnthropicModel('claude-3-5-sonnet-latest', api_key='your-api-key')
agent = Agent(model)
...

```

## Gemini
For prototyping only
Google themselves refer to this API as the "hobby" API, I've received 503 responses from it a number of times. The API is easy to use and useful for prototyping and simple demos, but I would not rely on it in production.
If you want to run Gemini models in production, you should use the [VertexAI API](https://ai.pydantic.dev/models/<#gemini-via-vertexai>) described below.
### Install
To use `GeminiModel`[](https://ai.pydantic.dev/models/<../api/models/gemini/#pydantic_ai.models.gemini.GeminiModel>) models, you just need to install `pydantic-ai`[](https://ai.pydantic.dev/models/<../install/>) or `pydantic-ai-slim`[](https://ai.pydantic.dev/models/<../install/#slim-install>), no extra dependencies are required.
### Configuration
`GeminiModel`[](https://ai.pydantic.dev/models/<../api/models/gemini/#pydantic_ai.models.gemini.GeminiModel>) let's you use the Google's Gemini models through their [Generative Language API](https://ai.pydantic.dev/models/<https:/ai.google.dev/api/all-methods>), `generativelanguage.googleapis.com`.
`GeminiModelName`[](https://ai.pydantic.dev/models/<../api/models/gemini/#pydantic_ai.models.gemini.GeminiModelName>) contains a list of available Gemini models that can be used through this interface.
To use `GeminiModel`, go to [aistudio.google.com](https://ai.pydantic.dev/models/<https:/aistudio.google.com/>) and follow your nose until you find the place to generate an API key.
### Environment variable
Once you have the API key, you can set it as an environment variable:
```
exportGEMINI_API_KEY=your-api-key

```

You can then use `GeminiModel`[](https://ai.pydantic.dev/models/<../api/models/gemini/#pydantic_ai.models.gemini.GeminiModel>) by name:
gemini_model_by_name.py```
from pydantic_ai import Agent
agent = Agent('google-gla:gemini-1.5-flash')
...

```

Note
The `google-gla` provider prefix represents the [Google **G** enerative **L** anguage **A** PI](https://ai.pydantic.dev/models/<https:/ai.google.dev/api/all-methods>) for `GeminiModel`s. `google-vertex` is used with [Vertex AI](https://ai.pydantic.dev/models/<https:/cloud.google.com/vertex-ai/generative-ai/docs/learn/models>) for `VertexAIModel`s.
Or initialise the model directly with just the model name:
gemini_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.gemini import GeminiModel
model = GeminiModel('gemini-1.5-flash')
agent = Agent(model)
...

```

### `api_key` argument
If you don't want to or can't set the environment variable, you can pass it at runtime via the `api_key`[ argument](https://ai.pydantic.dev/models/<../api/models/gemini/#pydantic_ai.models.gemini.GeminiModel.__init__>):
gemini_model_api_key.py```
from pydantic_ai import Agent
from pydantic_ai.models.gemini import GeminiModel
model = GeminiModel('gemini-1.5-flash', api_key='your-api-key')
agent = Agent(model)
...

```

## Gemini via VertexAI
To run Google's Gemini models in production, you should use `VertexAIModel`[](https://ai.pydantic.dev/models/<../api/models/vertexai/#pydantic_ai.models.vertexai.VertexAIModel>) which uses the `*-aiplatform.googleapis.com` API.
`GeminiModelName`[](https://ai.pydantic.dev/models/<../api/models/gemini/#pydantic_ai.models.gemini.GeminiModelName>) contains a list of available Gemini models that can be used through this interface.
### Install
To use `VertexAIModel`[](https://ai.pydantic.dev/models/<../api/models/vertexai/#pydantic_ai.models.vertexai.VertexAIModel>), you need to either install `pydantic-ai`[](https://ai.pydantic.dev/models/<../install/>), or install `pydantic-ai-slim`[](https://ai.pydantic.dev/models/<../install/#slim-install>) with the `vertexai` optional group:
[pip](https://ai.pydantic.dev/models/<#__tabbed_3_1>)[uv](https://ai.pydantic.dev/models/<#__tabbed_3_2>)
```
pipinstall'pydantic-ai-slim[vertexai]'

```

```
uvadd'pydantic-ai-slim[vertexai]'

```

### Configuration
This interface has a number of advantages over `generativelanguage.googleapis.com` documented above:
  1. The VertexAI API is more reliably and marginally lower latency in our experience.
  2. You can [purchase provisioned throughput](https://ai.pydantic.dev/models/<https:/cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput#purchase-provisioned-throughput>) with VertexAI to guarantee capacity.
  3. If you're running PydanticAI inside GCP, you don't need to set up authentication, it should "just work".
  4. You can decide which region to use, which might be important from a regulatory perspective, and might improve latency.


The big disadvantage is that for local development you may need to create and configure a "service account", which I've found extremely painful to get right in the past.
Whichever way you authenticate, you'll need to have VertexAI enabled in your GCP account.
### Application default credentials
Luckily if you're running PydanticAI inside GCP, or you have the `gcloud`[ CLI](https://ai.pydantic.dev/models/<https:/cloud.google.com/sdk/gcloud>) installed and configured, you should be able to use `VertexAIModel` without any additional setup.
To use `VertexAIModel`, with [application default credentials](https://ai.pydantic.dev/models/<https:/cloud.google.com/docs/authentication/application-default-credentials>) configured (e.g. with `gcloud`), you can simply use:
vertexai_application_default_credentials.py```
from pydantic_ai import Agent
from pydantic_ai.models.vertexai import VertexAIModel
model = VertexAIModel('gemini-1.5-flash')
agent = Agent(model)
...

```

Internally this uses `google.auth.default()`[](https://ai.pydantic.dev/models/<https:/google-auth.readthedocs.io/en/master/reference/google.auth.html>) from the `google-auth` package to obtain credentials.
Won't fail until `agent.run()`
Because `google.auth.default()` requires network requests and can be slow, it's not run until you call `agent.run()`. Meaning any configuration or permissions error will only be raised when you try to use the model. To initialize the model for this check to be run, call `await model.ainit()`[](https://ai.pydantic.dev/models/<../api/models/vertexai/#pydantic_ai.models.vertexai.VertexAIModel.ainit>).
You may also need to pass the `project_id`[ argument to `VertexAIModel`](https://ai.pydantic.dev/models/<../api/models/vertexai/#pydantic_ai.models.vertexai.VertexAIModel.__init__>) if application default credentials don't set a project, if you pass `project_id` and it conflicts with the project set by application default credentials, an error is raised.
### Service account
If instead of application default credentials, you want to authenticate with a service account, you'll need to create a service account, add it to your GCP project (note: AFAIK this step is necessary even if you created the service account within the project), give that service account the "Vertex AI Service Agent" role, and download the service account JSON file.
Once you have the JSON file, you can use it thus:
vertexai_service_account.py```
from pydantic_ai import Agent
from pydantic_ai.models.vertexai import VertexAIModel
model = VertexAIModel(
  'gemini-1.5-flash',
  service_account_file='path/to/service-account.json',
)
agent = Agent(model)
...

```

### Customising region
Whichever way you authenticate, you can specify which region requests will be sent to via the `region`[ argument](https://ai.pydantic.dev/models/<../api/models/vertexai/#pydantic_ai.models.vertexai.VertexAIModel.__init__>).
Using a region close to your application can improve latency and might be important from a regulatory perspective.
vertexai_region.py```
from pydantic_ai import Agent
from pydantic_ai.models.vertexai import VertexAIModel
model = VertexAIModel('gemini-1.5-flash', region='asia-east1')
agent = Agent(model)
...

```

`VertexAiRegion`[](https://ai.pydantic.dev/models/<../api/models/vertexai/#pydantic_ai.models.vertexai.VertexAiRegion>) contains a list of available regions.
## Groq
### Install
To use `GroqModel`[](https://ai.pydantic.dev/models/<../api/models/groq/#pydantic_ai.models.groq.GroqModel>), you need to either install `pydantic-ai`[](https://ai.pydantic.dev/models/<../install/>), or install `pydantic-ai-slim`[](https://ai.pydantic.dev/models/<../install/#slim-install>) with the `groq` optional group:
[pip](https://ai.pydantic.dev/models/<#__tabbed_4_1>)[uv](https://ai.pydantic.dev/models/<#__tabbed_4_2>)
```
pipinstall'pydantic-ai-slim[groq]'

```

```
uvadd'pydantic-ai-slim[groq]'

```

### Configuration
To use [Groq](https://ai.pydantic.dev/models/<https:/groq.com/>) through their API, go to [console.groq.com/keys](https://ai.pydantic.dev/models/<https:/console.groq.com/keys>) and follow your nose until you find the place to generate an API key.
`GroqModelName`[](https://ai.pydantic.dev/models/<../api/models/groq/#pydantic_ai.models.groq.GroqModelName>) contains a list of available Groq models.
### Environment variable
Once you have the API key, you can set it as an environment variable:
```
exportGROQ_API_KEY='your-api-key'

```

You can then use `GroqModel`[](https://ai.pydantic.dev/models/<../api/models/groq/#pydantic_ai.models.groq.GroqModel>) by name:
groq_model_by_name.py```
from pydantic_ai import Agent
agent = Agent('groq:llama-3.3-70b-versatile')
...

```

Or initialise the model directly with just the model name:
groq_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.groq import GroqModel
model = GroqModel('llama-3.3-70b-versatile')
agent = Agent(model)
...

```

### `api_key` argument
If you don't want to or can't set the environment variable, you can pass it at runtime via the `api_key`[ argument](https://ai.pydantic.dev/models/<../api/models/groq/#pydantic_ai.models.groq.GroqModel.__init__>):
groq_model_api_key.py```
from pydantic_ai import Agent
from pydantic_ai.models.groq import GroqModel
model = GroqModel('llama-3.3-70b-versatile', api_key='your-api-key')
agent = Agent(model)
...

```

## Mistral
### Install
To use `MistralModel`[](https://ai.pydantic.dev/models/<../api/models/mistral/#pydantic_ai.models.mistral.MistralModel>), you need to either install `pydantic-ai`[](https://ai.pydantic.dev/models/<../install/>), or install `pydantic-ai-slim`[](https://ai.pydantic.dev/models/<../install/#slim-install>) with the `mistral` optional group:
[pip](https://ai.pydantic.dev/models/<#__tabbed_5_1>)[uv](https://ai.pydantic.dev/models/<#__tabbed_5_2>)
```
pipinstall'pydantic-ai-slim[mistral]'

```

```
uvadd'pydantic-ai-slim[mistral]'

```

### Configuration
To use [Mistral](https://ai.pydantic.dev/models/<https:/mistral.ai>) through their API, go to [console.mistral.ai/api-keys/](https://ai.pydantic.dev/models/<https:/console.mistral.ai/api-keys/>) and follow your nose until you find the place to generate an API key.
`NamedMistralModels`[](https://ai.pydantic.dev/models/<../api/models/mistral/#pydantic_ai.models.mistral.NamedMistralModels>) contains a list of the most popular Mistral models.
### Environment variable
Once you have the API key, you can set it as an environment variable:
```
exportMISTRAL_API_KEY='your-api-key'

```

You can then use `MistralModel`[](https://ai.pydantic.dev/models/<../api/models/mistral/#pydantic_ai.models.mistral.MistralModel>) by name:
mistral_model_by_name.py```
from pydantic_ai import Agent
agent = Agent('mistral:mistral-large-latest')
...

```

Or initialise the model directly with just the model name:
mistral_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.mistral import MistralModel
model = MistralModel('mistral-small-latest')
agent = Agent(model)
...

```

### `api_key` argument
If you don't want to or can't set the environment variable, you can pass it at runtime via the `api_key`[ argument](https://ai.pydantic.dev/models/<../api/models/mistral/#pydantic_ai.models.mistral.MistralModel.__init__>):
mistral_model_api_key.py```
from pydantic_ai import Agent
from pydantic_ai.models.mistral import MistralModel
model = MistralModel('mistral-small-latest', api_key='your-api-key')
agent = Agent(model)
...

```

## Cohere
### Install
To use `CohereModel`[](https://ai.pydantic.dev/models/<../api/models/cohere/#pydantic_ai.models.cohere.CohereModel>), you need to either install `pydantic-ai`[](https://ai.pydantic.dev/models/<../install/>), or install `pydantic-ai-slim`[](https://ai.pydantic.dev/models/<../install/#slim-install>) with the `cohere` optional group:
[pip](https://ai.pydantic.dev/models/<#__tabbed_6_1>)[uv](https://ai.pydantic.dev/models/<#__tabbed_6_2>)
```
pipinstall'pydantic-ai-slim[cohere]'

```

```
uvadd'pydantic-ai-slim[cohere]'

```

### Configuration
To use [Cohere](https://ai.pydantic.dev/models/<https:/cohere.com/>) through their API, go to [dashboard.cohere.com/api-keys](https://ai.pydantic.dev/models/<https:/dashboard.cohere.com/api-keys>) and follow your nose until you find the place to generate an API key.
`NamedCohereModels`[](https://ai.pydantic.dev/models/<../api/models/cohere/#pydantic_ai.models.cohere.NamedCohereModels>) contains a list of the most popular Cohere models.
### Environment variable
Once you have the API key, you can set it as an environment variable:
```
exportCO_API_KEY='your-api-key'

```

You can then use `CohereModel`[](https://ai.pydantic.dev/models/<../api/models/cohere/#pydantic_ai.models.cohere.CohereModel>) by name:
cohere_model_by_name.py```
from pydantic_ai import Agent
agent = Agent('cohere:command')
...

```

Or initialise the model directly with just the model name:
cohere_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.cohere import CohereModel
model = CohereModel('command', api_key='your-api-key')
agent = Agent(model)
...

```

### `api_key` argument
If you don't want to or can't set the environment variable, you can pass it at runtime via the `api_key`[ argument](https://ai.pydantic.dev/models/<../api/models/cohere/#pydantic_ai.models.cohere.CohereModel.__init__>):
cohere_model_api_key.py```
from pydantic_ai import Agent
from pydantic_ai.models.cohere import CohereModel
model = CohereModel('command', api_key='your-api-key')
agent = Agent(model)
...

```

## OpenAI-compatible Models
Many of the models are compatible with OpenAI API, and thus can be used with `OpenAIModel`[](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel>) in PydanticAI. Before getting started, check the [OpenAI](https://ai.pydantic.dev/models/<#openai>) section for installation and configuration instructions.
To use another OpenAI-compatible API, you can make use of the `base_url`[](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel.__init__>) and `api_key`[](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel.__init__>) arguments:
openai_model_base_url.py```
from pydantic_ai.models.openai import OpenAIModel
model = OpenAIModel(
  'model_name',
  base_url='https://<openai-compatible-api-endpoint>.com',
  api_key='your-api-key',
)
...

```

### Ollama
To use [Ollama](https://ai.pydantic.dev/models/<https:/ollama.com/>), you must first download the Ollama client, and then download a model using the [Ollama model library](https://ai.pydantic.dev/models/<https:/ollama.com/library>).
You must also ensure the Ollama server is running when trying to make requests to it. For more information, please see the [Ollama documentation](https://ai.pydantic.dev/models/<https:/github.com/ollama/ollama/tree/main/docs>).
#### Example local usage
With `ollama` installed, you can run the server with the model you want to use:
terminal-run-ollama```
ollamarunllama3.2

```

(this will pull the `llama3.2` model if you don't already have it downloaded) 
Then run your code, here's a minimal example:
ollama_example.py```
from pydantic import BaseModel
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel

class CityLocation(BaseModel):
  city: str
  country: str

ollama_model = OpenAIModel(model_name='llama3.2', base_url='http://localhost:11434/v1')
agent = Agent(ollama_model, result_type=CityLocation)
result = agent.run_sync('Where were the olympics held in 2012?')
print(result.data)
#> city='London' country='United Kingdom'
print(result.usage())
"""
Usage(requests=1, request_tokens=57, response_tokens=8, total_tokens=65, details=None)
"""

```

#### Example using a remote server
ollama_example_with_remote_server.py```
from pydantic import BaseModel
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
ollama_model = OpenAIModel(
  model_name='qwen2.5-coder:7b', 
The name of the model running on the remote server
[](https://ai.pydantic.dev/models/<#__code_43_annotation_1>)
  base_url='http://192.168.1.74:11434/v1', 
The url of the remote server
[](https://ai.pydantic.dev/models/<#__code_43_annotation_2>)
)

class CityLocation(BaseModel):
  city: str
  country: str

agent = Agent(model=ollama_model, result_type=CityLocation)
result = agent.run_sync('Where were the olympics held in 2012?')
print(result.data)
#> city='London' country='United Kingdom'
print(result.usage())
"""
Usage(requests=1, request_tokens=57, response_tokens=8, total_tokens=65, details=None)
"""

```

### OpenRouter
To use [OpenRouter](https://ai.pydantic.dev/models/<https:/openrouter.ai>), first create an API key at [openrouter.ai/keys](https://ai.pydantic.dev/models/<https:/openrouter.ai/keys>).
Once you have the API key, you can pass it to `OpenAIModel`[](https://ai.pydantic.dev/models/<../api/models/openai/#pydantic_ai.models.openai.OpenAIModel>) as the `api_key` argument:
openrouter_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
model = OpenAIModel(
  'anthropic/claude-3.5-sonnet',
  base_url='https://openrouter.ai/api/v1',
  api_key='your-openrouter-api-key',
)
agent = Agent(model)
...

```

### Grok (xAI)
Go to [xAI API Console](https://ai.pydantic.dev/models/<https:/console.x.ai/>) and create an API key. Once you have the API key, follow the [xAI API Documentation](https://ai.pydantic.dev/models/<https:/docs.x.ai/docs/overview>), and set the `base_url` and `api_key` arguments appropriately:
grok_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
model = OpenAIModel(
  'grok-2-1212',
  base_url='https://api.x.ai/v1',
  api_key='your-xai-api-key',
)
agent = Agent(model)
...

```

### DeepSeek
Go to [DeepSeek API Platform](https://ai.pydantic.dev/models/<https:/platform.deepseek.com/api_keys>) and create an API key. Once you have the API key, follow the [DeepSeek API Documentation](https://ai.pydantic.dev/models/<https:/platform.deepseek.com/docs/api/overview>), and set the `base_url` and `api_key` arguments appropriately:
deepseek_model_init.py```
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
model = OpenAIModel(
  'deepseek-chat',
  base_url='https://api.deepseek.com',
  api_key='your-deepseek-api-key',
)
agent = Agent(model)
...

```

## Implementing Custom Models
To implement support for models not already supported, you will need to subclass the `Model`[](https://ai.pydantic.dev/models/<../api/models/base/#pydantic_ai.models.Model>) abstract base class.
This in turn will require you to implement the following other abstract base classes:
  * `AgentModel`[](https://ai.pydantic.dev/models/<../api/models/base/#pydantic_ai.models.AgentModel>)
  * `StreamedResponse`[](https://ai.pydantic.dev/models/<../api/models/base/#pydantic_ai.models.StreamedResponse>)


The best place to start is to review the source code for existing implementations, e.g. `OpenAIModel`[](https://ai.pydantic.dev/models/<https:/github.com/pydantic/pydantic-ai/blob/main/pydantic_ai_slim/pydantic_ai/models/openai.py>).
For details on when we'll accept contributions adding new models to PydanticAI, see the [contributing guidelines](https://ai.pydantic.dev/models/<../contributing/#new-model-rules>).
Â© Pydantic Services Inc. 2024 to present 
